{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"/]+|(?!\\b)(?=[A-Z][a-z])|\\.(?!\\d)|&[lg]t;","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Vulcan Book","text":"<p>Vulcan is a complete stack for building data products.</p> <p>Tired of stitching together tools for testing, quality, semantics, and APIs? Ready to ship data products like software?</p>"},{"location":"#what-it-does","title":"What It Does","text":"<p>Vulcan gives you:</p> <ul> <li>CI/CD for data - Plan changes, test in virtual environments, deploy safely. See what breaks before you break it. Review impact, approve changes, roll back if needed. Just like software engineering, but for data.</li> <li>Unit testing - Test transformations locally without touching your warehouse. Fast feedback, no costs. Write tests that run in seconds, not hours. Catch bugs before they hit production.</li> <li>Data quality - Assertions that block bad data, checks that monitor quality. Quality as code, not an afterthought. Write validation rules alongside your models. Bad data gets stopped at the door.</li> <li>Semantic layer - Define metrics and dimensions. Vulcan generates schemas and APIs automatically. Business users get self-service analytics. Developers get automatic API generation. Everyone wins.</li> <li>Automatic APIs - REST, Python, and Graph APIs generated from your models. No manual API code needed. Query lineage with Cypher. Discover metrics programmatically. Access data however you need it.</li> <li>Lifecycle management - Dev, staging, prod environments with proper isolation. Ship with confidence. Test changes safely. Deploy when ready. No surprises.</li> </ul>"},{"location":"#the-complete-stack","title":"The Complete Stack","text":"<p>Everything you need to go from code to production-ready data products:</p> <p>Write SQL or Python transformations. Use what you know. No new languages to learn. Test locally with unit tests and assertions. Fast feedback. No warehouse costs. Validate with built-in quality checks. Block bad data. Monitor quality over time. Deploy with CI/CD workflows and virtual environments. Review changes. Test safely. Ship with confidence. Expose via semantic layer and automatic APIs. Define metrics once. Generate APIs automatically. Monitor and iterate. Track changes. Understand impact. Fix issues quickly.</p> <p>No tool sprawl. No manual stitching. Just write your transformations and let Vulcan handle the rest.</p>"},{"location":"#how-it-works-together","title":"How It Works Together","text":"<p>Vulcan isn't a collection of tools. It's a unified stack where everything works together:</p> <ol> <li>You write a transformation - SQL or Python, your choice</li> <li>Vulcan validates it - Syntax checks, type validation, dependency analysis</li> <li>You test it locally - Unit tests run in seconds, no warehouse needed</li> <li>You add assertions - Define what \"good data\" means, right in your model</li> <li>You plan the change - See what will break, review impact, approve when ready</li> <li>Vulcan deploys it - Virtual environments for testing, proper isolation for production</li> <li>Vulcan generates APIs - REST, Python, and Graph APIs from your semantic layer</li> <li>You monitor and iterate - Track changes, understand impact, fix issues quickly</li> </ol> <p>Each step builds on the last. No manual handoffs. No context switching. Just a smooth workflow from code to production.</p>"},{"location":"#why-vulcan","title":"Why Vulcan?","text":"<p>Most data teams spend more time on tooling than on building. You write SQL, then you write tests, then you write quality checks, then you write APIs, then you write documentation. It's exhausting.</p> <p>Vulcan does all of that automatically. You write transformations. Vulcan handles testing, quality, semantics, and APIs. It's that simple.</p>"},{"location":"#the-problem","title":"The Problem","text":"<p>Building data products shouldn't require a PhD in DevOps. But that's what it feels like:</p> <ul> <li>No CI/CD - Deploy changes blindly, hope nothing breaks, fix it in production</li> <li>No testing - Run transformations in production, wait hours for results, debug when things go wrong</li> <li>No quality gates - Bad data slips through, downstream systems break, trust erodes</li> <li>No semantic layer - Business users write SQL, metrics get redefined, nothing is consistent</li> <li>No APIs - Every consumer writes custom queries, performance suffers, maintenance nightmare</li> </ul> <p>Sound familiar? You're not alone.</p>"},{"location":"#the-solution","title":"The Solution","text":"<p>Vulcan fixes all of that. It's a complete stack that handles the entire data product lifecycle:</p> <p>Write your transformations in SQL or Python. That's it. Vulcan takes care of the rest.</p> <p>Test locally with unit tests. Get feedback in seconds. No warehouse costs. No waiting.</p> <p>Validate with assertions and checks. Bad data gets blocked. Quality issues get caught early.</p> <p>Deploy with CI/CD workflows. Review changes before deploying. Test in virtual environments. Roll back if needed.</p> <p>Expose via semantic layer and APIs. Define metrics once. Vulcan generates everything else automatically.</p> <p>Monitor and iterate. Track what changed. Understand impact. Fix issues quickly.</p> <p>No tool sprawl. No manual stitching. No PhD required.</p>"},{"location":"#quick-start","title":"Quick Start","text":"<ol> <li>Getting Started - Install and create your first project</li> <li>Models - Write SQL and Python transformations</li> <li>Semantic Layer - Define metrics and dimensions</li> <li>Audits - Block bad data with assertions</li> <li>Data Quality - Monitor data quality over time</li> <li>APIs - Access your data via REST, Python, and Graph APIs</li> </ol>"},{"location":"#how-its-different","title":"How It's Different","text":"<p>Vulcan isn't just another data tool. It's a complete rethink of how data products should be built:</p> <p>CI/CD First - Not an afterthought. Built into the workflow from day one. Plan, test, deploy, roll back. Just like software.</p> <p>Developer Experience First - Fast feedback. Local testing. Great tooling. You shouldn't have to fight your tools.</p> <p>Quality Built-In - Not a separate process. Write assertions alongside your models. Quality as code, not a checklist.</p> <p>Semantic Layer Native - Not bolted on. Define metrics and dimensions. Get APIs automatically. No manual schema management.</p> <p>Automatic Everything - APIs, schemas, documentation. You define the logic. Vulcan generates the rest.</p> <p>Complete Stack - Not a collection of tools. Everything works together. No integration hell. No tool sprawl.</p>"},{"location":"#learning-path","title":"Learning Path","text":"<p>Start with the basics, then build complexity:</p> <pre><code>Foundation (Chapters 1-2)\n    \u2193\nCore Features (Chapters 3-6)\n</code></pre> <p>Each chapter stands alone. Read what you need, when you need it.</p> <p>New to Vulcan? Start with Getting Started. You'll be productive in 30 minutes.</p> <p>Building models? Jump to Models. Everything you need to write transformations.</p> <p>Defining metrics? Check out Semantic Layer. Define business logic, get APIs automatically.</p> <p>Need quality? Read Audits and Data Quality. Block bad data, monitor quality.</p> <p>Ready to build data products the right way?</p> <p>Get Started \u2192</p>"},{"location":"apis/","title":"APIs","text":"<p>Complete API reference - REST, Python, and CLI interfaces for programmatic access to Vulcan.</p>"},{"location":"apis/#overview","title":"Overview","text":"<p>Vulcan provides multiple API interfaces:</p> <ul> <li>REST API - HTTP endpoints for web applications</li> <li>Python API - VulcanContext for programmatic access</li> <li>CLI - Command-line interface for operations</li> <li>Meta Graph - Cypher queries for lineage and relationships</li> </ul>"},{"location":"apis/#api-sections","title":"API Sections","text":"<ul> <li>Activity Tracking - Monitor runs and model activity</li> <li>Meta Graph - Query lineage and impact analysis</li> <li>Python API - VulcanContext reference</li> <li>REST API - HTTP endpoints documentation</li> <li>CLI Reference - Command-line commands</li> </ul> <p>Content coming soon...</p>"},{"location":"audits/","title":"Chapter 04: Audits","text":"<p>Audits are SQL queries that validate your model's data after execution - they act as automatic gatekeepers, ensuring only valid data flows downstream to dependent models and consumers.</p>"},{"location":"audits/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Introduction</li> <li>Quick Start</li> <li>Built-in Audits Reference</li> <li>Creating Custom Audits</li> <li>Inline Audits</li> <li>Advanced Audit Patterns</li> <li>Audit Execution and Lifecycle</li> <li>Troubleshooting and Debugging</li> <li>Best Practices</li> <li>Real-World Examples</li> <li>Quick Reference</li> <li>Summary and Next Steps</li> </ol>"},{"location":"audits/#1-introduction","title":"1. Introduction","text":""},{"location":"audits/#11-what-are-audits","title":"1.1 What are Audits?","text":"<p>Audits are SQL queries that run automatically after model execution to validate data quality. They search for invalid data, and if any is found, they halt the flow of data to prevent bad data from propagating downstream.</p>"},{"location":"audits/#111-terminology-audits-and-assertions","title":"1.1.1 Terminology: Audits and Assertions","text":"<p>Two related concepts: - AUDIT - The validation rule (the SQL query that checks for problems) - ASSERTION - Attaching an audit to a model (claiming it should pass)</p> <p>In MODEL definitions: <pre><code>-- Define the AUDIT (the rule)\nAUDIT (name check_positive_price);\nSELECT * FROM @this_model WHERE price &lt;= 0;\n\n-- Make ASSERTIONS about your model (attach the audit)\nMODEL (\n  name products,\n  assertions (check_positive_price)  -- Declaring this audit should pass\n);\n</code></pre></p> <p>Note: You may encounter older code that attaches audits using <code>audits</code> instead of <code>assertions</code> in MODEL definitions. While both work identically, please update to use <code>assertions</code> for clearer semantics. This chapter uses <code>assertions</code> throughout.</p>"},{"location":"audits/#112-how-audits-work","title":"1.1.2 How Audits Work","text":"<p>Core Principles:</p> <p>Audits are: - Automatic - Run after every model execution without manual intervention - Blocking - Always halt execution when they fail (no \"warning-only\" mode in Vulcan) - Scoped - For incremental models, validate only the newly processed intervals - SQL-based - Written as SQL queries that search for invalid data</p> <p>How audits work: 1. Model executes and generates/updates table 2. Audits run automatically against the result 3. Each audit query:    - Returns NO rows \u2192 Audit passes    - Returns ANY rows \u2192 Audit fails \u2192 Execution halts 4. If all audits pass \u2192 Data flows downstream 5. If any audit fails \u2192 Execution stops, bad data is contained</p>"},{"location":"audits/#113-why-use-audits","title":"1.1.3 Why Use Audits?","text":"<p>Audits provide immediate feedback during transformation:</p> Without Audits With Audits Bad data propagates silently Bad data is caught immediately Downstream models consume invalid data Downstream models never see invalid data Data quality issues discovered by users Data quality issues discovered by system Manual validation required Automatic validation built-in Root cause is hard to trace Failure points to exact model <p>Real-world impact: <pre><code>-- Without audit: $0 revenue records propagate to finance dashboard\n-- Finance team discovers it 2 days later, traces through 5 models\n\n-- With audit: Caught immediately at source\nMODEL (\n  name sales.orders,\n  assertions (\n    accepted_range(column := revenue, min_v := 0, max_v := 10000000)\n  )\n);\n-- Audit fails \u2192 Execution halts \u2192 Alert sent \u2192 Fixed within 30 minutes\n</code></pre></p>"},{"location":"audits/#12-audits-vs-quality-checks-vs-profiles","title":"1.2 Audits vs Quality Checks vs Profiles","text":"<p>Vulcan provides three complementary data quality mechanisms. Understanding when to use each is critical:</p>"},{"location":"audits/#comparison-table","title":"Comparison Table","text":"Feature Audits Quality Checks Profiles Purpose Validate &amp; block invalid data Monitor &amp; track quality over time Observe &amp; track statistical trends Definition SQL queries (inline or <code>audits/</code>) YAML configurations (<code>checks.yml</code>) Column list in model metadata Execution After model execution (automatic) Scheduled/triggered (flexible) After model execution (automatic) Behavior Always blocking Configurable (blocking or warning) Always non-blocking Output Pass/Fail \u2192 Halts on failure Pass/Fail + historical tracking Metrics stored in <code>_check_profiles</code> Scope Model-level (coupled to model) Project-level (centralized) Model-level (observability) Use Case Critical validations Comprehensive monitoring Baseline tracking, anomaly detection Example <code>not_null(columns := (id))</code> <code>row_count &gt; 1000</code> Track null % trend over 30 days"},{"location":"audits/#when-to-use-each","title":"When to Use Each","text":"<p>Use Audits When: - Data quality is critical - invalid data must not pass through - Validation must be tightly coupled to model transformation logic - You need immediate feedback during execution - The rule is a hard constraint (similar to database constraints) - Failure should halt the flow of data</p> <p>Examples: <pre><code>-- Primary key must be unique and not null\nassertions (\n  not_null(columns := (order_id)),\n  unique_values(columns := (order_id))\n)\n\n-- Revenue must be positive\nassertions (\n  forall(criteria := (revenue &gt;= 0))\n)\n\n-- Status must be in valid set\nassertions (\n  accepted_values(column := status, is_in := ('pending', 'completed', 'cancelled'))\n)\n</code></pre></p> <p>Use Quality Checks When: - Monitoring data quality trends over time - Need flexible scheduling independent of model runs - Want centralized configuration across all models - Require detailed reporting and alerting - Some checks should be warnings rather than blocking</p> <p>Examples (YAML): <pre><code># checks/orders.yml\nchecks:\n  sales.orders:\n    completeness:\n      - row_count &gt; 1000:\n          name: sufficient_daily_orders\n          attributes:\n            description: \"At least 1000 orders expected daily\"\n\n    validity:\n      - failed rows:\n          name: invalid_status_values\n          fail query: |\n            SELECT order_id, status\n            FROM sales.orders\n            WHERE status NOT IN ('pending', 'completed', 'cancelled')\n          samples limit: 10\n</code></pre></p> <p>Use Profiles When: - Tracking statistical trends (mean, stddev, null %, distinct count) - Understanding data distribution changes over time - Building baseline metrics for anomaly detection - Data observability without enforcing rules - Planning future audits based on observed patterns</p> <p>Examples: <pre><code>MODEL (\n  name sales.orders,\n  profiles (revenue, customer_id, order_date, discount)\n);\n\n-- Profiles automatically track:\n-- \u2022 Null count/percentage\n-- \u2022 Distinct value count\n-- \u2022 Min/max/mean/stddev (numeric columns)\n-- \u2022 Date ranges (date columns)\n</code></pre></p>"},{"location":"audits/#decision-flow","title":"Decision Flow","text":"<pre><code>Need data quality control?\n\u2502\n\u251c\u2500 Must BLOCK bad data?\n\u2502  \u2514\u2500 YES \u2192 Use AUDIT\n\u2502     \u251c\u2500 Reusable across models? \u2192 File-based audit in audits/\n\u2502     \u2514\u2500 Model-specific? \u2192 Inline audit in MODEL()\n\u2502\n\u251c\u2500 Need historical tracking?\n\u2502  \u2514\u2500 YES \u2192 Use QUALITY CHECK\n\u2502     \u251c\u2500 Should block? \u2192 Set blocking: true\n\u2502     \u2514\u2500 Just monitor? \u2192 Set blocking: false\n\u2502\n\u2514\u2500 Just observing patterns?\n   \u2514\u2500 YES \u2192 Use PROFILE\n      \u2514\u2500 View trends in _check_profiles table\n</code></pre>"},{"location":"audits/#13-audits-and-oltp-constraints-similar-but-different","title":"1.3 Audits and OLTP Constraints: Similar But Different","text":"<p>If you're familiar with relational databases, audits serve a similar purpose to table constraints (like <code>NOT NULL</code>, <code>CHECK</code>, <code>UNIQUE</code>, <code>FOREIGN KEY</code>) - but with a critical difference in where the blocking happens.</p>"},{"location":"audits/#the-key-difference-where-blocking-happens","title":"The Key Difference: WHERE Blocking Happens","text":"<p>OLTP Constraints: Block at INSERT/UPDATE</p> <p>In traditional OLTP databases, constraints are enforced at the row-insert level:</p> <pre><code>-- Traditional OLTP database\nCREATE TABLE customers (\n  customer_id INT PRIMARY KEY,\n  email VARCHAR(255) NOT NULL,\n  customer_tier VARCHAR(20) CHECK (customer_tier IN ('free', 'pro', 'enterprise')),\n  lifetime_value DECIMAL(10,2) CHECK (lifetime_value &gt;= 0)\n);\n\n-- What happens during INSERT:\nINSERT INTO customers VALUES (1, 'user@example.com', 'invalid_tier', 100);\n-- \u274c ERROR: Check constraint violation\n-- \u274c Transaction ABORTED\n-- \u274c Data never written to table\n</code></pre> <p>Key characteristics: - Blocking happens during the write operation - Individual bad rows are rejected immediately - Good rows can still be inserted (if constraints pass) - Bad data never enters the table</p> <p>Audits: Block Downstream Data Flow</p> <p>In Vulcan, audits are enforced after transformation completes:</p> <pre><code>-- Vulcan model\nMODEL (\n  name analytics.customers,\n  assertions (\n    not_null(columns := (customer_id, email)),\n    accepted_values(\n      column := customer_tier, \n      is_in := ('free', 'pro', 'enterprise')\n    ),\n    forall(criteria := (lifetime_value &gt;= 0))\n  )\n);\n\nSELECT\n  customer_id,\n  email,\n  customer_tier,\n  lifetime_value\nFROM raw.customers;\n\n-- What happens during execution:\n-- 1. Model executes \u2192 Table is written/updated\n-- 2. Audits run against the complete result\n-- 3. If audit finds violations:\n--    \u274c Execution halts\n--    \u274c Downstream models DO NOT run\n--    \u274c Bad data is CONTAINED in this model (doesn't propagate)\n-- 4. Note: The table itself contains the bad data, \n--    but it's isolated - downstream flow is blocked\n</code></pre> <p>Key characteristics: - Blocking happens after transformation completes - Entire result set is validated (batch-level) - Bad data may be written to the table, but is contained - Downstream models never see the bad data</p>"},{"location":"audits/#visualizing-the-difference","title":"Visualizing the Difference","text":"<p>OLTP Constraints: <pre><code>Source Data \u2192 INSERT \u2192 [Constraint Check] \u2192 \u274c REJECTED \u2192 Table unchanged\n                                          \u2192 \u2705 PASS \u2192 Data in table\n</code></pre></p> <p>Audits/Assertions: <pre><code>Source Data \u2192 Model Execution \u2192 Data written to table \u2192 [Audit Check] \n                                                       \u2192 \u274c FAIL \u2192 Stop here; Downstream blocked\n                                                       \u2192 \u2705 PASS \u2192 Flow downstream\n</code></pre></p>"},{"location":"audits/#why-this-difference-matters","title":"Why This Difference Matters","text":"<p>Scenario: Bad data appears in source system</p> <p>With OLTP Constraints: <pre><code>-- Bad rows are rejected at INSERT time\nINSERT INTO orders (order_id, amount) VALUES (1, -100);  -- \u274c Rejected\nINSERT INTO orders (order_id, amount) VALUES (2, 50);    -- \u2705 Accepted\n-- Result: Partial data load, some rows missing\n</code></pre></p> <p>With Audits: <pre><code>-- All data is transformed, then validated\nMODEL (name orders, assertions (forall(criteria := (amount &gt;= 0))));\nSELECT * FROM raw.orders;  -- Includes order_id=1 with amount=-100\n\n-- Result: \n-- \u2022 Entire batch is validated\n-- \u2022 If ANY row violates audit, ALL data is flagged\n-- \u2022 Downstream models are protected from seeing ANY of this batch\n-- \u2022 You fix the source, then reprocess the entire batch\n</code></pre></p> <p>CORRECT: Use audits when: - You're transforming batch data (not transactional inserts) - You want to validate entire result sets - You want to protect downstream consumers - You can reprocess data after fixing source issues</p> <p>INCORRECT: Don't expect audits to: - Reject individual rows and accept others - Prevent bad data from being written to the model's own table - Work like row-level INSERT constraints</p>"},{"location":"audits/#mapping-oltp-constraints-to-audits","title":"Mapping OLTP Constraints to Audits","text":"OLTP Constraint Audit Equivalent Purpose <code>NOT NULL</code> <code>not_null(columns := (col))</code> Ensure required fields exist <code>UNIQUE</code> <code>unique_values(columns := (col))</code> Prevent duplicate values <code>PRIMARY KEY</code> <code>not_null(...)</code> + <code>unique_values(...)</code> Enforce primary key integrity <code>CHECK (price &gt; 0)</code> <code>forall(criteria := (price &gt; 0))</code> Business rule validation <code>CHECK (status IN (...))</code> <code>accepted_values(column := status, is_in := (...))</code> Enum/domain validation <code>CHECK (start &lt; end)</code> <code>forall(criteria := (start_date &lt; end_date))</code> Multi-column validation <code>FOREIGN KEY</code> Custom audit with <code>LEFT JOIN</code> Referential integrity <p>Example: Complete constraint mapping</p> <p>OLTP Table: <pre><code>CREATE TABLE orders (\n  order_id INT PRIMARY KEY,\n  customer_id INT NOT NULL,\n  order_date DATE NOT NULL,\n  shipped_date DATE,\n  amount DECIMAL(10,2) NOT NULL CHECK (amount &gt;= 0),\n  status VARCHAR(20) CHECK (status IN ('pending', 'completed', 'cancelled')),\n  CHECK (shipped_date IS NULL OR shipped_date &gt;= order_date),\n  FOREIGN KEY (customer_id) REFERENCES customers(customer_id)\n);\n</code></pre></p> <p>Vulcan Model with Equivalent Audits: <pre><code>MODEL (\n  name analytics.orders,\n  grain order_id,\n  references (customer_id),\n  assertions (\n    -- PRIMARY KEY: NOT NULL + UNIQUE\n    not_null(columns := (order_id)),\n    unique_values(columns := (order_id)),\n\n    -- NOT NULL columns\n    not_null(columns := (customer_id, order_date, amount)),\n\n    -- CHECK (amount &gt;= 0)\n    forall(criteria := (amount &gt;= 0)),\n\n    -- CHECK (status IN (...))\n    accepted_values(\n      column := status,\n      is_in := ('pending', 'completed', 'cancelled')\n    ),\n\n    -- CHECK (shipped_date &gt;= order_date)\n    forall(criteria := (\n      shipped_date IS NULL OR shipped_date &gt;= order_date\n    ))\n\n    -- FOREIGN KEY - requires custom audit (see Section 6.1)\n  )\n);\n\nSELECT\n  order_id::INT,\n  customer_id::INT,\n  order_date::DATE,\n  shipped_date::DATE,\n  amount::DECIMAL(10,2),\n  status::VARCHAR\nFROM raw.orders;\n</code></pre></p>"},{"location":"audits/#audits-go-beyond-row-level-constraints","title":"Audits Go Beyond Row-Level Constraints","text":"<p>While OLTP constraints work at the row level, audits can validate much more:</p> <p>1. Aggregate Validations (impossible with row-level constraints) <pre><code>-- Ensure table has minimum number of rows\nassertions (\n  number_of_rows(threshold := 1000)\n)\n\n-- Ensure we have data for all expected dates\nAUDIT (name complete_date_range);\nSELECT expected_date\nFROM (\n  SELECT GENERATE_SERIES(\n    '2024-01-01'::DATE, \n    CURRENT_DATE, \n    '1 day'::INTERVAL\n  ) AS expected_date\n) expected\nLEFT JOIN @this_model actual ON expected.expected_date = actual.order_date\nWHERE actual.order_date IS NULL;\n</code></pre></p> <p>2. Statistical Validations <pre><code>-- Ensure revenue mean is within expected range\nassertions (\n  mean_in_range(column := revenue, min_v := 50, max_v := 500)\n)\n\n-- Detect outliers\nassertions (\n  z_score(column := transaction_amount, threshold := 3)\n)\n\n-- Ensure distributions are similar\nassertions (\n  kl_divergence(\n    column := current_month_revenue,\n    target_column := last_month_revenue,\n    threshold := 0.1\n  )\n)\n</code></pre></p> <p>3. Cross-Table Referential Integrity (more flexible than FK constraints) <pre><code>-- Validate foreign key relationship\nAUDIT (name valid_customer_reference);\nSELECT o.* \nFROM @this_model o\nLEFT JOIN dim.customers c ON o.customer_id = c.customer_id\nWHERE o.customer_id IS NOT NULL  -- Exclude nulls (separate audit)\n  AND c.customer_id IS NULL;      -- Customer doesn't exist\n\n-- Validate multi-column foreign key\nAUDIT (name valid_product_location_reference);\nSELECT ol.*\nFROM @this_model ol\nLEFT JOIN dim.product_locations pl \n  ON ol.product_id = pl.product_id \n  AND ol.warehouse_id = pl.warehouse_id\nWHERE pl.product_id IS NULL;\n</code></pre></p> <p>4. Complex Business Logic <pre><code>-- Validate discount rules\nassertions (\n  forall(criteria := (\n    -- Discount amount can't exceed order amount\n    discount_amount &lt;= order_amount,\n    -- Discount percentage can't exceed 100%\n    discount_percent &lt;= 1.0,\n    -- Can't have both dollar discount AND percentage discount\n    (discount_amount = 0) OR (discount_percent = 0),\n    -- Premium customers get discounts, others don't\n    (customer_tier = 'premium') OR (discount_amount = 0 AND discount_percent = 0)\n  ))\n)\n</code></pre></p> <p>5. Time-Series Consistency <pre><code>-- Ensure no gaps in time series data\nAUDIT (name no_gaps_in_daily_data);\nWITH expected_dates AS (\n  SELECT DATE_TRUNC('day', GENERATE_SERIES(\n    (SELECT MIN(order_date) FROM @this_model),\n    (SELECT MAX(order_date) FROM @this_model),\n    '1 day'::INTERVAL\n  )) AS expected_date\n)\nSELECT ed.expected_date\nFROM expected_dates ed\nLEFT JOIN (\n  SELECT DISTINCT DATE_TRUNC('day', order_date) AS order_date\n  FROM @this_model\n) actual ON ed.expected_date = actual.order_date\nWHERE actual.order_date IS NULL;\n\n-- Ensure monotonic increase\nAUDIT (name cumulative_revenue_increases);\nSELECT \n  t1.date,\n  t1.cumulative_revenue,\n  t2.cumulative_revenue AS previous_cumulative_revenue\nFROM @this_model t1\nJOIN @this_model t2 \n  ON t2.date = t1.date - INTERVAL '1 day'\nWHERE t1.cumulative_revenue &lt; t2.cumulative_revenue;\n</code></pre></p> <p>Summary: Constraints vs Audits</p> Capability OLTP Constraints Audits Row-level validation Yes Yes Aggregate validation No Yes Statistical validation No Yes Cross-table validation Limited (FK only) Full SQL flexibility Complex business logic Limited Full SQL flexibility Time-series validation No Yes Blocking location At INSERT/UPDATE After transformation, before downstream Granularity Individual rows Entire batch"},{"location":"audits/#14-when-to-use-audits","title":"1.4 When to Use Audits","text":""},{"location":"audits/#audit-coverage-strategy","title":"Audit Coverage Strategy","text":"<p>Layer your audits by criticality and impact:</p> <p>CRITICAL (Always Audit)</p> <p>These validations are non-negotiable - failure indicates severe data corruption:</p> Validation Type Why Critical Audit Primary Key Integrity Breaks joins, violates uniqueness <code>not_null</code> + <code>unique_values</code> Foreign Key Integrity Orphaned records, broken relationships Custom JOIN audit Non-negative Amounts Business logic violation <code>forall(criteria := (amount &gt;= 0))</code> Required Fields Downstream models expect them <code>not_null(columns := (...))</code> Date Ordering Illogical sequences <code>forall(criteria := (start &lt;= end))</code> <p>Example: Orders table (critical audits only) <pre><code>MODEL (\n  name sales.orders,\n  grain order_id,\n  references (customer_id),\n  assertions (\n    -- Critical validations only\n    not_null(columns := (order_id, customer_id, order_date, amount)),\n    unique_values(columns := (order_id)),\n    forall(criteria := (amount &gt;= 0))\n  )\n);\n</code></pre></p> <p>IMPORTANT (Audit Frequently)</p> <p>Should catch these, but rare edge cases may exist:</p> Validation Type Why Important Audit Enum Validation Protects downstream case statements <code>accepted_values</code> Range Validation Business constraints <code>accepted_range</code> Format Validation Ensures parsability <code>valid_email</code>, <code>valid_url</code> Calculated Field Logic Derived values must be consistent Custom audit Row Count Thresholds Catches upstream failures <code>number_of_rows</code> <p>Example: Adding important audits <pre><code>MODEL (\n  name sales.orders,\n  assertions (\n    -- Critical (from above)\n    not_null(columns := (order_id, customer_id, order_date, amount)),\n    unique_values(columns := (order_id)),\n    forall(criteria := (amount &gt;= 0)),\n\n    -- Important (added)\n    accepted_values(\n      column := status, \n      is_in := ('pending', 'completed', 'cancelled', 'refunded')\n    ),\n    accepted_range(column := amount, min_v := 0, max_v := 1000000),\n    number_of_rows(threshold := 100)  -- Expect at least 100 orders\n  )\n);\n</code></pre></p> <p>NICE-TO-HAVE (Audit Selectively)</p> <p>These improve data quality but don't justify blocking:</p> Validation Type Consideration Audit or Profile? String Length Rarely breaks downstream Profile first, audit if issues found Statistical Bounds Natural variation exists Profile first, audit for outliers Format Patterns Best-effort validation Audit if format is critical Data Consistency Soft business rules Check (warning) first, audit if critical <p>Recommendation: Start with profiles to understand patterns, then promote to audits if you find recurring issues.</p>"},{"location":"audits/#anti-patterns-when-not-to-use-audits","title":"Anti-Patterns: When NOT to Use Audits","text":"<p>INCORRECT: Don't audit just because you can <pre><code>-- TOO MANY AUDITS (over-engineering)\nMODEL (\n  name sales.orders,\n  assertions (\n    not_null(columns := (order_id, customer_id)),           -- CORRECT\n    unique_values(columns := (order_id)),                    -- CORRECT\n    string_length_equal(column := order_id, v := 36),        -- Overkill\n    valid_uuid(column := order_id),                           -- Overkill\n    not_constant(column := order_id),                         -- Redundant\n    at_least_one(column := order_id),                         -- Redundant\n    z_score(column := order_id, threshold := 3),              -- Nonsensical\n    mean_in_range(column := order_id, min_v := 1000, max_v := 9999)  -- Nonsensical\n  )\n);\n</code></pre></p> <p>INCORRECT: Don't use audits for exploratory validation <pre><code>-- INCORRECT: Blocking on unknown thresholds\nassertions (\n  accepted_range(column := session_duration, min_v := 0, max_v := 3600)\n)\n\n-- CORRECT: Use profiles to understand distribution first\nprofiles (session_duration)\n-- After seeing the distribution, add audit with appropriate threshold\n</code></pre></p> <p>INCORRECT: Don't use audits when the business rule is unclear <pre><code>-- INCORRECT: What if legitimate orders exceed $1M?\nassertions (\n  accepted_range(column := amount, min_v := 0, max_v := 1000000)\n)\n\n-- CORRECT: Clarify business rules first, or use profiles\n-- Option 1: Clarify with stakeholders\nassertions (\n  accepted_range(column := amount, min_v := 0, max_v := 10000000)  -- Confirmed max\n)\n\n-- Option 2: Profile and monitor instead\nprofiles (amount)\n</code></pre></p>"},{"location":"audits/#15-audit-execution-lifecycle","title":"1.5 Audit Execution Lifecycle","text":""},{"location":"audits/#when-audits-run","title":"When Audits Run","text":"<p>Audits execute automatically in this sequence:</p> <p>1. Model Execution <pre><code>Model SQL executes \u2192 Data written to table\n</code></pre></p> <p>2. Audit Execution (Automatic) <pre><code>For each audit defined in MODEL():\n  \u2192 Run audit SQL query\n  \u2192 Check if any rows returned\n  \u2192 If rows returned: FAIL\n  \u2192 If no rows returned: PASS\n</code></pre></p> <p>3. Result Handling <pre><code>All audits pass \u2192 Continue to next model in execution graph\nAny audit fails \u2192 Halt execution, log failure, send alerts\n</code></pre></p>"},{"location":"audits/#incremental-models-audit-scope","title":"Incremental Models: Audit Scope","text":"<p>For incremental models, audits only validate newly processed intervals:</p> <pre><code>MODEL (\n  name sales.daily_revenue,\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column order_date\n  ),\n  assertions (\n    not_null(columns := (order_date, revenue))\n  )\n);\n\n-- If processing 2024-01-15:\n-- Audit runs: SELECT * FROM daily_revenue \n--             WHERE order_date = '2024-01-15' \n--             AND revenue IS NULL\n--\n-- Historical data (2024-01-01 to 2024-01-14) is NOT re-audited\n</code></pre> <p>Why? Efficiency. Re-auditing the entire table on every run would be expensive and unnecessary.</p> <p>Special macro: <code>@this_model</code> automatically handles interval filtering for incremental models.</p>"},{"location":"audits/#full-refresh-models-audit-scope","title":"Full Refresh Models: Audit Scope","text":"<p>For full refresh models, audits validate the entire table:</p> <pre><code>MODEL (\n  name dim.customers,\n  kind FULL,\n  assertions (\n    unique_values(columns := (customer_id))\n  )\n);\n\n-- Every execution: SELECT customer_id, COUNT(*) \n--                  FROM dim.customers \n--                  GROUP BY customer_id \n--                  HAVING COUNT(*) &gt; 1\n</code></pre>"},{"location":"audits/#16-audit-philosophy-query-for-bad-data","title":"1.6 Audit Philosophy: Query for Bad Data","text":""},{"location":"audits/#the-inverted-logic-pattern","title":"The Inverted Logic Pattern","text":"<p>Audits use inverted logic - they query for violations, not compliance:</p> <p>CORRECT: Find Bad Data <pre><code>-- Audit succeeds if NO rows are returned\nAUDIT (name assert_positive_revenue);\nSELECT * FROM @this_model \nWHERE revenue &lt;= 0;  -- Find violations\n\n-- Returns 0 rows \u2192 All revenue is positive \u2192 Audit passes\n-- Returns N rows \u2192 Found negative revenue \u2192 Audit fails\n</code></pre></p> <p>INCORRECT: Find Good Data <pre><code>-- DON'T DO THIS - Logic is backwards!\nAUDIT (name assert_positive_revenue);\nSELECT * FROM @this_model \nWHERE revenue &gt; 0;  -- Find compliant rows\n\n-- Returns N rows \u2192 Audit fails (found data!)\n-- This is backwards - you want to find PROBLEMS, not successes\n</code></pre></p>"},{"location":"audits/#why-this-pattern","title":"Why This Pattern?","text":"<p>This pattern aligns with how constraints work:</p> System Pattern SQL Constraints Define what's NOT allowed: <code>CHECK (price &gt; 0)</code> Unit Tests Assert what should NOT happen: <code>assert x != null</code> Audits Query for what should NOT exist: <code>SELECT ... WHERE bad_condition</code>"},{"location":"audits/#common-audit-patterns","title":"Common Audit Patterns","text":"<p>Pattern 1: Null Check <pre><code>-- CORRECT: Find rows with nulls\nSELECT * FROM @this_model WHERE customer_id IS NULL;\n</code></pre></p> <p>Pattern 2: Range Validation <pre><code>-- CORRECT: Find rows outside valid range\nSELECT * FROM @this_model WHERE age &lt; 0 OR age &gt; 120;\n</code></pre></p> <p>Pattern 3: Enum Validation <pre><code>-- CORRECT: Find rows with invalid status\nSELECT * FROM @this_model \nWHERE status NOT IN ('pending', 'completed', 'cancelled');\n</code></pre></p> <p>Pattern 4: Uniqueness <pre><code>-- CORRECT: Find duplicate keys\nSELECT order_id, COUNT(*) as duplicate_count\nFROM @this_model\nGROUP BY order_id\nHAVING COUNT(*) &gt; 1;\n</code></pre></p> <p>Pattern 5: Referential Integrity <pre><code>-- CORRECT: Find orphaned records (customer_id doesn't exist)\nSELECT o.*\nFROM @this_model o\nLEFT JOIN dim.customers c ON o.customer_id = c.customer_id\nWHERE o.customer_id IS NOT NULL  -- Exclude nulls (separate audit)\n  AND c.customer_id IS NULL;      -- Customer doesn't exist\n</code></pre></p> <p>\u2191 Back to Top</p>"},{"location":"audits/#2-quick-start","title":"2. Quick Start","text":""},{"location":"audits/#21-your-first-audit","title":"2.1 Your First Audit","text":"<p>Let's start with the most common use case: ensuring required fields have no NULL values.</p> <p>Model without audit: <pre><code>MODEL (\n  name sales.orders,\n  grain order_id\n);\n\nSELECT\n  order_id,\n  customer_id,\n  order_date,\n  amount\nFROM raw.orders;\n</code></pre></p> <p>Add your first audit: <pre><code>MODEL (\n  name sales.orders,\n  grain order_id,\n  assertions (\n    not_null(columns := (order_id, customer_id, order_date, amount))\n  )\n);\n\nSELECT\n  order_id,\n  customer_id,\n  order_date,\n  amount\nFROM raw.orders;\n</code></pre></p> <p>What happens: 1. Model executes and populates <code>sales.orders</code> table 2. Audit runs automatically: <code>SELECT * FROM sales.orders WHERE order_id IS NULL OR customer_id IS NULL OR order_date IS NULL OR amount IS NULL</code> 3. If query returns 0 rows \u2192 Audit passes \u2192 Downstream models can run 4. If query returns any rows \u2192 Audit fails \u2192 Execution halts</p> <p>Example failure output: <pre><code>Failure in audit 'not_null' for model 'sales.orders'.\nGot 3 results, expected 0.\nQuery: SELECT * FROM sales.orders WHERE ... IS NULL\n</code></pre></p>"},{"location":"audits/#22-common-patterns-5-most-used-audits","title":"2.2 Common Patterns (5 Most-Used Audits)","text":"<p>Here are the five audits you'll use most frequently:</p>"},{"location":"audits/#1-not-null-required-fields","title":"1. Not Null - Required Fields","text":"<pre><code>MODEL (\n  name sales.orders,\n  assertions (\n    not_null(columns := (order_id, customer_id, order_date))\n  )\n);\n</code></pre> <p>Use when: Fields are required for downstream processing.</p>"},{"location":"audits/#2-unique-values-primary-keys","title":"2. Unique Values - Primary Keys","text":"<pre><code>MODEL (\n  name dim.customers,\n  grain customer_id,\n  assertions (\n    unique_values(columns := (customer_id))\n  )\n);\n</code></pre> <p>Use when: Column must be unique (typically primary keys).</p>"},{"location":"audits/#3-accepted-values-enum-validation","title":"3. Accepted Values - Enum Validation","text":"<pre><code>MODEL (\n  name sales.orders,\n  assertions (\n    accepted_values(\n      column := status,\n      is_in := ('pending', 'completed', 'cancelled', 'refunded')\n    )\n  )\n);\n</code></pre> <p>Use when: Column has a fixed set of valid values.</p>"},{"location":"audits/#4-accepted-range-numeric-bounds","title":"4. Accepted Range - Numeric Bounds","text":"<pre><code>MODEL (\n  name sales.orders,\n  assertions (\n    accepted_range(column := amount, min_v := 0, max_v := 10000000)\n  )\n);\n</code></pre> <p>Use when: Numeric columns must fall within business-defined bounds.</p>"},{"location":"audits/#5-forall-custom-business-logic","title":"5. Forall - Custom Business Logic","text":"<pre><code>MODEL (\n  name sales.orders,\n  assertions (\n    forall(criteria := (\n      amount &gt;= 0,\n      order_date &lt;= CURRENT_DATE,\n      shipped_date IS NULL OR shipped_date &gt;= order_date\n    ))\n  )\n);\n</code></pre> <p>Use when: You need custom SQL logic that built-in audits don't cover.</p>"},{"location":"audits/#23-multiple-audits-on-one-model","title":"2.3 Multiple Audits on One Model","text":"<p>You can (and should) apply multiple audits to the same model:</p> <pre><code>MODEL (\n  name sales.orders,\n  grain order_id,\n  references (customer_id),\n  assertions (\n    -- Completeness: Required fields\n    not_null(columns := (order_id, customer_id, order_date, amount)),\n\n    -- Uniqueness: Primary key\n    unique_values(columns := (order_id)),\n\n    -- Validity: Status enum\n    accepted_values(\n      column := status,\n      is_in := ('pending', 'completed', 'cancelled', 'refunded')\n    ),\n\n    -- Validity: Amount range\n    accepted_range(column := amount, min_v := 0, max_v := 10000000),\n\n    -- Business logic: Date ordering\n    forall(criteria := (\n      shipped_date IS NULL OR shipped_date &gt;= order_date\n    )),\n\n    -- Data quality: Minimum row count\n    number_of_rows(threshold := 100)\n  )\n);\n\nSELECT\n  order_id,\n  customer_id,\n  order_date,\n  shipped_date,\n  amount,\n  status\nFROM raw.orders;\n</code></pre> <p>Execution order: - Audits run in the order they're defined - If any audit fails, execution halts immediately - Subsequent audits don't run after a failure</p> <p>TIP: Order audits from fastest to slowest (cheap checks first, expensive checks last).</p> <p>\u2191 Back to Top</p>"},{"location":"audits/#3-built-in-audits-reference","title":"3. Built-in Audits Reference","text":"<p>Vulcan provides 29 built-in audits covering common validation scenarios. All audits are blocking by default (and only blocking in Vulcan - there is no non-blocking mode).</p>"},{"location":"audits/#audit-categories","title":"Audit Categories","text":"<ul> <li>3.1 Data Completeness Audits - NULL values, row counts</li> <li>3.2 Data Uniqueness Audits - Duplicates, distinct values</li> <li>3.3 Data Validity Audits - Enums, ranges, sequences</li> <li>3.4 String Validation Audits - Length, format, patterns</li> <li>3.5 Pattern Matching Audits - Regex, LIKE patterns</li> <li>3.6 Statistical Audits - Mean, stddev, outliers</li> <li>3.7 Generic Assertion Audit - Custom boolean logic</li> </ul>"},{"location":"audits/#31-data-completeness-audits","title":"3.1 Data Completeness Audits","text":"<p>These audits validate that required data is present.</p>"},{"location":"audits/#not_null","title":"<code>not_null</code>","text":"<p>Ensures specified columns contain no NULL values.</p> <p>Parameters: - <code>columns</code> - List of column names to check (required)</p> <p>Example: <pre><code>MODEL (\n  name sales.orders,\n  assertions (\n    not_null(columns := (order_id, customer_id, order_date, amount))\n  )\n);\n</code></pre></p> <p>Equivalent SQL: <pre><code>SELECT * FROM sales.orders\nWHERE order_id IS NULL\n   OR customer_id IS NULL\n   OR order_date IS NULL\n   OR amount IS NULL;\n</code></pre></p> <p>Use when: - Columns are required for downstream processing - Missing values would break joins or calculations - Implementing NOT NULL constraint equivalent</p> <p>TIP: Group related required fields together for clarity.</p>"},{"location":"audits/#at_least_one","title":"<code>at_least_one</code>","text":"<p>Ensures a column contains at least one non-NULL value.</p> <p>Parameters: - <code>column</code> - Column name to check (required)</p> <p>Example: <pre><code>MODEL (\n  name dim.customers,\n  assertions (\n    at_least_one(column := email)\n  )\n);\n</code></pre></p> <p>Equivalent SQL: <pre><code>SELECT CASE \n  WHEN COUNT(*) = 0 THEN 'No rows in table'\n  WHEN COUNT(email) = 0 THEN 'All emails are NULL'\nEND AS violation\nFROM dim.customers\nHAVING COUNT(email) = 0;\n</code></pre></p> <p>Use when: - Optional column should have at least some data - Detecting complete data loss in a column - Ensuring a table isn't completely empty</p> <p>WARNING: This audit fails if the table is empty OR if all values are NULL.</p>"},{"location":"audits/#not_null_proportion","title":"<code>not_null_proportion</code>","text":"<p>Ensures the proportion of NULL values doesn't exceed a threshold.</p> <p>Parameters: - <code>column</code> - Column name to check (required) - <code>threshold</code> - Maximum proportion of NULLs allowed, as decimal 0-1 (required)</p> <p>Example: <pre><code>MODEL (\n  name dim.customers,\n  assertions (\n    not_null_proportion(column := zip_code, threshold := 0.2)  -- Max 20% NULLs\n  )\n);\n</code></pre></p> <p>Equivalent SQL: <pre><code>SELECT \n  COUNT(*) AS total_rows,\n  COUNT(zip_code) AS non_null_count,\n  (COUNT(*) - COUNT(zip_code)) / COUNT(*)::FLOAT AS null_proportion\nFROM dim.customers\nHAVING (COUNT(*) - COUNT(zip_code)) / COUNT(*)::FLOAT &gt; 0.2;\n</code></pre></p> <p>Use when: - Column is optional but should be mostly populated - Monitoring data quality degradation over time - Soft requirement (not completely required, but expected)</p> <p>Example thresholds: - <code>threshold := 0.1</code> - Max 10% NULLs (mostly required) - <code>threshold := 0.5</code> - Max 50% NULLs (nice to have) - <code>threshold := 0.9</code> - Max 90% NULLs (rarely populated)</p>"},{"location":"audits/#number_of_rows","title":"<code>number_of_rows</code>","text":"<p>Ensures the table contains at least a minimum number of rows.</p> <p>Parameters: - <code>threshold</code> - Minimum number of rows required (required)</p> <p>Example: <pre><code>MODEL (\n  name sales.daily_orders,\n  assertions (\n    number_of_rows(threshold := 100)  -- Expect at least 100 orders\n  )\n);\n</code></pre></p> <p>Equivalent SQL: <pre><code>SELECT COUNT(*) AS row_count\nFROM sales.daily_orders\nHAVING COUNT(*) &lt; 100;\n</code></pre></p> <p>Use when: - Detecting upstream data source failures - Ensuring minimum data volume for analytics - Catching incomplete data loads</p> <p>TIP: Set threshold based on historical patterns. If you typically have 10,000 rows, a threshold of 1,000 catches major issues without false positives.</p>"},{"location":"audits/#32-data-uniqueness-audits","title":"3.2 Data Uniqueness Audits","text":"<p>These audits validate that values or combinations are unique.</p>"},{"location":"audits/#unique_values","title":"<code>unique_values</code>","text":"<p>Ensures specified columns contain no duplicate values.</p> <p>Parameters: - <code>columns</code> - List of column names to check for uniqueness (required)</p> <p>Example: <pre><code>MODEL (\n  name dim.customers,\n  grain customer_id,\n  assertions (\n    unique_values(columns := (customer_id))\n  )\n);\n</code></pre></p> <p>Equivalent SQL: <pre><code>SELECT customer_id, COUNT(*) AS duplicate_count\nFROM dim.customers\nGROUP BY customer_id\nHAVING COUNT(*) &gt; 1;\n</code></pre></p> <p>Multiple columns (each must be individually unique): <pre><code>assertions (\n  unique_values(columns := (customer_id, email))\n)\n-- Both customer_id must be unique AND email must be unique\n</code></pre></p> <p>Use when: - Enforcing primary key uniqueness - Ensuring no duplicate records - Validating unique constraint equivalent</p> <p>WARNING: <code>unique_values(columns := (col1, col2))</code> checks that BOTH are unique individually, NOT that the combination is unique. For combination uniqueness, use <code>unique_combination_of_columns</code>.</p>"},{"location":"audits/#unique_combination_of_columns","title":"<code>unique_combination_of_columns</code>","text":"<p>Ensures each row has a unique combination of values across specified columns.</p> <p>Parameters: - <code>columns</code> - List of column names that form composite key (required)</p> <p>Example: <pre><code>MODEL (\n  name sales.daily_customer_revenue,\n  grains (customer_id, order_date),\n  assertions (\n    unique_combination_of_columns(columns := (customer_id, order_date))\n  )\n);\n</code></pre></p> <p>Equivalent SQL: <pre><code>SELECT customer_id, order_date, COUNT(*) AS duplicate_count\nFROM sales.daily_customer_revenue\nGROUP BY customer_id, order_date\nHAVING COUNT(*) &gt; 1;\n</code></pre></p> <p>Use when: - Composite primary keys (multi-column grain) - Ensuring no duplicate rows for customer + date - Fact tables with compound keys</p> <p>Example use cases: - <code>(user_id, date)</code> - One row per user per day - <code>(order_id, line_item)</code> - One row per line item - <code>(product_id, warehouse_id)</code> - One row per product-warehouse combination</p>"},{"location":"audits/#not_constant","title":"<code>not_constant</code>","text":"<p>Ensures a column has at least two distinct non-NULL values.</p> <p>Parameters: - <code>column</code> - Column name to check (required)</p> <p>Example: <pre><code>MODEL (\n  name sales.customer_segmentation,\n  assertions (\n    not_constant(column := customer_segment)\n  )\n);\n</code></pre></p> <p>Equivalent SQL: <pre><code>SELECT COUNT(DISTINCT customer_segment) AS distinct_count\nFROM sales.customer_segmentation\nWHERE customer_segment IS NOT NULL\nHAVING COUNT(DISTINCT customer_segment) &lt; 2;\n</code></pre></p> <p>Use when: - Ensuring variation in a column (not all same value) - Catching upstream filter mistakes (e.g., WHERE country = 'US' applied incorrectly) - Validating segmentation columns have multiple segments</p> <p>WARNING: This audit ignores NULL values. A column with all NULLs will fail <code>at_least_one</code>, not <code>not_constant</code>.</p>"},{"location":"audits/#33-data-validity-audits","title":"3.3 Data Validity Audits","text":"<p>These audits validate that values fall within expected sets or ranges.</p>"},{"location":"audits/#accepted_values","title":"<code>accepted_values</code>","text":"<p>Ensures all values in a column are in an allowed list.</p> <p>Parameters: - <code>column</code> - Column name to check (required) - <code>is_in</code> - List of accepted values (required)</p> <p>Example: <pre><code>MODEL (\n  name sales.orders,\n  assertions (\n    accepted_values(\n      column := status,\n      is_in := ('pending', 'completed', 'cancelled', 'refunded')\n    )\n  )\n);\n</code></pre></p> <p>Equivalent SQL: <pre><code>SELECT * FROM sales.orders\nWHERE status NOT IN ('pending', 'completed', 'cancelled', 'refunded');\n</code></pre></p> <p>Use when: - Enum columns (status, type, category) - Fixed set of valid values - Protecting downstream CASE statements</p> <p>NOTE: NULL values pass this audit. If you want to ensure no NULLs, add a separate <code>not_null</code> audit.</p>"},{"location":"audits/#not_accepted_values","title":"<code>not_accepted_values</code>","text":"<p>Ensures no values in a column are in a rejected list.</p> <p>Parameters: - <code>column</code> - Column name to check (required) - <code>is_in</code> - List of rejected values (required)</p> <p>Example: <pre><code>MODEL (\n  name dim.products,\n  assertions (\n    not_accepted_values(\n      column := product_name,\n      is_in := ('test', 'dummy', 'placeholder')\n    )\n  )\n);\n</code></pre></p> <p>Equivalent SQL: <pre><code>SELECT * FROM dim.products\nWHERE product_name IN ('test', 'dummy', 'placeholder');\n</code></pre></p> <p>Use when: - Ensuring test data doesn't reach production - Blocking known invalid values - Catching placeholder values</p> <p>NOTE: This audit does not reject NULL values. Use <code>not_null</code> for that.</p>"},{"location":"audits/#accepted_range","title":"<code>accepted_range</code>","text":"<p>Ensures numeric values fall within a specified range.</p> <p>Parameters: - <code>column</code> - Column name to check (required) - <code>min_v</code> - Minimum value (required) - <code>max_v</code> - Maximum value (required) - <code>inclusive</code> - Whether range boundaries are included (optional, default: true)</p> <p>Example (inclusive): <pre><code>MODEL (\n  name sales.orders,\n  assertions (\n    accepted_range(column := amount, min_v := 0, max_v := 1000000)\n    -- Allows amount &gt;= 0 AND amount &lt;= 1000000\n  )\n);\n</code></pre></p> <p>Example (exclusive): <pre><code>MODEL (\n  name analytics.metrics,\n  assertions (\n    accepted_range(column := percentage, min_v := 0, max_v := 1, inclusive := false)\n    -- Allows percentage &gt; 0 AND percentage &lt; 1 (excludes 0 and 1)\n  )\n);\n</code></pre></p> <p>Equivalent SQL (inclusive): <pre><code>SELECT * FROM sales.orders\nWHERE amount &lt; 0 OR amount &gt; 1000000;\n</code></pre></p> <p>Equivalent SQL (exclusive): <pre><code>SELECT * FROM analytics.metrics\nWHERE percentage &lt;= 0 OR percentage &gt;= 1;\n</code></pre></p> <p>Use when: - Enforcing business rules (revenue &gt; 0, age between 0-120) - Catching outliers or data entry errors - Implementing CHECK constraint equivalent</p>"},{"location":"audits/#mutually_exclusive_ranges","title":"<code>mutually_exclusive_ranges</code>","text":"<p>Ensures numeric ranges in different rows don't overlap.</p> <p>Parameters: - <code>lower_bound_column</code> - Column containing range start (required) - <code>upper_bound_column</code> - Column containing range end (required)</p> <p>Example: <pre><code>MODEL (\n  name pricing.tier_ranges,\n  assertions (\n    mutually_exclusive_ranges(\n      lower_bound_column := min_revenue,\n      upper_bound_column := max_revenue\n    )\n  )\n);\n</code></pre></p> <p>Equivalent SQL: <pre><code>SELECT \n  t1.tier_name AS tier1,\n  t2.tier_name AS tier2,\n  t1.min_revenue AS t1_min,\n  t1.max_revenue AS t1_max,\n  t2.min_revenue AS t2_min,\n  t2.max_revenue AS t2_max\nFROM pricing.tier_ranges t1\nJOIN pricing.tier_ranges t2 ON t1.tier_id &lt; t2.tier_id\nWHERE t1.min_revenue &lt;= t2.max_revenue \n  AND t1.max_revenue &gt;= t2.min_revenue;\n</code></pre></p> <p>Use when: - Pricing tiers with revenue ranges - Date ranges that shouldn't overlap - Territory assignments (zip code ranges)</p> <p>Example data: <pre><code>Tier      | Min Revenue | Max Revenue\n----------|-------------|-------------\nBronze    | 0           | 10000       \u2713 Valid\nSilver    | 10001       | 50000       \u2713 Valid  \nGold      | 50001       | 100000      \u2713 Valid\nPlatinum  | 40000       | 200000      \u2717 Overlaps with Silver &amp; Gold\n</code></pre></p>"},{"location":"audits/#sequential_values","title":"<code>sequential_values</code>","text":"<p>Ensures ordered numeric column values are sequential with consistent interval.</p> <p>Parameters: - <code>column</code> - Column name to check (required) - <code>interval</code> - Expected difference between consecutive values (required)</p> <p>Example: <pre><code>MODEL (\n  name dim.date_spine,\n  assertions (\n    sequential_values(column := date_key, interval := 1)\n    -- date_key should be 20240101, 20240102, 20240103, ... (no gaps)\n  )\n);\n</code></pre></p> <p>Equivalent SQL: <pre><code>WITH ordered_values AS (\n  SELECT \n    date_key,\n    LAG(date_key) OVER (ORDER BY date_key) AS prev_date_key\n  FROM dim.date_spine\n)\nSELECT * FROM ordered_values\nWHERE prev_date_key IS NOT NULL\n  AND date_key != prev_date_key + 1;\n</code></pre></p> <p>Use when: - Date dimensions with no gaps - Sequential ID columns - Time series with regular intervals</p> <p>WARNING: This audit assumes values are naturally ordered. It fails if there are gaps in the sequence.</p>"},{"location":"audits/#34-string-validation-audits","title":"3.4 String Validation Audits","text":"<p>These audits validate string/character data characteristics.</p>"},{"location":"audits/#not_empty_string","title":"<code>not_empty_string</code>","text":"<p>Ensures no rows contain empty strings ('').</p> <p>Parameters: - <code>column</code> - Column name to check (required)</p> <p>Example: <pre><code>MODEL (\n  name dim.products,\n  assertions (\n    not_empty_string(column := product_name)\n  )\n);\n</code></pre></p> <p>Equivalent SQL: <pre><code>SELECT * FROM dim.products\nWHERE product_name = '';\n</code></pre></p> <p>Use when: - Catching empty strings vs NULL (they're different!) - Ensuring string columns have meaningful content - Validating user input</p> <p>NOTE: Empty string ('') and NULL are different. This audit checks for '', not NULL.</p>"},{"location":"audits/#string_length_equal","title":"<code>string_length_equal</code>","text":"<p>Ensures all string values have exactly the specified length.</p> <p>Parameters: - <code>column</code> - Column name to check (required) - <code>v</code> - Expected string length (required)</p> <p>Example: <pre><code>MODEL (\n  name dim.locations,\n  assertions (\n    string_length_equal(column := zip_code, v := 5)\n    -- All zip codes must be exactly 5 characters\n  )\n);\n</code></pre></p> <p>Equivalent SQL: <pre><code>SELECT * FROM dim.locations\nWHERE LENGTH(zip_code) != 5;\n</code></pre></p> <p>Use when: - Fixed-length codes (zip codes, country codes, SKUs) - Standardized identifiers - Validating data format</p>"},{"location":"audits/#string_length_between","title":"<code>string_length_between</code>","text":"<p>Ensures string values have length within a specified range.</p> <p>Parameters: - <code>column</code> - Column name to check (required) - <code>min_v</code> - Minimum length (required) - <code>max_v</code> - Maximum length (required) - <code>inclusive</code> - Whether boundaries are included (optional, default: true)</p> <p>Example: <pre><code>MODEL (\n  name dim.customers,\n  assertions (\n    string_length_between(column := customer_name, min_v := 2, max_v := 100)\n    -- Names between 2 and 100 characters (inclusive)\n  )\n);\n</code></pre></p> <p>Equivalent SQL (inclusive): <pre><code>SELECT * FROM dim.customers\nWHERE LENGTH(customer_name) &lt; 2 OR LENGTH(customer_name) &gt; 100;\n</code></pre></p> <p>Use when: - Validating reasonable name lengths - Ensuring text fields aren't too long - Catching truncated data</p>"},{"location":"audits/#valid_email","title":"<code>valid_email</code>","text":"<p>Ensures strings match email address format.</p> <p>Parameters: - <code>column</code> - Column name to check (required)</p> <p>Example: <pre><code>MODEL (\n  name dim.users,\n  assertions (\n    valid_email(column := email)\n  )\n);\n</code></pre></p> <p>Equivalent SQL: <pre><code>-- Uses regex: ^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$\nSELECT * FROM dim.users\nWHERE email IS NOT NULL\n  AND NOT REGEXP_MATCHES(email, '^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$');\n</code></pre></p> <p>Use when: - Validating email addresses - Ensuring parseable contact information - Catching malformed data</p> <p>NOTE: NULL values pass this audit. Use <code>not_null</code> separately if required.</p>"},{"location":"audits/#valid_url","title":"<code>valid_url</code>","text":"<p>Ensures strings match URL format.</p> <p>Parameters: - <code>column</code> - Column name to check (required)</p> <p>Example: <pre><code>MODEL (\n  name dim.products,\n  assertions (\n    valid_url(column := product_url)\n  )\n);\n</code></pre></p> <p>Equivalent SQL: <pre><code>-- Uses regex: ^(https?|ftp)://[^\\s/$.?#].[^\\s]*$\nSELECT * FROM dim.products\nWHERE product_url IS NOT NULL\n  AND NOT REGEXP_MATCHES(product_url, '^(https?|ftp)://[^\\s/$.?#].[^\\s]*$');\n</code></pre></p> <p>Use when: - Validating website URLs - Ensuring clickable links - API endpoint validation</p>"},{"location":"audits/#valid_uuid","title":"<code>valid_uuid</code>","text":"<p>Ensures strings match UUID format.</p> <p>Parameters: - <code>column</code> - Column name to check (required)</p> <p>Example: <pre><code>MODEL (\n  name events.user_sessions,\n  assertions (\n    valid_uuid(column := session_id)\n  )\n);\n</code></pre></p> <p>Equivalent SQL: <pre><code>-- UUID format: 8-4-4-4-12 hexadecimal digits\n-- Example: 550e8400-e29b-41d4-a716-446655440000\nSELECT * FROM events.user_sessions\nWHERE session_id IS NOT NULL\n  AND NOT REGEXP_MATCHES(session_id, \n    '^[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}$');\n</code></pre></p> <p>Use when: - Validating UUID identifiers - Ensuring proper format from UUID generators - Catching malformed IDs</p>"},{"location":"audits/#valid_http_method","title":"<code>valid_http_method</code>","text":"<p>Ensures values are valid HTTP methods.</p> <p>Parameters: - <code>column</code> - Column name to check (required)</p> <p>Example: <pre><code>MODEL (\n  name logs.api_requests,\n  assertions (\n    valid_http_method(column := http_method)\n  )\n);\n</code></pre></p> <p>Valid HTTP methods: - GET, POST, PUT, DELETE, PATCH, HEAD, OPTIONS, TRACE, CONNECT</p> <p>Equivalent SQL: <pre><code>SELECT * FROM logs.api_requests\nWHERE http_method NOT IN ('GET', 'POST', 'PUT', 'DELETE', 'PATCH', \n                          'HEAD', 'OPTIONS', 'TRACE', 'CONNECT');\n</code></pre></p> <p>Use when: - Validating API logs - Ensuring standardized HTTP methods - Catching typos or malformed requests</p>"},{"location":"audits/#35-pattern-matching-audits","title":"3.5 Pattern Matching Audits","text":"<p>These audits validate strings against patterns.</p>"},{"location":"audits/#match_regex_pattern_list","title":"<code>match_regex_pattern_list</code>","text":"<p>Ensures all non-NULL values match at least one regex pattern.</p> <p>Parameters: - <code>column</code> - Column name to check (required) - <code>patterns</code> - List of regex patterns (required)</p> <p>Example: <pre><code>MODEL (\n  name products.inventory,\n  assertions (\n    match_regex_pattern_list(\n      column := sku,\n      patterns := ('^[A-Z]{3}-[0-9]{6}$', '^LEGACY-.*')\n      -- Matches: ABC-123456 OR LEGACY-anything\n    )\n  )\n);\n</code></pre></p> <p>Equivalent SQL: <pre><code>SELECT * FROM products.inventory\nWHERE sku IS NOT NULL\n  AND NOT (\n    REGEXP_MATCHES(sku, '^[A-Z]{3}-[0-9]{6}$') OR\n    REGEXP_MATCHES(sku, '^LEGACY-.*')\n  );\n</code></pre></p> <p>Use when: - Multiple valid format patterns - Complex validation rules - Migrating between formats</p>"},{"location":"audits/#not_match_regex_pattern_list","title":"<code>not_match_regex_pattern_list</code>","text":"<p>Ensures no non-NULL values match any regex pattern.</p> <p>Parameters: - <code>column</code> - Column name to check (required) - <code>patterns</code> - List of regex patterns to reject (required)</p> <p>Example: <pre><code>MODEL (\n  name products.inventory,\n  assertions (\n    not_match_regex_pattern_list(\n      column := sku,\n      patterns := ('^TEST-.*', '^TEMP-.*', '^DEBUG-.*')\n      -- Reject: TEST-*, TEMP-*, DEBUG-*\n    )\n  )\n);\n</code></pre></p> <p>Use when: - Blocking test data patterns - Ensuring production-only data - Catching debug/temporary records</p>"},{"location":"audits/#match_like_pattern_list","title":"<code>match_like_pattern_list</code>","text":"<p>Ensures all non-NULL values match at least one LIKE pattern.</p> <p>Parameters: - <code>column</code> - Column name to check (required) - <code>patterns</code> - List of LIKE patterns (required)</p> <p>Example: <pre><code>MODEL (\n  name sales.customers,\n  assertions (\n    match_like_pattern_list(\n      column := email,\n      patterns := ('%@company.com', '%@subsidiary.com')\n      -- Only company or subsidiary emails\n    )\n  )\n);\n</code></pre></p> <p>Equivalent SQL: <pre><code>SELECT * FROM sales.customers\nWHERE email IS NOT NULL\n  AND NOT (email LIKE '%@company.com' OR email LIKE '%@subsidiary.com');\n</code></pre></p> <p>Use when: - Simple wildcard patterns - Domain validation - Simpler than regex</p>"},{"location":"audits/#not_match_like_pattern_list","title":"<code>not_match_like_pattern_list</code>","text":"<p>Ensures no non-NULL values match any LIKE pattern.</p> <p>Parameters: - <code>column</code> - Column name to check (required) - <code>patterns</code> - List of LIKE patterns to reject (required)</p> <p>Example: <pre><code>MODEL (\n  name products.catalog,\n  assertions (\n    not_match_like_pattern_list(\n      column := product_name,\n      patterns := ('%test%', '%dummy%', '%placeholder%')\n    )\n  )\n);\n</code></pre></p> <p>Use when: - Blocking keywords (test, dummy, etc.) - Ensuring clean data - Catching placeholders</p>"},{"location":"audits/#36-statistical-audits","title":"3.6 Statistical Audits","text":"<p>These audits validate statistical properties of numeric columns.</p> <p>WARNING: Thresholds for statistical audits typically require tuning based on your data distribution. Start with profiles to understand baseline statistics before setting audit thresholds.</p>"},{"location":"audits/#mean_in_range","title":"<code>mean_in_range</code>","text":"<p>Ensures column mean falls within specified range.</p> <p>Parameters: - <code>column</code> - Column name to check (required) - <code>min_v</code> - Minimum mean (required) - <code>max_v</code> - Maximum mean (required) - <code>inclusive</code> - Whether boundaries are included (optional, default: true)</p> <p>Example: <pre><code>MODEL (\n  name sales.daily_revenue,\n  assertions (\n    mean_in_range(column := order_amount, min_v := 50, max_v := 200)\n    -- Average order should be between $50-$200\n  )\n);\n</code></pre></p> <p>Use when: - Detecting shifts in average behavior - Ensuring expected data distribution - Catching data quality issues affecting aggregates</p>"},{"location":"audits/#stddev_in_range","title":"<code>stddev_in_range</code>","text":"<p>Ensures column standard deviation falls within specified range.</p> <p>Parameters: - <code>column</code> - Column name to check (required) - <code>min_v</code> - Minimum standard deviation (required) - <code>max_v</code> - Maximum standard deviation (required) - <code>inclusive</code> - Whether boundaries are included (optional, default: true)</p> <p>Example: <pre><code>MODEL (\n  name analytics.customer_metrics,\n  assertions (\n    stddev_in_range(column := purchase_frequency, min_v := 5, max_v := 20)\n  )\n);\n</code></pre></p> <p>Use when: - Monitoring data variability - Detecting unusual distribution changes - Ensuring consistent spread</p>"},{"location":"audits/#z_score","title":"<code>z_score</code>","text":"<p>Ensures no values have absolute z-score exceeding threshold (outlier detection).</p> <p>Parameters: - <code>column</code> - Column name to check (required) - <code>threshold</code> - Maximum absolute z-score (required, typically 3 or 4)</p> <p>Example: <pre><code>MODEL (\n  name sales.transactions,\n  assertions (\n    z_score(column := transaction_amount, threshold := 3)\n    -- Flag values &gt;3 standard deviations from mean\n  )\n);\n</code></pre></p> <p>Z-score calculation: <pre><code>z = |value - mean| / stddev\n</code></pre></p> <p>Common thresholds: - <code>threshold := 2</code> - Strict (catches values &gt;2\u03c3 from mean, ~5% of normal distribution) - <code>threshold := 3</code> - Standard (catches values &gt;3\u03c3 from mean, ~0.3% of normal distribution) - <code>threshold := 4</code> - Lenient (catches extreme outliers only)</p> <p>Use when: - Detecting extreme outliers - Catching data entry errors - Ensuring realistic value ranges</p>"},{"location":"audits/#kl_divergence","title":"<code>kl_divergence</code>","text":"<p>Ensures symmetrized KL divergence between two columns doesn't exceed threshold.</p> <p>Parameters: - <code>column</code> - First column to compare (required) - <code>target_column</code> - Second column to compare (required) - <code>threshold</code> - Maximum KL divergence (required)</p> <p>Example: <pre><code>MODEL (\n  name analytics.cohort_comparison,\n  assertions (\n    kl_divergence(\n      column := current_month_revenue_distribution,\n      target_column := last_month_revenue_distribution,\n      threshold := 0.1\n    )\n  )\n);\n</code></pre></p> <p>Use when: - Comparing distributions across time periods - Detecting distribution shifts - A/B test validation</p> <p>NOTE: This is an advanced statistical audit. Most use cases are better served by profiles or quality checks with trending.</p>"},{"location":"audits/#chi_square","title":"<code>chi_square</code>","text":"<p>Ensures chi-square statistic for two categorical columns doesn't exceed critical value.</p> <p>Parameters: - <code>column</code> - First categorical column (required) - <code>target_column</code> - Second categorical column (required) - <code>critical_value</code> - Chi-square critical value (required)</p> <p>Example: <pre><code>MODEL (\n  name analytics.user_segments,\n  assertions (\n    chi_square(\n      column := user_region,\n      target_column := subscription_tier,\n      critical_value := 6.635  -- p-value 0.95, df=1\n    )\n  )\n);\n</code></pre></p> <p>Finding critical values: <pre><code>from scipy.stats import chi2\n# critical_value for p=0.95, degrees_of_freedom=1\nchi2.ppf(0.95, 1)  # Returns 3.841\n</code></pre></p> <p>Use when: - Testing independence of categorical variables - Validating expected relationships - Advanced statistical validation</p> <p>NOTE: This is an advanced statistical audit requiring knowledge of chi-square testing.</p>"},{"location":"audits/#37-generic-assertion-audit","title":"3.7 Generic Assertion Audit","text":""},{"location":"audits/#forall","title":"<code>forall</code>","text":"<p>Ensures arbitrary boolean expressions evaluate to TRUE for all rows.</p> <p>Parameters: - <code>criteria</code> - List of boolean SQL expressions (required)</p> <p>Example: <pre><code>MODEL (\n  name sales.orders,\n  assertions (\n    forall(criteria := (\n      amount &gt;= 0,\n      order_date &lt;= CURRENT_DATE,\n      shipped_date IS NULL OR shipped_date &gt;= order_date,\n      discount_amount &lt;= amount,\n      (customer_tier = 'premium') OR (discount_percent = 0)\n    ))\n  )\n);\n</code></pre></p> <p>Equivalent SQL: <pre><code>SELECT * FROM sales.orders\nWHERE NOT (\n  amount &gt;= 0\n  AND order_date &lt;= CURRENT_DATE\n  AND (shipped_date IS NULL OR shipped_date &gt;= order_date)\n  AND discount_amount &lt;= amount\n  AND ((customer_tier = 'premium') OR (discount_percent = 0))\n);\n</code></pre></p> <p>Use when: - Multiple related conditions - Complex business logic - Custom validation not covered by built-in audits</p> <p>TIP: This is the most flexible audit - use it when built-in audits don't fit your needs.</p> <p>\u2191 Back to Top</p>"},{"location":"audits/#4-creating-custom-audits","title":"4. Creating Custom Audits","text":"<p>When built-in audits don't cover your specific validation needs, create custom audits.</p>"},{"location":"audits/#41-basic-custom-audit","title":"4.1 Basic Custom Audit","text":"<p>Custom audits are defined in <code>.sql</code> files within an <code>audits/</code> directory in your project.</p> <p>Project structure: <pre><code>my_project/\n\u251c\u2500\u2500 models/\n\u2502   \u251c\u2500\u2500 staging/\n\u2502   \u2514\u2500\u2500 marts/\n\u251c\u2500\u2500 audits/           \u2190 Create this directory\n\u2502   \u2514\u2500\u2500 business_rules.sql\n\u2514\u2500\u2500 config.yaml\n</code></pre></p> <p>Example: audits/business_rules.sql <pre><code>AUDIT (\n  name assert_positive_price,\n  dialect postgres\n);\n\nSELECT * FROM @this_model\nWHERE price IS NOT NULL \n  AND price &lt;= 0;\n</code></pre></p> <p>Apply to model: <pre><code>-- models/staging/products.sql\nMODEL (\n  name staging.products,\n  assertions (assert_positive_price)\n);\n\nSELECT\n  product_id,\n  product_name,\n  price,\n  cost\nFROM raw.products;\n</code></pre></p> <p>Key components: 1. <code>AUDIT (name ...)</code> - Defines the audit name 2. <code>dialect</code> - Optional, specifies SQL dialect if different from project default 3. <code>SELECT * FROM @this_model WHERE ...</code> - Query for bad data</p>"},{"location":"audits/#42-parameterized-audits-reusable","title":"4.2 Parameterized Audits (Reusable)","text":"<p>Make audits reusable by adding parameters:</p> <p>audits/generic_checks.sql <pre><code>AUDIT (\n  name threshold_check\n);\n\nSELECT * FROM @this_model\nWHERE @column &gt; @threshold;\n</code></pre></p> <p>Apply with different parameters: <pre><code>MODEL (\n  name sales.orders,\n  assertions (\n    threshold_check(column := amount, threshold := 10000),\n    threshold_check(column := quantity, threshold := 100)\n  )\n);\n</code></pre></p> <p>How it works: - <code>@column</code> and <code>@threshold</code> are macro variables - Values are substituted when audit runs - Same audit definition, multiple uses</p> <p>Example: Range check audit <pre><code>AUDIT (\n  name value_in_range\n);\n\nSELECT * FROM @this_model\nWHERE @column &lt; @min_value OR @column &gt; @max_value;\n</code></pre></p> <p>Usage: <pre><code>assertions (\n  value_in_range(column := age, min_value := 0, max_value := 120),\n  value_in_range(column := discount_percent, min_value := 0, max_value := 1)\n)\n</code></pre></p>"},{"location":"audits/#43-audit-file-organization","title":"4.3 Audit File Organization","text":"<p>Organize audits by domain or function:</p> <p>Recommended structure: <pre><code>audits/\n\u251c\u2500\u2500 common/                    # Reusable generic audits\n\u2502   \u251c\u2500\u2500 nulls.sql             # Null-related checks\n\u2502   \u251c\u2500\u2500 ranges.sql            # Range validations\n\u2502   \u2514\u2500\u2500 formats.sql           # Format validations\n\u251c\u2500\u2500 sales/                     # Domain-specific audits\n\u2502   \u251c\u2500\u2500 orders.sql\n\u2502   \u2514\u2500\u2500 revenue.sql\n\u251c\u2500\u2500 finance/\n\u2502   \u2514\u2500\u2500 transactions.sql\n\u2514\u2500\u2500 data_quality/\n    \u2514\u2500\u2500 referential.sql       # Referential integrity checks\n</code></pre></p> <p>Example: audits/common/ranges.sql <pre><code>-- Generic positive value check\nAUDIT (name assert_positive);\nSELECT * FROM @this_model\nWHERE @column &lt;= 0;\n\n-- Generic non-negative check\nAUDIT (name assert_non_negative);\nSELECT * FROM @this_model\nWHERE @column &lt; 0;\n\n-- Generic percentage check (0-1)\nAUDIT (name assert_valid_percentage);\nSELECT * FROM @this_model\nWHERE @column &lt; 0 OR @column &gt; 1;\n\n-- Generic percentage check (0-100)\nAUDIT (name assert_valid_percentage_100);\nSELECT * FROM @this_model\nWHERE @column &lt; 0 OR @column &gt; 100;\n</code></pre></p> <p>Example: audits/sales/orders.sql <pre><code>-- Order-specific business rules\nAUDIT (name valid_order_dates);\nSELECT * FROM @this_model\nWHERE order_date &gt; CURRENT_DATE\n   OR (shipped_date IS NOT NULL AND shipped_date &lt; order_date)\n   OR (delivered_date IS NOT NULL AND delivered_date &lt; shipped_date);\n\n-- Order amount validation\nAUDIT (name valid_order_amounts);\nSELECT * FROM @this_model\nWHERE amount &lt; 0\n   OR discount_amount &gt; amount\n   OR tax_amount &lt; 0\n   OR total_amount != amount - discount_amount + tax_amount;\n</code></pre></p> <p>TIP: Multiple audits can be defined in a single file. Group related audits together.</p>"},{"location":"audits/#44-special-macros","title":"4.4 Special Macros","text":"<p>Vulcan provides special macros for audit queries:</p>"},{"location":"audits/#this_model","title":"<code>@this_model</code>","text":"<p>References the model being audited. For incremental models, automatically filters to processed intervals.</p> <p>Usage: <pre><code>AUDIT (name check_values);\nSELECT * FROM @this_model\nWHERE invalid_condition;\n</code></pre></p> <p>For incremental models: <pre><code>-- If model is INCREMENTAL_BY_TIME_RANGE with time_column = order_date\n-- And processing interval 2024-01-15\n\n-- @this_model expands to:\n-- (SELECT * FROM sales.orders WHERE order_date = '2024-01-15')\n\nAUDIT (name check_today_orders);\nSELECT * FROM @this_model\nWHERE amount &lt; 0;\n-- Only checks orders from 2024-01-15\n</code></pre></p>"},{"location":"audits/#start_ds-and-end_ds","title":"<code>@start_ds</code> and <code>@end_ds</code>","text":"<p>For incremental models, these provide the date/timestamp boundaries of the processed interval.</p> <p>Usage: <pre><code>AUDIT (name check_date_range);\nSELECT * FROM @this_model\nWHERE order_date &lt; @start_ds\n   OR order_date &gt; @end_ds;\n</code></pre></p> <p>Example: Ensure all data is within expected interval <pre><code>AUDIT (name data_within_interval);\nSELECT \n  order_date,\n  '@start_ds' AS expected_start,\n  '@end_ds' AS expected_end\nFROM @this_model\nWHERE order_date NOT BETWEEN @start_ds AND @end_ds;\n</code></pre></p>"},{"location":"audits/#custom-parameters","title":"Custom Parameters","text":"<p>Any parameter passed to the audit becomes a macro variable:</p> <p>Audit definition: <pre><code>AUDIT (name multi_param_check);\nSELECT * FROM @this_model\nWHERE @column1 &gt; @threshold1\n   OR @column2 &lt; @threshold2\n   OR @status NOT IN @valid_statuses;\n</code></pre></p> <p>Usage: <pre><code>assertions (\n  multi_param_check(\n    column1 := revenue,\n    threshold1 := 1000000,\n    column2 := margin,\n    threshold2 := 0.1,\n    valid_statuses := ('active', 'pending')\n  )\n)\n</code></pre></p>"},{"location":"audits/#45-dialect-specific-audits","title":"4.5 Dialect-Specific Audits","text":"<p>Specify SQL dialect if different from project default:</p> <p>audits/spark_specific.sql <pre><code>AUDIT (\n  name check_array_length,\n  dialect spark\n);\n\nSELECT * FROM @this_model\nWHERE SIZE(@array_column) &lt; @min_size;\n</code></pre></p> <p>Common use cases: - Using database-specific functions - Warehouse-specific syntax - Multi-warehouse projects</p> <p>Example: BigQuery specific <pre><code>AUDIT (\n  name check_json_field,\n  dialect bigquery\n);\n\nSELECT * FROM @this_model\nWHERE JSON_EXTRACT_SCALAR(@json_column, '$.field') IS NULL;\n</code></pre></p> <p>Example: Snowflake specific <pre><code>AUDIT (\n  name check_variant_field,\n  dialect snowflake\n);\n\nSELECT * FROM @this_model\nWHERE @variant_column:field::STRING IS NULL;\n</code></pre></p>"},{"location":"audits/#46-default-parameters","title":"4.6 Default Parameters","text":"<p>Provide default values for parameters:</p> <p>audits/defaults_example.sql <pre><code>AUDIT (\n  name threshold_check,\n  defaults (\n    threshold = 100,\n    column = value\n  )\n);\n\nSELECT * FROM @this_model\nWHERE @column &gt; @threshold;\n</code></pre></p> <p>Usage with defaults: <pre><code>-- Use default threshold (100) and default column (value)\nassertions (\n  threshold_check()\n)\n\n-- Override threshold, use default column\nassertions (\n  threshold_check(threshold := 1000)\n)\n\n-- Override both\nassertions (\n  threshold_check(column := amount, threshold := 5000)\n)\n</code></pre></p> <p>Example: Flexible range check <pre><code>AUDIT (\n  name range_check,\n  defaults (\n    min_value = 0,\n    max_value = 999999,\n    column = amount,\n    inclusive = true\n  )\n);\n\nSELECT * FROM @this_model\nWHERE (\n  CASE WHEN @inclusive THEN\n    @column &lt; @min_value OR @column &gt; @max_value\n  ELSE\n    @column &lt;= @min_value OR @column &gt;= @max_value\n  END\n);\n</code></pre></p>"},{"location":"audits/#47-naming-conventions-for-custom-audits","title":"4.7 Naming Conventions for Custom Audits","text":"<p>CORRECT naming: <pre><code>-- Descriptive, action-oriented names\nassert_positive_revenue\nvalidate_customer_exists\ncheck_order_date_before_shipped_date\nensure_email_format_valid\nverify_no_duplicate_transactions\n</code></pre></p> <p>INCORRECT naming: <pre><code>-- Too vague\naudit1\ncheck_data\nvalidation\nmy_audit\n\n-- Too generic\ncheck\nvalidate\nensure\n</code></pre></p> <p>Naming patterns: - <code>assert_*</code> - For simple assertions (assert_positive_price) - <code>validate_*</code> - For complex validations (validate_referential_integrity) - <code>check_*</code> - For conditional checks (check_date_ordering) - <code>ensure_*</code> - For guarantee checks (ensure_completeness) - <code>verify_*</code> - For verification logic (verify_calculations)</p>"},{"location":"audits/#48-documenting-custom-audits","title":"4.8 Documenting Custom Audits","text":"<p>Add comments to explain complex audits:</p> <p>audits/documented_example.sql <pre><code>-- =============================================================================\n-- Audit: validate_revenue_calculation\n-- Description: Ensures revenue calculation is correct\n-- Business Rule: Revenue = Quantity * Unit Price - Discounts + Taxes\n-- Tolerance: Allow $0.01 rounding difference\n-- =============================================================================\nAUDIT (name validate_revenue_calculation);\n\nSELECT \n  order_id,\n  revenue AS recorded_revenue,\n  (quantity * unit_price - discount_amount + tax_amount) AS calculated_revenue,\n  ABS(revenue - (quantity * unit_price - discount_amount + tax_amount)) AS difference\nFROM @this_model\nWHERE ABS(revenue - (quantity * unit_price - discount_amount + tax_amount)) &gt; 0.01;\n</code></pre></p> <p>Complex business logic audit: <pre><code>-- =============================================================================\n-- Audit: validate_subscription_lifecycle\n-- Description: Ensures subscription dates follow valid lifecycle\n-- Business Rules:\n--   1. start_date &lt;= current_date\n--   2. end_date &gt; start_date (if not NULL)\n--   3. cancelled_date between start_date and end_date\n--   4. renewal_date &gt; end_date (for auto-renew subscriptions)\n-- =============================================================================\nAUDIT (name validate_subscription_lifecycle);\n\nSELECT \n  subscription_id,\n  start_date,\n  end_date,\n  cancelled_date,\n  renewal_date,\n  CASE\n    WHEN start_date &gt; CURRENT_DATE THEN 'Future start date'\n    WHEN end_date IS NOT NULL AND end_date &lt;= start_date THEN 'End before start'\n    WHEN cancelled_date IS NOT NULL AND cancelled_date &lt; start_date THEN 'Cancelled before start'\n    WHEN cancelled_date IS NOT NULL AND end_date IS NOT NULL AND cancelled_date &gt; end_date THEN 'Cancelled after end'\n    WHEN renewal_date IS NOT NULL AND end_date IS NOT NULL AND renewal_date &lt;= end_date THEN 'Renewal before end'\n    ELSE 'Unknown violation'\n  END AS violation_type\nFROM @this_model\nWHERE start_date &gt; CURRENT_DATE\n   OR (end_date IS NOT NULL AND end_date &lt;= start_date)\n   OR (cancelled_date IS NOT NULL AND cancelled_date &lt; start_date)\n   OR (cancelled_date IS NOT NULL AND end_date IS NOT NULL AND cancelled_date &gt; end_date)\n   OR (renewal_date IS NOT NULL AND end_date IS NOT NULL AND renewal_date &lt;= end_date);\n</code></pre></p> <p>\u2191 Back to Top</p>"},{"location":"audits/#5-inline-audits","title":"5. Inline Audits","text":"<p>Inline audits are defined directly within model files, keeping audit logic close to the model it validates.</p>"},{"location":"audits/#51-when-to-use-inline-vs-file-based-audits","title":"5.1 When to Use Inline vs File-Based Audits","text":"Use Inline Audits Use File-Based Audits Model-specific validation Reusable across models Simple, one-off checks Complex parameterized logic Keep audit close to model logic Shared team standards Quick prototyping Organized by domain Few audits (1-3) Many audits (4+) <p>CORRECT: Use inline for model-specific logic <pre><code>-- models/sales/daily_metrics.sql\nMODEL (\n  name sales.daily_metrics,\n  assertions (revenue_matches_orders, no_future_dates)\n);\n\nSELECT\n  order_date,\n  SUM(amount) AS revenue,\n  COUNT(*) AS order_count\nFROM sales.orders\nGROUP BY order_date;\n\n-- Inline audit 1: Model-specific calculation check\nAUDIT (name revenue_matches_orders);\nSELECT dm.order_date, dm.revenue, SUM(o.amount) AS actual_revenue\nFROM @this_model dm\nJOIN sales.orders o ON dm.order_date = o.order_date\nGROUP BY dm.order_date, dm.revenue\nHAVING dm.revenue != SUM(o.amount);\n\n-- Inline audit 2: Model-specific date check\nAUDIT (name no_future_dates);\nSELECT * FROM @this_model\nWHERE order_date &gt; CURRENT_DATE;\n</code></pre></p> <p>INCORRECT: Don't inline generic reusable audits <pre><code>-- DON'T DO THIS - This should be in audits/common/\nMODEL (\n  name sales.orders,\n  assertions (not_null_check, positive_amount_check)\n);\n\nSELECT * FROM raw.orders;\n\nAUDIT (name not_null_check);  -- Generic! Should be in audits/\nSELECT * FROM @this_model WHERE order_id IS NULL;\n\nAUDIT (name positive_amount_check);  -- Generic! Should be in audits/\nSELECT * FROM @this_model WHERE amount &lt;= 0;\n</code></pre></p>"},{"location":"audits/#52-inline-audit-syntax","title":"5.2 Inline Audit Syntax","text":"<p>Basic syntax: <pre><code>MODEL (\n  name schema.table_name,\n  assertions (audit1, audit2, audit3)  -- Reference inline audits\n);\n\n-- Model query\nSELECT ...;\n\n-- Inline audit definitions\nAUDIT (name audit1);\nSELECT ...;\n\nAUDIT (name audit2);\nSELECT ...;\n\nAUDIT (name audit3);\nSELECT ...;\n</code></pre></p> <p>Example: Product inventory <pre><code>MODEL (\n  name inventory.product_stock,\n  grain (product_id, warehouse_id),\n  assertions (\n    valid_stock_levels,\n    consistent_totals\n  )\n);\n\nSELECT\n  product_id,\n  warehouse_id,\n  on_hand_qty,\n  reserved_qty,\n  available_qty\nFROM raw.inventory;\n\n-- Audit 1: Stock quantities make sense\nAUDIT (name valid_stock_levels);\nSELECT * FROM @this_model\nWHERE on_hand_qty &lt; 0\n   OR reserved_qty &lt; 0\n   OR available_qty &lt; 0\n   OR reserved_qty &gt; on_hand_qty\n   OR available_qty != (on_hand_qty - reserved_qty);\n\n-- Audit 2: Totals match warehouse aggregates\nAUDIT (name consistent_totals);\nSELECT \n  product_id,\n  COUNT(*) AS warehouse_count,\n  SUM(on_hand_qty) AS total_on_hand\nFROM @this_model\nGROUP BY product_id\nHAVING SUM(on_hand_qty) &lt; 0;  -- Shouldn't be possible if audit 1 passes\n</code></pre></p>"},{"location":"audits/#53-multiple-inline-audits","title":"5.3 Multiple Inline Audits","text":"<p>You can define many inline audits in a single model file:</p> <p>Example: Comprehensive order validation <pre><code>MODEL (\n  name sales.orders,\n  grain order_id,\n  assertions (\n    valid_amounts,\n    valid_dates,\n    valid_status_transitions,\n    valid_customer_references,\n    valid_calculations\n  )\n);\n\nSELECT\n  order_id,\n  customer_id,\n  order_date,\n  shipped_date,\n  delivered_date,\n  amount,\n  discount_amount,\n  tax_amount,\n  total_amount,\n  status\nFROM raw.orders;\n\n-- Audit 1: Amount validations\nAUDIT (name valid_amounts);\nSELECT * FROM @this_model\nWHERE amount &lt;= 0\n   OR discount_amount &lt; 0\n   OR tax_amount &lt; 0\n   OR total_amount &lt; 0\n   OR discount_amount &gt; amount;\n\n-- Audit 2: Date validations\nAUDIT (name valid_dates);\nSELECT * FROM @this_model\nWHERE order_date &gt; CURRENT_DATE\n   OR (shipped_date IS NOT NULL AND shipped_date &lt; order_date)\n   OR (delivered_date IS NOT NULL AND delivered_date &lt; shipped_date);\n\n-- Audit 3: Status logic\nAUDIT (name valid_status_transitions);\nSELECT * FROM @this_model\nWHERE (status = 'shipped' AND shipped_date IS NULL)\n   OR (status = 'delivered' AND delivered_date IS NULL)\n   OR (status = 'pending' AND shipped_date IS NOT NULL);\n\n-- Audit 4: Referential integrity\nAUDIT (name valid_customer_references);\nSELECT o.*\nFROM @this_model o\nLEFT JOIN dim.customers c ON o.customer_id = c.customer_id\nWHERE c.customer_id IS NULL;\n\n-- Audit 5: Calculation validation\nAUDIT (name valid_calculations);\nSELECT * FROM @this_model\nWHERE ABS(total_amount - (amount - discount_amount + tax_amount)) &gt; 0.01;\n</code></pre></p> <p>TIP: Inline audits run in the order defined. Put fast audits first, expensive audits last.</p>"},{"location":"audits/#54-combining-inline-and-file-based-audits","title":"5.4 Combining Inline and File-Based Audits","text":"<p>You can use both inline and file-based audits together:</p> <p>Example: Mix generic and specific audits <pre><code>MODEL (\n  name sales.orders,\n  grain order_id,\n  assertions (\n    -- File-based generic audits\n    not_null(columns := (order_id, customer_id, order_date)),\n    unique_values(columns := (order_id)),\n    accepted_range(column := amount, min_v := 0, max_v := 1000000),\n\n    -- Inline model-specific audits\n    valid_order_lifecycle,\n    revenue_matches_line_items\n  )\n);\n\nSELECT\n  order_id,\n  customer_id,\n  order_date,\n  shipped_date,\n  amount,\n  discount_amount\nFROM raw.orders;\n\n-- Inline audit 1: Order-specific lifecycle\nAUDIT (name valid_order_lifecycle);\nSELECT * FROM @this_model\nWHERE shipped_date IS NOT NULL \n  AND shipped_date &lt; order_date;\n\n-- Inline audit 2: Order-specific calculation\nAUDIT (name revenue_matches_line_items);\nSELECT \n  o.order_id,\n  o.amount AS order_amount,\n  SUM(li.quantity * li.unit_price) AS line_items_total\nFROM @this_model o\nJOIN raw.order_line_items li ON o.order_id = li.order_id\nGROUP BY o.order_id, o.amount\nHAVING ABS(o.amount - SUM(li.quantity * li.unit_price)) &gt; 0.01;\n</code></pre></p> <p>When to combine: - Use file-based audits for standard validations (nulls, uniqueness, ranges) - Use inline audits for model-specific business logic - This gives you both reusability and specificity</p>"},{"location":"audits/#55-inline-audits-with-parameters","title":"5.5 Inline Audits with Parameters","text":"<p>Inline audits can be parameterized too:</p> <pre><code>MODEL (\n  name sales.orders,\n  assertions (\n    threshold_check(column := amount, threshold := 10000),\n    threshold_check(column := quantity, threshold := 100)\n  )\n);\n\nSELECT * FROM raw.orders;\n\n-- Parameterized inline audit\nAUDIT (name threshold_check);\nSELECT * FROM @this_model\nWHERE @column &gt; @threshold;\n</code></pre> <p>Reusing inline audits within the same model: <pre><code>MODEL (\n  name sales.metrics,\n  assertions (\n    range_check(column := revenue, min_val := 0, max_val := 1000000),\n    range_check(column := profit, min_val := -100000, max_val := 500000),\n    range_check(column := margin, min_val := 0, max_val := 1)\n  )\n);\n\nSELECT * FROM raw.metrics;\n\nAUDIT (name range_check);\nSELECT * FROM @this_model\nWHERE @column &lt; @min_val OR @column &gt; @max_val;\n</code></pre></p>"},{"location":"audits/#56-organizing-inline-audits","title":"5.6 Organizing Inline Audits","text":"<p>For clarity, add comments: <pre><code>MODEL (\n  name sales.complex_metrics,\n  assertions (\n    completeness_checks,\n    business_rule_validations,\n    calculation_validations\n  )\n);\n\nSELECT * FROM ...;\n\n-- =============================================================================\n-- COMPLETENESS CHECKS\n-- =============================================================================\n\nAUDIT (name completeness_checks);\nSELECT * FROM @this_model\nWHERE customer_id IS NULL\n   OR revenue IS NULL\n   OR order_count IS NULL;\n\n-- =============================================================================\n-- BUSINESS RULE VALIDATIONS\n-- =============================================================================\n\nAUDIT (name business_rule_validations);\nSELECT * FROM @this_model\nWHERE revenue &lt; 0\n   OR order_count &lt; 0\n   OR (order_count = 0 AND revenue &gt; 0);  -- Revenue without orders\n\n-- =============================================================================\n-- CALCULATION VALIDATIONS\n-- =============================================================================\n\nAUDIT (name calculation_validations);\nSELECT * FROM @this_model\nWHERE ABS(average_order_value - (revenue / NULLIF(order_count, 0))) &gt; 0.01;\n</code></pre></p>"},{"location":"audits/#57-inline-audit-anti-patterns","title":"5.7 Inline Audit Anti-Patterns","text":"<p>INCORRECT: Too many inline audits <pre><code>-- DON'T DO THIS - Too many inline audits (10+)\nMODEL (\n  name sales.orders,\n  assertions (audit1, audit2, audit3, audit4, audit5, audit6, audit7, audit8, audit9, audit10, audit11, audit12)\n);\n\nSELECT * FROM ...;\n\nAUDIT (name audit1); SELECT ...;\nAUDIT (name audit2); SELECT ...;\nAUDIT (name audit3); SELECT ...;\n-- ... 12 total audits ...\n\n-- RESULT: Model file is 500+ lines, hard to navigate\n</code></pre></p> <p>CORRECT: Move to file-based <pre><code>-- Create audits/sales/orders.sql with the 12 audits\n-- Keep model file clean\n\nMODEL (\n  name sales.orders,\n  assertions (\n    orders_completeness,\n    orders_validity,\n    orders_calculations,\n    orders_referential_integrity\n    -- Only 4 references, but 12+ actual audits in audits/sales/orders.sql\n  )\n);\n\nSELECT * FROM ...;\n</code></pre></p> <p>INCORRECT: Generic inline audits <pre><code>-- DON'T DO THIS - These should be in audits/common/\nMODEL (name dim.products, assertions (check_not_null));\nSELECT * FROM ...;\n\nAUDIT (name check_not_null);\nSELECT * FROM @this_model WHERE product_id IS NULL;\n</code></pre></p> <p>CORRECT: Use built-in or file-based <pre><code>MODEL (\n  name dim.products,\n  assertions (not_null(columns := (product_id)))  -- Built-in\n);\nSELECT * FROM ...;\n</code></pre></p> <p>\u2191 Back to Top</p>"},{"location":"audits/#6-advanced-audit-patterns","title":"6. Advanced Audit Patterns","text":"<p>This section covers complex audit patterns for sophisticated data validation scenarios.</p>"},{"location":"audits/#61-referential-integrity-checks","title":"6.1 Referential Integrity Checks","text":"<p>Validate foreign key relationships using JOINs:</p> <p>Basic referential integrity: <pre><code>-- audits/referential/customer_orders.sql\nAUDIT (name valid_customer_references);\n\nSELECT o.*\nFROM @this_model o\nLEFT JOIN dim.customers c ON o.customer_id = c.customer_id\nWHERE o.customer_id IS NOT NULL  -- Separate null check\n  AND c.customer_id IS NULL;      -- Customer doesn't exist\n</code></pre></p> <p>Multi-column foreign keys: <pre><code>AUDIT (name valid_product_location_references);\n\nSELECT ol.*\nFROM @this_model ol\nLEFT JOIN dim.product_locations pl \n  ON ol.product_id = pl.product_id \n  AND ol.warehouse_id = pl.warehouse_id\nWHERE ol.product_id IS NOT NULL\n  AND ol.warehouse_id IS NOT NULL\n  AND pl.product_id IS NULL;\n</code></pre></p> <p>Conditional referential integrity: <pre><code>-- Only certain statuses require customer reference\nAUDIT (name conditional_customer_reference);\n\nSELECT o.*\nFROM @this_model o\nLEFT JOIN dim.customers c ON o.customer_id = c.customer_id\nWHERE o.status IN ('completed', 'shipped')  -- Only these statuses\n  AND o.customer_id IS NOT NULL\n  AND c.customer_id IS NULL;\n</code></pre></p> <p>Temporal referential integrity: <pre><code>-- Order date must be within customer's active period\nAUDIT (name temporal_customer_reference);\n\nSELECT o.*\nFROM @this_model o\nJOIN dim.customers c ON o.customer_id = c.customer_id\nWHERE o.order_date &lt; c.first_purchase_date\n   OR (c.last_purchase_date IS NOT NULL AND o.order_date &gt; c.last_purchase_date);\n</code></pre></p>"},{"location":"audits/#62-multi-column-business-logic","title":"6.2 Multi-Column Business Logic","text":"<p>Validate complex relationships between multiple columns:</p> <p>Date ordering: <pre><code>AUDIT (name valid_date_sequence);\n\nSELECT * FROM @this_model\nWHERE order_date &gt; CURRENT_DATE\n   OR (shipped_date IS NOT NULL AND shipped_date &lt; order_date)\n   OR (delivered_date IS NOT NULL AND delivered_date &lt; shipped_date)\n   OR (cancelled_date IS NOT NULL AND cancelled_date &lt; order_date);\n</code></pre></p> <p>Calculated fields validation: <pre><code>AUDIT (name revenue_calculation_valid);\n\nSELECT \n  order_id,\n  subtotal,\n  discount_amount,\n  tax_amount,\n  shipping_cost,\n  total_amount,\n  (subtotal - discount_amount + tax_amount + shipping_cost) AS calculated_total,\n  ABS(total_amount - (subtotal - discount_amount + tax_amount + shipping_cost)) AS difference\nFROM @this_model\nWHERE ABS(total_amount - (subtotal - discount_amount + tax_amount + shipping_cost)) &gt; 0.01;\n</code></pre></p> <p>Conditional logic: <pre><code>AUDIT (name conditional_business_rules);\n\nSELECT * FROM @this_model\nWHERE \n  -- Premium customers get free shipping\n  (customer_tier = 'premium' AND shipping_cost &gt; 0)\n\n  -- Orders over $100 get discount\n  OR (subtotal &gt; 100 AND discount_amount = 0)\n\n  -- Cancelled orders shouldn't have shipped/delivered dates\n  OR (status = 'cancelled' AND (shipped_date IS NOT NULL OR delivered_date IS NOT NULL))\n\n  -- Delivered orders must have both shipped and delivered dates\n  OR (status = 'delivered' AND (shipped_date IS NULL OR delivered_date IS NULL));\n</code></pre></p> <p>Percentage validations: <pre><code>AUDIT (name percentage_consistency);\n\nSELECT * FROM @this_model\nWHERE \n  -- Discount percentage should match discount amount\n  ABS(discount_percent - (discount_amount / NULLIF(subtotal, 0))) &gt; 0.001\n\n  -- Tax percentage should match tax amount\n  OR ABS(tax_percent - (tax_amount / NULLIF(subtotal, 0))) &gt; 0.001\n\n  -- Margin percentage should match margin amount\n  OR ABS(margin_percent - ((revenue - cost) / NULLIF(revenue, 0))) &gt; 0.001;\n</code></pre></p>"},{"location":"audits/#63-cross-model-validation","title":"6.3 Cross-Model Validation","text":"<p>Validate data consistency across multiple models:</p> <p>Aggregate consistency: <pre><code>AUDIT (name orders_match_line_items);\n\nSELECT \n  o.order_id,\n  o.total_amount AS order_total,\n  SUM(li.quantity * li.unit_price) AS line_items_total,\n  ABS(o.total_amount - SUM(li.quantity * li.unit_price)) AS difference\nFROM @this_model o\nJOIN raw.order_line_items li ON o.order_id = li.order_id\nGROUP BY o.order_id, o.total_amount\nHAVING ABS(o.total_amount - SUM(li.quantity * li.unit_price)) &gt; 0.01;\n</code></pre></p> <p>Count consistency: <pre><code>AUDIT (name customer_order_count_matches);\n\nSELECT \n  c.customer_id,\n  c.total_orders AS recorded_count,\n  COUNT(o.order_id) AS actual_count\nFROM @this_model c\nLEFT JOIN sales.orders o ON c.customer_id = o.customer_id\nGROUP BY c.customer_id, c.total_orders\nHAVING c.total_orders != COUNT(o.order_id);\n</code></pre></p> <p>Date range consistency: <pre><code>AUDIT (name date_ranges_match_detail_data);\n\nSELECT \n  s.customer_id,\n  s.first_order_date AS summary_first_date,\n  s.last_order_date AS summary_last_date,\n  MIN(o.order_date) AS actual_first_date,\n  MAX(o.order_date) AS actual_last_date\nFROM @this_model s\nLEFT JOIN sales.orders o ON s.customer_id = o.customer_id\nGROUP BY s.customer_id, s.first_order_date, s.last_order_date\nHAVING s.first_order_date != MIN(o.order_date)\n   OR s.last_order_date != MAX(o.order_date);\n</code></pre></p>"},{"location":"audits/#64-time-based-audits","title":"6.4 Time-Based Audits","text":"<p>Special considerations for incremental and time-series data:</p> <p>No gaps in time series: <pre><code>AUDIT (name no_date_gaps);\n\nWITH expected_dates AS (\n  SELECT DATE_TRUNC('day', GENERATE_SERIES(\n    (SELECT MIN(order_date) FROM @this_model),\n    (SELECT MAX(order_date) FROM @this_model),\n    '1 day'::INTERVAL\n  )) AS expected_date\n)\nSELECT ed.expected_date\nFROM expected_dates ed\nLEFT JOIN (\n  SELECT DISTINCT DATE_TRUNC('day', order_date) AS order_date\n  FROM @this_model\n) actual ON ed.expected_date = actual.order_date\nWHERE actual.order_date IS NULL;\n</code></pre></p> <p>Monotonic increase validation: <pre><code>AUDIT (name cumulative_values_increase);\n\nSELECT \n  t1.date,\n  t1.cumulative_revenue,\n  t2.cumulative_revenue AS previous_cumulative_revenue\nFROM @this_model t1\nJOIN @this_model t2 \n  ON t2.date = t1.date - INTERVAL '1 day'\nWHERE t1.cumulative_revenue &lt; t2.cumulative_revenue;\n</code></pre></p> <p>Late arrival data detection: <pre><code>AUDIT (name no_late_arriving_data);\n\n-- For incremental models: ensure no data before current interval\nSELECT * FROM @this_model\nWHERE order_date &lt; @start_ds\n   OR order_date &gt; @end_ds;\n</code></pre></p> <p>Rolling window consistency: <pre><code>AUDIT (name rolling_average_consistency);\n\nSELECT \n  date,\n  rolling_7day_avg,\n  daily_value\nFROM @this_model\nWHERE ABS(\n  rolling_7day_avg - \n  AVG(daily_value) OVER (\n    ORDER BY date \n    ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n  )\n) &gt; 0.01;\n</code></pre></p>"},{"location":"audits/#65-state-transition-validation","title":"6.5 State Transition Validation","text":"<p>Validate that status/state changes follow valid paths:</p> <p>Valid status transitions: <pre><code>AUDIT (name valid_status_lifecycle);\n\nSELECT * FROM @this_model\nWHERE \n  -- Pending can only transition to processing or cancelled\n  (previous_status = 'pending' AND status NOT IN ('processing', 'cancelled', 'pending'))\n\n  -- Processing can only transition to completed, failed, or cancelled\n  OR (previous_status = 'processing' AND status NOT IN ('completed', 'failed', 'cancelled', 'processing'))\n\n  -- Completed is terminal (no transitions)\n  OR (previous_status = 'completed' AND status != 'completed')\n\n  -- Failed can transition to processing (retry)\n  OR (previous_status = 'failed' AND status NOT IN ('processing', 'failed'))\n\n  -- Cancelled is terminal\n  OR (previous_status = 'cancelled' AND status != 'cancelled');\n</code></pre></p> <p>Status-date consistency: <pre><code>AUDIT (name status_date_consistency);\n\nSELECT * FROM @this_model\nWHERE \n  -- Shipped status requires shipped_date\n  (status = 'shipped' AND shipped_date IS NULL)\n\n  -- Delivered status requires both shipped_date and delivered_date\n  OR (status = 'delivered' AND (shipped_date IS NULL OR delivered_date IS NULL))\n\n  -- Cancelled status requires cancelled_date\n  OR (status = 'cancelled' AND cancelled_date IS NULL)\n\n  -- Pending/processing shouldn't have these dates\n  OR (status IN ('pending', 'processing') AND (shipped_date IS NOT NULL OR delivered_date IS NOT NULL));\n</code></pre></p> <p>One-way transitions: <pre><code>AUDIT (name subscription_no_reactivation);\n\n-- Once cancelled, subscription shouldn't reactivate\nSELECT \n  subscription_id,\n  status,\n  LAG(status) OVER (PARTITION BY subscription_id ORDER BY updated_at) AS previous_status\nFROM @this_model\nWHERE LAG(status) OVER (PARTITION BY subscription_id ORDER BY updated_at) = 'cancelled'\n  AND status = 'active';\n</code></pre></p>"},{"location":"audits/#66-aggregate-consistency-checks","title":"6.6 Aggregate Consistency Checks","text":"<p>Validate that aggregates match their detail data:</p> <p>Sum of parts equals whole: <pre><code>AUDIT (name revenue_components_sum_to_total);\n\nSELECT * FROM @this_model\nWHERE ABS(\n  total_revenue - (\n    product_revenue + \n    shipping_revenue + \n    tax_revenue + \n    other_revenue\n  )\n) &gt; 0.01;\n</code></pre></p> <p>Percentage parts sum to 100%: <pre><code>AUDIT (name category_percentages_sum_to_one);\n\nSELECT \n  product_id,\n  category_a_percent + category_b_percent + category_c_percent + other_percent AS total_percent\nFROM @this_model\nWHERE ABS((category_a_percent + category_b_percent + category_c_percent + other_percent) - 1.0) &gt; 0.001;\n</code></pre></p> <p>Count aggregates match: <pre><code>AUDIT (name aggregate_counts_consistent);\n\nSELECT * FROM @this_model\nWHERE total_customers != (active_customers + inactive_customers + cancelled_customers)\n   OR total_orders != (completed_orders + pending_orders + cancelled_orders);\n</code></pre></p> <p>Weighted averages: <pre><code>AUDIT (name weighted_average_valid);\n\nSELECT \n  product_id,\n  weighted_average_price,\n  SUM(quantity * unit_price) / NULLIF(SUM(quantity), 0) AS calculated_weighted_avg\nFROM @this_model\nJOIN sales.order_line_items li ON @this_model.product_id = li.product_id\nGROUP BY product_id, weighted_average_price\nHAVING ABS(weighted_average_price - (SUM(quantity * unit_price) / NULLIF(SUM(quantity), 0))) &gt; 0.01;\n</code></pre></p>"},{"location":"audits/#67-statistical-outlier-detection","title":"6.7 Statistical Outlier Detection","text":"<p>Beyond simple z-score, detect complex outliers:</p> <p>Inter-quartile range (IQR) method: <pre><code>AUDIT (name iqr_outlier_detection);\n\nWITH stats AS (\n  SELECT \n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY amount) AS q1,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY amount) AS q3\n  FROM @this_model\n),\nbounds AS (\n  SELECT \n    q1,\n    q3,\n    q3 - q1 AS iqr,\n    q1 - 1.5 * (q3 - q1) AS lower_bound,\n    q3 + 1.5 * (q3 - q1) AS upper_bound\n  FROM stats\n)\nSELECT m.*\nFROM @this_model m, bounds\nWHERE m.amount &lt; bounds.lower_bound\n   OR m.amount &gt; bounds.upper_bound;\n</code></pre></p> <p>Moving average deviation: <pre><code>AUDIT (name moving_average_deviation);\n\nWITH moving_stats AS (\n  SELECT \n    date,\n    daily_value,\n    AVG(daily_value) OVER (ORDER BY date ROWS BETWEEN 29 PRECEDING AND CURRENT ROW) AS moving_avg_30d,\n    STDDEV(daily_value) OVER (ORDER BY date ROWS BETWEEN 29 PRECEDING AND CURRENT ROW) AS moving_stddev_30d\n  FROM @this_model\n)\nSELECT *\nFROM moving_stats\nWHERE ABS(daily_value - moving_avg_30d) &gt; 3 * moving_stddev_30d;\n</code></pre></p> <p>Comparing to historical baseline: <pre><code>AUDIT (name deviation_from_historical_baseline);\n\nWITH historical_stats AS (\n  SELECT \n    AVG(daily_revenue) AS baseline_avg,\n    STDDEV(daily_revenue) AS baseline_stddev\n  FROM @this_model\n  WHERE date BETWEEN @start_ds - INTERVAL '90 days' AND @start_ds - INTERVAL '1 day'\n)\nSELECT m.*\nFROM @this_model m, historical_stats\nWHERE ABS(m.daily_revenue - historical_stats.baseline_avg) &gt; 3 * historical_stats.baseline_stddev;\n</code></pre></p>"},{"location":"audits/#68-hierarchical-data-validation","title":"6.8 Hierarchical Data Validation","text":"<p>Validate parent-child relationships:</p> <p>Parent exists: <pre><code>AUDIT (name category_parent_exists);\n\nSELECT c.*\nFROM @this_model c\nLEFT JOIN @this_model p ON c.parent_category_id = p.category_id\nWHERE c.parent_category_id IS NOT NULL\n  AND p.category_id IS NULL;\n</code></pre></p> <p>No circular references: <pre><code>AUDIT (name no_circular_category_references);\n\nWITH RECURSIVE category_path AS (\n  -- Base case: start with leaf categories\n  SELECT \n    category_id,\n    parent_category_id,\n    ARRAY[category_id] AS path,\n    1 AS depth\n  FROM @this_model\n  WHERE parent_category_id IS NOT NULL\n\n  UNION ALL\n\n  -- Recursive case: walk up the hierarchy\n  SELECT \n    cp.category_id,\n    c.parent_category_id,\n    cp.path || c.category_id,\n    cp.depth + 1\n  FROM category_path cp\n  JOIN @this_model c ON cp.parent_category_id = c.category_id\n  WHERE c.parent_category_id IS NOT NULL\n    AND NOT (c.category_id = ANY(cp.path))  -- Stop if we see a cycle\n    AND cp.depth &lt; 10  -- Prevent infinite recursion\n)\nSELECT *\nFROM category_path\nWHERE parent_category_id = ANY(path);  -- Found a cycle\n</code></pre></p> <p>Hierarchy consistency: <pre><code>AUDIT (name hierarchy_level_consistency);\n\n-- Ensure level matches actual depth in hierarchy\nWITH RECURSIVE hierarchy_depth AS (\n  SELECT \n    category_id,\n    parent_category_id,\n    level,\n    1 AS actual_depth\n  FROM @this_model\n  WHERE parent_category_id IS NULL\n\n  UNION ALL\n\n  SELECT \n    c.category_id,\n    c.parent_category_id,\n    c.level,\n    hd.actual_depth + 1\n  FROM @this_model c\n  JOIN hierarchy_depth hd ON c.parent_category_id = hd.category_id\n)\nSELECT *\nFROM hierarchy_depth\nWHERE level != actual_depth;\n</code></pre></p> <p>\u2191 Back to Top</p>"},{"location":"audits/#7-audit-execution-and-lifecycle","title":"7. Audit Execution and Lifecycle","text":""},{"location":"audits/#71-when-audits-run","title":"7.1 When Audits Run","text":"<p>Audits execute automatically at specific points:</p> <p>1. After model execution completes <pre><code>Model SQL runs \u2192 Data written \u2192 Audits run immediately\n</code></pre></p> <p>2. During <code>vulcan plan</code> and <code>vulcan run</code> <pre><code>vulcan plan \u2192 Models execute in virtual environments \u2192 Audits run \u2192 Apply promotes clean data\nvulcan run \u2192 Models execute in target environments \u2192 Audits run \u2192 Blocks downstream on failure\n</code></pre></p> <p>3. Not during schema changes <pre><code>ALTER TABLE statements \u2192 No audits run\n</code></pre></p>"},{"location":"audits/#72-plan-vs-run-where-bad-data-lives","title":"7.2 Plan vs Run: Where Bad Data Lives","text":"<p>This is a critical distinction that affects how you recover from audit failures.</p>"},{"location":"audits/#during-vulcan-plan-developmentstaging-workflow","title":"During <code>vulcan plan</code> (Development/Staging Workflow)","text":"<p>Virtual Environments: - Vulcan creates isolated schemas/databases (virtual environments) - Models execute and write to isolated tables, NOT production - Audits run against the isolated tables - Only models that pass audits get promoted to production when you apply the plan</p> <p>Execution flow: <pre><code>vulcan plan\n  \u2192 Creates virtual environment (e.g., schema: myproject__dev_123)\n  \u2192 Model writes to: myproject__dev_123.sales.orders\n  \u2192 Audit runs on: myproject__dev_123.sales.orders\n  \u2192 \u274c Audit fails\n      \u2192 Bad data stays in virtual environment\n      \u2192 Production tables remain untouched \u2705\n      \u2192 Fix and re-plan (virtual env is disposable)\n  \u2192 \u2705 Audit passes\n      \u2192 vulcan plan apply\n      \u2192 Promotes clean data to production \u2705\n</code></pre></p> <p>Key benefits: - Safe testing - Production never sees bad data - Easy rollback - Just don't apply the plan - Isolated debugging - Inspect bad data in virtual environment without production impact</p> <p>Example: <pre><code># Plan creates virtual environment and runs audits\nvulcan plan\n\n# Output:\n# ======================================================================\n# Model: sales.orders (myproject__dev_456.sales.orders)\n# Status: \u274c AUDIT FAILED\n# Audit: not_null\n# Violations: 3 rows\n# ======================================================================\n# \n# Bad data is in: myproject__dev_456.sales.orders\n# Production table: myproject__prod.sales.orders (unchanged \u2705)\n\n# Investigate bad data in virtual environment\nSELECT * FROM myproject__dev_456.sales.orders WHERE order_id IS NULL;\n\n# Fix source issue, then re-plan (creates new virtual env)\nvulcan plan\n\n# All audits pass \u2705\nvulcan plan apply  # Now promote to production\n</code></pre></p>"},{"location":"audits/#during-vulcan-run-direct-execution","title":"During <code>vulcan run</code> (Direct Execution)","text":"<p>Direct Writes: - Models execute and write directly to target tables (often production) - Audits run after the model has already written data - If audit fails, bad data is already committed to the table</p> <p>Execution flow: <pre><code>vulcan run\n  \u2192 Model writes directly to: myproject__prod.sales.orders\n  \u2192 Data is committed \u2705 (already in table)\n  \u2192 Audit runs on: myproject__prod.sales.orders\n  \u2192 \u274c Audit fails\n      \u2192 Bad data is ALREADY in production table \u26a0\ufe0f\n      \u2192 Downstream models are blocked \u2705 (won't see bad data)\n      \u2192 Must fix source and re-run to overwrite \u26a0\ufe0f\n  \u2192 \u2705 Audit passes\n      \u2192 Downstream models proceed\n</code></pre></p> <p>Key implications: - Production impact - Failed model's table contains bad data - Downstream protection - Dependent models don't run (data doesn't propagate further) - Recovery required - Must fix issue and re-run to replace bad data</p> <p>Example: <pre><code># Run directly writes to production\nvulcan run\n\n# Output:\n# ======================================================================\n# Model: sales.orders\n# Table updated: myproject__prod.sales.orders \u2705\n# Auditing...\n# Status: \u274c AUDIT FAILED\n# Audit: not_null\n# Violations: 3 rows\n# ======================================================================\n# \n# \u26a0\ufe0f  Bad data is now in: myproject__prod.sales.orders\n# \u2705  Downstream models blocked: sales.daily_metrics, sales.customer_summary\n# \n# Recovery steps:\n# 1. Investigate: SELECT * FROM myproject__prod.sales.orders WHERE order_id IS NULL\n# 2. Fix source data\n# 3. Re-run: vulcan run (overwrites bad data)\n\n# Investigate bad data (already in production)\nSELECT * FROM myproject__prod.sales.orders WHERE order_id IS NULL;\n\n# After fixing source issue\nvulcan run  # Overwrites the bad data\n</code></pre></p>"},{"location":"audits/#comparison-plan-vs-run","title":"Comparison: Plan vs Run","text":"Aspect <code>vulcan plan</code> <code>vulcan run</code> Write destination Virtual environment (isolated) Target environment (often production) Audit failure impact Bad data in isolated schema Bad data in production table \u26a0\ufe0f Production safety \u2705 Production never sees bad data \u26a0\ufe0f Failed model's table has bad data Downstream protection \u2705 Never promoted \u2705 Blocked from running Recovery Easy - don't apply plan Must fix and re-run to overwrite Use case Development, staging, testing changes Direct production updates (use cautiously)"},{"location":"audits/#73-audit-execution-order","title":"7.3 Audit Execution Order","text":"<p>Audits run in the order they're defined:</p> <pre><code>MODEL (\n  name sales.orders,\n  assertions (\n    not_null(columns := (order_id)),      -- Runs 1st\n    unique_values(columns := (order_id)), -- Runs 2nd\n    accepted_range(column := amount, min_v := 0, max_v := 1000000), -- Runs 3rd\n    forall(criteria := (order_date &lt;= CURRENT_DATE))  -- Runs 4th\n  )\n);\n</code></pre> <p>If any audit fails: - Execution halts immediately - Subsequent audits don't run - Downstream models don't execute</p> <p>Optimization tip: Order audits by execution speed (fast \u2192 slow): <pre><code>assertions (\n  not_null(columns := (order_id)),           -- Fast: simple null check\n  unique_values(columns := (order_id)),       -- Medium: GROUP BY + HAVING\n  referential_integrity_check,                 -- Slow: JOIN with large table\n  complex_statistical_outlier_detection        -- Slowest: multiple passes\n)\n</code></pre></p>"},{"location":"audits/#74-incremental-models-and-audits","title":"7.4 Incremental Models and Audits","text":"<p>For incremental models, audits scope automatically to processed intervals:</p> <p>Example: Incremental model <pre><code>MODEL (\n  name sales.daily_orders,\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column order_date\n  ),\n  assertions (\n    not_null(columns := (order_id, amount))\n  )\n);\n\nSELECT * FROM raw.orders\nWHERE order_date BETWEEN @start_ds AND @end_ds;\n</code></pre></p> <p>Execution on 2024-01-15: <pre><code>1. Model processes: WHERE order_date BETWEEN '2024-01-15' AND '2024-01-15'\n2. Audit runs on: Only rows with order_date = '2024-01-15'\n3. Historical data (2024-01-01 to 2024-01-14) is NOT re-audited\n</code></pre></p> <p>How <code>@this_model</code> works: <pre><code>-- Your audit definition\nAUDIT (name check_amounts);\nSELECT * FROM @this_model WHERE amount &lt; 0;\n\n-- For incremental model on 2024-01-15, expands to:\nSELECT * FROM (\n  SELECT * FROM sales.daily_orders \n  WHERE order_date BETWEEN '2024-01-15' AND '2024-01-15'\n) WHERE amount &lt; 0;\n</code></pre></p> <p>Why this matters: - Efficiency: Don't re-audit unchanged historical data - Correctness: Only validate what you just processed - Performance: Audits scale with interval size, not total table size</p>"},{"location":"audits/#75-full-refresh-and-audits","title":"7.5 Full Refresh and Audits","text":"<p>For full refresh models, audits validate the entire table:</p> <pre><code>MODEL (\n  name dim.customers,\n  kind FULL,\n  assertions (\n    unique_values(columns := (customer_id))\n  )\n);\n\nSELECT * FROM raw.customers;\n</code></pre> <p>Every execution: <pre><code>1. Table is completely replaced\n2. Audit runs on entire new table contents\n3. All rows validated every time\n</code></pre></p> <p>Performance consideration: - Full refresh + expensive audits = slow execution - Use profiles instead for less critical validations - Consider incremental models if possible</p>"},{"location":"audits/#76-temporarily-skipping-audits","title":"7.6 Temporarily Skipping Audits","text":"<p>Use <code>skip</code> flag to temporarily disable audits:</p> <p>Skip specific audit: <pre><code>-- audits/temp_disabled.sql\nAUDIT (\n  name experimental_check,\n  skip true  -- This audit won't run\n);\nSELECT * FROM @this_model WHERE experimental_condition;\n</code></pre></p> <p>When to skip: - Developing/testing a new audit - Known data quality issue being fixed - Temporarily expensive audit during investigation</p> <p>WARNING: Never skip critical audits in production. Use <code>skip</code> only for development or temporary issues.</p> <p>Alternative: Comment out instead of skip <pre><code>MODEL (\n  name sales.orders,\n  assertions (\n    not_null(columns := (order_id)),\n    -- unique_values(columns := (order_id)),  -- Temporarily disabled\n    accepted_range(column := amount, min_v := 0, max_v := 1000000)\n  )\n);\n</code></pre></p>"},{"location":"audits/#77-audit-failure-handling","title":"7.7 Audit Failure Handling","text":"<p>What happens when an audit fails:</p> <ol> <li>Execution halts immediately</li> <li>Model execution completed</li> <li>Audit detected violations</li> <li> <p>Downstream models blocked</p> </li> <li> <p>Error message includes:</p> </li> <li>Audit name</li> <li>Model name</li> <li>Number of violating rows</li> <li>Audit SQL query</li> </ol> <p>Example error: <pre><code>Failure in audit 'not_null' for model 'sales.orders'.\nGot 3 results, expected 0.\nQuery: SELECT * FROM sales.orders WHERE order_id IS NULL OR customer_id IS NULL\n</code></pre></p> <ol> <li>Data state:</li> <li>Model's own table contains the bad data (already written)</li> <li>Downstream models don't run (data doesn't propagate)</li> <li> <p>Source data unchanged</p> </li> <li> <p>Next steps:</p> </li> <li>Investigate root cause</li> <li>Fix source data or model logic</li> <li>Re-run execution</li> </ol>"},{"location":"audits/#78-audit-performance-impact","title":"7.8 Audit Performance Impact","text":"<p>Audits add to execution time: <pre><code>Total execution time = Model execution + All audits execution\n</code></pre></p> <p>Performance tips:</p> <p>1. Keep audits simple: <pre><code>-- Fast audit\nSELECT * FROM @this_model WHERE amount &lt; 0;\n\n-- Slow audit\nSELECT * FROM @this_model t1\nJOIN huge_dimension_table d ON t1.id = d.id\nWHERE complex_function(d.column) = invalid_value;\n</code></pre></p> <p>2. Use indexes on audited columns: <pre><code>-- If auditing customer_id frequently, add index:\nCREATE INDEX idx_customer_id ON sales.orders (customer_id);\n\n-- Audits will be faster:\nSELECT * FROM @this_model WHERE customer_id IS NULL;\n</code></pre></p> <p>3. Limit cross-model audits: <pre><code>-- Expensive: JOINs with large tables\nAUDIT (name referential_check);\nSELECT * FROM @this_model o\nJOIN enormous_table e ON o.key = e.key\nWHERE validation_condition;\n\n-- Consider: Move to quality check (runs separately) or profile\n</code></pre></p> <p>4. Avoid function calls in audits: <pre><code>-- Slow: Function call per row\nSELECT * FROM @this_model\nWHERE EXPENSIVE_UDF(column) = 'invalid';\n\n-- Better: Pre-compute if possible\nSELECT * FROM @this_model\nWHERE computed_column = 'invalid';\n</code></pre></p> <p>\u2191 Back to Top</p>"},{"location":"audits/#8-troubleshooting-and-debugging","title":"8. Troubleshooting and Debugging","text":""},{"location":"audits/#81-reading-audit-failure-messages","title":"8.1 Reading Audit Failure Messages","text":"<p>Audit failures provide detailed information:</p> <p>Example failure: <pre><code>Failure in audit 'not_null' for model 'sales.orders'.\nGot 3 results, expected 0.\nQuery: SELECT * FROM sales.orders WHERE order_id IS NULL OR customer_id IS NULL\n</code></pre></p> <p>Message components: 1. Audit name: <code>not_null</code> 2. Model name: <code>sales.orders</code> 3. Row count: <code>Got 3 results</code> (3 rows violated) 4. SQL query: The actual audit query that found violations</p>"},{"location":"audits/#82-debugging-failed-audits-step-by-step","title":"8.2 Debugging Failed Audits (Step-by-Step)","text":"<p>Step 1: Run the audit query manually <pre><code>-- Copy the query from error message\nSELECT * FROM sales.orders \nWHERE order_id IS NULL OR customer_id IS NULL;\n\n-- Result shows the 3 problematic rows\n</code></pre></p> <p>Step 2: Add context to understand the issue <pre><code>-- Expand query to see full row context\nSELECT \n  *,\n  'Missing order_id' AS issue_type\nFROM sales.orders \nWHERE order_id IS NULL\n\nUNION ALL\n\nSELECT \n  *,\n  'Missing customer_id' AS issue_type\nFROM sales.orders \nWHERE customer_id IS NULL;\n</code></pre></p> <p>Step 3: Trace upstream to find root cause <pre><code>-- Check source data\nSELECT * FROM raw.orders\nWHERE order_id IS NULL OR customer_id IS NULL;\n\n-- If source is clean, check model logic\n-- Look for JOIN conditions that might create nulls\n</code></pre></p> <p>Step 4: Determine fix location - Source data issue: Fix upstream system, re-run extraction - Model logic issue: Update model SQL, re-run transformation - Audit logic issue: Audit is too strict, adjust audit query</p>"},{"location":"audits/#83-common-audit-issues","title":"8.3 Common Audit Issues","text":"<p>Issue 1: Audit fails intermittently</p> <p>Cause: Time-dependent data or race conditions</p> <p>Solution: <pre><code>-- Bad: Checks against current time (changes every second)\nSELECT * FROM @this_model \nWHERE created_at &gt; CURRENT_TIMESTAMP;\n\n-- Good: Check against model's time range\nSELECT * FROM @this_model\nWHERE created_at &gt; @end_ds + INTERVAL '1 hour';\n</code></pre></p> <p>Issue 2: Audit too strict (fails on edge cases)</p> <p>Cause: Missing business context</p> <p>Solution: <pre><code>-- Too strict: Fails on valid $0 free-tier products\nSELECT * FROM @this_model WHERE price &lt;= 0;\n\n-- Better: Account for free-tier\nSELECT * FROM @this_model \nWHERE price &lt;= 0 \n  AND product_tier != 'free';\n</code></pre></p> <p>Issue 3: Audit passes but data still wrong</p> <p>Cause: Inverted logic</p> <p>Solution: <pre><code>-- Wrong: Returns good data\nSELECT * FROM @this_model WHERE price &gt; 0;  -- Audit always fails!\n\n-- Right: Returns bad data\nSELECT * FROM @this_model WHERE price &lt;= 0;  -- Audit passes if no bad data\n</code></pre></p> <p>Issue 4: Performance issues</p> <p>Cause: Expensive audit queries</p> <p>Solution: <pre><code>-- Slow: Full table scan with function\nSELECT * FROM @this_model\nWHERE EXPENSIVE_FUNCTION(column) = 'invalid';\n\n-- Fast: Use indexed column or pre-computed value\nSELECT * FROM @this_model\nWHERE computed_flag = 'invalid';\n</code></pre></p>"},{"location":"audits/#84-fixing-failed-audits","title":"8.4 Fixing Failed Audits","text":"<p>Scenario A: Fix source data <pre><code>1. Identify bad data in source system\n2. Correct at source\n3. Re-extract data\n4. Re-run Vulcan model\n5. Audit passes\n</code></pre></p> <p>Scenario B: Fix model logic <pre><code>-- Before: Model creates nulls via LEFT JOIN\nSELECT o.*, c.customer_name\nFROM raw.orders o\nLEFT JOIN raw.customers c ON o.customer_id = c.id;\n-- Result: customer_name is NULL for some rows\n\n-- After: Use INNER JOIN or handle nulls\nSELECT o.*, COALESCE(c.customer_name, 'Unknown') AS customer_name\nFROM raw.orders o\nLEFT JOIN raw.customers c ON o.customer_id = c.id;\n</code></pre></p> <p>Scenario C: Adjust audit <pre><code>-- Before: Too strict\nSELECT * FROM @this_model WHERE discount_amount &gt; 0;\n\n-- After: Account for legitimate discounts\nSELECT * FROM @this_model \nWHERE discount_amount &gt; 0 \n  AND discount_amount &gt; order_amount;  -- Only invalid discounts\n</code></pre></p>"},{"location":"audits/#85-testing-audits-before-deployment","title":"8.5 Testing Audits Before Deployment","text":"<p>Test with <code>skip</code> flag during development: <pre><code>AUDIT (\n  name new_audit_under_development,\n  skip true  -- Won't run yet\n);\nSELECT * FROM @this_model WHERE new_condition;\n</code></pre></p> <p>Test audit query separately: <pre><code>-- Run audit query manually on existing data\nSELECT * FROM sales.orders  -- Replace @this_model with actual table\nWHERE new_condition;\n\n-- Verify it finds issues (or doesn't) as expected\n</code></pre></p> <p>Test with small dataset: <pre><code>-- Add WHERE clause to limit scope during testing\nAUDIT (name test_audit);\nSELECT * FROM @this_model\nWHERE condition\n  AND order_date &gt;= '2024-01-01'  -- Temporary: test on recent data only\nLIMIT 100;\n</code></pre></p> <p>\u2191 Back to Top</p>"},{"location":"audits/#9-best-practices","title":"9. Best Practices","text":""},{"location":"audits/#91-audit-logic-patterns","title":"9.1 Audit Logic Patterns","text":"<p>Always query for bad data (inverted logic): <pre><code>-- Correct\nSELECT * FROM @this_model WHERE price &lt;= 0;  -- Find violations\n\n-- Incorrect\nSELECT * FROM @this_model WHERE price &gt; 0;   -- Find good data (backwards!)\n</code></pre></p> <p>Use clear, explicit conditions: <pre><code>-- Vague\nSELECT * FROM @this_model WHERE status != 'good';\n\n-- Clear\nSELECT * FROM @this_model \nWHERE status NOT IN ('completed', 'shipped', 'delivered');\n</code></pre></p>"},{"location":"audits/#92-audit-granularity-strategy","title":"9.2 Audit Granularity Strategy","text":"<p>Start broad, add specificity over time:</p> <p>Phase 1: Essential validations <pre><code>assertions (\n  not_null(columns := (order_id, customer_id)),\n  unique_values(columns := (order_id))\n)\n</code></pre></p> <p>Phase 2: Add business rules <pre><code>assertions (\n  not_null(columns := (order_id, customer_id)),\n  unique_values(columns := (order_id)),\n  accepted_range(column := amount, min_v := 0, max_v := 1000000)\n)\n</code></pre></p> <p>Phase 3: Add complex validations <pre><code>assertions (\n  not_null(columns := (order_id, customer_id)),\n  unique_values(columns := (order_id)),\n  accepted_range(column := amount, min_v := 0, max_v := 1000000),\n  forall(criteria := (order_date &lt;= shipped_date))\n)\n</code></pre></p>"},{"location":"audits/#93-performance-optimization","title":"9.3 Performance Optimization","text":"<p>1. Order audits by cost (fast first) <pre><code>assertions (\n  not_null(columns := (id)),           -- Fast\n  unique_values(columns := (id)),       -- Medium\n  referential_integrity_check           -- Slow\n)\n</code></pre></p> <p>2. Add indexes on audited columns <pre><code>CREATE INDEX idx_customer_id ON orders (customer_id);\nCREATE INDEX idx_order_date ON orders (order_date);\n</code></pre></p> <p>3. Avoid expensive operations <pre><code>-- Slow\nSELECT * FROM @this_model WHERE REGEXP_MATCH(email, complex_pattern);\n\n-- Fast\nSELECT * FROM @this_model WHERE email NOT LIKE '%@%';\n</code></pre></p>"},{"location":"audits/#94-naming-conventions","title":"9.4 Naming Conventions","text":"<p>Use descriptive, action-oriented names: - <code>assert_positive_revenue</code> - <code>validate_customer_exists</code> - <code>check_date_ordering</code> - <code>ensure_email_format</code> - <code>verify_calculations</code></p> <p>Avoid: - <code>audit1</code>, <code>check</code>, <code>test</code>, <code>validation</code></p>"},{"location":"audits/#95-audit-coverage-strategy","title":"9.5 Audit Coverage Strategy","text":"<p>Critical (always audit): - Primary keys: <code>not_null</code> + <code>unique_values</code> - Foreign keys: referential integrity - Non-negative amounts: <code>forall(criteria := (amount &gt;= 0))</code> - Required fields: <code>not_null</code></p> <p>Important (audit frequently): - Enums: <code>accepted_values</code> - Ranges: <code>accepted_range</code> - Formats: <code>valid_email</code>, <code>valid_url</code></p> <p>Nice-to-have (use profiles first): - String lengths - Statistical bounds - Format patterns</p>"},{"location":"audits/#96-organizing-audits-by-domain","title":"9.6 Organizing Audits by Domain","text":"<p>Recommended structure: <pre><code>audits/\n\u251c\u2500\u2500 common/           # Reusable\n\u2502   \u251c\u2500\u2500 nulls.sql\n\u2502   \u251c\u2500\u2500 ranges.sql\n\u2502   \u2514\u2500\u2500 formats.sql\n\u251c\u2500\u2500 sales/            # Domain-specific\n\u2502   \u251c\u2500\u2500 orders.sql\n\u2502   \u2514\u2500\u2500 revenue.sql\n\u2514\u2500\u2500 finance/\n    \u2514\u2500\u2500 transactions.sql\n</code></pre></p> <p>\u2191 Back to Top</p>"},{"location":"audits/#10-real-world-examples","title":"10. Real-World Examples","text":""},{"location":"audits/#101-e-commerce-order-validation","title":"10.1 E-commerce Order Validation","text":"<p>Complete order model with audits: <pre><code>MODEL (\n  name sales.orders,\n  grain order_id,\n  references (customer_id),\n  assertions (\n    -- Completeness\n    not_null(columns := (order_id, customer_id, order_date, amount)),\n\n    -- Uniqueness\n    unique_values(columns := (order_id)),\n\n    -- Business rules\n    forall(criteria := (\n      amount &gt; 0,\n      discount_amount &gt;= 0,\n      discount_amount &lt;= amount,\n      tax_amount &gt;= 0,\n      order_date &lt;= CURRENT_DATE,\n      shipped_date IS NULL OR shipped_date &gt;= order_date,\n      delivered_date IS NULL OR delivered_date &gt;= shipped_date\n    )),\n\n    -- Status logic\n    valid_order_status,\n\n    -- Referential integrity\n    valid_customer_reference\n  )\n);\n\nSELECT\n  order_id,\n  customer_id,\n  order_date,\n  shipped_date,\n  delivered_date,\n  amount,\n  discount_amount,\n  tax_amount,\n  status\nFROM raw.orders;\n\nAUDIT (name valid_order_status);\nSELECT * FROM @this_model\nWHERE (status = 'shipped' AND shipped_date IS NULL)\n   OR (status = 'delivered' AND (shipped_date IS NULL OR delivered_date IS NULL))\n   OR (status NOT IN ('pending', 'processing', 'shipped', 'delivered', 'cancelled'));\n\nAUDIT (name valid_customer_reference);\nSELECT o.*\nFROM @this_model o\nLEFT JOIN dim.customers c ON o.customer_id = c.customer_id\nWHERE c.customer_id IS NULL;\n</code></pre></p>"},{"location":"audits/#102-financial-transaction-audits","title":"10.2 Financial Transaction Audits","text":"<pre><code>MODEL (\n  name finance.transactions,\n  grain transaction_id,\n  assertions (\n    not_null(columns := (transaction_id, account_id, transaction_date, amount)),\n    unique_values(columns := (transaction_id)),\n    forall(criteria := (\n      transaction_date &lt;= CURRENT_DATE,\n      ABS(amount) &gt; 0,  -- No zero transactions\n      (transaction_type = 'debit' AND amount &lt; 0) OR \n      (transaction_type = 'credit' AND amount &gt; 0)  -- Sign matches type\n    )),\n    balanced_transactions  -- Credits = Debits\n  )\n);\n\nSELECT * FROM raw.transactions;\n\nAUDIT (name balanced_transactions);\n-- For each account, ensure sum of transactions = 0 (balanced)\nSELECT \n  account_id,\n  transaction_date,\n  SUM(amount) AS net_amount\nFROM @this_model\nGROUP BY account_id, transaction_date\nHAVING ABS(SUM(amount)) &gt; 0.01;  -- Allow rounding difference\n</code></pre>"},{"location":"audits/#103-user-registration-validation","title":"10.3 User Registration Validation","text":"<pre><code>MODEL (\n  name users.registrations,\n  grain user_id,\n  assertions (\n    not_null(columns := (user_id, email, signup_date)),\n    unique_values(columns := (user_id, email)),\n    valid_email(column := email),\n    forall(criteria := (\n      signup_date &lt;= CURRENT_DATE,\n      age &gt;= 13,  -- Legal requirement\n      age &lt;= 120  -- Reasonable maximum\n    )),\n    valid_country_codes\n  )\n);\n\nSELECT * FROM raw.user_registrations;\n\nAUDIT (name valid_country_codes);\nSELECT * FROM @this_model u\nLEFT JOIN dim.countries c ON u.country_code = c.code\nWHERE u.country_code IS NOT NULL\n  AND c.code IS NULL;\n</code></pre> <p>\u2191 Back to Top</p>"},{"location":"audits/#11-quick-reference","title":"11. Quick Reference","text":""},{"location":"audits/#111-most-common-audits-cheat-sheet","title":"11.1 Most Common Audits (Cheat Sheet)","text":"Use Case Audit Example No NULLs <code>not_null</code> <code>not_null(columns := (id, email))</code> Unique <code>unique_values</code> <code>unique_values(columns := (id))</code> In list <code>accepted_values</code> <code>accepted_values(column := status, is_in := ('A', 'B'))</code> Numeric range <code>accepted_range</code> <code>accepted_range(column := age, min_v := 0, max_v := 120)</code> Positive <code>forall</code> <code>forall(criteria := (amount &gt; 0))</code> Email format <code>valid_email</code> <code>valid_email(column := email)</code> No duplicate combo <code>unique_combination_of_columns</code> <code>unique_combination_of_columns(columns := (user, date))</code> Min rows <code>number_of_rows</code> <code>number_of_rows(threshold := 100)</code> Not empty string <code>not_empty_string</code> <code>not_empty_string(column := name)</code> Custom logic <code>forall</code> <code>forall(criteria := (start_date &lt; end_date))</code>"},{"location":"audits/#112-syntax-quick-reference","title":"11.2 Syntax Quick Reference","text":"<p>Built-in audit: <pre><code>MODEL (\n  name schema.table,\n  assertions (\n    not_null(columns := (col1, col2))\n  )\n);\n</code></pre></p> <p>Custom audit (file-based): <pre><code>-- audits/my_audit.sql\nAUDIT (name my_audit, dialect postgres);\nSELECT * FROM @this_model WHERE bad_condition;\n\n-- In model\nMODEL (name schema.table, assertions (my_audit));\n</code></pre></p> <p>Inline audit: <pre><code>MODEL (name schema.table, assertions (my_audit));\nSELECT * FROM source;\n\nAUDIT (name my_audit);\nSELECT * FROM @this_model WHERE bad_condition;\n</code></pre></p> <p>Parameterized audit: <pre><code>AUDIT (name check_threshold);\nSELECT * FROM @this_model WHERE @column &gt; @threshold;\n\n-- Usage\nassertions (check_threshold(column := amount, threshold := 1000))\n</code></pre></p>"},{"location":"audits/#113-decision-tree","title":"11.3 Decision Tree","text":"<pre><code>Need data validation?\n\u2502\n\u251c\u2500 Must BLOCK bad data immediately?\n\u2502  \u2514\u2500 YES \u2192 Use AUDIT\n\u2502     \u251c\u2500 Reusable? \u2192 audits/common/*.sql\n\u2502     \u2514\u2500 Model-specific? \u2192 Inline audit\n\u2502\n\u251c\u2500 Need historical tracking?\n\u2502  \u2514\u2500 Use QUALITY CHECK (YAML)\n\u2502\n\u2514\u2500 Just observing trends?\n   \u2514\u2500 Use PROFILE\n</code></pre>"},{"location":"audits/#114-complete-audit-index-alphabetical","title":"11.4 Complete Audit Index (Alphabetical)","text":"<p>Built-in audits (29 total): - <code>accepted_range</code> - <code>accepted_values</code> - <code>at_least_one</code> - <code>chi_square</code> - <code>forall</code> - <code>kl_divergence</code> - <code>match_like_pattern_list</code> - <code>match_regex_pattern_list</code> - <code>mean_in_range</code> - <code>mutually_exclusive_ranges</code> - <code>not_accepted_values</code> - <code>not_constant</code> - <code>not_empty_string</code> - <code>not_match_like_pattern_list</code> - <code>not_match_regex_pattern_list</code> - <code>not_null</code> - <code>not_null_proportion</code> - <code>number_of_rows</code> - <code>sequential_values</code> - <code>stddev_in_range</code> - <code>string_length_between</code> - <code>string_length_equal</code> - <code>unique_combination_of_columns</code> - <code>unique_values</code> - <code>valid_email</code> - <code>valid_http_method</code> - <code>valid_url</code> - <code>valid_uuid</code> - <code>z_score</code></p> <p>\u2191 Back to Top</p>"},{"location":"audits/#12-summary-and-next-steps","title":"12. Summary and Next Steps","text":""},{"location":"audits/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>Audits = Data Warehouse Constraints</li> <li>Similar to OLTP constraints but block downstream flow instead of INSERT/UPDATE</li> <li> <p>Always blocking in Vulcan (no warning-only mode)</p> </li> <li> <p>Three Quality Mechanisms</p> </li> <li>Audits: Critical, blocking validation</li> <li>Quality Checks: Monitoring with history</li> <li> <p>Profiles: Trend tracking</p> </li> <li> <p>Query for Bad Data</p> </li> <li>Audits use inverted logic: return violations</li> <li> <p><code>SELECT * FROM @this_model WHERE bad_condition</code></p> </li> <li> <p>29 Built-in Audits</p> </li> <li>Completeness, uniqueness, validity, strings, patterns, statistics</li> <li> <p>Use <code>forall</code> for custom logic</p> </li> <li> <p>Custom Audits</p> </li> <li>File-based: Reusable in <code>audits/</code> directory</li> <li>Inline: Model-specific within model file</li> <li> <p>Parameterized: Use <code>@column</code>, <code>@threshold</code>, etc.</p> </li> <li> <p>Performance Matters</p> </li> <li>Order audits fast \u2192 slow</li> <li>Add indexes on audited columns</li> <li> <p>Keep audits simple</p> </li> <li> <p>Layer by Criticality</p> </li> <li>Critical: PKs, FKs, non-negative amounts</li> <li>Important: Enums, ranges, formats</li> <li>Nice-to-have: Start with profiles</li> </ol>"},{"location":"audits/#related-topics","title":"Related Topics","text":"<p>For deeper learning:</p> <ol> <li>Quality Checks - Scheduled monitoring with historical tracking</li> <li>Profiles - Statistical trend analysis</li> <li>Tests - Unit tests for model logic (run before audits)</li> <li>Semantic Layer - How audits integrate with semantic validations</li> </ol>"},{"location":"audits/#next-steps","title":"Next Steps","text":"<p>Immediate: 1. Add basic audits to your critical models (<code>not_null</code>, <code>unique_values</code>) 2. Review existing models for audit opportunities 3. Create <code>audits/</code> directory and organize by domain</p> <p>Short-term: 4. Implement referential integrity audits 5. Add business rule validations with <code>forall</code> 6. Set up profiles to understand data patterns</p> <p>Long-term: 7. Build comprehensive audit coverage across all models 8. Integrate audits into CI/CD 9. Monitor audit performance and optimize</p>"},{"location":"audits/#final-thoughts","title":"Final Thoughts","text":"<p>Audits are your first line of defense against bad data. They: - Catch issues immediately during transformation - Prevent bad data from propagating downstream - Build confidence in your data products - Document expected data characteristics</p> <p>Start simple with critical validations, then expand coverage over time. Your future self (and downstream consumers) will thank you.</p> <p>Congratulations! You've completed the Audits chapter.</p>"},{"location":"audits/#appendix-audit-catalog","title":"Appendix: Audit Catalog","text":"<p>For a complete list of all 29 built-in audits with parameters, see Section 3: Built-in Audits Reference.</p> <p>\u2191 Back to Top</p>"},{"location":"data-quality/","title":"Chapter 05: Data Quality","text":"<p>Monitor and validate data quality with comprehensive checks - Validation rules that run separately from models, track trends over time, and integrate with the Activity API for monitoring and alerting.</p>"},{"location":"data-quality/#prerequisites","title":"Prerequisites","text":"<p>Before diving into this chapter, you should have:</p>"},{"location":"data-quality/#required-knowledge","title":"Required Knowledge","text":"<p>SQL Proficiency - Level 2 - SELECT statements, WHERE clauses - Aggregations (COUNT, AVG, SUM) - Basic window functions (helpful)</p> <p>YAML Syntax - Basic YAML structure (dictionaries, lists) - Multi-line strings</p> <p>Chapter 2 (Models) - Understanding of: - Model execution lifecycle - Audits vs Checks distinction - Data quality strategy</p>"},{"location":"data-quality/#optional-but-helpful","title":"Optional but Helpful","text":"<p>Data Quality Concepts - Data quality dimensions (completeness, validity, accuracy) - Statistical concepts (mean, standard deviation, anomalies)</p> <p>Activity API (Chapter 6) - Helpful for: - Querying check results - Building monitoring dashboards</p>"},{"location":"data-quality/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Introduction</li> <li>Quick Start</li> <li>Check Configuration</li> <li>Built-in Check Types</li> <li>Data Profiling</li> <li>Check Results and Activity API</li> <li>Advanced Patterns</li> <li>Best Practices</li> <li>Troubleshooting</li> </ol>"},{"location":"data-quality/#1-introduction","title":"1. Introduction","text":""},{"location":"data-quality/#11-what-are-quality-checks","title":"1.1 What Are Quality Checks?","text":"<p>Quality checks are comprehensive validation rules configured in YAML files that monitor data quality over time. Unlike audits (which block pipeline execution), checks:</p> <ul> <li>Run separately from model execution (or alongside it)</li> <li>Don't block pipelines (non-blocking validation)</li> <li>Track trends and historical patterns</li> <li>Support complex statistical analysis</li> <li>Integrate with Activity API for monitoring</li> </ul> <p>Key characteristics: - Configured in <code>checks/</code> directory - Use declarative YAML syntax - Organized by data quality dimensions - Results stored for historical analysis - Integrated with Activity API</p>"},{"location":"data-quality/#12-checks-vs-audits-vs-profiles","title":"1.2 Checks vs Audits vs Profiles","text":"<p>Understanding the three data quality mechanisms:</p> Feature Audits Checks Profiles Purpose Critical validation Monitoring &amp; analysis Observation &amp; tracking When runs With model (inline) Separately or with models With model Blocks pipeline? Yes (always) No No Configuration In MODEL DDL or .sql files YAML files (<code>checks/</code>) In MODEL DDL Output Pass/fail Pass/fail + samples Statistical metrics Best for Business rules, data integrity Trend monitoring, anomalies Understanding data Historical tracking No Yes (Activity API) Yes (<code>_check_profiles</code>) <p>The Three-Layer Strategy:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  AUDITS (Critical - Blocks Pipeline)   \u2502\n\u2502  \u2022 Primary keys must be unique          \u2502\n\u2502  \u2022 Revenue must be non-negative         \u2502\n\u2502  \u2022 Foreign key relationships valid      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n              \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  CHECKS (Monitoring - Non-Blocking)     \u2502\n\u2502  \u2022 Row count within expected range      \u2502\n\u2502  \u2022 Anomaly detection on metrics         \u2502\n\u2502  \u2022 Cross-table consistency              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n              \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  PROFILES (Observation - Metrics)       \u2502\n\u2502  \u2022 Track null percentages               \u2502\n\u2502  \u2022 Monitor column distributions         \u2502\n\u2502  \u2022 Detect data drift                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"data-quality/#13-when-to-use-checks","title":"1.3 When to Use Checks","text":"<p>\u2705 Use Quality Checks for: - Monitoring data quality trends over time - Statistical anomaly detection - Cross-model validation (joins across models) - Non-critical validation (warnings, not blockers) - Complex validation requiring historical context - Building data quality dashboards</p> <p>\u274c Use Audits Instead for: - Critical business rules that must pass - Model-specific validation (runs inline) - Simple SQL assertions - Blocking invalid data from flowing downstream</p> <p>\u274c Use Profiles Instead for: - Understanding data characteristics - Discovering patterns (not validation) - Detecting data drift - Informing which checks/audits to add</p> <p>Example: Revenue validation strategy</p> <pre><code>-- AUDIT (Critical - blocks if fails)\nMODEL (\n  name analytics.revenue,\n  assertions (\n    not_null(columns := (customer_id, revenue)),\n    accepted_range(column := revenue, min_v := 0, max_v := 100000000)\n  )\n);\n</code></pre> <pre><code># CHECK (Monitoring - warns if unusual)\nchecks:\n  analytics.revenue:\n    accuracy:\n      - anomaly detection for avg(revenue):\n          name: revenue_anomaly_detection\n      - change for row_count &gt;= -30%:\n          name: row_count_drop_alert\n</code></pre> <pre><code>-- PROFILE (Observation - tracks over time)\nMODEL (\n  name analytics.revenue,\n  profiles (revenue, order_count, customer_tier)\n);\n</code></pre>"},{"location":"data-quality/#14-check-language-overview","title":"1.4 Check Language Overview","text":"<p>Quality checks use a declarative YAML-based language for data quality validation.</p> <p>Key concepts: - Check - A validation rule (e.g., \"row_count &gt; 1000\") - Dimension - Data quality category (completeness, validity, etc.) - Filter - Subset of data to validate - Attributes - Metadata (name, description, severity) - Samples - Example rows that failed validation</p> <p>Example:</p> <pre><code>checks:\n  analytics.customers:\n    completeness:\n      - row_count &gt; 100:\n          name: sufficient_customers\n          attributes:\n            description: \"At least 100 customers expected\"\n            severity: warning\n</code></pre> <p>\u2191 Back to Top</p>"},{"location":"data-quality/#2-quick-start","title":"2. Quick Start","text":""},{"location":"data-quality/#21-your-first-check","title":"2.1 Your First Check","text":"<p>Create <code>checks/customers.yml</code>:</p> <pre><code>checks:\n  analytics.customers:\n    completeness:\n      - missing_count(email) = 0:\n          name: no_missing_emails\n          attributes:\n            description: \"All customers must have an email address\"\n</code></pre> <p>Run the check:</p> <pre><code>vulcan check\n</code></pre> <p>Output:</p> <pre><code>Running checks...\n\n\u2713 analytics.customers.no_missing_emails\n  Pass: missing_count(email) = 0 (actual: 0)\n\n----------------------------------------------------------------------\nRan 1 check in 0.234s\n\nOK\n</code></pre>"},{"location":"data-quality/#22-common-check-patterns","title":"2.2 Common Check Patterns","text":""},{"location":"data-quality/#pattern-1-completeness-checks","title":"Pattern 1: Completeness Checks","text":"<p>Ensure required data is present:</p> <pre><code>checks:\n  analytics.orders:\n    completeness:\n      - missing_count(customer_id) = 0:\n          name: customer_id_required\n\n      - missing_percent(email) &lt; 5:\n          name: email_mostly_complete\n\n      - row_count &gt; 1000:\n          name: sufficient_orders\n</code></pre>"},{"location":"data-quality/#pattern-2-validity-checks","title":"Pattern 2: Validity Checks","text":"<p>Validate data format and values:</p> <pre><code>checks:\n  analytics.users:\n    validity:\n      - failed rows:\n          name: invalid_emails\n          fail query: |\n            SELECT user_id, email\n            FROM analytics.users\n            WHERE email NOT LIKE '%@%'\n          samples limit: 10\n\n      - failed rows:\n          name: invalid_ages\n          fail query: |\n            SELECT user_id, age\n            FROM analytics.users\n            WHERE age &lt; 0 OR age &gt; 120\n</code></pre>"},{"location":"data-quality/#pattern-3-uniqueness-checks","title":"Pattern 3: Uniqueness Checks","text":"<p>Ensure no duplicates:</p> <pre><code>checks:\n  analytics.customers:\n    uniqueness:\n      - duplicate_count(email) = 0:\n          name: unique_emails\n\n      - duplicate_count(customer_id, order_date) = 0:\n          name: unique_customer_date_combination\n</code></pre>"},{"location":"data-quality/#pattern-4-anomaly-detection","title":"Pattern 4: Anomaly Detection","text":"<p>Detect unusual patterns:</p> <pre><code>checks:\n  analytics.daily_revenue:\n    accuracy:\n      - anomaly detection for row_count:\n          name: row_count_anomaly\n\n      - anomaly detection for avg(revenue):\n          name: revenue_anomaly\n</code></pre>"},{"location":"data-quality/#pattern-5-change-monitoring","title":"Pattern 5: Change Monitoring","text":"<p>Track changes over time:</p> <pre><code>checks:\n  analytics.orders:\n    timeliness:\n      - change for row_count &gt;= -50%:\n          name: row_count_drop_alert\n          attributes:\n            description: \"Alert if row count drops more than 50%\"\n</code></pre> <p>\u2191 Back to Top</p>"},{"location":"data-quality/#3-check-configuration","title":"3. Check Configuration","text":""},{"location":"data-quality/#31-file-structure","title":"3.1 File Structure","text":"<p>Checks are YAML files in the <code>checks/</code> directory:</p> <pre><code>project/\n\u251c\u2500\u2500 models/\n\u251c\u2500\u2500 checks/\n\u2502   \u251c\u2500\u2500 users.yml           # Checks for user tables\n\u2502   \u251c\u2500\u2500 orders.yml          # Checks for order tables\n\u2502   \u251c\u2500\u2500 revenue.yml         # Checks for revenue tables\n\u2502   \u2514\u2500\u2500 cross_model.yml     # Checks spanning multiple tables\n\u2514\u2500\u2500 config.yaml\n</code></pre> <p>File naming: - Must end with <code>.yml</code> or <code>.yaml</code> - Name doesn't matter (Vulcan reads all files) - Organize by domain or table for clarity</p>"},{"location":"data-quality/#32-basic-check-syntax","title":"3.2 Basic Check Syntax","text":"<pre><code>checks:\n  &lt;fully_qualified_table_name&gt;:\n    &lt;dimension&gt;:\n      - &lt;check_expression&gt;:\n          name: &lt;check_name&gt;\n          attributes:\n            description: &lt;human_readable_description&gt;\n            severity: &lt;warning|error&gt;\n            tags: [&lt;tag1&gt;, &lt;tag2&gt;]\n</code></pre> <p>Example:</p> <pre><code>checks:\n  analytics.customers:\n    completeness:\n      - row_count &gt; 100:\n          name: sufficient_customers\n          attributes:\n            description: \"At least 100 customers expected in production\"\n            severity: warning\n            tags: [critical, daily]\n</code></pre>"},{"location":"data-quality/#33-data-quality-dimensions","title":"3.3 Data Quality Dimensions","text":"<p>Organize checks by 8 standard dimensions (ODPS v3.1):</p>"},{"location":"data-quality/#1-completeness","title":"1. Completeness","text":"<p>No missing required data</p> <pre><code>completeness:\n  - missing_count(customer_id) = 0\n  - missing_percent(email) &lt; 5\n  - row_count &gt; 1000\n</code></pre>"},{"location":"data-quality/#2-validity","title":"2. Validity","text":"<p>Data conforms to format/syntax</p> <pre><code>validity:\n  - failed rows:\n      fail query: |\n        SELECT * FROM table\n        WHERE email NOT LIKE '%@%'\n</code></pre>"},{"location":"data-quality/#3-accuracy","title":"3. Accuracy","text":"<p>Data matches reality</p> <pre><code>accuracy:\n  - anomaly detection for avg(revenue)\n  - avg(age) between 18 and 65\n</code></pre>"},{"location":"data-quality/#4-consistency","title":"4. Consistency","text":"<p>Data agrees across sources</p> <pre><code>consistency:\n  - failed rows:\n      fail query: |\n        SELECT *\n        FROM orders o\n        LEFT JOIN customers c ON o.customer_id = c.customer_id\n        WHERE c.customer_id IS NULL\n</code></pre>"},{"location":"data-quality/#5-uniqueness","title":"5. Uniqueness","text":"<p>No duplicates</p> <pre><code>uniqueness:\n  - duplicate_count(email) = 0\n  - duplicate_count(order_id) = 0\n</code></pre>"},{"location":"data-quality/#6-timeliness","title":"6. Timeliness","text":"<p>Data is current</p> <pre><code>timeliness:\n  - change for row_count &gt;= -30%\n  - failed rows:\n      fail query: |\n        SELECT *\n        FROM orders\n        WHERE updated_at &lt; CURRENT_DATE - INTERVAL '7 days'\n</code></pre>"},{"location":"data-quality/#7-conformity","title":"7. Conformity","text":"<p>Follows standards</p> <pre><code>conformity:\n  - failed rows:\n      fail query: |\n        SELECT *\n        FROM addresses\n        WHERE LENGTH(zip_code) != 5\n</code></pre>"},{"location":"data-quality/#8-coverage","title":"8. Coverage","text":"<p>All records are present</p> <pre><code>coverage:\n  - row_count &gt;= 95% of historical_avg(row_count)\n</code></pre>"},{"location":"data-quality/#34-filtering-checks","title":"3.4 Filtering Checks","text":"<p>Apply checks to a subset of data:</p> <pre><code>checks:\n  analytics.orders:\n    filter: \"status = 'completed' AND order_date &gt;= CURRENT_DATE - INTERVAL '30 days'\"\n\n    completeness:\n      - missing_count(customer_id) = 0:\n          name: completed_orders_have_customers\n</code></pre> <p>Multiple filters:</p> <pre><code>checks:\n  analytics.customers:\n    filter: \"country = 'US'\"\n    completeness:\n      - row_count &gt; 1000\n\n  analytics.customers:\n    filter: \"country = 'EU'\"\n    completeness:\n      - row_count &gt; 500\n</code></pre>"},{"location":"data-quality/#35-check-attributes","title":"3.5 Check Attributes","text":"<p>Add metadata to checks:</p> <pre><code>checks:\n  analytics.revenue:\n    completeness:\n      - row_count &gt; 1000:\n          name: sufficient_revenue_data\n          attributes:\n            description: \"Revenue table must have at least 1000 rows for analysis\"\n            severity: error\n            tags: [critical, daily, revenue]\n            owner: data-team\n            jira: DATA-1234\n            sla: \"&lt; 1 hour\"\n</code></pre> <p>Standard attributes: - <code>description</code> - Human-readable explanation - <code>severity</code> - <code>error</code> (default) or <code>warning</code> - <code>tags</code> - List of tags for filtering/organization - <code>owner</code> - Team or person responsible - Custom attributes - Any key-value pairs</p> <p>\u2191 Back to Top</p>"},{"location":"data-quality/#4-built-in-check-types","title":"4. Built-in Check Types","text":""},{"location":"data-quality/#41-missing-data-checks","title":"4.1 Missing Data Checks","text":""},{"location":"data-quality/#missing_countcolumn","title":"<code>missing_count(column)</code>","text":"<p>Count of NULL values:</p> <pre><code>completeness:\n  - missing_count(email) = 0:\n      name: no_missing_emails\n\n  - missing_count(phone) &lt;= 100:\n      name: phone_mostly_complete\n</code></pre>"},{"location":"data-quality/#missing_percentcolumn","title":"<code>missing_percent(column)</code>","text":"<p>Percentage of NULL values:</p> <pre><code>completeness:\n  - missing_percent(email) &lt; 5:\n      name: email_95_percent_complete\n\n  - missing_percent(optional_field) &lt; 50:\n      name: optional_field_half_complete\n</code></pre>"},{"location":"data-quality/#42-row-count-checks","title":"4.2 Row Count Checks","text":""},{"location":"data-quality/#row_count","title":"<code>row_count</code>","text":"<p>Total rows in table:</p> <pre><code>completeness:\n  - row_count &gt; 1000:\n      name: sufficient_data\n\n  - row_count between 1000 and 100000:\n      name: expected_row_range\n</code></pre>"},{"location":"data-quality/#row_count-with-filter","title":"<code>row_count</code> with filter","text":"<pre><code>completeness:\n  - row_count &gt; 500:\n      name: sufficient_active_users\n      filter: \"status = 'active'\"\n</code></pre>"},{"location":"data-quality/#43-duplicate-count-checks","title":"4.3 Duplicate Count Checks","text":""},{"location":"data-quality/#duplicate_countcolumn","title":"<code>duplicate_count(column)</code>","text":"<p>Count of duplicate values:</p> <pre><code>uniqueness:\n  - duplicate_count(email) = 0:\n      name: unique_emails\n\n  - duplicate_count(customer_id) = 0:\n      name: unique_customer_ids\n</code></pre>"},{"location":"data-quality/#duplicate_countcolumn1-column2","title":"<code>duplicate_count(column1, column2)</code>","text":"<p>Composite key duplicates:</p> <pre><code>uniqueness:\n  - duplicate_count(customer_id, order_date) = 0:\n      name: unique_customer_date\n      attributes:\n        description: \"Each customer can have at most one order per day\"\n</code></pre>"},{"location":"data-quality/#44-failed-rows-checks","title":"4.4 Failed Rows Checks","text":""},{"location":"data-quality/#sql-based-validation-with-samples","title":"SQL-based validation with samples","text":"<p>Most flexible check type - any SQL query:</p> <pre><code>validity:\n  - failed rows:\n      name: invalid_revenue\n      fail query: |\n        SELECT customer_id, revenue, order_date\n        FROM analytics.orders\n        WHERE revenue &lt; 0 OR revenue &gt; 10000000\n      samples limit: 20\n      attributes:\n        description: \"Revenue must be between 0 and 10M\"\n</code></pre> <p>Key features: - <code>fail query</code> - SELECT statement that returns invalid rows - <code>samples limit</code> - How many example rows to capture (default: 5) - Returns empty = check passes - Returns rows = check fails (captures samples)</p> <p>Complex validation:</p> <pre><code>validity:\n  - failed rows:\n      name: orphaned_orders\n      fail query: |\n        SELECT o.order_id, o.customer_id\n        FROM analytics.orders o\n        LEFT JOIN analytics.customers c ON o.customer_id = c.customer_id\n        WHERE c.customer_id IS NULL\n      samples limit: 10\n</code></pre>"},{"location":"data-quality/#45-threshold-checks","title":"4.5 Threshold Checks","text":""},{"location":"data-quality/#numeric-aggregations","title":"Numeric aggregations","text":"<pre><code>accuracy:\n  - avg(revenue) between 100 and 10000:\n      name: revenue_in_expected_range\n\n  - sum(amount) &gt; 1000000:\n      name: sufficient_total_revenue\n\n  - max(age) &lt;= 120:\n      name: age_within_human_range\n\n  - min(price) &gt;= 0:\n      name: non_negative_prices\n</code></pre>"},{"location":"data-quality/#statistical-checks","title":"Statistical checks","text":"<pre><code>accuracy:\n  - stddev(revenue) &lt; 5000:\n      name: revenue_low_variance\n\n  - percentile(revenue, 95) &lt; 50000:\n      name: revenue_95th_percentile_check\n</code></pre>"},{"location":"data-quality/#46-anomaly-detection","title":"4.6 Anomaly Detection","text":""},{"location":"data-quality/#ml-based-anomaly-detection","title":"ML-based anomaly detection","text":"<p>Uses historical check results to detect anomalies:</p> <pre><code>accuracy:\n  - anomaly detection for row_count:\n      name: row_count_anomaly\n      attributes:\n        description: \"Detect unusual changes in row count\"\n\n  - anomaly detection for avg(revenue):\n      name: revenue_anomaly\n\n  - anomaly detection for distinct_count(customer_id):\n      name: customer_count_anomaly\n</code></pre> <p>How it works: 1. Collects historical metric values over time 2. Builds statistical model (mean, std dev, trends) 3. Compares current value to expected range 4. Flags significant deviations (typically &gt; 3 std devs)</p> <p>Requirements: - Needs historical data (runs multiple times) - Works best with regular schedules (daily, hourly) - More accurate after 30+ data points</p>"},{"location":"data-quality/#47-change-over-time-checks","title":"4.7 Change Over Time Checks","text":""},{"location":"data-quality/#monitor-changes-compared-to-previous-run","title":"Monitor changes compared to previous run","text":"<pre><code>timeliness:\n  - change for row_count &gt;= -50%:\n      name: row_count_drop_alert\n      attributes:\n        description: \"Alert if row count drops more than 50% from last week\"\n\n  - change for avg(revenue) &gt;= -20%:\n      name: revenue_drop_alert\n\n  - change for distinct_count(customer_id) &gt;= 10%:\n      name: customer_growth_check\n</code></pre> <p>Change calculation: <pre><code>change = (current_value - previous_value) / previous_value * 100\n</code></pre></p> <p>Examples: - <code>change &gt;= -30%</code> - Alert if metric drops more than 30% - <code>change &gt;= 10%</code> - Alert if metric grows more than 10% - <code>change between -10% and 10%</code> - Alert if metric changes more than 10% either way</p> <p>\u2191 Back to Top</p>"},{"location":"data-quality/#5-data-profiling","title":"5. Data Profiling","text":""},{"location":"data-quality/#51-what-is-profiling","title":"5.1 What is Profiling?","text":"<p>Profiles automatically collect statistical metrics about your data over time.</p> <p>Unlike checks (which validate), profiles observe and track data characteristics:</p> <pre><code>MODEL (\n  name analytics.customers,\n  kind FULL,\n  grains (customer_id),\n  profiles (revenue, signup_date, customer_tier, order_count)\n);\n</code></pre> <p>What gets profiled:</p> <p>Table-level metrics: - Row count</p> <p>Column-level metrics (all columns): - Null count &amp; percentage - Distinct count - Duplicate count - Uniqueness percentage</p> <p>Numeric columns: - Min, max, avg, sum - Standard deviation, variance - Histogram buckets</p> <p>Text columns: - Min, max, avg length - Most frequent values</p>"},{"location":"data-quality/#52-profile-configuration","title":"5.2 Profile Configuration","text":"<p>Enable profiling in MODEL:</p> <pre><code>MODEL (\n  name analytics.revenue_metrics,\n  kind INCREMENTAL_BY_TIME_RANGE (time_column metric_date),\n\n  -- Profile these columns\n  profiles (\n    revenue,\n    order_count,\n    customer_tier,\n    region\n  )\n);\n</code></pre>"},{"location":"data-quality/#53-profile-storage","title":"5.3 Profile Storage","text":"<p>Profiles are stored in the <code>_check_profiles</code> table:</p> <pre><code>SELECT\n  data_source,        -- Table name (e.g., 'analytics.customers')\n  column_name,        -- Column profiled\n  null_count,         -- Number of NULLs\n  null_percentage,    -- Percentage NULLs\n  distinct_count,     -- Number of unique values\n  duplicate_count,    -- Number of duplicates\n  min_value,          -- Minimum value (numeric/date)\n  max_value,          -- Maximum value (numeric/date)\n  avg_value,          -- Average (numeric)\n  stddev_value,       -- Standard deviation (numeric)\n  profiled_at,        -- When profile was collected\n  histogram           -- Distribution (JSON)\nFROM _check_profiles\nWHERE data_source = 'analytics.customers'\n  AND column_name = 'revenue'\nORDER BY profiled_at DESC;\n</code></pre>"},{"location":"data-quality/#54-querying-profiles","title":"5.4 Querying Profiles","text":""},{"location":"data-quality/#track-null-percentage-over-time","title":"Track null percentage over time","text":"<pre><code>SELECT\n  profiled_at::DATE as date,\n  null_percentage\nFROM _check_profiles\nWHERE data_source = 'analytics.customers'\n  AND column_name = 'email'\nORDER BY profiled_at DESC\nLIMIT 30;  -- Last 30 days\n</code></pre>"},{"location":"data-quality/#monitor-data-drift","title":"Monitor data drift","text":"<pre><code>WITH current AS (\n  SELECT distinct_count, avg_value\n  FROM _check_profiles\n  WHERE data_source = 'analytics.customers'\n    AND column_name = 'revenue'\n  ORDER BY profiled_at DESC\n  LIMIT 1\n),\nhistorical AS (\n  SELECT AVG(distinct_count) as avg_distinct, AVG(avg_value) as avg_revenue\n  FROM _check_profiles\n  WHERE data_source = 'analytics.customers'\n    AND column_name = 'revenue'\n    AND profiled_at &gt;= CURRENT_DATE - INTERVAL '30 days'\n)\nSELECT\n  c.distinct_count,\n  h.avg_distinct,\n  (c.distinct_count - h.avg_distinct) / h.avg_distinct * 100 as distinct_change_pct,\n  c.avg_value,\n  h.avg_revenue,\n  (c.avg_value - h.avg_revenue) / h.avg_revenue * 100 as revenue_change_pct\nFROM current c, historical h;\n</code></pre>"},{"location":"data-quality/#55-using-profiles-to-inform-checks","title":"5.5 Using Profiles to Inform Checks","text":"<p>Workflow:</p> <ol> <li>Enable profiling on new models</li> <li>Observe patterns for 30+ days</li> <li>Identify anomalies in profile data</li> <li>Create checks based on observed patterns</li> </ol> <p>Example:</p> <pre><code>-- Step 1: Enable profiling\nMODEL (\n  name analytics.orders,\n  profiles (order_count, revenue, customer_tier)\n);\n</code></pre> <pre><code>-- Step 2: Query profiles after 30 days\nSELECT\n  MIN(avg_value) as min_revenue,\n  MAX(avg_value) as max_revenue,\n  AVG(avg_value) as typical_revenue,\n  STDDEV(avg_value) as revenue_stddev\nFROM _check_profiles\nWHERE data_source = 'analytics.orders'\n  AND column_name = 'revenue'\n  AND profiled_at &gt;= CURRENT_DATE - INTERVAL '30 days';\n\n-- Results:\n-- min_revenue: 45000\n-- max_revenue: 75000\n-- typical_revenue: 58000\n-- revenue_stddev: 6000\n</code></pre> <pre><code># Step 3: Create checks based on observed patterns\nchecks:\n  analytics.orders:\n    accuracy:\n      - avg(revenue) between 40000 and 80000:\n          name: revenue_within_observed_range\n          attributes:\n            description: \"Based on 30-day historical analysis\"\n\n      - anomaly detection for avg(revenue):\n          name: revenue_anomaly_detection\n</code></pre>"},{"location":"data-quality/#56-profile-best-practices","title":"5.6 Profile Best Practices","text":"<p>\u2705 DO: - Profile high-value production tables - Profile columns used in downstream analysis - Use profiles to understand new data sources - Query profiles to detect data drift - Use profiles to inform check thresholds</p> <p>\u274c DON'T: - Profile sensitive/PII columns (privacy risk) - Profile every column (performance overhead) - Profile temporary/experimental models - Use profiles as a replacement for checks - Profile very high-frequency models (storage cost)</p> <p>When to use profiles: - Building new models (understand the data) - Monitoring production tables - Detecting data drift - Informing audit/check strategy - Debugging data quality issues</p> <p>When to skip profiles: - Temporary models - Models with sensitive data - Very high-frequency models (&gt; 100 runs/day) - Models where you only need pass/fail validation</p> <p>\u2191 Back to Top</p>"},{"location":"data-quality/#6-check-results-and-activity-api","title":"6. Check Results and Activity API","text":"<p>Status: To be determined - will be covered in Chapter 6 (APIs).</p> <p>This section will cover: - Activity API endpoints for check results - Querying check history - Building monitoring dashboards - Integrating with alerting systems</p> <p>\u2191 Back to Top</p>"},{"location":"data-quality/#7-advanced-patterns","title":"7. Advanced Patterns","text":""},{"location":"data-quality/#71-cross-model-validation","title":"7.1 Cross-Model Validation","text":"<p>Validate relationships between models:</p> <pre><code># checks/cross_model.yml\nchecks:\n  analytics.orders:\n    consistency:\n      - failed rows:\n          name: orphaned_orders\n          fail query: |\n            SELECT o.order_id, o.customer_id\n            FROM analytics.orders o\n            LEFT JOIN analytics.customers c ON o.customer_id = c.customer_id\n            WHERE c.customer_id IS NULL\n          samples limit: 10\n          attributes:\n            description: \"All orders must have a valid customer\"\n\n      - failed rows:\n          name: revenue_mismatch\n          fail query: |\n            SELECT\n              o.order_id,\n              o.revenue as order_revenue,\n              r.revenue as revenue_table_revenue\n            FROM analytics.orders o\n            JOIN analytics.revenue r ON o.order_id = r.order_id\n            WHERE ABS(o.revenue - r.revenue) &gt; 0.01\n</code></pre>"},{"location":"data-quality/#72-time-based-validation","title":"7.2 Time-Based Validation","text":"<p>Ensure data timeliness:</p> <pre><code>checks:\n  analytics.orders:\n    timeliness:\n      - failed rows:\n          name: stale_data\n          fail query: |\n            SELECT *\n            FROM analytics.orders\n            WHERE updated_at &lt; CURRENT_TIMESTAMP - INTERVAL '24 hours'\n              AND status != 'completed'\n          attributes:\n            description: \"Pending orders should update within 24 hours\"\n\n      - failed rows:\n          name: future_dates\n          fail query: |\n            SELECT *\n            FROM analytics.orders\n            WHERE order_date &gt; CURRENT_DATE\n</code></pre>"},{"location":"data-quality/#73-statistical-outlier-detection","title":"7.3 Statistical Outlier Detection","text":"<p>Custom outlier detection:</p> <pre><code>checks:\n  analytics.revenue:\n    accuracy:\n      - failed rows:\n          name: revenue_outliers\n          fail query: |\n            WITH stats AS (\n              SELECT\n                AVG(revenue) as mean,\n                STDDEV(revenue) as stddev\n              FROM analytics.revenue\n            )\n            SELECT r.*,\n              (r.revenue - s.mean) / s.stddev as z_score\n            FROM analytics.revenue r, stats s\n            WHERE ABS((r.revenue - s.mean) / s.stddev) &gt; 3\n          samples limit: 20\n</code></pre>"},{"location":"data-quality/#74-hierarchical-data-validation","title":"7.4 Hierarchical Data Validation","text":"<p>Validate parent-child relationships:</p> <pre><code>checks:\n  analytics.categories:\n    consistency:\n      - failed rows:\n          name: orphaned_subcategories\n          fail query: |\n            SELECT c.*\n            FROM analytics.categories c\n            LEFT JOIN analytics.categories p ON c.parent_id = p.category_id\n            WHERE c.parent_id IS NOT NULL\n              AND p.category_id IS NULL\n          attributes:\n            description: \"Subcategories must have valid parent\"\n\n      - failed rows:\n          name: circular_references\n          fail query: |\n            WITH RECURSIVE category_tree AS (\n              SELECT category_id, parent_id, 1 as depth\n              FROM analytics.categories\n              WHERE parent_id IS NOT NULL\n\n              UNION ALL\n\n              SELECT c.category_id, c.parent_id, ct.depth + 1\n              FROM analytics.categories c\n              JOIN category_tree ct ON c.parent_id = ct.category_id\n              WHERE ct.depth &lt; 10\n            )\n            SELECT *\n            FROM category_tree\n            WHERE depth &gt;= 10\n</code></pre>"},{"location":"data-quality/#75-multi-environment-checks","title":"7.5 Multi-Environment Checks","text":"<p>Different thresholds per environment:</p> <pre><code># checks/orders_prod.yml\nchecks:\n  analytics.orders:\n    filter: \"@{environment} = 'prod'\"\n    completeness:\n      - row_count &gt; 10000:\n          name: sufficient_orders_prod\n</code></pre> <pre><code># checks/orders_dev.yml\nchecks:\n  analytics.orders:\n    filter: \"@{environment} = 'dev'\"\n    completeness:\n      - row_count &gt; 100:\n          name: sufficient_orders_dev\n</code></pre>"},{"location":"data-quality/#76-custom-metrics","title":"7.6 Custom Metrics","text":"<p>Define reusable metric functions:</p> <pre><code>checks:\n  analytics.customers:\n    accuracy:\n      - failed rows:\n          name: suspicious_activity\n          fail query: |\n            WITH customer_metrics AS (\n              SELECT\n                customer_id,\n                COUNT(*) as order_count,\n                SUM(amount) as total_spent,\n                MAX(amount) as max_order\n              FROM analytics.orders\n              WHERE order_date &gt;= CURRENT_DATE - INTERVAL '30 days'\n              GROUP BY customer_id\n            )\n            SELECT *\n            FROM customer_metrics\n            WHERE order_count &gt; 100  -- Unusually high\n              OR total_spent &gt; 100000  -- Unusually expensive\n              OR max_order &gt; 50000  -- Single large order\n</code></pre> <p>\u2191 Back to Top</p>"},{"location":"data-quality/#8-best-practices","title":"8. Best Practices","text":""},{"location":"data-quality/#81-check-organization","title":"8.1 Check Organization","text":"<p>By domain:</p> <pre><code>checks/\n\u251c\u2500\u2500 customers/\n\u2502   \u251c\u2500\u2500 completeness.yml\n\u2502   \u251c\u2500\u2500 validity.yml\n\u2502   \u2514\u2500\u2500 consistency.yml\n\u251c\u2500\u2500 orders/\n\u2502   \u251c\u2500\u2500 completeness.yml\n\u2502   \u2514\u2500\u2500 timeliness.yml\n\u2514\u2500\u2500 revenue/\n    \u2514\u2500\u2500 accuracy.yml\n</code></pre> <p>By priority:</p> <pre><code>checks/\n\u251c\u2500\u2500 critical.yml      # Must never fail\n\u251c\u2500\u2500 important.yml     # Should rarely fail\n\u251c\u2500\u2500 monitoring.yml    # Track trends\n\u2514\u2500\u2500 experimental.yml  # Testing new checks\n</code></pre>"},{"location":"data-quality/#82-naming-conventions","title":"8.2 Naming Conventions","text":"<p>Use descriptive names:</p> <pre><code># \u274c Bad\nchecks:\n  analytics.customers:\n    completeness:\n      - missing_count(email) = 0:\n          name: check1\n\n# \u2705 Good\nchecks:\n  analytics.customers:\n    completeness:\n      - missing_count(email) = 0:\n          name: no_missing_customer_emails\n          attributes:\n            description: \"All customers must have an email for marketing\"\n</code></pre> <p>Naming pattern: - <code>&lt;dimension&gt;_&lt;what&gt;_&lt;constraint&gt;</code> - Examples:   - <code>completeness_email_required</code>   - <code>validity_email_format</code>   - <code>uniqueness_email_no_duplicates</code>   - <code>timeliness_order_within_24hrs</code></p>"},{"location":"data-quality/#83-threshold-selection","title":"8.3 Threshold Selection","text":"<p>Start conservative, adjust based on data:</p> <pre><code># Step 1: Start with wide range\nchecks:\n  analytics.orders:\n    completeness:\n      - row_count &gt; 100:\n          name: sufficient_orders_v1\n\n# Step 2: Monitor for 30 days, see actual range: 5000-10000\n\n# Step 3: Tighten based on observed patterns\nchecks:\n  analytics.orders:\n    completeness:\n      - row_count between 4000 and 12000:\n          name: sufficient_orders_v2\n          attributes:\n            description: \"Based on 30-day historical analysis\"\n</code></pre> <p>Use profiles to inform thresholds:</p> <pre><code>-- Query profiles\nSELECT\n  MIN(metric_value) as min_observed,\n  MAX(metric_value) as max_observed,\n  AVG(metric_value) as typical,\n  STDDEV(metric_value) as stddev\nFROM check_results\nWHERE check_name = 'row_count'\n  AND executed_at &gt;= CURRENT_DATE - INTERVAL '90 days';\n\n-- Set threshold as: typical \u00b1 3*stddev\n</code></pre>"},{"location":"data-quality/#84-sample-collection","title":"8.4 Sample Collection","text":"<p>Collect enough samples for debugging:</p> <pre><code>validity:\n  - failed rows:\n      name: invalid_emails\n      fail query: |\n        SELECT user_id, email, created_at\n        FROM users\n        WHERE email NOT LIKE '%@%'\n      samples limit: 20  # Enough to see patterns\n</code></pre> <p>Don't collect too many: - Storage cost increases - API response size grows - Usually 10-20 samples is enough</p>"},{"location":"data-quality/#85-check-cadence","title":"8.5 Check Cadence","text":"<p>Match check frequency to data freshness:</p> <pre><code># Real-time data (runs every hour)\nchecks:\n  analytics.orders:\n    timeliness:\n      - change for row_count &gt;= -30%:\n          name: hourly_order_count_check\n\n# Daily batch data (runs once per day)\nchecks:\n  analytics.daily_revenue:\n    completeness:\n      - row_count = 1:\n          name: one_row_per_day\n</code></pre> <p>Schedule checks appropriately: - High-frequency models \u2192 more frequent checks - Daily batch models \u2192 daily checks - Historical tables \u2192 weekly checks</p>"},{"location":"data-quality/#86-avoiding-check-fatigue","title":"8.6 Avoiding Check Fatigue","text":"<p>Don't create too many checks:</p> <pre><code># \u274c Too many (alert fatigue)\nchecks:\n  analytics.customers:\n    completeness:\n      - missing_count(email) = 0\n      - missing_count(first_name) = 0\n      - missing_count(last_name) = 0\n      - missing_count(phone) = 0\n      - missing_count(address) = 0\n      # ... 20 more columns\n\n# \u2705 Focus on critical fields\nchecks:\n  analytics.customers:\n    completeness:\n      - missing_count(email) = 0:\n          name: email_required\n      - missing_count(customer_id) = 0:\n          name: customer_id_required\n</code></pre> <p>Prioritize: 1. Critical business fields 2. Fields used in downstream analysis 3. Fields affecting revenue/compliance 4. Skip: internal metadata, optional fields</p>"},{"location":"data-quality/#87-documentation","title":"8.7 Documentation","text":"<p>Add context to every check:</p> <pre><code>checks:\n  analytics.revenue:\n    accuracy:\n      - avg(revenue) between 50000 and 80000:\n          name: revenue_within_expected_range\n          attributes:\n            description: |\n              Based on 90-day historical analysis (Dec 2023 - Feb 2024).\n              Alert data team if fails - may indicate:\n              - Missing data load\n              - Pricing change\n              - Seasonal anomaly\n            owner: data-team\n            slack: #data-quality-alerts\n            runbook: https://wiki.company.com/data/revenue-checks\n</code></pre>"},{"location":"data-quality/#88-integration-strategy","title":"8.8 Integration Strategy","text":"<p>Layer validation:</p> <pre><code>-- LAYER 1: Audits (critical - blocks)\nMODEL (\n  name analytics.orders,\n  assertions (\n    not_null(columns := (order_id, customer_id)),\n    unique_values(columns := (order_id))\n  )\n);\n</code></pre> <pre><code># LAYER 2: Checks (monitoring - warns)\nchecks:\n  analytics.orders:\n    completeness:\n      - row_count between 5000 and 15000:\n          name: order_count_in_range\n\n    timeliness:\n      - change for row_count &gt;= -30%:\n          name: order_count_stable\n</code></pre> <pre><code>-- LAYER 3: Profiles (observe - tracks)\nMODEL (\n  name analytics.orders,\n  profiles (order_count, revenue, customer_tier)\n);\n</code></pre> <p>\u2191 Back to Top</p>"},{"location":"data-quality/#9-troubleshooting","title":"9. Troubleshooting","text":""},{"location":"data-quality/#91-check-failures","title":"9.1 Check Failures","text":""},{"location":"data-quality/#investigate-failed-check","title":"Investigate failed check","text":"<pre><code># Run specific check with verbose output\nvulcan check --select analytics.customers.invalid_emails --verbose\n</code></pre>"},{"location":"data-quality/#query-failed-samples","title":"Query failed samples","text":"<pre><code>-- Get samples from last failed run\nSELECT *\nFROM check_samples\nWHERE check_name = 'invalid_emails'\n  AND status = 'failed'\nORDER BY executed_at DESC\nLIMIT 10;\n</code></pre>"},{"location":"data-quality/#compare-to-previous-runs","title":"Compare to previous runs","text":"<pre><code>-- Compare current vs previous\nWITH current_run AS (\n  SELECT metric_value\n  FROM check_results\n  WHERE check_name = 'row_count'\n  ORDER BY executed_at DESC\n  LIMIT 1\n),\nprevious_run AS (\n  SELECT metric_value\n  FROM check_results\n  WHERE check_name = 'row_count'\n  ORDER BY executed_at DESC\n  LIMIT 1 OFFSET 1\n)\nSELECT\n  c.metric_value as current_value,\n  p.metric_value as previous_value,\n  (c.metric_value - p.metric_value) / p.metric_value * 100 as change_pct\nFROM current_run c, previous_run p;\n</code></pre>"},{"location":"data-quality/#92-performance-issues","title":"9.2 Performance Issues","text":""},{"location":"data-quality/#slow-check-queries","title":"Slow check queries","text":"<p>Problem: Check takes too long to run</p> <p>Solution 1: Add filters</p> <pre><code># \u274c Slow - scans entire table\nchecks:\n  analytics.orders:\n    validity:\n      - failed rows:\n          fail query: |\n            SELECT * FROM analytics.orders\n            WHERE email NOT LIKE '%@%'\n\n# \u2705 Fast - filters to recent data\nchecks:\n  analytics.orders:\n    filter: \"order_date &gt;= CURRENT_DATE - INTERVAL '30 days'\"\n    validity:\n      - failed rows:\n          fail query: |\n            SELECT * FROM analytics.orders\n            WHERE email NOT LIKE '%@%'\n</code></pre> <p>Solution 2: Add indexes</p> <pre><code>-- Add index on frequently checked columns\nCREATE INDEX idx_orders_email ON analytics.orders(email);\nCREATE INDEX idx_orders_order_date ON analytics.orders(order_date);\n</code></pre> <p>Solution 3: Sample data</p> <pre><code># Check sample instead of full table\nchecks:\n  analytics.orders:\n    validity:\n      - failed rows:\n          fail query: |\n            SELECT * FROM analytics.orders TABLESAMPLE (10 PERCENT)\n            WHERE email NOT LIKE '%@%'\n</code></pre>"},{"location":"data-quality/#93-false-positives","title":"9.3 False Positives","text":""},{"location":"data-quality/#threshold-too-strict","title":"Threshold too strict","text":"<p>Problem: Check fails during normal variance</p> <pre><code># \u274c Too strict\nchecks:\n  analytics.orders:\n    completeness:\n      - row_count = 10000  # Exact match\n\n# \u2705 Allow variance\nchecks:\n  analytics.orders:\n    completeness:\n      - row_count between 9000 and 11000  # \u00b110% variance\n</code></pre>"},{"location":"data-quality/#use-anomaly-detection-instead","title":"Use anomaly detection instead","text":"<pre><code># Replace strict threshold with ML-based detection\nchecks:\n  analytics.orders:\n    accuracy:\n      - anomaly detection for row_count:\n          name: row_count_anomaly\n</code></pre>"},{"location":"data-quality/#94-missing-historical-data","title":"9.4 Missing Historical Data","text":"<p>Problem: Anomaly detection or change checks fail due to lack of history</p> <p>Solution: Wait for historical data to accumulate</p> <pre><code># Temporarily disable until enough history\nchecks:\n  analytics.new_table:\n    accuracy:\n      # - anomaly detection for row_count  # Commented until 30 days of data\n      - row_count &gt; 100  # Use simple threshold initially\n</code></pre>"},{"location":"data-quality/#95-check-configuration-errors","title":"9.5 Check Configuration Errors","text":""},{"location":"data-quality/#yaml-syntax-errors","title":"YAML syntax errors","text":"<pre><code># Validate YAML syntax\nvulcan check --dry-run\n\n# Error output:\n# ERROR: Invalid YAML in checks/customers.yml\n#   Line 15: unexpected character\n</code></pre>"},{"location":"data-quality/#invalid-sql-in-fail-query","title":"Invalid SQL in fail query","text":"<pre><code># Test SQL query directly\nvulcan run -c \"\n  SELECT * FROM analytics.orders\n  WHERE email NOT LIKE '%@%'\n  LIMIT 5\n\"\n</code></pre>"},{"location":"data-quality/#96-common-errors","title":"9.6 Common Errors","text":"<p>ERROR: Table not found</p> <pre><code># \u274c Wrong table name\nchecks:\n  analytics.customer:  # Should be 'customers'\n    completeness:\n      - row_count &gt; 100\n</code></pre> <p>ERROR: Column not found</p> <pre><code># \u274c Typo in column name\nchecks:\n  analytics.customers:\n    completeness:\n      - missing_count(emial) = 0  # Should be 'email'\n</code></pre> <p>ERROR: Check always fails</p> <pre><code># \u274c Logic error\nchecks:\n  analytics.orders:\n    completeness:\n      - row_count = 10000  # Exact match rarely works\n\n# \u2705 Use range\nchecks:\n  analytics.orders:\n    completeness:\n      - row_count between 9000 and 11000\n</code></pre> <p>\u2191 Back to Top</p>"},{"location":"data-quality/#summary","title":"Summary","text":"<p>You've learned the complete quality checks workflow in Vulcan:</p>"},{"location":"data-quality/#core-concepts","title":"Core Concepts","text":"<p>1. Quality Checks - YAML-configured validation rules - Non-blocking (don't stop pipelines) - Track trends over time - Integrate with Activity API</p> <p>2. Check Types - Missing data checks (<code>missing_count</code>, <code>missing_percent</code>) - Row count checks (<code>row_count</code>) - Duplicate checks (<code>duplicate_count</code>) - Failed rows (SQL-based) - Anomaly detection (ML-based) - Change monitoring (compare to previous)</p> <p>3. Data Profiling - Automatic statistical metric collection - Stored in <code>_check_profiles</code> table - Observe patterns without validation - Inform check threshold selection</p> <p>4. Data Quality Strategy - Audits - Critical, blocking - Checks - Monitoring, non-blocking - Profiles - Observation, tracking</p>"},{"location":"data-quality/#next-steps","title":"Next Steps","text":"<p>Continue to Chapter 6: APIs</p> <p>Learn how to: - Query check results via Activity API - Build data quality dashboards - Integrate checks with monitoring systems - Use Meta Graph API for lineage</p> <p>Additional Resources</p> <ul> <li>Check Language Documentation - Full language reference</li> <li>Activity API Reference (Chapter 6) - REST endpoints</li> <li>Examples - <code>examples/b2b_saas/checks/</code> in your Vulcan installation</li> </ul> <p>\u2191 Back to Top</p>"},{"location":"getting-started/","title":"Getting Started","text":"<p>Get productive in 30 minutes - Install Vulcan, create your first project, and understand the core concepts.</p>"},{"location":"getting-started/#what-is-vulcan","title":"What is Vulcan?","text":"<p>Vulcan is a complete stack for building data products. It gives you:</p> <ul> <li>Semantic Layer - Define business metrics and dimensions on top of physical models</li> <li>Data Validation - Built-in audits and quality checks</li> <li>Graph Database - Query lineage and relationships using Cypher</li> <li>API Layer - REST and Python APIs for programmatic access</li> </ul>"},{"location":"getting-started/#quick-start","title":"Quick Start","text":"<ol> <li>Installation - Install Vulcan and dependencies</li> <li>Your First Project - Create a simple project in 5 minutes</li> <li>Core Concepts - Understand how Vulcan works</li> <li>Integrations - Connect to DuckDB, Postgres, Snowflake, BigQuery, Databricks</li> </ol> <p>Content coming soon...</p>"},{"location":"models/","title":"Chapter 02: Models","text":"<p>Models are the foundation of your Vulcan project - SQL or Python transformations that create tables and views. Everything else (semantic layer, metrics, checks) builds on models.</p>"},{"location":"models/#prerequisites","title":"Prerequisites","text":"<p>Before diving into this chapter, you should have:</p>"},{"location":"models/#required-knowledge","title":"Required Knowledge","text":"<p>SQL Proficiency - Level 2 or 3 - CTEs (Common Table Expressions) - Window functions (<code>ROW_NUMBER</code>, <code>RANK</code>, <code>LAG</code>/<code>LEAD</code>) - Aggregations and <code>GROUP BY</code> - Joins (<code>INNER</code>, <code>LEFT</code>, <code>FULL</code>) - Basic date/time functions - ANSI SQL syntax - Vulcan supports ANSI SQL and can transpile between dialects - Type casting: <code>column::TYPE</code> syntax (e.g., <code>customer_id::INT</code>) - Your target warehouse SQL dialect (BigQuery, Snowflake, DuckDB, etc.)</p> <p>Data Modeling Concepts - Primary keys and foreign keys - Star schema / dimensional modeling basics - Normalization vs denormalization tradeoffs - Slowly changing dimensions (helpful but not required)</p>"},{"location":"models/#optional-but-helpful","title":"Optional but Helpful","text":"<p>Python - Intermediate Level (only if writing Python models) - Pandas DataFrame operations - Type hints and function signatures - Working with decorators (<code>@model</code>, <code>@signal</code>) - Virtual environments</p> <p>Adding Python Dependencies:</p> <p>If your Python models need additional packages (e.g., <code>scikit-learn</code> for ML, <code>requests</code> for API calls):</p> <pre><code># Add to your project's requirements.txt\npandas&gt;=2.0.0\nscikit-learn&gt;=1.3.0\nrequests&gt;=2.31.0\njoblib&gt;=1.3.0\n\n# Install in your virtual environment\npip install -r requirements.txt\n\n# Vulcan will use these packages during model execution\n</code></pre> <p>Basic Understanding of: - Data warehouses (Snowflake, BigQuery, DuckDB, Postgres) - ETL/ELT concepts - Version control (Git)</p> <p>If you're coming from dbt, you'll feel right at home - many concepts are similar, with added features for incremental processing, native semantic layer integration, and built-in data quality.</p>"},{"location":"models/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Model Basics</li> <li>SQL Models</li> <li>Python Models</li> <li>Model Kinds</li> <li>Essential Model Properties</li> <li>Grain and Keys</li> <li>Audits</li> <li>Data Quality Checks</li> <li>Unit Tests</li> <li>Signals</li> <li>Macros</li> <li>Best Practices</li> <li>Quick Reference</li> </ol>"},{"location":"models/#1-model-basics","title":"1. Model Basics","text":"<p>Models are SQL or Python transformations that create tables and views in your data warehouse. They're the foundation of your Vulcan project - everything else (semantic layer, metrics, checks) builds on top of models.</p> <p>Vulcan extends the transformation layer popularized by dbt with additional features like incremental processing, data quality checks, and native semantic layer integration.</p>"},{"location":"models/#what-are-models","title":"What Are Models?","text":"<p>Quick Example:</p> <pre><code>-- models/customers.sql\nMODEL (\n  name my_project.customers,\n  kind FULL,\n  cron '@daily'\n);\n\nSELECT \n  customer_id,\n  email,\n  signup_date,\n  plan_type\nFROM raw.user_accounts;\n</code></pre> <p>This creates a <code>customers</code> table that refreshes daily.</p>"},{"location":"models/#model-types","title":"Model Types","text":"Type Use Case Example SQL Model Most common - SQL transformations Aggregations, joins, filters Python Model Complex logic, ML, API calls Feature engineering, predictions Seed Model Static reference data Country codes, product categories External Model Existing tables not managed by Vulcan Raw data sources"},{"location":"models/#model-kinds-materialization","title":"Model Kinds (Materialization)","text":"Kind When to Use Performance <code>VIEW</code> Fast-changing logic, small data Instant refresh <code>FULL</code> Complete refresh needed Slow for large tables <code>INCREMENTAL_BY_TIME_RANGE</code> Time-partitioned data 10-100x faster <code>INCREMENTAL_BY_UNIQUE_KEY</code> Upsert by key Fast <code>SCD_TYPE_2</code> Track historical changes Medium"},{"location":"models/#decision-tree-which-model-kind","title":"Decision Tree: Which Model Kind?","text":"<pre><code>Do you have a timestamp column?\n\u251c\u2500 Yes \u2192 Use INCREMENTAL_BY_TIME_RANGE \u2705 (90% of cases)\n\u2502\n\u2514\u2500 No \u2192 Does the data have a unique key?\n   \u251c\u2500 Yes \u2192 Need history tracking?\n   \u2502  \u251c\u2500 Yes \u2192 Use SCD_TYPE_2 \u2705\n   \u2502  \u2514\u2500 No \u2192 Use INCREMENTAL_BY_UNIQUE_KEY \u2705\n   \u2502\n   \u2514\u2500 No \u2192 Is the table small (&lt;1M rows)?\n      \u251c\u2500 Yes \u2192 Use FULL \u2705\n      \u2514\u2500 No \u2192 Use VIEW \u2705 (or add a timestamp!)\n</code></pre>"},{"location":"models/#model-structure-overview","title":"Model Structure Overview","text":"<p>Every model has two parts:</p> <p>1. MODEL DDL (Metadata)</p> <pre><code>MODEL (\n  name schema.table_name,     -- Required: Where to store results\n  kind INCREMENTAL_BY_...,     -- Required: How to refresh\n  cron '@daily',               -- When to run\n  grain unique_key,            -- Primary key (optional but recommended)\n  assertions (...)             -- Data quality checks (optional)\n);\n</code></pre> <p>2. Query (Transformation Logic)</p> <pre><code>SELECT\n  column1::TYPE,\n  column2::TYPE,\n  ...\nFROM source_table\nWHERE conditions;\n</code></pre>"},{"location":"models/#vulcan-specific-considerations","title":"Vulcan-Specific Considerations","text":"<p>Key Insight: Model columns automatically become dimensions in the semantic layer!</p> <pre><code>-- This model:\nSELECT \n  customer_id,\n  customer_tier,\n  signup_date\nFROM raw.users;\n\n-- Automatically exposes these dimensions:\n-- \u2713 customer_id\n-- \u2713 customer_tier  (filterable, groupable)\n-- \u2713 signup_date    (time dimension)\n</code></pre> <p>Design Principle: Write models with business users in mind, not just technical requirements.</p> <p>\u2191 Back to Top</p>"},{"location":"models/#2-sql-models","title":"2. SQL Models","text":"<p>SQL models are the most common model type. They define transformations using SQL with metadata in the <code>MODEL</code> DDL.</p>"},{"location":"models/#basic-structure","title":"Basic Structure","text":"<pre><code>-- models/orders.sql\n\n-- MODEL DDL (metadata)\nMODEL (\n  name my_project.orders,           -- Required: Fully qualified name\n  kind INCREMENTAL_BY_TIME_RANGE (  -- How to refresh data\n    time_column order_date\n  ),\n  cron '@hourly',                   -- When to run\n  grain order_id,                   -- Unique identifier\n  assertions (not_null(columns := (order_id, customer_id)))  -- Data quality\n);\n\n-- SQL Query (transformation logic)\nSELECT\n  order_id::INT,\n  customer_id::INT,\n  order_date::DATE,\n  total_amount::DECIMAL(10,2),\n  status::VARCHAR\nFROM raw.orders\nWHERE order_date BETWEEN @start_date AND @end_date;\n</code></pre>"},{"location":"models/#sql-dialect-and-type-casting","title":"SQL Dialect and Type Casting","text":"<p>Vulcan supports ANSI SQL and can transpile between dialects automatically.</p>"},{"location":"models/#type-casting-syntax","title":"Type Casting Syntax","text":"<p>Always use PostgreSQL-style casting with <code>::TYPE</code>:</p> <pre><code>SELECT\n  customer_id::INT,              -- Cast to integer\n  email::VARCHAR,                -- Cast to string\n  signup_date::DATE,             -- Cast to date\n  revenue::DECIMAL(10,2),        -- Cast to decimal with precision\n  is_active::BOOLEAN,            -- Cast to boolean\n  metadata::JSON                 -- Cast to JSON\nFROM staging.customers;\n</code></pre>"},{"location":"models/#common-sql-types","title":"Common SQL Types","text":"Type Example Use Case <code>::INT</code> <code>customer_id::INT</code> Integer IDs, counts <code>::BIGINT</code> <code>user_id::BIGINT</code> Large integers <code>::VARCHAR</code> <code>email::VARCHAR</code> Text/strings <code>::TEXT</code> <code>description::TEXT</code> Long text <code>::DATE</code> <code>order_date::DATE</code> Dates (no time) <code>::TIMESTAMP</code> <code>created_at::TIMESTAMP</code> Dates with time <code>::DECIMAL(p,s)</code> <code>revenue::DECIMAL(10,2)</code> Money, precise numbers <code>::FLOAT</code> <code>score::FLOAT</code> Approximate numbers <code>::BOOLEAN</code> <code>is_active::BOOLEAN</code> True/false <code>::JSON</code> <code>metadata::JSON</code> JSON data"},{"location":"models/#multi-dialect-support","title":"Multi-Dialect Support","text":"<ul> <li>Write models in your target warehouse dialect (BigQuery, Snowflake, DuckDB, etc.)</li> <li>Vulcan can transpile SQL between dialects when needed</li> <li>Warehouse-specific functions and syntax are supported</li> </ul>"},{"location":"models/#why-explicit-type-casting","title":"Why Explicit Type Casting?","text":"<p>Always cast column types for: - Clear data contracts - Documents expected types - Type safety - Catch type mismatches early - Better error messages - Fails fast with clear errors - Semantic layer integration - Knows column types for metrics/dimensions</p> <pre><code>-- \u274c Bad: No type casting\nSELECT\n  customer_id,\n  revenue,\n  order_date\nFROM staging.orders;\n\n-- \u2705 Good: Explicit types\nSELECT\n  customer_id::INT,\n  revenue::DECIMAL(10,2),\n  order_date::DATE\nFROM staging.orders;\n</code></pre>"},{"location":"models/#complete-example-analytics-model","title":"Complete Example: Analytics Model","text":"<pre><code>-- models/analytics/customer_daily_revenue.sql\nMODEL (\n  name analytics.customer_daily_revenue,\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column revenue_date\n  ),\n  cron '@hourly',\n  start '2024-01-01',\n  grain (customer_id, revenue_date),\n  owner 'data-team',\n  tags ('analytics', 'revenue', 'customer'),\n  description 'Daily revenue aggregated by customer',\n  column_descriptions (\n    customer_id = 'Unique customer identifier',\n    revenue_date = 'Date of revenue (YYYY-MM-DD)',\n    revenue = 'Total revenue in USD from completed orders',\n    order_count = 'Number of completed orders'\n  ),\n  assertions (\n    not_null(columns := (customer_id, revenue_date, revenue)),\n    unique_combination_of_columns(columns := (customer_id, revenue_date)),\n    accepted_range(column := revenue, min_v := 0, max_v := 10000000)\n  )\n);\n\nSELECT\n  customer_id::INT,\n  order_date::DATE as revenue_date,\n  SUM(amount)::DECIMAL(10,2) as revenue,\n  COUNT(*)::INT as order_count\nFROM staging.orders\nWHERE order_date BETWEEN @start_date AND @end_date\n  AND status = 'completed'\nGROUP BY customer_id, order_date;\n</code></pre> <p>For comprehensive property reference, see Chapter 2A: Model Properties</p> <p>\u2191 Back to Top</p>"},{"location":"models/#3-python-models","title":"3. Python Models","text":"<p>Use Python models when SQL isn't enough - complex business logic, machine learning, API calls, or data science workflows.</p>"},{"location":"models/#when-to-use-python-models","title":"When to Use Python Models","text":"<p>\u2705 Good Use Cases: - Machine learning inference - Complex calculations (statistical models, financial formulas) - API calls to external services - Data enrichment from external sources - Custom data transformations not possible in SQL - Advanced pandas/numpy operations</p> <p>\u274c Use SQL Instead: - Joins, aggregations, filters (SQL is faster) - Standard transformations (SQL is more maintainable) - Simple calculations - Time-series windowing</p>"},{"location":"models/#basic-structure_1","title":"Basic Structure","text":"<pre><code># models/ml_predictions.py\n\nfrom vulcan import ExecutionContext, model\nimport pandas as pd\nimport typing as t\nfrom datetime import datetime\n\n@model(\n    \"my_project.customer_predictions\",\n    kind=\"FULL\",\n    cron=\"@daily\",\n    columns={\n        \"customer_id\": \"INT\",\n        \"churn_probability\": \"FLOAT\",\n        \"predicted_ltv\": \"DECIMAL(10,2)\",\n        \"prediction_date\": \"DATE\",\n    },\n    column_descriptions={\n        \"churn_probability\": \"Probability customer will churn in next 30 days (0-1)\",\n        \"predicted_ltv\": \"Predicted lifetime value in USD\",\n    }\n)\ndef execute(\n    context: ExecutionContext,\n    start: datetime,\n    end: datetime,\n    execution_time: datetime,\n    **kwargs: t.Any,\n) -&gt; pd.DataFrame:\n    \"\"\"Generate customer churn predictions using ML model.\"\"\"\n\n    # Fetch data from warehouse\n    customers = context.fetchdf(\"\"\"\n        SELECT \n            customer_id,\n            tenure_days,\n            total_spent,\n            engagement_score\n        FROM analytics.customers\n        WHERE status = 'active'\n    \"\"\")\n\n    # Load your ML model\n    import joblib\n    model = joblib.load(\"models/churn_model.pkl\")\n\n    # Make predictions\n    features = customers[['tenure_days', 'total_spent', 'engagement_score']]\n    customers['churn_probability'] = model.predict_proba(features)[:, 1]\n    customers['predicted_ltv'] = customers['total_spent'] * (1 - customers['churn_probability']) * 2\n    customers['prediction_date'] = execution_time.date()\n\n    return customers[['customer_id', 'churn_probability', 'predicted_ltv', 'prediction_date']]\n</code></pre>"},{"location":"models/#model-decorator-parameters","title":"@model Decorator Parameters","text":""},{"location":"models/#required-parameters","title":"Required Parameters","text":"<p>Model name:</p> <pre><code>@model(\"my_project.table_name\")\n</code></pre> <p>Column definitions:</p> <pre><code>columns={\n    \"id\": \"INT\",\n    \"name\": \"VARCHAR\",\n    \"amount\": \"DECIMAL(10,2)\",\n    \"created_at\": \"TIMESTAMP\",\n}\n</code></pre> <p>NOTE: Required - Python can't infer column types like SQL can</p>"},{"location":"models/#optional-parameters","title":"Optional Parameters","text":"<p>Model kind:</p> <pre><code>kind=\"FULL\"  # Default for Python models\n\n# Incremental also supported:\nkind=dict(\n    name=\"INCREMENTAL_BY_TIME_RANGE\",\n    time_column=\"event_date\"\n)\n</code></pre> <p>Scheduling:</p> <pre><code>cron=\"@daily\",\nowner=\"ml-team\",\ntags=[\"ml\", \"predictions\"],\n</code></pre> <p>Column descriptions:</p> <pre><code>column_descriptions={\n    \"churn_probability\": \"ML model prediction (0-1 scale)\",\n    \"customer_id\": \"Foreign key to customers table\",\n}\n</code></pre> <p>\u2705 Flows through to semantic layer</p> <p>Audits:</p> <pre><code>audits=[\n    (\"not_null\", {\"columns\": [\"customer_id\"]}),\n    (\"accepted_range\", {\"column\": \"churn_probability\", \"min_v\": 0, \"max_v\": 1}),\n]\n</code></pre>"},{"location":"models/#executioncontext-api","title":"ExecutionContext API","text":"<p>The <code>context</code> object provides access to your warehouse:</p>"},{"location":"models/#fetch-data","title":"Fetch Data","text":"<p><code>context.fetchdf(query)</code> - Execute SQL, return pandas DataFrame</p> <pre><code>df = context.fetchdf(\"SELECT * FROM customers WHERE active = true\")\n</code></pre> <p><code>context.fetchone(query)</code> - Return single row as tuple</p> <pre><code>(max_id,) = context.fetchone(\"SELECT MAX(id) FROM customers\")\n</code></pre> <p><code>context.fetchall(query)</code> - Return all rows as list of tuples</p> <pre><code>rows = context.fetchall(\"SELECT id, name FROM customers LIMIT 10\")\n</code></pre>"},{"location":"models/#table-operations","title":"Table Operations","text":"<p><code>context.table(table_name)</code> - Get table reference</p> <pre><code>table_ref = context.table(\"raw.events\")\ndf = context.fetchdf(f\"SELECT * FROM {table_ref} LIMIT 1000\")\n</code></pre>"},{"location":"models/#macros-and-variables","title":"Macros and Variables","text":"<p>Built-in time variables:</p> <pre><code>def execute(context, start, end, execution_time, **kwargs):\n    print(f\"Processing data from {start} to {end}\")\n    print(f\"Execution time: {execution_time}\")\n    # start/end: datetime objects for incremental models\n    # execution_time: when the model is running\n</code></pre>"},{"location":"models/#python-model-limitations","title":"Python Model Limitations","text":"<p>Unsupported model kinds: - <code>VIEW</code> - Use SQL models for views - <code>SEED</code> - Use SQL models for seed data - <code>MANAGED</code> - Use SQL models for managed tables - <code>EMBEDDED</code> - Use SQL models for embedded queries</p> <p>Supported model kinds for Python: - \u2705 <code>FULL</code> - Complete refresh (default) - \u2705 <code>INCREMENTAL_BY_TIME_RANGE</code> - Time-partitioned incremental - \u2705 <code>INCREMENTAL_BY_UNIQUE_KEY</code> - Upsert by key - \u2705 <code>SCD_TYPE_2</code> - Historical tracking</p> <p>For advanced Python patterns, see Chapter 2C: Model Operations</p> <p>\u2191 Back to Top</p>"},{"location":"models/#4-model-kinds","title":"4. Model Kinds","text":"<p>How your model refreshes data - the most important performance decision.</p>"},{"location":"models/#quick-reference","title":"Quick Reference","text":"Kind Refresh Strategy Use Case Performance <code>VIEW</code> Query-time Fast-changing logic Instant refresh <code>FULL</code> Drop + recreate Small tables Slow for large data <code>INCREMENTAL_BY_TIME_RANGE</code> Partition by date Time-series data 10-100x faster <code>INCREMENTAL_BY_UNIQUE_KEY</code> Upsert by key Slowly changing Fast <code>SCD_TYPE_2</code> Track history Historical tracking Medium <code>SEED</code> Load from CSV Static reference data One-time load <code>EXTERNAL</code> No refresh Existing tables N/A <code>EMBEDDED</code> Inline subquery Reusable logic No storage <code>MANAGED</code> Engine-managed Engine auto-refresh Engine-dependent"},{"location":"models/#choosing-the-right-kind","title":"Choosing the Right Kind","text":"<p>Decision Tree:</p> <pre><code>Does the data have a timestamp column?\n\u251c\u2500 Yes \u2192 Use INCREMENTAL_BY_TIME_RANGE \u2705 (90% of cases)\n\u2502\n\u2514\u2500 No \u2192 Does the data have a unique key?\n   \u251c\u2500 Yes \u2192 Need history tracking?\n   \u2502  \u251c\u2500 Yes \u2192 Use SCD_TYPE_2 \u2705\n   \u2502  \u2514\u2500 No \u2192 Use INCREMENTAL_BY_UNIQUE_KEY \u2705\n   \u2502\n   \u2514\u2500 No \u2192 Is the table small (&lt;1M rows)?\n      \u251c\u2500 Yes \u2192 Use FULL \u2705\n      \u2514\u2500 No \u2192 Use VIEW \u2705 (or add a timestamp!)\n</code></pre>"},{"location":"models/#view-no-materialization","title":"VIEW - No Materialization","text":"<p>How it works: Model is a view - query runs every time someone accesses it</p> <pre><code>MODEL (\n  name my_project.active_customers,\n  kind VIEW\n);\n\nSELECT * FROM customers WHERE status = 'active';\n</code></pre> <p>When to use: - Logic changes frequently - Data volume is small - Real-time freshness required - NOT recommended if queries are slow (use FULL instead)</p>"},{"location":"models/#full-complete-refresh","title":"FULL - Complete Refresh","text":"<p>How it works: Drops table and rebuilds from scratch every run</p> <pre><code>MODEL (\n  name my_project.customer_summary,\n  kind FULL,\n  cron '@daily'\n);\n\nSELECT \n  customer_id,\n  COUNT(*) as order_count,\n  SUM(amount) as total_spent\nFROM orders\nGROUP BY customer_id;\n</code></pre> <p>When to use: - Small to medium tables (&lt; 10M rows) - Simple, reliable refresh logic - NOT recommended for large tables (too slow)</p>"},{"location":"models/#incremental_by_time_range-time-partitions-most-common","title":"INCREMENTAL_BY_TIME_RANGE - Time Partitions (Most Common)","text":"<p>How it works: Only processes new time intervals</p> <pre><code>MODEL (\n  name my_project.daily_events,\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column event_date,\n    lookback 3  -- Reprocess last 3 days\n  ),\n  cron '@daily',\n  start '2020-01-01'\n);\n\nSELECT\n  event_id::INT,\n  event_date::DATE,\n  user_id::INT,\n  event_type::VARCHAR\nFROM raw.events\nWHERE event_date BETWEEN @start_date AND @end_date;  -- Magic variables!\n</code></pre> <p>When to use: - \u2705 Time-series data (events, transactions, metrics) - \u2705 Large datasets (millions+ rows) - \u2705 Need 10-100x performance improvement - \u2705 Data arrives in time order</p> <p>Key features: - <code>time_column</code> - Column that defines time intervals - <code>lookback</code> - Reprocess last N intervals (handles late-arriving data) - <code>@start_date</code> / <code>@end_date</code> - Automatic variables for time range</p> <p>For advanced incremental properties, see Chapter 2A: Model Properties</p>"},{"location":"models/#incremental_by_unique_key-upsert-by-key","title":"INCREMENTAL_BY_UNIQUE_KEY - Upsert by Key","text":"<p>How it works: Upserts (insert or update) rows based on unique key</p> <pre><code>MODEL (\n  name my_project.customers,\n  kind INCREMENTAL_BY_UNIQUE_KEY (\n    unique_key customer_id\n  ),\n  cron '@daily'\n);\n\nSELECT\n  customer_id::INT,\n  email::VARCHAR,\n  signup_date::DATE,\n  last_login_date::DATE,\n  total_spent::DECIMAL(10,2)\nFROM raw.customer_updates;\n</code></pre> <p>When to use: - \u2705 Slowly changing dimensions (customer info, product catalog) - \u2705 Upsert semantics (update existing, insert new) - \u2705 No timestamp column available - \u2705 Need to track current state (not history)</p> <p>Key features: - <code>unique_key</code> - Column(s) that uniquely identify a row - Automatically handles INSERT for new rows, UPDATE for existing rows - More efficient than FULL refresh for large dimension tables</p>"},{"location":"models/#scd_type_2-historical-tracking","title":"SCD_TYPE_2 - Historical Tracking","text":"<p>How it works: Tracks historical changes with <code>valid_from</code> and <code>valid_to</code> columns</p> <pre><code>MODEL (\n  name my_project.customer_history,\n  kind SCD_TYPE_2 (\n    unique_key customer_id\n  ),\n  cron '@daily'\n);\n\nSELECT\n  customer_id::INT,\n  email::VARCHAR,\n  customer_tier::VARCHAR,\n  updated_at::TIMESTAMP\nFROM raw.customer_updates;\n</code></pre> <p>When to use: - \u2705 Need to track historical changes - \u2705 \"Point in time\" queries (what was customer tier on date X?) - \u2705 Audit trail requirements - \u2705 Dimension tables with changing attributes</p> <p>Key features: - Automatically adds <code>valid_from</code> and <code>valid_to</code> columns - Tracks when each version of a row was valid - Enables time-travel queries</p>"},{"location":"models/#seed-static-reference-data","title":"SEED - Static Reference Data","text":"<p>How it works: Loads data from CSV files stored in your project</p> <pre><code>-- models/reference/national_holidays.sql\nMODEL (\n  name reference.national_holidays,\n  kind SEED (\n    path 'national_holidays.csv'\n  ),\n  columns (\n    holiday_name VARCHAR,\n    holiday_date DATE\n  ),\n  grain (holiday_date)\n);\n</code></pre> <p>When to use: - \u2705 Static reference data (country codes, product categories) - \u2705 Data that changes infrequently - \u2705 Small datasets (&lt; 100K rows) - \u2705 No SQL source available</p> <p>Key features: - CSV file stored in <code>seeds/</code> directory - Loaded once unless CSV or model changes - Can be referenced by other models like any table - NOTE: Python models don't support SEED kind - use SQL</p> <p>Example CSV:</p> <pre><code>holiday_name,holiday_date\nNew Year's Day,2024-01-01\nIndependence Day,2024-07-04\nChristmas,2024-12-25\n</code></pre>"},{"location":"models/#external-existing-tables","title":"EXTERNAL - Existing Tables","text":"<p>How it works: Declares metadata about tables managed outside Vulcan</p> <pre><code># external_models.yaml\n- name: external_db.external_table\n  description: Third-party data source\n  columns:\n    id: int\n    name: varchar\n    created_at: timestamp\n</code></pre> <p>When to use: - \u2705 Tables created/managed outside Vulcan - \u2705 Third-party data sources - \u2705 Read-only external systems - \u2705 Need column-level lineage</p> <p>Key features: - No query defined (table exists externally) - Vulcan doesn't manage or refresh the table - Used for lineage and type information - Can define audits on external models</p> <p>NOTE: External models are defined in YAML, not SQL files.</p>"},{"location":"models/#embedded-inline-subqueries","title":"EMBEDDED - Inline Subqueries","text":"<p>How it works: Query is embedded directly into downstream models (no physical table)</p> <pre><code>MODEL (\n  name my_project.unique_employees,\n  kind EMBEDDED\n);\n\nSELECT DISTINCT\n  employee_name,\n  department\nFROM raw.employees;\n</code></pre> <p>When to use: - \u2705 Reusable logic that doesn't need storage - \u2705 Common subqueries used by multiple models - \u2705 Performance optimization (avoids materialization) - \u2705 Logic that changes frequently</p> <p>Key features: - No physical table created - Query injected as subquery into downstream models - Useful for reusable CTEs - NOTE: Python models don't support EMBEDDED kind - use SQL</p>"},{"location":"models/#managed-engine-managed-tables","title":"MANAGED - Engine-Managed Tables","text":"<p>How it works: Database engine automatically refreshes the table (no manual refresh needed)</p> <pre><code>MODEL (\n  name analytics.real_time_events,\n  kind MANAGED,\n  physical_properties (\n    warehouse = 'COMPUTE_WH',\n    target_lag = '2 minutes',\n    data_retention_time_in_days = 2\n  )\n);\n\nSELECT\n  event_id::INT,\n  event_date::DATE,\n  event_type::VARCHAR\nFROM raw.events;\n</code></pre> <p>When to use: - \u2705 Real-time data freshness requirements - \u2705 Engine-native auto-refresh (Snowflake Dynamic Tables) - \u2705 External data sources not managed by Vulcan - \u2705 Need automatic incremental updates</p> <p>Key features: - Engine manages data refresh automatically - No <code>cron</code> needed (engine handles scheduling) - No date filters needed (engine handles incremental updates) - Currently only supported in Snowflake (Dynamic Tables) - NOTE: Python models don't support MANAGED kind - use SQL - NOTE: Still under development - API may change</p> <p>\u26a0\ufe0f Important considerations: - Engine-specific (not portable between warehouses) - Additional costs (e.g., Snowflake Dynamic Tables) - Limited visibility into refresh state - Typically built off External Models, not other Vulcan models</p> <p>For comprehensive model kind details, see Chapter 2A: Model Properties</p> <p>\u2191 Back to Top</p>"},{"location":"models/#5-essential-model-properties","title":"5. Essential Model Properties","text":"<p>Model properties control how models behave, when they run, and how they're configured. This section covers the essential properties you'll use most often.</p>"},{"location":"models/#required-properties","title":"Required Properties","text":""},{"location":"models/#name-model-name","title":"<code>name</code> - Model Name","text":"<p>Fully qualified model name in <code>schema.table</code> format:</p> <pre><code>MODEL (\n  name analytics.customers  -- schema.table format\n);\n</code></pre> <p>Best Practice: Use consistent naming: - <code>raw.*</code> - Raw ingested data - <code>staging.*</code> - Cleaned, typed data - <code>analytics.*</code> - Business logic transformations - <code>metrics.*</code> - Aggregated metrics</p>"},{"location":"models/#kind-materialization-strategy","title":"<code>kind</code> - Materialization Strategy","text":"<p>How the model materializes data:</p> <p>For Time-Series Data (90% of models):</p> <pre><code>kind INCREMENTAL_BY_TIME_RANGE (\n  time_column event_timestamp\n)\n</code></pre> <p>\u2705 Only processes new/changed data \u2705 10-100x faster than FULL refresh \u2705 Required for large datasets</p> <p>For Full Refresh:</p> <pre><code>kind FULL\n</code></pre> <p>\u26a0\ufe0f WARNING: Rebuilds entire table every run \u2705 Simple, reliable \u274c Slow for large data</p>"},{"location":"models/#scheduling-properties","title":"Scheduling Properties","text":""},{"location":"models/#cron-schedule-expression","title":"<code>cron</code> - Schedule Expression","text":"<p>When the model runs:</p> <pre><code>cron '@hourly'         -- Every hour\ncron '@daily'          -- Every day at midnight UTC\ncron '@weekly'         -- Every Monday at midnight\ncron '0 */4 * * *'     -- Every 4 hours (cron expression)\n</code></pre> <p>TIP: Match <code>cron</code> to your data freshness needs, not your model complexity!</p>"},{"location":"models/#start-historical-backfill-start","title":"<code>start</code> - Historical Backfill Start","text":"<p>Earliest date to process:</p> <pre><code>start '2024-01-01'      -- Absolute date\nstart '1 year ago'       -- Relative date\n</code></pre>"},{"location":"models/#end-stop-processing-after-date","title":"<code>end</code> - Stop Processing After Date","text":"<p>Latest date to process:</p> <pre><code>end '2024-12-31'        -- Absolute date\nend '1 month ago'       -- Relative date\n</code></pre>"},{"location":"models/#data-quality-properties","title":"Data Quality Properties","text":""},{"location":"models/#grain-primary-key","title":"<code>grain</code> - Primary Key","text":"<p>Declares the model's primary key:</p> <pre><code>grain order_id                    -- Single column\ngrains (customer_id, order_date)   -- Composite key\n</code></pre> <p>Why define grain? - \u2705 Enables automatic joins in semantic layer - \u2705 Validates uniqueness with audits - \u2705 Documents data model</p>"},{"location":"models/#assertions-data-quality-audits","title":"<code>assertions</code> - Data Quality Audits","text":"<p>Attach audits to validate data:</p> <pre><code>assertions (\n  not_null(columns := (order_id, customer_id)),\n  unique_values(columns := (order_id)),\n  accepted_range(column := amount, min_v := 0, max_v := 1000000)\n)\n</code></pre> <p>For comprehensive audit documentation, see Chapter 4: Audits</p>"},{"location":"models/#metadata-properties","title":"Metadata Properties","text":""},{"location":"models/#description-model-description","title":"<code>description</code> - Model Description","text":"<p>Human-readable description:</p> <pre><code>description 'Daily customer revenue metrics aggregated by customer and date'\n</code></pre> <p>\u2705 Flows to data catalog and BI tools</p>"},{"location":"models/#owner-model-owner","title":"<code>owner</code> - Model Owner","text":"<p>Team or person responsible:</p> <pre><code>owner 'data-team'\n</code></pre>"},{"location":"models/#tags-categorization","title":"<code>tags</code> - Categorization","text":"<p>Organize models with tags:</p> <pre><code>tags ('analytics', 'revenue', 'customer', 'pii')\n</code></pre>"},{"location":"models/#column_descriptions-column-documentation","title":"<code>column_descriptions</code> - Column Documentation","text":"<p>Document each column:</p> <pre><code>column_descriptions (\n  customer_id = 'Unique customer identifier (integer)',\n  revenue = 'Total revenue in USD from completed orders',\n  customer_tier = 'Subscription tier: Free, Pro, Enterprise'\n)\n</code></pre> <p>\u2705 Flows to semantic layer and BI tools</p>"},{"location":"models/#incremental-model-properties","title":"Incremental Model Properties","text":""},{"location":"models/#time_column-time-partition-column","title":"<code>time_column</code> - Time Partition Column","text":"<p>Required for <code>INCREMENTAL_BY_TIME_RANGE</code>:</p> <pre><code>kind INCREMENTAL_BY_TIME_RANGE (\n  time_column event_date\n)\n</code></pre>"},{"location":"models/#lookback-late-arriving-data","title":"<code>lookback</code> - Late-Arriving Data","text":"<p>Reprocess last N intervals:</p> <pre><code>kind INCREMENTAL_BY_TIME_RANGE (\n  time_column event_date,\n  lookback 3  -- Reprocess last 3 days\n)\n</code></pre> <p>For comprehensive property reference, see Chapter 2A: Model Properties</p> <p>\u2191 Back to Top</p>"},{"location":"models/#6-grain-and-keys","title":"6. Grain and Keys","text":"<p>Grain defines your model's primary key - the column(s) that uniquely identify each row. This is critical for data quality and semantic layer integration.</p>"},{"location":"models/#what-is-grain","title":"What is Grain?","text":"<p>Grain = Primary Key</p> <p>The grain is the column or combination of columns that uniquely identify a row:</p> <pre><code>MODEL (\n  name analytics.orders,\n  grain order_id  -- Each row = one unique order\n);\n</code></pre>"},{"location":"models/#single-vs-composite-grain","title":"Single vs Composite Grain","text":"<p>Single column grain:</p> <pre><code>MODEL (\n  name analytics.customers,\n  grain customer_id  -- One row per customer\n);\n</code></pre> <p>Composite grain (multiple columns):</p> <pre><code>MODEL (\n  name analytics.daily_customer_metrics,\n  grains (customer_id, metric_date)  -- One row per customer per day\n);\n</code></pre>"},{"location":"models/#foreign-key-references","title":"Foreign Key References","text":"<p>Use <code>references</code> to declare foreign key relationships:</p> <pre><code>MODEL (\n  name analytics.orders,\n  grain order_id,\n  references (customer_id)  -- Foreign key to customers table\n);\n</code></pre> <p>Benefits: - \u2705 Documents relationships - \u2705 Helps with automatic join detection in semantic layer - \u2705 Can be used for referential integrity validation</p>"},{"location":"models/#grain-as-prerequisite-for-joins","title":"Grain as Prerequisite for Joins","text":"<p>Grains are required for semantic layer joins. The semantic layer validates that models with joins have grains defined:</p> <pre><code># Semantic layer automatically creates joins when:\n# 1. Model has grains defined (required)\n# 2. Join relationships are declared in semantic YAML\n# Example: customers (grain: customer_id) \u2190\u2192 orders (grain: order_id, references: customer_id)\n</code></pre> <p>For detailed grain documentation, see Chapter 2A: Model Properties</p> <p>\u2191 Back to Top</p>"},{"location":"models/#7-audits","title":"7. Audits","text":"<p>For comprehensive audit documentation, see Chapter 4: Audits - This section provides a brief overview of how to attach audits to models.</p>"},{"location":"models/#what-are-audits","title":"What Are Audits?","text":"<p>Audits are SQL queries that validate your model's data after execution. They search for invalid data, and if any is found, they halt the flow of data to prevent bad data from propagating downstream.</p> <p>Key characteristics: - Run automatically after model execution - Always blocking in Vulcan (no warning-only mode) - Query for bad data (returns rows = audit fails) - For incremental models, only validate newly processed intervals</p>"},{"location":"models/#attaching-audits-to-models","title":"Attaching Audits to Models","text":"<p>Use the <code>assertions</code> property in your MODEL definition:</p> <pre><code>MODEL (\n  name analytics.orders,\n  kind INCREMENTAL_BY_TIME_RANGE (time_column order_date),\n  grain order_id,\n  assertions (\n    -- Built-in audits\n    not_null(columns := (order_id, customer_id, amount)),\n    unique_values(columns := (order_id)),\n    accepted_range(column := amount, min_v := 0, max_v := 1000000),\n    accepted_values(column := status, is_in := ('pending', 'completed', 'cancelled'))\n  )\n);\n</code></pre>"},{"location":"models/#common-built-in-audits","title":"Common Built-in Audits","text":"<p>Vulcan provides 29 built-in audits. Here are the most commonly used:</p> Audit Purpose Example <code>not_null(columns := (...))</code> No NULL values Primary keys, required fields <code>unique_values(columns := (...))</code> No duplicates Unique identifiers <code>accepted_values(column := ..., is_in := (...))</code> Enum validation Status codes, categories <code>accepted_range(column := ..., min_v := ..., max_v := ...)</code> Numeric bounds Revenue, age, counts <code>forall(criteria := (...))</code> Custom logic Complex business rules"},{"location":"models/#when-to-use-audits","title":"When to Use Audits","text":"<p>Always audit: - \u2705 Primary keys (not_null + unique_values) - \u2705 Foreign keys (referential integrity) - \u2705 Financial data (non-negative, within ranges) - \u2705 Critical business rules</p> <p>For comprehensive audit documentation, see Chapter 4: Audits - Complete guide with all 29 built-in audits, advanced patterns, troubleshooting, and best practices.</p> <p>\u2191 Back to Top</p>"},{"location":"models/#8-data-quality-checks","title":"8. Data Quality Checks","text":"<p>For comprehensive quality checks documentation, see Chapter 5: Quality Checks - This section provides a brief overview.</p>"},{"location":"models/#what-are-quality-checks","title":"What Are Quality Checks?","text":"<p>Quality checks are comprehensive validation rules configured in YAML files. Unlike audits (which block pipeline execution), checks:</p> <ul> <li>Run separately from model execution (or alongside it)</li> <li>Don't block pipelines (non-blocking validation)</li> <li>Track trends and historical patterns</li> <li>Support complex statistical analysis</li> <li>Integrate with Activity API for monitoring</li> </ul>"},{"location":"models/#checks-vs-audits","title":"Checks vs Audits","text":"Feature Audits Checks Purpose Critical validation Monitoring &amp; analysis When runs With model (inline) Separately or with models Blocks pipeline? Yes (always) No Configuration In MODEL DDL or .sql files YAML files (<code>checks/</code>) Output Pass/fail Pass/fail + samples Best for Business rules, data integrity Trend monitoring, anomalies"},{"location":"models/#basic-check-configuration","title":"Basic Check Configuration","text":"<p>Checks are defined in YAML files:</p> <pre><code># checks/orders.yml\nchecks:\n  analytics.orders:\n    completeness:\n      - missing_count(customer_id) = 0:\n          name: no_missing_customers\n          attributes:\n            description: \"All orders must have a customer\"\n\n    validity:\n      - failed rows:\n          name: invalid_amounts\n          fail query: |\n            SELECT order_id, amount\n            FROM analytics.orders\n            WHERE amount &lt; 0 OR amount &gt; 1000000\n          samples limit: 10\n</code></pre> <p>For comprehensive quality checks documentation, see Chapter 5: Quality Checks - Complete guide with check types, configuration, and best practices.</p> <p>\u2191 Back to Top</p>"},{"location":"models/#9-unit-tests","title":"9. Unit Tests","text":"<p>Unit tests validate model logic with predefined inputs and expected outputs. They prevent regressions and ensure models behave as expected after changes.</p>"},{"location":"models/#what-are-unit-tests","title":"What Are Unit Tests?","text":"<p>Unit tests: - Define input fixtures (mock data) - Specify expected outputs - Run model logic in isolation - Execute on demand (<code>vulcan test</code>) - Run automatically during <code>vulcan plan</code></p> <p>Unlike audits/checks: - Don't run in production - Use mock data (not real data) - Test logic, not data quality</p>"},{"location":"models/#test-structure","title":"Test Structure","text":"<p>Tests are defined in YAML files in the <code>tests/</code> directory:</p> <pre><code># tests/test_revenue_metrics.yml\ntest_revenue_aggregation:\n  model: analytics.revenue_metrics\n\n  inputs:\n    staging.orders:\n      rows:\n        - order_id: 1\n          customer_id: 101\n          order_date: 2024-01-01\n          amount: 100.00\n          status: completed\n        - order_id: 2\n          customer_id: 101\n          order_date: 2024-01-01\n          amount: 50.00\n          status: completed\n\n  outputs:\n    query:\n      rows:\n        - customer_id: 101\n          metric_date: 2024-01-01\n          revenue: 150.00\n          order_count: 2\n</code></pre>"},{"location":"models/#running-tests","title":"Running Tests","text":"<pre><code># Run all tests\nvulcan test\n\n# Run specific test\nvulcan test --select test_revenue_aggregation\n\n# Run tests for specific model\nvulcan test --select analytics.revenue_metrics\n</code></pre> <p>For comprehensive testing documentation, see Chapter 2B: Model Testing - Complete guide with advanced patterns, CI/CD integration, and troubleshooting.</p> <p>\u2191 Back to Top</p>"},{"location":"models/#10-signals","title":"10. Signals","text":"<p>Signals define custom criteria for when models should run. They enable advanced scheduling beyond simple <code>cron</code> expressions.</p>"},{"location":"models/#what-are-signals","title":"What Are Signals?","text":"<p>Signals: - Check if conditions are met before running a model - Handle late-arriving data - Wait for external dependencies - Implement custom scheduling logic - Work with the built-in scheduler (<code>vulcan run</code>)</p> <p>When to use: - Late-arriving data (data lands after scheduled run) - External API dependencies - File arrival detection (S3, SFTP) - Business hours gates - Complex scheduling logic</p>"},{"location":"models/#signal-basics","title":"Signal Basics","text":"<p>A signal is a Python function with the <code>@signal</code> decorator:</p> <pre><code># signals/__init__.py\n\nfrom vulcan import signal, DatetimeRanges\nimport typing as t\n\n@signal()\ndef file_arrived(batch: DatetimeRanges, file_path: str) -&gt; t.Union[bool, DatetimeRanges]:\n    \"\"\"Check if file exists before running model.\"\"\"\n    import os\n    return os.path.exists(file_path)\n</code></pre> <p>Use in model:</p> <pre><code>MODEL (\n  name analytics.partner_data,\n  kind INCREMENTAL_BY_TIME_RANGE (time_column data_date),\n  signals (\n    file_arrived(file_path := '/data/partner_upload.csv')\n  )\n);\n\nSELECT * FROM raw.partner_data\nWHERE data_date BETWEEN @start_date AND @end_date;\n</code></pre> <p>For advanced signal patterns, see Chapter 2C: Model Operations</p> <p>\u2191 Back to Top</p>"},{"location":"models/#11-macros","title":"11. Macros","text":"<p>Macros are reusable logic in SQL models. They enable parameterized queries and reduce repetition.</p>"},{"location":"models/#built-in-macros","title":"Built-in Macros","text":"<p>Vulcan provides predefined macro variables:</p>"},{"location":"models/#time-macros","title":"Time Macros","text":"<p>Incremental models:</p> <pre><code>-- Date range for incremental processing\nWHERE event_date BETWEEN @start_date AND @end_date\n\n-- Date strings (YYYY-MM-DD format)\nWHERE event_date BETWEEN @start_ds AND @end_ds\n\n-- Execution time\nWHERE processed_at = @execution_ds\n</code></pre> <p>Available variables: - <code>@start_date</code>, <code>@end_date</code> - Date objects - <code>@start_ds</code>, <code>@end_ds</code> - Date strings - <code>@execution_ds</code> - When model is running</p>"},{"location":"models/#environment-macros","title":"Environment Macros","text":"<pre><code>-- Current environment\nWHERE environment = '@{environment}'\n\n-- Gateway name\nWHERE gateway = '@{gateway}'\n</code></pre>"},{"location":"models/#user-defined-macros","title":"User-Defined Macros","text":""},{"location":"models/#inline-variables","title":"Inline Variables","text":"<p>Define variables in your model:</p> <pre><code>MODEL (...);\n\n@DEF(size, 1);\n\nSELECT * FROM items\nWHERE item_id &gt; @size;\n</code></pre>"},{"location":"models/#python-based-macros","title":"Python-Based Macros","text":"<p>Create macros in <code>macros/__init__.py</code>:</p> <pre><code># macros/__init__.py\n\nfrom vulcan import macro\n\n@macro()\ndef standardize_email(email: str) -&gt; str:\n    \"\"\"Standardize email to lowercase.\"\"\"\n    return f\"LOWER(TRIM({email}))\"\n</code></pre> <p>Use in models:</p> <pre><code>SELECT\n  customer_id,\n  @standardize_email(email) AS email_clean\nFROM customers;\n</code></pre> <p>For advanced macro patterns, see Chapter 2C: Model Operations</p> <p>\u2191 Back to Top</p>"},{"location":"models/#12-best-practices","title":"12. Best Practices","text":"<p>Production-ready patterns for maintainable, performant, and business-friendly models.</p>"},{"location":"models/#model-organization","title":"Model Organization","text":"<p>Organize models into semantic layers:</p> <pre><code>models/\n\u251c\u2500\u2500 raw/                    # External sources (EXTERNAL models)\n\u251c\u2500\u2500 staging/                # Cleaning, type casting\n\u251c\u2500\u2500 analytics/              # Business logic, semantic layer\n\u2514\u2500\u2500 metrics/                # Pre-aggregated KPIs\n</code></pre> <p>Naming conventions:</p> <pre><code># \u2705 Good\nstaging/stg_customers.sql\nanalytics/customer_lifetime_value.sql\nmetrics/daily_active_users.sql\n\n# \u274c Bad\nstaging/c.sql\nanalytics/cust_ltv.sql\nmetrics/dau.sql\n</code></pre>"},{"location":"models/#column-naming","title":"Column Naming","text":"<p>Design for the semantic layer:</p> <pre><code>-- \u274c Bad: Technical names\nSELECT\n  cust_id,\n  ord_cnt,\n  rev_usd\n\n-- \u2705 Good: Business names\nSELECT\n  customer_id,\n  order_count,\n  revenue  -- Document units in description\n</code></pre>"},{"location":"models/#always-use-column-descriptions","title":"Always Use Column Descriptions","text":"<pre><code>MODEL (\n  name analytics.customer_metrics,\n  column_descriptions (\n    customer_id = 'Unique customer identifier',\n    revenue = 'Total revenue in USD from completed orders',\n    customer_tier = 'Subscription tier: Free, Pro, Enterprise'\n  )\n);\n</code></pre> <p>Benefits: - \u2705 Flows to BI tools - \u2705 Shows in data catalog - \u2705 Self-documenting - \u2705 Helps business users</p>"},{"location":"models/#production-checklist","title":"Production Checklist","text":"<p>Essential properties for production models:</p> <pre><code>MODEL (\n  name analytics.customer_daily_revenue,\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column revenue_date,\n    lookback 3\n  ),\n  cron '@hourly',\n  start '2024-01-01',\n\n  -- Data quality\n  grain (customer_id, revenue_date),\n  assertions (\n    not_null(columns := (customer_id, revenue_date, revenue)),\n    unique_combination_of_columns(columns := (customer_id, revenue_date)),\n    accepted_range(column := revenue, min_v := 0, max_v := 10000000)\n  ),\n\n  -- Metadata\n  owner 'data-team',\n  tags ('analytics', 'revenue', 'customer'),\n  description 'Daily revenue aggregated by customer',\n  column_descriptions (\n    customer_id = 'Unique customer identifier',\n    revenue = 'Total revenue in USD',\n    revenue_date = 'Date of revenue (YYYY-MM-DD)'\n  )\n);\n</code></pre> <p>For performance optimization, see Chapter 2D: Model Optimization</p> <p>\u2191 Back to Top</p>"},{"location":"models/#13-quick-reference","title":"13. Quick Reference","text":""},{"location":"models/#model-kinds-quick-reference","title":"Model Kinds Quick Reference","text":"Kind Use When Performance <code>INCREMENTAL_BY_TIME_RANGE</code> Time-series data 10-100x faster <code>INCREMENTAL_BY_UNIQUE_KEY</code> Upsert by key Fast <code>FULL</code> Small tables Slow for large data <code>VIEW</code> Fast-changing logic Instant refresh <code>SCD_TYPE_2</code> Historical tracking Medium <code>SEED</code> Static CSV data One-time load <code>EXTERNAL</code> Existing tables N/A <code>EMBEDDED</code> Reusable subqueries No storage <code>MANAGED</code> Engine auto-refresh Engine-dependent"},{"location":"models/#essential-properties-quick-reference","title":"Essential Properties Quick Reference","text":"Property Required? Purpose Example <code>name</code> \u2705 Yes Model name <code>analytics.customers</code> <code>kind</code> \u2705 Yes Materialization <code>INCREMENTAL_BY_TIME_RANGE(...)</code> <code>cron</code> No Schedule <code>@daily</code> <code>grain</code> No Primary key <code>customer_id</code> <code>assertions</code> No Audits <code>not_null(columns := (id))</code> <code>description</code> No Documentation <code>'Customer metrics'</code> <code>owner</code> No Ownership <code>'data-team'</code> <code>tags</code> No Categorization <code>('analytics', 'customer')</code>"},{"location":"models/#common-patterns-cheat-sheet","title":"Common Patterns Cheat Sheet","text":"<p>Time-series incremental model:</p> <pre><code>MODEL (\n  name analytics.daily_metrics,\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column metric_date,\n    lookback 3\n  ),\n  cron '@daily',\n  start '2024-01-01',\n  grain (customer_id, metric_date)\n);\n\nSELECT * FROM source\nWHERE metric_date BETWEEN @start_date AND @end_date;\n</code></pre> <p>Upsert dimension model:</p> <pre><code>MODEL (\n  name dimensions.customers,\n  kind INCREMENTAL_BY_UNIQUE_KEY (\n    unique_key customer_id\n  ),\n  cron '@daily',\n  grain customer_id\n);\n\nSELECT * FROM source;\n</code></pre> <p>Full refresh model:</p> <pre><code>MODEL (\n  name analytics.customer_summary,\n  kind FULL,\n  cron '@daily'\n);\n\nSELECT \n  customer_id,\n  COUNT(*) as order_count,\n  SUM(amount) as total_revenue\nFROM orders\nGROUP BY customer_id;\n</code></pre>"},{"location":"models/#cross-references-to-detailed-chapters","title":"Cross-References to Detailed Chapters","text":"<p>For comprehensive documentation:</p> <ul> <li>Chapter 2A: Model Properties - Complete property reference</li> <li>Chapter 2B: Model Testing - Advanced testing patterns</li> <li>Chapter 2C: Model Operations - Advanced SQL/Python patterns, signals, macros</li> <li>Chapter 2D: Model Optimization - Performance tuning, warehouse-specific</li> <li>Chapter 4: Audits - Comprehensive audit guide</li> <li>Chapter 5: Quality Checks - Comprehensive checks guide</li> </ul> <p>\u2191 Back to Top</p>"},{"location":"models/#summary","title":"Summary","text":"<p>You've learned the fundamentals of Vulcan models:</p>"},{"location":"models/#core-concepts","title":"Core Concepts","text":"<p>1. Model Basics - SQL and Python transformations - MODEL DDL metadata + query logic - Integration with semantic layer</p> <p>2. Model Kinds - <code>VIEW</code> - Real-time, no storage - <code>FULL</code> - Complete refresh - <code>INCREMENTAL_BY_TIME_RANGE</code> - Time partitions (most common, 10-100x faster) - <code>INCREMENTAL_BY_UNIQUE_KEY</code> - Upsert by key - <code>SCD_TYPE_2</code> - Historical tracking - <code>SEED</code> - Static CSV data - <code>EXTERNAL</code> - Existing tables - <code>EMBEDDED</code> - Inline subqueries - <code>MANAGED</code> - Engine-managed auto-refresh (Snowflake Dynamic Tables)</p> <p>3. Data Quality - Grain - Primary key definition, enables auto-joins - Audits - Inline SQL checks (blocking) - Checks - YAML-configured validation (monitoring) - Unit Tests - Logic validation with fixtures</p> <p>4. Advanced Features - Signals - Custom scheduling (late data, external dependencies) - Macros - Reusable SQL logic - References - Foreign key relationships</p>"},{"location":"models/#next-steps","title":"Next Steps","text":"<p>Continue to Chapter 03: Semantic Layer</p> <p>Learn how to expose your models as business metrics: - Measures and dimensions - Joins across models - Segments for filtering - Business metrics (time-series KPIs)</p> <p>Additional Resources</p> <ul> <li>Vulcan CLI Reference - <code>vulcan --help</code></li> <li>Examples - <code>examples/b2b_saas/</code> in your Vulcan installation</li> <li>Advanced Chapters - Model Properties, Testing, Operations, Optimization</li> </ul> <p>Congratulations! You now have a solid foundation in Vulcan models. You can: - \u2705 Write production-ready SQL and Python models - \u2705 Choose optimal materialization strategies - \u2705 Implement basic data quality checks - \u2705 Test model logic - \u2705 Handle basic scheduling scenarios</p> <p>Happy modeling!</p> <p>\u2191 Back to Top</p>"},{"location":"models/model-operations/","title":"Chapter 2C: Model Operations","text":"<p>Advanced patterns and operations for building sophisticated models - Blueprinting, dynamic SQL generation, advanced signals and macros, dependency management, and more.</p>"},{"location":"models/model-operations/#prerequisites","title":"Prerequisites","text":"<p>Before reading this chapter, you should be familiar with:</p> <ul> <li>Chapter 2: Models - Foundation concepts</li> <li>Basic SQL and Python</li> <li>Understanding of model kinds and properties</li> </ul>"},{"location":"models/model-operations/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Introduction</li> <li>Advanced SQL Patterns</li> <li>Advanced Python Patterns</li> <li>Signals (Detailed)</li> <li>Macros (Detailed)</li> <li>Model Dependencies</li> <li>Model Blueprinting</li> <li>Summary and Next Steps</li> </ol>"},{"location":"models/model-operations/#1-introduction","title":"1. Introduction","text":"<p>This chapter covers advanced patterns and operations for building sophisticated models in Vulcan. While Chapter 2: Models covers the fundamentals, this chapter dives deep into:</p> <ul> <li>Advanced SQL Patterns: Blueprinting, Python-based SQL models, dynamic SQL generation</li> <li>Advanced Python Patterns: Blueprinting, serialization, DataFrame APIs</li> <li>Signals: Advanced scheduling patterns and best practices</li> <li>Macros: Complex macro patterns and debugging</li> <li>Dependencies: Managing model relationships</li> <li>Blueprinting: Creating model templates</li> </ul> <p>When to use this chapter:</p> <ul> <li>You need to create multiple similar models (blueprinting)</li> <li>You want dynamic SQL generation based on runtime conditions</li> <li>You need advanced scheduling logic (signals)</li> <li>You're building complex reusable logic (macros)</li> <li>You need fine-grained control over model dependencies</li> </ul> <p>For basics, see Chapter 2: Models</p> <p>\u2191 Back to Top</p>"},{"location":"models/model-operations/#2-advanced-sql-patterns","title":"2. Advanced SQL Patterns","text":""},{"location":"models/model-operations/#21-python-based-sql-models","title":"2.1 Python-Based SQL Models","text":"<p>Python-based SQL models allow you to generate SQL dynamically using Python code, while still benefiting from Vulcan's semantic understanding and column-level lineage.</p> <p>Key Characteristics:</p> <ul> <li>Use <code>@model(..., is_sql=True)</code> decorator</li> <li>Function returns SQL string or SQLGlot expression</li> <li>Supports all SQL model features (lineage, macros, etc.)</li> <li>Useful for complex dynamic SQL generation</li> </ul> <p>Basic Example:</p> <pre><code>from sqlglot import exp\nfrom vulcan import model\nfrom vulcan.core.macros import MacroEvaluator\n\n@model(\n    \"analytics.customers\",\n    is_sql=True,\n    kind=\"FULL\",\n    pre_statements=[\"CACHE TABLE countries AS SELECT * FROM raw.countries\"],\n    post_statements=[\"UNCACHE TABLE countries\"],\n    on_virtual_update=[\"GRANT SELECT ON VIEW @this_model TO ROLE dev_role\"],\n)\ndef entrypoint(evaluator: MacroEvaluator) -&gt; str | exp.Expression:\n    return (\n        exp.select(\"r.id::int\", \"r.name::text\", \"c.country::text\")\n        .from_(\"raw.restaurants as r\")\n        .join(\"countries as c\", on=\"r.id = c.restaurant_id\")\n    )\n</code></pre> <p>Dynamic SQL Generation:</p> <pre><code>from sqlglot import exp\nfrom vulcan import model\nfrom vulcan.core.macros import MacroEvaluator\n\n@model(\n    \"analytics.dynamic_metrics\",\n    is_sql=True,\n    kind=\"FULL\",\n)\ndef entrypoint(evaluator: MacroEvaluator) -&gt; str | exp.Expression:\n    # Get blueprint variables or global variables\n    metrics = evaluator.var(\"metrics\", [\"revenue\", \"orders\", \"customers\"])\n\n    # Build dynamic SELECT clause\n    select_clauses = []\n    for metric in metrics:\n        if metric == \"revenue\":\n            select_clauses.append(exp.alias_(\"SUM(amount)\", \"revenue\"))\n        elif metric == \"orders\":\n            select_clauses.append(exp.alias_(\"COUNT(*)\", \"orders\"))\n        elif metric == \"customers\":\n            select_clauses.append(exp.alias_(\"COUNT(DISTINCT customer_id)\", \"customers\"))\n\n    return (\n        exp.select(*select_clauses)\n        .from_(\"raw.transactions\")\n        .group_by(\"date\")\n    )\n</code></pre> <p>Accessing Model Schemas:</p> <pre><code>from sqlglot import exp\nfrom vulcan import model\nfrom vulcan.core.macros import MacroEvaluator\n\n@model(\n    \"analytics.schema_aware_transform\",\n    is_sql=True,\n    kind=\"FULL\",\n)\ndef entrypoint(evaluator: MacroEvaluator) -&gt; str | exp.Expression:\n    # Access upstream model schema\n    upstream_columns = evaluator.columns_to_types(\"raw.transactions\")\n\n    # Build query based on available columns\n    select_clauses = []\n    for col_name, col_type in upstream_columns.items():\n        if col_type.this == exp.DataType.Type.INT:\n            select_clauses.append(exp.alias_(f\"SUM({col_name})\", f\"total_{col_name}\"))\n\n    return (\n        exp.select(*select_clauses)\n        .from_(\"raw.transactions\")\n        .group_by(\"date\")\n    )\n</code></pre> <p>When to Use:</p> <ul> <li>\u2705 Complex conditional SQL logic</li> <li>\u2705 Dynamic column selection</li> <li>\u2705 Schema-aware transformations</li> <li> <p>\u2705 Reusable SQL templates</p> </li> <li> <p>\u274c Simple static queries (use regular SQL models)</p> </li> <li>\u274c Data transformations (use Python models returning DataFrames)</li> </ul>"},{"location":"models/model-operations/#22-complex-ctes-and-subqueries","title":"2.2 Complex CTEs and Subqueries","text":"<p>Multiple CTEs:</p> <pre><code>MODEL (\n  name analytics.complex_aggregation,\n  kind FULL\n);\n\nWITH \n  filtered_orders AS (\n    SELECT * FROM raw.orders\n    WHERE order_date &gt;= @start_ds\n      AND status = 'completed'\n  ),\n  customer_totals AS (\n    SELECT \n      customer_id,\n      SUM(amount) AS total_spent,\n      COUNT(*) AS order_count\n    FROM filtered_orders\n    GROUP BY customer_id\n  ),\n  customer_segments AS (\n    SELECT \n      customer_id,\n      total_spent,\n      order_count,\n      CASE \n        WHEN total_spent &gt; 1000 THEN 'high_value'\n        WHEN total_spent &gt; 500 THEN 'medium_value'\n        ELSE 'low_value'\n      END AS segment\n    FROM customer_totals\n  )\nSELECT * FROM customer_segments;\n</code></pre> <p>Recursive CTEs:</p> <pre><code>MODEL (\n  name analytics.hierarchical_data,\n  kind FULL\n);\n\nWITH RECURSIVE org_hierarchy AS (\n  -- Base case\n  SELECT \n    employee_id,\n    manager_id,\n    name,\n    1 AS level\n  FROM raw.employees\n  WHERE manager_id IS NULL\n\n  UNION ALL\n\n  -- Recursive case\n  SELECT \n    e.employee_id,\n    e.manager_id,\n    e.name,\n    oh.level + 1\n  FROM raw.employees e\n  INNER JOIN org_hierarchy oh ON e.manager_id = oh.employee_id\n)\nSELECT * FROM org_hierarchy;\n</code></pre>"},{"location":"models/model-operations/#23-advanced-prepost-statements","title":"2.3 Advanced Pre/Post Statements","text":"<p>Conditional Execution:</p> <pre><code>MODEL (\n  name analytics.orders,\n  kind FULL\n);\n\nSELECT * FROM raw.orders;\n\n-- Only create indexes after table creation\n@IF(@runtime_stage = 'creating',\n  CREATE INDEX idx_customer_id ON analytics.orders(customer_id);\n  CREATE INDEX idx_order_date ON analytics.orders(order_date);\n);\n\n-- Only analyze after evaluation\n@IF(@runtime_stage = 'evaluating',\n  ANALYZE TABLE analytics.orders;\n);\n</code></pre> <p>Multiple Statements:</p> <pre><code>MODEL (\n  name analytics.partitioned_table,\n  kind FULL\n);\n\nSELECT * FROM raw.events;\n\n-- Pre-statements: Set up partitioning\n@IF(@runtime_stage = 'creating',\n  ALTER TABLE analytics.partitioned_table \n    SET PARTITION BY (event_date);\n\n  CREATE INDEX idx_event_type \n    ON analytics.partitioned_table(event_type);\n);\n\n-- Post-statements: Optimize and grant access\n@IF(@runtime_stage = 'evaluating',\n  OPTIMIZE TABLE analytics.partitioned_table;\n\n  GRANT SELECT ON TABLE analytics.partitioned_table \n    TO ROLE analyst_role;\n);\n</code></pre> <p>Using Macros in Statements:</p> <pre><code>MODEL (\n  name analytics.customers,\n  kind FULL\n);\n\nSELECT * FROM raw.customers;\n\n-- Use macro to generate index creation\n@IF(@runtime_stage = 'creating',\n  @CREATE_INDEXES(@this_model, customer_id, email, created_at);\n);\n</code></pre>"},{"location":"models/model-operations/#24-on-virtual-update-statements","title":"2.4 On-Virtual-Update Statements","text":"<p>On-virtual-update statements run after views are swapped in development environments (virtual updates). They're useful for:</p> <ul> <li>Granting permissions</li> <li>Updating metadata</li> <li>Refreshing caches</li> </ul> <p>Basic Example:</p> <pre><code>MODEL (\n  name analytics.customers,\n  kind FULL\n);\n\nSELECT * FROM raw.customers;\n\nON_VIRTUAL_UPDATE_BEGIN;\nGRANT SELECT ON VIEW @this_model TO ROLE analyst_role;\nGRANT SELECT ON VIEW @this_model TO ROLE readonly_role;\nON_VIRTUAL_UPDATE_END;\n</code></pre> <p>Multiple Statements:</p> <pre><code>MODEL (\n  name analytics.sensitive_data,\n  kind FULL\n);\n\nSELECT * FROM raw.sensitive_data;\n\nON_VIRTUAL_UPDATE_BEGIN;\n-- Grant role-based access\nGRANT SELECT ON VIEW @this_model TO ROLE analyst_role;\nGRANT SELECT ON VIEW @this_model TO ROLE admin_role;\n\n-- Update metadata\nCOMMENT ON VIEW @this_model IS 'Updated via virtual update';\n\n-- Refresh materialized view cache\nREFRESH MATERIALIZED VIEW analytics.cache_view;\nON_VIRTUAL_UPDATE_END;\n</code></pre> <p>Conditional Virtual Updates:</p> <pre><code>MODEL (\n  name analytics.environment_specific,\n  kind FULL\n);\n\nSELECT * FROM raw.data;\n\nON_VIRTUAL_UPDATE_BEGIN;\n@IF(@environment = 'dev',\n  GRANT SELECT ON VIEW @this_model TO ROLE dev_role;\n);\n\n@IF(@environment = 'prod',\n  GRANT SELECT ON VIEW @this_model TO ROLE prod_role;\n);\nON_VIRTUAL_UPDATE_END;\n</code></pre> <p>Note: Table resolution occurs at the virtual layer. <code>@this_model</code> resolves to the view name (e.g., <code>analytics__dev.customers</code>), not the physical table.</p> <p>\u2191 Back to Top</p>"},{"location":"models/model-operations/#3-advanced-python-patterns","title":"3. Advanced Python Patterns","text":""},{"location":"models/model-operations/#31-python-model-blueprinting","title":"3.1 Python Model Blueprinting","text":"<p>Python models can serve as templates for creating multiple models using blueprinting.</p> <p>Basic Blueprinting:</p> <pre><code>import typing as t\nfrom datetime import datetime\nimport pandas as pd\nfrom vulcan import ExecutionContext, model\n\n@model(\n    \"@{customer}.revenue_metrics\",\n    kind=\"FULL\",\n    blueprints=[\n        {\"customer\": \"customer1\", \"currency\": \"USD\", \"region\": \"US\"},\n        {\"customer\": \"customer2\", \"currency\": \"EUR\", \"region\": \"EU\"},\n        {\"customer\": \"customer3\", \"currency\": \"GBP\", \"region\": \"UK\"},\n    ],\n    columns={\n        \"date\": \"date\",\n        \"revenue\": \"decimal(10,2)\",\n        \"currency\": \"text\",\n        \"region\": \"text\",\n    },\n)\ndef execute(\n    context: ExecutionContext,\n    start: datetime,\n    end: datetime,\n    execution_time: datetime,\n    **kwargs: t.Any,\n) -&gt; pd.DataFrame:\n    customer = context.blueprint_var(\"customer\")\n    currency = context.blueprint_var(\"currency\")\n    region = context.blueprint_var(\"region\")\n\n    # Fetch customer-specific data\n    table = context.resolve_table(f\"raw.{customer}_transactions\")\n    df = context.fetchdf(f\"\"\"\n        SELECT \n            transaction_date AS date,\n            SUM(amount) AS revenue,\n            '{currency}' AS currency,\n            '{region}' AS region\n        FROM {table}\n        WHERE transaction_date BETWEEN '{start}' AND '{end}'\n        GROUP BY transaction_date\n    \"\"\")\n\n    return df\n</code></pre> <p>Dynamic Blueprint Generation:</p> <pre><code>from vulcan import macro\n\n@macro()\ndef gen_customer_blueprints(evaluator):\n    \"\"\"Generate blueprints from external source.\"\"\"\n    import csv\n\n    blueprints = []\n    with open('customers.csv', 'r') as f:\n        reader = csv.DictReader(f)\n        for row in reader:\n            blueprints.append({\n                \"customer\": row['customer_id'],\n                \"currency\": row['currency'],\n                \"region\": row['region'],\n            })\n\n    return blueprints\n</code></pre> <p>Using EACH Macro:</p> <pre><code>@model(\n    \"@{schema}.metrics\",\n    blueprints=\"@EACH(@customer_list, x -&gt; (schema := @x))\",\n    kind=\"FULL\",\n    columns={\"metric\": \"text\", \"value\": \"int\"},\n)\ndef execute(context, **kwargs):\n    schema = context.blueprint_var(\"schema\")\n    table = context.resolve_table(f\"{schema}.raw_data\")\n    return context.fetchdf(f\"SELECT * FROM {table}\")\n</code></pre>"},{"location":"models/model-operations/#32-returning-empty-dataframes","title":"3.2 Returning Empty DataFrames","text":"<p>Python models cannot return empty DataFrames directly. Use generators instead:</p> <pre><code>@model(\n    \"analytics.conditional_output\",\n    columns={\"id\": \"int\", \"value\": \"text\"},\n)\ndef execute(\n    context: ExecutionContext,\n    **kwargs: t.Any,\n) -&gt; pd.DataFrame:\n    df = context.fetchdf(\"SELECT * FROM raw.data WHERE condition = true\")\n\n    if df.empty:\n        # Return empty generator instead of empty DataFrame\n        yield from ()\n    else:\n        yield df\n</code></pre>"},{"location":"models/model-operations/#33-user-defined-variables","title":"3.3 User-Defined Variables","text":"<p>Accessing Variables:</p> <pre><code>@model(\n    \"analytics.configurable_model\",\n    columns={\"id\": \"int\"},\n)\ndef execute(\n    context: ExecutionContext,\n    start: datetime,\n    end: datetime,\n    execution_time: datetime,\n    threshold: int = 100,  # Variable as function argument\n    **kwargs: t.Any,\n) -&gt; pd.DataFrame:\n    # Access via context.var()\n    batch_size = context.var(\"batch_size\", 1000)\n\n    # Access via function argument (preferred)\n    # threshold is already available as argument\n\n    table = context.resolve_table(\"raw.data\")\n    df = context.fetchdf(f\"\"\"\n        SELECT * FROM {table}\n        WHERE value &gt; {threshold}\n        LIMIT {batch_size}\n    \"\"\")\n\n    return df\n</code></pre> <p>Variable Precedence:</p> <ol> <li>Blueprint variables (highest)</li> <li>Gateway-specific variables</li> <li>Global variables</li> <li>Function argument defaults (lowest)</li> </ol>"},{"location":"models/model-operations/#34-dataframe-apis","title":"3.4 DataFrame APIs","text":"<p>PySpark:</p> <pre><code>from pyspark.sql import DataFrame, functions as F\nfrom vulcan import ExecutionContext, model\n\n@model(\n    \"analytics.spark_transform\",\n    columns={\"id\": \"int\", \"category\": \"text\", \"amount\": \"decimal(10,2)\"},\n)\ndef execute(\n    context: ExecutionContext,\n    **kwargs: t.Any,\n) -&gt; DataFrame:\n    table = context.resolve_table(\"raw.transactions\")\n\n    # Use Spark DataFrame API\n    df = context.spark.table(table)\n\n    df = (\n        df\n        .withColumn(\"category\", F.upper(F.col(\"category\")))\n        .filter(F.col(\"amount\") &gt; 100)\n        .groupBy(\"category\")\n        .agg(F.sum(\"amount\").alias(\"total\"))\n    )\n\n    return df  # Returns Spark DataFrame, computation happens in Spark\n</code></pre> <p>Snowpark:</p> <pre><code>from snowflake.snowpark.dataframe import DataFrame\nfrom vulcan import ExecutionContext, model\n\n@model(\n    \"analytics.snowpark_transform\",\n    columns={\"id\": \"int\", \"value\": \"decimal(10,2)\"},\n)\ndef execute(\n    context: ExecutionContext,\n    **kwargs: t.Any,\n) -&gt; DataFrame:\n    # Create Snowpark DataFrame\n    df = context.snowpark.create_dataframe(\n        [[1, 100.0], [2, 200.0]], \n        schema=[\"id\", \"value\"]\n    )\n\n    # Use Snowpark DataFrame API\n    df = df.filter(df.id &gt; 1)\n\n    return df  # Returns Snowpark DataFrame, computation happens in Snowflake\n</code></pre> <p>Bigframe:</p> <pre><code>from bigframes.pandas import DataFrame\nfrom vulcan import ExecutionContext, model\n\n@model(\n    \"analytics.bigframe_transform\",\n    columns={\"title\": \"text\", \"views\": \"int\", \"bucket\": \"text\"},\n)\ndef execute(\n    context: ExecutionContext,\n    **kwargs: t.Any,\n) -&gt; DataFrame:\n    # Read from BigQuery\n    df = context.bigframe.read_gbq(\"project.dataset.table\")\n\n    # Use Bigframe API (lazy evaluation)\n    df = (\n        df[df.title.str.contains(\"Google\")]\n        .groupby([\"title\"], as_index=False)[\"views\"]\n        .sum(numeric_only=True)\n        .sort_values(\"views\", ascending=False)\n    )\n\n    return df  # Returns Bigframe DataFrame, computation happens in BigQuery\n</code></pre>"},{"location":"models/model-operations/#35-batching-large-outputs","title":"3.5 Batching Large Outputs","text":"<p>For large outputs, use generators to batch data:</p> <pre><code>@model(\n    \"analytics.batched_output\",\n    columns={\"id\": \"int\", \"value\": \"text\"},\n)\ndef execute(\n    context: ExecutionContext,\n    **kwargs: t.Any,\n) -&gt; pd.DataFrame:\n    table = context.resolve_table(\"raw.large_table\")\n    batch_size = 10000\n\n    # Process in batches\n    offset = 0\n    while True:\n        df = context.fetchdf(f\"\"\"\n            SELECT * FROM {table}\n            ORDER BY id\n            LIMIT {batch_size} OFFSET {offset}\n        \"\"\")\n\n        if df.empty:\n            break\n\n        yield df\n        offset += batch_size\n</code></pre>"},{"location":"models/model-operations/#36-serialization","title":"3.6 Serialization","text":"<p>Vulcan uses a custom serialization framework to execute Python models. Key points:</p> <ul> <li>Models are serialized and executed where Vulcan runs</li> <li>Dependencies are captured automatically</li> <li>Python environment is isolated per model</li> <li>Supports custom Python environments</li> </ul> <p>Best Practices:</p> <ul> <li>Keep model code focused and minimal</li> <li>Avoid heavy imports in model files</li> <li>Use project-level Python environment configuration</li> <li>Test serialization in development environments</li> </ul> <p>\u2191 Back to Top</p>"},{"location":"models/model-operations/#4-signals-detailed","title":"4. Signals (Detailed)","text":"<p>Signals provide advanced scheduling logic beyond simple <code>cron</code> expressions. For basics, see Chapter 2: Models.</p>"},{"location":"models/model-operations/#41-multiple-signals","title":"4.1 Multiple Signals","text":"<p>A model can have multiple signals - ALL must pass for the model to run:</p> <pre><code># signals/__init__.py\nfrom vulcan import signal, DatetimeRanges\nimport typing as t\n\n@signal()\ndef s3_file_exists(batch: DatetimeRanges, bucket: str, key_pattern: str) -&gt; bool:\n    \"\"\"Check if S3 file exists.\"\"\"\n    import boto3\n    s3 = boto3.client('s3')\n    # Check file existence logic\n    return True\n\n@signal()\ndef api_healthy(batch: DatetimeRanges, api_url: str) -&gt; bool:\n    \"\"\"Check if API is healthy.\"\"\"\n    import requests\n    try:\n        response = requests.get(api_url, timeout=5)\n        return response.status_code == 200\n    except:\n        return False\n\n@signal()\ndef business_hours_only(batch: DatetimeRanges) -&gt; bool:\n    \"\"\"Only run during business hours.\"\"\"\n    from datetime import datetime\n    now = datetime.now()\n    return 9 &lt;= now.hour &lt; 17\n</code></pre> <p>Model Usage:</p> <pre><code>MODEL (\n  name analytics.critical_data,\n  kind INCREMENTAL_BY_TIME_RANGE (time_column event_date),\n  signals (\n    s3_file_exists(bucket := 'data-lake', key_pattern := 'events.parquet'),\n    api_healthy(api_url := 'https://api.example.com'),\n    business_hours_only()\n  )\n);\n\nSELECT * FROM raw.events\nWHERE event_date BETWEEN @start_date AND @end_date;\n</code></pre> <p>Model runs only when: 1. \u2705 S3 file exists 2. \u2705 API is healthy 3. \u2705 During business hours</p>"},{"location":"models/model-operations/#42-returning-specific-intervals","title":"4.2 Returning Specific Intervals","text":"<p>Signals can return specific intervals from a batch instead of <code>True</code>/<code>False</code>:</p> <pre><code>from vulcan import signal, DatetimeRanges\nfrom vulcan.utils.date import to_datetime\nimport typing as t\n\n@signal()\ndef one_week_ago(batch: DatetimeRanges) -&gt; t.Union[bool, DatetimeRanges]:\n    \"\"\"Only process intervals older than 1 week.\"\"\"\n    cutoff = to_datetime(\"1 week ago\")\n\n    return [\n        (start, end)\n        for start, end in batch\n        if start &lt;= cutoff\n    ]\n</code></pre> <p>Use Case:</p> <pre><code>MODEL (\n  name analytics.historical_backfill,\n  kind INCREMENTAL_BY_TIME_RANGE (time_column event_date),\n  signals (one_week_ago())\n);\n\nSELECT * FROM raw.events\nWHERE event_date BETWEEN @start_date AND @end_date;\n</code></pre> <p>This ensures only data older than 1 week is processed, preventing premature processing of recent data.</p>"},{"location":"models/model-operations/#43-advanced-signal-patterns","title":"4.3 Advanced Signal Patterns","text":"<p>File Arrival Detection:</p> <pre><code>@signal()\ndef file_arrived(\n    batch: DatetimeRanges, \n    file_path: str,\n    expected_size: int = None\n) -&gt; bool:\n    \"\"\"Check if file exists and optionally verify size.\"\"\"\n    import os\n\n    if not os.path.exists(file_path):\n        return False\n\n    if expected_size:\n        actual_size = os.path.getsize(file_path)\n        return actual_size &gt;= expected_size\n\n    return True\n</code></pre> <p>Late-Arriving Data:</p> <pre><code>@signal()\ndef upstream_freshness(\n    batch: DatetimeRanges,\n    upstream_model: str,\n    max_age_hours: int = 24\n) -&gt; t.Union[bool, DatetimeRanges]:\n    \"\"\"Wait for upstream model to be fresh.\"\"\"\n    from datetime import datetime, timedelta\n\n    # Check upstream model's last update time\n    # (Implementation depends on your tracking system)\n    last_update = get_model_last_update(upstream_model)\n    cutoff = datetime.now() - timedelta(hours=max_age_hours)\n\n    if last_update &lt; cutoff:\n        return False\n\n    # Return intervals that are ready\n    return [\n        (start, end)\n        for start, end in batch\n        if end &lt;= last_update\n    ]\n</code></pre> <p>External API Dependency:</p> <pre><code>@signal()\ndef external_api_ready(\n    batch: DatetimeRanges,\n    api_url: str,\n    endpoint: str,\n    timeout: int = 30\n) -&gt; bool:\n    \"\"\"Wait for external API to be ready.\"\"\"\n    import requests\n\n    try:\n        response = requests.get(\n            f\"{api_url}/{endpoint}\",\n            timeout=timeout\n        )\n        return response.status_code == 200\n    except requests.RequestException:\n        return False\n</code></pre>"},{"location":"models/model-operations/#44-testing-signals","title":"4.4 Testing Signals","text":"<p>Manual Testing:</p> <pre><code># Check intervals with signals\nvulcan check_intervals dev --select analytics.critical_data\n\n# Check intervals without signals\nvulcan check_intervals dev --select analytics.critical_data --no-signals\n\n# Run scheduler (evaluates signals automatically)\nvulcan run dev\n</code></pre> <p>Unit Testing Signals:</p> <pre><code># tests/test_signals.py\nfrom vulcan import DatetimeRanges\nfrom signals import s3_file_exists\n\ndef test_s3_file_exists():\n    batch = [\n        (datetime(2024, 1, 1), datetime(2024, 1, 2)),\n        (datetime(2024, 1, 2), datetime(2024, 1, 3)),\n    ]\n\n    result = s3_file_exists(\n        batch=DatetimeRanges(batch),\n        bucket=\"test-bucket\",\n        key_pattern=\"data.parquet\"\n    )\n\n    assert isinstance(result, bool)\n</code></pre>"},{"location":"models/model-operations/#45-signal-best-practices","title":"4.5 Signal Best Practices","text":"<p>\u2705 DO:</p> <ul> <li>Handle exceptions gracefully</li> <li>Use timeouts for external calls</li> <li>Log signal decisions for debugging</li> <li>Return specific intervals when possible</li> <li>Test signals in development environments</li> <li>Make signals idempotent</li> </ul> <p>\u274c DON'T:</p> <ul> <li>Make expensive computations in signals</li> <li>Depend on unreliable external services without retries</li> <li>Use signals for simple scheduling (use <code>cron</code>)</li> <li>Forget to handle edge cases</li> <li>Block signals indefinitely</li> </ul> <p>Performance Considerations:</p> <ul> <li>Signals are evaluated frequently (every scheduler run)</li> <li>Keep signal logic lightweight</li> <li>Cache expensive checks when possible</li> <li>Use timeouts to prevent hanging</li> </ul> <p>\u2191 Back to Top</p>"},{"location":"models/model-operations/#5-macros-detailed","title":"5. Macros (Detailed)","text":"<p>Macros enable reusable SQL logic and parameterized queries. For basics, see Chapter 2: Models.</p>"},{"location":"models/model-operations/#51-advanced-macro-operators","title":"5.1 Advanced Macro Operators","text":"<p>EACH Macro:</p> <pre><code>MODEL (\n  name analytics.multi_customer,\n  kind FULL\n);\n\n-- Generate multiple columns using EACH\nSELECT\n  @EACH(@customer_list, x -&gt; SUM(CASE WHEN customer_id = @x THEN amount ELSE 0 END) AS revenue_@x)\nFROM raw.transactions\nGROUP BY date;\n</code></pre> <p>IF Macro:</p> <pre><code>MODEL (\n  name analytics.conditional_logic,\n  kind FULL\n);\n\nSELECT\n  *,\n  @IF(@environment = 'prod', \n    'production',\n    'development'\n  ) AS environment_type\nFROM raw.data;\n</code></pre> <p>VAR Macro with Defaults:</p> <pre><code>MODEL (\n  name analytics.configurable,\n  kind FULL\n);\n\nSELECT *\nFROM raw.data\nWHERE value &gt; @VAR(threshold, 100);  -- Use 100 if threshold not defined\n</code></pre>"},{"location":"models/model-operations/#52-complex-macro-patterns","title":"5.2 Complex Macro Patterns","text":"<p>Nested Macros:</p> <pre><code>MODEL (\n  name analytics.nested_logic,\n  kind FULL\n);\n\nSELECT\n  @IF(@VAR(use_aggregation, false),\n    SUM(amount) AS total,\n    amount AS value\n  )\nFROM raw.transactions\nGROUP BY @IF(@VAR(use_aggregation, false), date, NULL);\n</code></pre> <p>Macro Functions:</p> <pre><code># macros/__init__.py\nfrom vulcan import macro\n\n@macro()\ndef fiscal_quarter(evaluator, date_col: str, fiscal_start_month: int = 1) -&gt; str:\n    \"\"\"Calculate fiscal quarter.\"\"\"\n    return f\"\"\"\n        CASE \n            WHEN MONTH({date_col}) &gt;= {fiscal_start_month} \n                AND MONTH({date_col}) &lt; {fiscal_start_month + 3}\n            THEN 1\n            WHEN MONTH({date_col}) &gt;= {fiscal_start_month + 3}\n                AND MONTH({date_col}) &lt; {fiscal_start_month + 6}\n            THEN 2\n            WHEN MONTH({date_col}) &gt;= {fiscal_start_month + 6}\n                AND MONTH({date_col}) &lt; {fiscal_start_month + 9}\n            THEN 3\n            ELSE 4\n        END\n    \"\"\"\n</code></pre> <p>Usage:</p> <pre><code>MODEL (\n  name analytics.fiscal_reporting,\n  kind FULL\n);\n\nSELECT\n  order_date,\n  @fiscal_quarter(order_date, 4) AS fiscal_qtr  -- Fiscal year starts in April\nFROM raw.orders;\n</code></pre> <p>Dynamic Column Generation:</p> <pre><code>@macro()\ndef generate_metrics(evaluator, base_table: str, metrics: list) -&gt; str:\n    \"\"\"Generate metric columns dynamically.\"\"\"\n    selects = []\n    for metric in metrics:\n        if metric == \"revenue\":\n            selects.append(f\"SUM(amount) AS revenue\")\n        elif metric == \"orders\":\n            selects.append(f\"COUNT(*) AS orders\")\n        elif metric == \"customers\":\n            selects.append(f\"COUNT(DISTINCT customer_id) AS customers\")\n\n    return \", \".join(selects)\n</code></pre> <p>Usage:</p> <pre><code>MODEL (\n  name analytics.dynamic_metrics,\n  kind FULL\n);\n\nSELECT\n  date,\n  @generate_metrics(raw.transactions, @metric_list)\nFROM raw.transactions\nGROUP BY date;\n</code></pre>"},{"location":"models/model-operations/#53-macro-debugging","title":"5.3 Macro Debugging","text":"<p>Rendering Macros:</p> <pre><code># Render model with macros expanded\nvulcan render analytics.my_model\n\n# Render specific environment\nvulcan render analytics.my_model --environment dev\n</code></pre> <p>Debugging Tips:</p> <ol> <li> <p>Check Macro Syntax: <pre><code>-- Correct: @DEF(var, value);\n@DEF(size, 1);\n\n-- Incorrect: Missing semicolon\n@DEF(size, 1)  -- ERROR\n</code></pre></p> </li> <li> <p>Verify Variable Scope:</p> </li> <li>Local variables (<code>@DEF</code>) take precedence</li> <li>Blueprint variables override global variables</li> <li> <p>Gateway variables override root variables</p> </li> <li> <p>Test Macro Functions: <pre><code># Test macro function independently\nfrom macros import fiscal_quarter\nresult = fiscal_quarter(evaluator, \"order_date\", 4)\nprint(result)  # Check output\n</code></pre></p> </li> <li> <p>Use Rendering: <pre><code># See rendered SQL\nvulcan render analytics.my_model &gt; rendered.sql\n</code></pre></p> </li> </ol>"},{"location":"models/model-operations/#54-macro-best-practices","title":"5.4 Macro Best Practices","text":"<p>\u2705 DO:</p> <ul> <li>Use macros for reusable logic</li> <li>Document macro functions</li> <li>Use type hints in Python macros</li> <li>Test macros independently</li> <li>Keep macro logic simple</li> </ul> <p>\u274c DON'T:</p> <ul> <li>Overuse macros (prefer CTEs for complex logic)</li> <li>Create circular macro dependencies</li> <li>Use macros for simple string substitution</li> <li>Forget to handle edge cases</li> <li>Make macros too complex</li> </ul> <p>Performance Considerations:</p> <ul> <li>Macros are evaluated at render time (not runtime)</li> <li>Complex macros can slow down rendering</li> <li>Cache macro results when possible</li> <li>Avoid expensive computations in macros</li> </ul> <p>\u2191 Back to Top</p>"},{"location":"models/model-operations/#6-model-dependencies","title":"6. Model Dependencies","text":"<p>Vulcan automatically detects model dependencies by analyzing SQL queries and Python model code. However, you can also manage dependencies explicitly.</p>"},{"location":"models/model-operations/#61-automatic-detection","title":"6.1 Automatic Detection","text":"<p>SQL Models:</p> <p>Dependencies are detected from: - <code>FROM</code> clauses - <code>JOIN</code> clauses - CTE references - Subquery references</p> <pre><code>MODEL (\n  name analytics.dependent_model,\n  kind FULL\n);\n\n-- Vulcan automatically detects dependency on raw.orders\nSELECT * FROM raw.orders;\n</code></pre> <p>Python Models:</p> <p>Dependencies are detected from: - <code>context.resolve_table()</code> calls - <code>context.fetchdf()</code> queries - <code>context.spark.table()</code> calls</p> <pre><code>@model(\"analytics.python_dependent\", columns={\"id\": \"int\"})\ndef execute(context, **kwargs):\n    # Vulcan automatically detects dependency on raw.orders\n    table = context.resolve_table(\"raw.orders\")\n    return context.fetchdf(f\"SELECT * FROM {table}\")\n</code></pre>"},{"location":"models/model-operations/#62-explicit-dependencies","title":"6.2 Explicit Dependencies","text":"<p>SQL Models:</p> <pre><code>MODEL (\n  name analytics.explicit_deps,\n  kind FULL,\n  depends_on (raw.orders, raw.customers)  -- Explicit dependencies\n);\n\n-- Even if not referenced in query, these are tracked\nSELECT 1;\n</code></pre> <p>Python Models:</p> <pre><code>@model(\n    \"analytics.explicit_python_deps\",\n    depends_on=[\"raw.orders\", \"raw.customers\"],  -- Explicit dependencies\n    columns={\"id\": \"int\"},\n)\ndef execute(context, **kwargs):\n    # Only explicit dependencies are tracked\n    # Dynamic references are ignored\n    return pd.DataFrame([{\"id\": 1}])\n</code></pre> <p>When to Use Explicit Dependencies:</p> <ul> <li>Dynamic table references (string interpolation)</li> <li>Conditional dependencies</li> <li>External dependencies not in queries</li> <li>Documentation purposes</li> </ul>"},{"location":"models/model-operations/#63-circular-dependencies","title":"6.3 Circular Dependencies","text":"<p>Vulcan detects circular dependencies and prevents them:</p> <pre><code>-- Model A depends on Model B\nMODEL (name analytics.model_a, kind FULL);\nSELECT * FROM analytics.model_b;\n\n-- Model B depends on Model A (CIRCULAR!)\nMODEL (name analytics.model_b, kind FULL);\nSELECT * FROM analytics.model_a;\n</code></pre> <p>Error: <pre><code>Circular dependency detected: analytics.model_a -&gt; analytics.model_b -&gt; analytics.model_a\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Refactor to remove circular dependency: <pre><code>-- Create intermediate model\nMODEL (name analytics.base_data, kind FULL);\nSELECT * FROM raw.source;\n\nMODEL (name analytics.model_a, kind FULL);\nSELECT * FROM analytics.base_data;\n\nMODEL (name analytics.model_b, kind FULL);\nSELECT * FROM analytics.base_data;\n</code></pre></p> </li> <li> <p>Use VIEW models for read-only dependencies: <pre><code>MODEL (name analytics.view_a, kind VIEW);\nSELECT * FROM analytics.model_b;\n\nMODEL (name analytics.model_b, kind FULL);\nSELECT * FROM analytics.view_a;  -- VIEW doesn't create circular dependency\n</code></pre></p> </li> </ol>"},{"location":"models/model-operations/#64-dependency-visualization","title":"6.4 Dependency Visualization","text":"<p>View DAG:</p> <pre><code># View dependency graph\nvulcan dag\n\n# View specific model dependencies\nvulcan dag --select analytics.my_model\n\n# Export to file\nvulcan dag --select analytics.my_model &gt; dag.dot\n</code></pre> <p>Understanding Dependencies:</p> <ul> <li>Upstream: Models that this model depends on</li> <li>Downstream: Models that depend on this model</li> <li>Direct: Explicitly referenced in query</li> <li>Indirect: Dependencies of dependencies</li> </ul> <p>\u2191 Back to Top</p>"},{"location":"models/model-operations/#7-model-blueprinting","title":"7. Model Blueprinting","text":"<p>Blueprinting allows you to create multiple models from a single template by parameterizing model names and properties.</p>"},{"location":"models/model-operations/#71-sql-model-blueprinting","title":"7.1 SQL Model Blueprinting","text":"<p>Basic Example:</p> <pre><code>MODEL (\n  name @customer.some_table,\n  kind FULL,\n  blueprints (\n    (customer := customer1, field_a := x, field_b := y),\n    (customer := customer2, field_a := z, field_b := w)\n  )\n);\n\nSELECT\n  @field_a,\n  @{field_b} AS field_b\nFROM @customer.some_source\n</code></pre> <p>Generated Models:</p> <pre><code>-- customer1.some_table\nMODEL (name customer1.some_table, kind FULL);\nSELECT 'x', y AS field_b FROM customer1.some_source;\n\n-- customer2.some_table\nMODEL (name customer2.some_table, kind FULL);\nSELECT 'z', w AS field_b FROM customer2.some_source;\n</code></pre> <p>Variable Syntax:</p> <ul> <li><code>@field_a</code> \u2192 String literal (<code>'x'</code>)</li> <li><code>@{field_b}</code> \u2192 SQL identifier (<code>y</code>)</li> <li><code>@customer</code> \u2192 Used in model name and table references</li> </ul>"},{"location":"models/model-operations/#72-python-model-blueprinting","title":"7.2 Python Model Blueprinting","text":"<p>Basic Example:</p> <pre><code>@model(\n    \"@{customer}.some_table\",\n    is_sql=True,\n    kind=\"FULL\",\n    blueprints=[\n        {\"customer\": \"customer1\", \"field_a\": \"x\", \"field_b\": \"y\"},\n        {\"customer\": \"customer2\", \"field_a\": \"z\", \"field_b\": \"w\"},\n    ],\n)\ndef entrypoint(evaluator: MacroEvaluator) -&gt; str | exp.Expression:\n    field_a = evaluator.blueprint_var(\"field_a\")\n    field_b = evaluator.blueprint_var(\"field_b\")\n    customer = evaluator.blueprint_var(\"customer\")\n\n    return exp.select(field_a, field_b).from_(f\"{customer}.some_source\")\n</code></pre> <p>Python DataFrame Models:</p> <pre><code>@model(\n    \"@{customer}.metrics\",\n    kind=\"FULL\",\n    blueprints=[\n        {\"customer\": \"customer1\", \"region\": \"US\"},\n        {\"customer\": \"customer2\", \"region\": \"EU\"},\n    ],\n    columns={\"date\": \"date\", \"revenue\": \"decimal(10,2)\", \"region\": \"text\"},\n)\ndef execute(context, **kwargs):\n    customer = context.blueprint_var(\"customer\")\n    region = context.blueprint_var(\"region\")\n\n    table = context.resolve_table(f\"raw.{customer}_transactions\")\n    df = context.fetchdf(f\"SELECT * FROM {table}\")\n    df['region'] = region\n    return df\n</code></pre>"},{"location":"models/model-operations/#73-dynamic-blueprint-generation","title":"7.3 Dynamic Blueprint Generation","text":"<p>Using Macros:</p> <pre><code># macros/__init__.py\nfrom vulcan import macro\n\n@macro()\ndef gen_blueprints(evaluator):\n    \"\"\"Generate blueprints from external source.\"\"\"\n    import csv\n\n    blueprints = []\n    with open('customers.csv', 'r') as f:\n        reader = csv.DictReader(f)\n        for row in reader:\n            blueprints.append({\n                \"customer\": row['customer_id'],\n                \"region\": row['region'],\n            })\n\n    return str(blueprints).replace(\"'\", \"\")  # Convert to SQL format\n</code></pre> <p>SQL Usage:</p> <pre><code>MODEL (\n  name @customer.metrics,\n  kind FULL,\n  blueprints @gen_blueprints()\n);\n\nSELECT * FROM @customer.source;\n</code></pre> <p>Using EACH:</p> <pre><code>MODEL (\n  name @customer.some_table,\n  kind FULL,\n  blueprints @EACH(@customer_list, x -&gt; (customer := @x))\n);\n\nSELECT * FROM @customer.source;\n</code></pre>"},{"location":"models/model-operations/#74-blueprint-best-practices","title":"7.4 Blueprint Best Practices","text":"<p>\u2705 DO:</p> <ul> <li>Use blueprints for similar models</li> <li>Document blueprint variables</li> <li>Test blueprints with sample data</li> <li>Use meaningful variable names</li> <li>Keep blueprint logic simple</li> </ul> <p>\u274c DON'T:</p> <ul> <li>Overuse blueprints (prefer separate models when logic differs significantly)</li> <li>Create too many blueprints (hard to maintain)</li> <li>Use blueprints for completely different models</li> <li>Forget to update all blueprints when changing template</li> </ul> <p>When to Use:</p> <ul> <li>\u2705 Multiple customers/tenants with same logic</li> <li>\u2705 Multiple regions with same structure</li> <li>\u2705 Multiple environments with same schema</li> <li> <p>\u2705 Repeated patterns across models</p> </li> <li> <p>\u274c Models with significantly different logic</p> </li> <li>\u274c One-off models</li> <li>\u274c Models that will diverge over time</li> </ul> <p>\u2191 Back to Top</p>"},{"location":"models/model-operations/#8-summary-and-next-steps","title":"8. Summary and Next Steps","text":""},{"location":"models/model-operations/#what-youve-learned","title":"What You've Learned","text":"<p>This chapter covered advanced patterns and operations for building sophisticated models:</p> <ol> <li>Advanced SQL Patterns: Python-based SQL models, complex CTEs, advanced pre/post statements</li> <li>Advanced Python Patterns: Blueprinting, DataFrame APIs, batching, serialization</li> <li>Signals: Multiple signals, interval filtering, advanced patterns, testing</li> <li>Macros: Advanced operators, complex patterns, debugging, best practices</li> <li>Dependencies: Automatic detection, explicit dependencies, circular dependency handling</li> <li>Blueprinting: SQL and Python blueprinting, dynamic generation</li> </ol>"},{"location":"models/model-operations/#next-steps","title":"Next Steps","text":"<ul> <li>Chapter 2D: Model Optimization - Performance optimization and warehouse-specific tuning</li> <li>Chapter 2A: Model Properties - Complete reference for all model properties</li> <li>Chapter 2B: Model Testing - Comprehensive testing guide</li> </ul>"},{"location":"models/model-operations/#related-chapters","title":"Related Chapters","text":"<ul> <li>Chapter 2: Models - Foundation concepts</li> <li>Chapter 4: Audits - Data quality checks</li> <li>Chapter 5: Quality Checks - Comprehensive validation</li> </ul> <p>Ready to optimize your models? Continue to Chapter 2D: Model Optimization</p> <p>\u2191 Back to Top</p>"},{"location":"models/model-optimization/","title":"Chapter 2D: Model Optimization","text":"<p>Optimize model performance and warehouse costs - Performance tuning, warehouse-specific optimization, query optimization, and best practices for production models.</p>"},{"location":"models/model-optimization/#prerequisites","title":"Prerequisites","text":"<p>Before reading this chapter, you should be familiar with:</p> <ul> <li>Chapter 2: Models - Foundation concepts</li> <li>Chapter 2A: Model Properties - Property reference</li> <li>Basic understanding of your data warehouse (Snowflake, BigQuery, Databricks, etc.)</li> <li>SQL query optimization concepts</li> </ul>"},{"location":"models/model-optimization/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Introduction</li> <li>Performance Fundamentals</li> <li>Model Kinds Optimization</li> <li>Query Optimization</li> <li>Warehouse-Specific Optimization</li> <li>Advanced Properties Optimization</li> <li>Cost Optimization</li> <li>Troubleshooting Performance</li> <li>Best Practices</li> <li>Summary and Next Steps</li> </ol>"},{"location":"models/model-optimization/#1-introduction","title":"1. Introduction","text":"<p>Model optimization is critical for: - Performance: Faster execution times - Cost: Lower warehouse compute costs - Reliability: Avoiding timeouts and failures - Scalability: Handling growing data volumes</p> <p>This chapter covers: - Choosing optimal model kinds - Query optimization strategies - Warehouse-specific tuning - Cost optimization techniques - Performance troubleshooting</p> <p>For basics, see Chapter 2: Models</p> <p>\u2191 Back to Top</p>"},{"location":"models/model-optimization/#2-performance-fundamentals","title":"2. Performance Fundamentals","text":""},{"location":"models/model-optimization/#21-understanding-performance-bottlenecks","title":"2.1 Understanding Performance Bottlenecks","text":"<p>Common bottlenecks:</p> <ol> <li>Full table scans - Scanning entire tables instead of partitions</li> <li>Large backfills - Processing years of data in one job</li> <li>Inefficient joins - Cartesian products, missing indexes</li> <li>Over-aggregation - Computing unnecessary aggregations</li> <li>Resource contention - Too many concurrent queries</li> </ol> <p>Performance equation:</p> <pre><code>Total Execution Time = \n  Query Execution Time + \n  Data Transfer Time + \n  Warehouse Overhead\n</code></pre> <p>Optimization targets: - Reduce data scanned (partitioning, filtering) - Reduce computation (aggregation, joins) - Reduce concurrency conflicts (batching, scheduling)</p>"},{"location":"models/model-optimization/#22-incremental-vs-full-refresh","title":"2.2 Incremental vs Full Refresh","text":"<p>The biggest performance win: Use incremental models</p> <pre><code>-- \u274c FULL: Rebuilds entire table every run\nMODEL (\n  name analytics.events,\n  kind FULL\n);\n-- Execution: 2 hours, scans 100M rows daily\n\n-- \u2705 INCREMENTAL: Only processes new data\nMODEL (\n  name analytics.events,\n  kind INCREMENTAL_BY_TIME_RANGE (time_column event_date)\n);\n-- Execution: 5 minutes, scans 1M rows daily (today's data only)\n</code></pre> <p>Performance improvement: - 10-100x faster execution - 10-100x lower compute costs - Scalable as data grows</p> <p>When incremental isn't possible: - Small lookup tables (&lt; 1M rows) - FULL is fine - Non-temporal data - Use FULL or INCREMENTAL_BY_UNIQUE_KEY - Frequently changing logic - Consider VIEW</p>"},{"location":"models/model-optimization/#23-query-execution-patterns","title":"2.3 Query Execution Patterns","text":"<p>Pattern 1: Filter Early</p> <pre><code>-- \u274c Bad: Filter after join\nSELECT *\nFROM large_table l\nJOIN huge_table h ON l.id = h.id\nWHERE l.event_date = '2024-01-15';\n\n-- \u2705 Good: Filter before join\nSELECT *\nFROM (\n  SELECT * FROM large_table \n  WHERE event_date = '2024-01-15'\n) l\nJOIN huge_table h ON l.id = h.id;\n</code></pre> <p>Pattern 2: Use Partition Pruning</p> <pre><code>-- \u2705 Partitioned table with filter\nMODEL (\n  name analytics.events,\n  partitioned_by event_date\n);\n\nSELECT * FROM analytics.events\nWHERE event_date BETWEEN @start_ds AND @end_ds;\n-- Only scans partitions for date range\n</code></pre> <p>Pattern 3: Pre-aggregate When Possible</p> <pre><code>-- \u274c Bad: Expose raw events (billions of rows)\nMODEL (name analytics.raw_events);\nSELECT * FROM raw.events;\n\n-- \u2705 Good: Pre-aggregate (millions of rows)\nMODEL (name analytics.daily_event_summary);\nSELECT\n  event_date,\n  customer_id,\n  event_type,\n  COUNT(*) as event_count,\n  SUM(value) as total_value\nFROM raw.events\nGROUP BY event_date, customer_id, event_type;\n</code></pre>"},{"location":"models/model-optimization/#24-batch-processing","title":"2.4 Batch Processing","text":"<p>Use <code>batch_size</code> for large backfills:</p> <pre><code>MODEL (\n  name analytics.hourly_events,\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column event_date,\n    batch_size 24  -- Process 24 hours per batch\n  ),\n  cron '@hourly'\n);\n</code></pre> <p>Why batch?</p> <ul> <li>Without batching: 72 hours = 1 job (may timeout)</li> <li>With batching: 72 hours \u00f7 24 = 3 jobs (reliable)</li> </ul> <p>Batch size guidelines:</p> Model Frequency Recommended Batch Size Hourly 12-48 hours Daily 7-30 days Weekly 4-12 weeks <p>Start conservative, increase if stable:</p> <pre><code>-- Start small\nbatch_size 7  -- 7 days per batch\n\n-- Increase if stable\nbatch_size 30  -- 30 days per batch\n</code></pre>"},{"location":"models/model-optimization/#25-concurrency-control","title":"2.5 Concurrency Control","text":"<p>Use <code>batch_concurrency</code> to limit parallel execution:</p> <pre><code>MODEL (\n  name analytics.events,\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column event_date,\n    batch_size 24,\n    batch_concurrency 3  -- Max 3 batches in parallel\n  )\n);\n</code></pre> <p>Why limit concurrency?</p> <ul> <li>Warehouse limits: Most warehouses have connection limits</li> <li>Resource contention: Too many queries compete for resources</li> <li>Cost control: Parallel queries multiply costs</li> </ul> <p>Concurrency guidelines:</p> <ul> <li>Snowflake: 5-10 concurrent queries per warehouse</li> <li>BigQuery: 100 concurrent queries (but use slots wisely)</li> <li>Databricks: Depends on cluster size</li> </ul> <p>Monitor and adjust:</p> <pre><code># Check warehouse utilization\nvulcan info\n\n# Adjust if you see:\n# - Query timeouts \u2192 Reduce batch_concurrency\n# - Underutilized warehouse \u2192 Increase batch_concurrency\n</code></pre> <p>\u2191 Back to Top</p>"},{"location":"models/model-optimization/#3-model-kinds-optimization","title":"3. Model Kinds Optimization","text":""},{"location":"models/model-optimization/#31-choosing-the-right-model-kind","title":"3.1 Choosing the Right Model Kind","text":"<p>Decision tree:</p> <pre><code>Is data temporal (time-based)?\n\u2502\n\u251c\u2500 YES \u2192 Use INCREMENTAL_BY_TIME_RANGE\n\u2502  \u2502\n\u2502  \u2514\u2500 Need late-arriving data handling?\n\u2502     \u2514\u2500 YES \u2192 Add lookback\n\u2502\n\u251c\u2500 NO \u2192 Is data append-only?\n\u2502  \u2502\n\u2502  \u251c\u2500 YES \u2192 Use INCREMENTAL_BY_UNIQUE_KEY\n\u2502  \u2502\n\u2502  \u2514\u2500 NO \u2192 Need historical tracking?\n\u2502     \u2502\n\u2502     \u251c\u2500 YES \u2192 Use SCD_TYPE_2\n\u2502     \u2502\n\u2502     \u2514\u2500 NO \u2192 Use FULL\n\u2502\n\u2514\u2500 Is table small (&lt; 1M rows)?\n   \u2514\u2500 YES \u2192 FULL is fine (simple, fast)\n</code></pre>"},{"location":"models/model-optimization/#32-incremental_by_time_range-optimization","title":"3.2 INCREMENTAL_BY_TIME_RANGE Optimization","text":"<p>Most common model kind - optimize carefully:</p>"},{"location":"models/model-optimization/#time-column-selection","title":"Time Column Selection","text":"<p>Choose the right time column:</p> <pre><code>-- \u2705 Good: UTC timestamp column\nMODEL (\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column event_timestamp_utc\n  )\n);\n\n-- \u274c Bad: Local time (timezone issues)\nMODEL (\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column event_timestamp_local  -- Avoid timezone confusion\n  )\n);\n</code></pre> <p>Best practices: - Use UTC timestamps - Use DATE columns for daily models - Index the time column</p>"},{"location":"models/model-optimization/#lookback-optimization","title":"Lookback Optimization","text":"<p>Balance late data vs performance:</p> <pre><code>-- \u274c Too aggressive: Reprocesses too much\nlookback 30  -- Reprocesses last 30 days every run\n\n-- \u2705 Balanced: Handles late data efficiently\nlookback 3  -- Reprocesses last 3 days\n\n-- \u274c Too conservative: Misses late data\nlookback 0  -- No late data handling\n</code></pre> <p>Lookback guidelines:</p> Data Latency Recommended Lookback Real-time (&lt; 1 hour) 0-1 intervals Daily batch 1-3 days Weekly batch 3-7 days High latency 7-30 days <p>Performance impact:</p> <pre><code>Without lookback: Processes 1 interval\nWith lookback 7: Processes 8 intervals (7 + current)\nCost: ~8x more expensive\n</code></pre> <p>Monitor late-arriving data:</p> <pre><code>-- Check for late arrivals\nSELECT \n  event_date,\n  COUNT(*) as late_arrivals\nFROM raw.events\nWHERE event_date &lt; CURRENT_DATE - INTERVAL '7 days'\n  AND created_at &gt; CURRENT_DATE - INTERVAL '1 day'\nGROUP BY event_date\nORDER BY event_date DESC;\n</code></pre>"},{"location":"models/model-optimization/#where-clause-optimization","title":"WHERE Clause Optimization","text":"<p>Always filter by time range:</p> <pre><code>-- \u2705 Good: Filters in query\nSELECT *\nFROM raw.events\nWHERE event_date BETWEEN @start_ds AND @end_ds;\n\n-- \u274c Bad: No filter (scans entire table)\nSELECT * FROM raw.events;\n</code></pre> <p>Use partition-aware filters:</p> <pre><code>-- \u2705 Good: Filter on partition column\nSELECT *\nFROM raw.events\nWHERE event_date BETWEEN @start_ds AND @end_ds\n  AND event_type = 'purchase';  -- Additional filter\n\n-- \u274c Bad: Filter on non-partition column first\nSELECT *\nFROM raw.events\nWHERE event_type = 'purchase'  -- Can't use partition pruning\n  AND event_date BETWEEN @start_ds AND @end_ds;\n</code></pre>"},{"location":"models/model-optimization/#33-incremental_by_unique_key-optimization","title":"3.3 INCREMENTAL_BY_UNIQUE_KEY Optimization","text":"<p>Optimize for append-only data:</p> <pre><code>MODEL (\n  name analytics.user_sessions,\n  kind INCREMENTAL_BY_UNIQUE_KEY (\n    unique_key session_id\n  )\n);\n</code></pre> <p>Key considerations:</p> <ul> <li>Unique key selection: Choose stable, unique identifier</li> <li>No lookback: This kind doesn't support lookback</li> <li>MERGE performance: Ensure unique key is indexed</li> </ul> <p>Optimize MERGE operations:</p> <pre><code>MODEL (\n  name analytics.orders,\n  kind INCREMENTAL_BY_UNIQUE_KEY (\n    unique_key order_id,\n    when_matched 'UPDATE',  -- Customize MERGE behavior\n    merge_filter 'source.status != target.status'  -- Only update if changed\n  )\n);\n</code></pre>"},{"location":"models/model-optimization/#34-scd_type_2-optimization","title":"3.4 SCD_TYPE_2 Optimization","text":"<p>Optimize for historical tracking:</p> <pre><code>MODEL (\n  name dim.customers,\n  kind SCD_TYPE_2_BY_TIME (\n    time_column updated_at,\n    unique_key customer_id\n  )\n);\n</code></pre> <p>Performance tips:</p> <ul> <li>Use SCD_TYPE_2_BY_TIME (recommended) - More efficient than BY_COLUMN</li> <li>Index unique key - Faster lookups</li> <li>Limit columns tracked - Only track columns that change</li> </ul> <p>Avoid tracking too many columns:</p> <pre><code>-- \u274c Bad: Tracks all columns (expensive)\nkind SCD_TYPE_2_BY_COLUMN (\n  columns (name, email, address, phone, preferences, ...)\n)\n\n-- \u2705 Good: Tracks only important columns\nkind SCD_TYPE_2_BY_TIME (\n  time_column updated_at  -- Simpler, more efficient\n)\n</code></pre>"},{"location":"models/model-optimization/#35-view-vs-table-tradeoffs","title":"3.5 VIEW vs TABLE Tradeoffs","text":"<p>VIEW models:</p> <pre><code>MODEL (\n  name analytics.realtime_metrics,\n  kind VIEW\n);\n</code></pre> <p>Use VIEW when: - \u2705 Data changes frequently - \u2705 Always need latest data - \u2705 Upstream models are fast - \u2705 No performance issues</p> <p>Use TABLE (FULL/INCREMENTAL) when: - \u2705 Downstream models need consistent snapshots - \u2705 Upstream models are slow - \u2705 Need to cache expensive computations - \u2705 Need to control refresh timing</p> <p>Performance comparison:</p> Aspect VIEW TABLE Execution Every query Once per refresh Consistency Always latest Snapshot at refresh time Performance Depends on upstream Cached Cost Per query Per refresh"},{"location":"models/model-optimization/#36-full-model-optimization","title":"3.6 FULL Model Optimization","text":"<p>Optimize full refresh models:</p> <pre><code>MODEL (\n  name dim.products,\n  kind FULL\n);\n</code></pre> <p>When FULL is appropriate:</p> <ul> <li>\u2705 Small tables (&lt; 1M rows)</li> <li>\u2705 Non-temporal data</li> <li>\u2705 Simple transformations</li> <li>\u2705 Infrequent changes</li> </ul> <p>Optimization strategies:</p> <ol> <li> <p>Add indexes (if supported): <pre><code>-- Postgres, MySQL\nCREATE INDEX idx_product_id ON dim.products(product_id);\n</code></pre></p> </li> <li> <p>Use materialized views (if supported): <pre><code>-- BigQuery\nCREATE MATERIALIZED VIEW dim.products_mv AS\nSELECT * FROM raw.products;\n</code></pre></p> </li> <li> <p>Schedule appropriately: <pre><code>MODEL (\n  name dim.products,\n  kind FULL,\n  cron '@weekly'  -- Refresh weekly, not daily\n);\n</code></pre></p> </li> </ol> <p>\u2191 Back to Top</p>"},{"location":"models/model-optimization/#4-query-optimization","title":"4. Query Optimization","text":""},{"location":"models/model-optimization/#41-sql-query-best-practices","title":"4.1 SQL Query Best Practices","text":""},{"location":"models/model-optimization/#select-only-needed-columns","title":"Select Only Needed Columns","text":"<pre><code>-- \u274c Bad: SELECT *\nSELECT * FROM large_table;\n\n-- \u2705 Good: Select specific columns\nSELECT \n  customer_id,\n  order_date,\n  amount\nFROM large_table;\n</code></pre> <p>Benefits: - Less data transferred - Faster execution - Lower costs</p>"},{"location":"models/model-optimization/#use-efficient-joins","title":"Use Efficient Joins","text":"<pre><code>-- \u274c Bad: Cartesian product risk\nSELECT *\nFROM table1 t1\nJOIN table2 t2;  -- Missing join condition\n\n-- \u2705 Good: Explicit join conditions\nSELECT *\nFROM table1 t1\nJOIN table2 t2 ON t1.id = t2.id;\n</code></pre> <p>Join order matters:</p> <pre><code>-- \u2705 Good: Filter before join\nSELECT *\nFROM (\n  SELECT * FROM large_table \n  WHERE event_date = '2024-01-15'\n) filtered\nJOIN small_table s ON filtered.id = s.id;\n\n-- \u274c Bad: Join before filter\nSELECT *\nFROM large_table l\nJOIN small_table s ON l.id = s.id\nWHERE l.event_date = '2024-01-15';\n</code></pre>"},{"location":"models/model-optimization/#avoid-unnecessary-aggregations","title":"Avoid Unnecessary Aggregations","text":"<pre><code>-- \u274c Bad: Aggregating then filtering\nSELECT customer_id, SUM(amount)\nFROM orders\nGROUP BY customer_id\nHAVING SUM(amount) &gt; 1000;\n\n-- \u2705 Good: Filter before aggregating\nSELECT customer_id, SUM(amount)\nFROM orders\nWHERE amount &gt; 0  -- Filter early\nGROUP BY customer_id\nHAVING SUM(amount) &gt; 1000;\n</code></pre>"},{"location":"models/model-optimization/#use-window-functions-efficiently","title":"Use Window Functions Efficiently","text":"<pre><code>-- \u2705 Good: Efficient window function\nSELECT \n  customer_id,\n  order_date,\n  amount,\n  SUM(amount) OVER (\n    PARTITION BY customer_id \n    ORDER BY order_date \n    ROWS BETWEEN 29 PRECEDING AND CURRENT ROW\n  ) AS rolling_30day_total\nFROM orders;\n\n-- \u274c Bad: Self-join for rolling calculation\nSELECT \n  o1.customer_id,\n  o1.order_date,\n  o1.amount,\n  SUM(o2.amount) AS rolling_30day_total\nFROM orders o1\nJOIN orders o2 \n  ON o1.customer_id = o2.customer_id\n  AND o2.order_date BETWEEN o1.order_date - INTERVAL '30 days' AND o1.order_date\nGROUP BY o1.customer_id, o1.order_date, o1.amount;\n</code></pre>"},{"location":"models/model-optimization/#42-sqlglot-query-optimizer","title":"4.2 SQLGlot Query Optimizer","text":"<p>Vulcan uses SQLGlot to optimize queries automatically:</p> <pre><code>MODEL (\n  name analytics.customers,\n  optimize_query TRUE  -- Default: enabled\n);\n</code></pre> <p>What the optimizer does:</p> <ol> <li>Qualifies column names - Adds table prefixes</li> <li>Simplifies expressions - Reduces complexity</li> <li>Inlines CTEs - Expands common table expressions</li> <li>Optimizes subqueries - Converts to joins when possible</li> <li>Removes redundant operations - Eliminates unnecessary steps</li> </ol> <p>Example optimization:</p> <pre><code>-- Before optimization\nWITH customer_totals AS (\n  SELECT customer_id, SUM(amount) as total\n  FROM orders\n  GROUP BY customer_id\n)\nSELECT * FROM customer_totals WHERE total &gt; 1000;\n\n-- After optimization (inlined)\nSELECT customer_id, SUM(amount) as total\nFROM orders\nGROUP BY customer_id\nHAVING SUM(amount) &gt; 1000;\n</code></pre> <p>When to disable optimizer:</p> <pre><code>MODEL (\n  name analytics.complex_query,\n  optimize_query FALSE  -- Disable if causes issues\n);\n</code></pre> <p>Disable when: - Query exceeds database text limits after optimization - Optimizer produces incorrect results (rare SQLGlot bugs) - Complex dynamic SQL with macros - You need to preserve exact query structure</p> <p>\u26a0\ufe0f Warning: Disabling prevents column-level lineage tracking!</p>"},{"location":"models/model-optimization/#43-cte-optimization","title":"4.3 CTE Optimization","text":"<p>Use CTEs for readability, but be aware of performance:</p> <pre><code>-- \u2705 Good: CTEs improve readability\nWITH \n  filtered_orders AS (\n    SELECT * FROM orders WHERE order_date &gt;= '2024-01-01'\n  ),\n  customer_totals AS (\n    SELECT customer_id, SUM(amount) as total\n    FROM filtered_orders\n    GROUP BY customer_id\n  )\nSELECT * FROM customer_totals WHERE total &gt; 1000;\n</code></pre> <p>CTE performance considerations:</p> <ul> <li>Materialized CTEs (some warehouses): CTEs are computed once</li> <li>Inlined CTEs (most warehouses): CTEs are expanded inline</li> <li>Multiple references: May recompute CTE multiple times</li> </ul> <p>Optimize multiple CTE references:</p> <pre><code>-- \u274c Bad: CTE referenced multiple times (may recompute)\nWITH expensive_cte AS (\n  SELECT * FROM huge_table WHERE complex_condition\n)\nSELECT * FROM expensive_cte\nUNION ALL\nSELECT * FROM expensive_cte;\n\n-- \u2705 Good: Materialize if needed (warehouse-specific)\n-- Or: Use temporary table for very expensive CTEs\n</code></pre>"},{"location":"models/model-optimization/#44-subquery-optimization","title":"4.4 Subquery Optimization","text":"<p>Convert correlated subqueries to joins:</p> <pre><code>-- \u274c Bad: Correlated subquery\nSELECT \n  customer_id,\n  (SELECT MAX(order_date) \n   FROM orders o2 \n   WHERE o2.customer_id = o1.customer_id) AS last_order_date\nFROM customers o1;\n\n-- \u2705 Good: Join with aggregation\nSELECT \n  c.customer_id,\n  MAX(o.order_date) AS last_order_date\nFROM customers c\nLEFT JOIN orders o ON c.customer_id = o.customer_id\nGROUP BY c.customer_id;\n</code></pre> <p>Use EXISTS instead of IN for large lists:</p> <pre><code>-- \u274c Bad: IN with large list\nSELECT * FROM orders\nWHERE customer_id IN (\n  SELECT customer_id FROM customers WHERE status = 'active'\n  -- Returns 1M customer IDs\n);\n\n-- \u2705 Good: EXISTS (often more efficient)\nSELECT * FROM orders o\nWHERE EXISTS (\n  SELECT 1 FROM customers c\n  WHERE c.customer_id = o.customer_id\n    AND c.status = 'active'\n);\n</code></pre>"},{"location":"models/model-optimization/#45-index-usage","title":"4.5 Index Usage","text":"<p>Add indexes on frequently filtered columns:</p> <pre><code>-- Post-query optimization (via post_statements)\nMODEL (\n  name analytics.orders,\n  post_statements [\n    'CREATE INDEX idx_customer_id ON analytics.orders(customer_id)',\n    'CREATE INDEX idx_order_date ON analytics.orders(order_date)'\n  ]\n);\n</code></pre> <p>Index guidelines:</p> <ul> <li>Filter columns: Index columns in WHERE clauses</li> <li>Join columns: Index foreign keys</li> <li>Time columns: Index time columns for incremental models</li> <li>Composite indexes: For multi-column filters</li> </ul> <p>Warehouse-specific:</p> <ul> <li>Snowflake: Automatic clustering (no manual indexes)</li> <li>BigQuery: Automatic indexing (no manual indexes)</li> <li>Postgres/MySQL: Manual indexes required</li> <li>Databricks: Z-ordering instead of indexes</li> </ul> <p>\u2191 Back to Top</p>"},{"location":"models/model-optimization/#5-warehouse-specific-optimization","title":"5. Warehouse-Specific Optimization","text":""},{"location":"models/model-optimization/#51-snowflake-optimization","title":"5.1 Snowflake Optimization","text":""},{"location":"models/model-optimization/#clustering-keys","title":"Clustering Keys","text":"<p>Snowflake uses automatic clustering, but you can optimize:</p> <pre><code>MODEL (\n  name analytics.events,\n  clustered_by (customer_id, event_date)  -- Optimize for common queries\n);\n</code></pre> <p>Clustering guidelines:</p> <ul> <li>High cardinality columns: Customer IDs, user IDs</li> <li>Filter columns: Columns frequently used in WHERE clauses</li> <li>Join columns: Foreign keys</li> <li>Limit to 3-4 columns: More columns = diminishing returns</li> </ul> <p>Monitor clustering:</p> <pre><code>-- Check clustering effectiveness\nSELECT SYSTEM$CLUSTERING_INFORMATION('analytics.events', '(customer_id, event_date)');\n</code></pre>"},{"location":"models/model-optimization/#warehouse-selection","title":"Warehouse Selection","text":"<p>Use appropriate warehouse size:</p> <pre><code>MODEL (\n  name analytics.large_processing,\n  physical_properties (\n    warehouse = 'LARGE_WH'  -- Use larger warehouse for heavy queries\n  )\n);\n</code></pre> <p>Warehouse sizing:</p> <ul> <li>X-Small: Development, small queries</li> <li>Small: Most production models</li> <li>Medium: Large aggregations, complex joins</li> <li>Large+: Very large backfills, heavy processing</li> </ul>"},{"location":"models/model-optimization/#transient-tables","title":"Transient Tables","text":"<p>Use transient tables for cost savings:</p> <pre><code>MODEL (\n  name analytics.temp_metrics,\n  physical_properties (\n    creatable_type = TRANSIENT,  -- Lower cost, no fail-safe\n    data_retention_time_in_days = 0  -- No Time Travel\n  )\n);\n</code></pre> <p>When to use transient:</p> <ul> <li>\u2705 Intermediate/temporary models</li> <li>\u2705 Models rebuilt frequently</li> <li>\u2705 No need for Time Travel</li> <li>\u274c Production fact tables (use permanent)</li> </ul>"},{"location":"models/model-optimization/#query-tagging","title":"Query Tagging","text":"<p>Tag queries for monitoring:</p> <pre><code>MODEL (\n  name analytics.customer_metrics,\n  session_properties (\n    query_tag = 'analytics_pipeline_customer'  -- Track in query history\n  )\n);\n</code></pre> <p>Benefits:</p> <ul> <li>Track query costs by pipeline</li> <li>Monitor performance trends</li> <li>Debug slow queries</li> </ul>"},{"location":"models/model-optimization/#52-bigquery-optimization","title":"5.2 BigQuery Optimization","text":""},{"location":"models/model-optimization/#partitioning","title":"Partitioning","text":"<p>Partition by date for time-series data:</p> <pre><code>MODEL (\n  name analytics.events,\n  partitioned_by event_date,  -- Partition by DATE column\n  physical_properties (\n    partition_expiration_days = 90,  -- Auto-delete old partitions\n    require_partition_filter = TRUE  -- Force partition filtering\n  )\n);\n</code></pre> <p>Partition types:</p> <ul> <li>DATE: Daily partitions (most common)</li> <li>TIMESTAMP: Hourly partitions (for high-frequency data)</li> <li>INTEGER: Range partitions (for numeric ranges)</li> </ul> <p>Partition expiration:</p> <pre><code>physical_properties (\n  partition_expiration_days = 365  -- Auto-delete partitions older than 1 year\n)\n</code></pre>"},{"location":"models/model-optimization/#clustering","title":"Clustering","text":"<p>Cluster by high-cardinality columns:</p> <pre><code>MODEL (\n  name analytics.orders,\n  partitioned_by order_date,\n  clustered_by (customer_id, product_id)  -- Optimize for common filters\n);\n</code></pre> <p>Clustering guidelines:</p> <ul> <li>Up to 4 columns: More columns = diminishing returns</li> <li>High cardinality: Customer IDs, product IDs</li> <li>Filter columns: Columns in WHERE clauses</li> <li>Join columns: Foreign keys</li> </ul> <p>Performance impact:</p> <ul> <li>10-100x faster queries with partition + cluster filters</li> <li>Lower costs (scan less data)</li> </ul>"},{"location":"models/model-optimization/#require-partition-filter","title":"Require Partition Filter","text":"<p>Force partition filtering:</p> <pre><code>MODEL (\n  name analytics.events,\n  partitioned_by event_date,\n  physical_properties (\n    require_partition_filter = TRUE  -- Prevents full table scans\n  )\n);\n</code></pre> <p>Benefits:</p> <ul> <li>Prevents accidental full table scans</li> <li>Enforces best practices</li> <li>Reduces costs</li> </ul>"},{"location":"models/model-optimization/#maximum-bytes-billed","title":"Maximum Bytes Billed","text":"<p>Set cost limits:</p> <pre><code>MODEL (\n  name analytics.experimental_query,\n  session_properties (\n    'maximum_bytes_billed' = '10000000000'  -- 10GB limit\n  )\n);\n</code></pre> <p>Use for:</p> <ul> <li>Experimental queries</li> <li>Cost control</li> <li>Preventing runaway queries</li> </ul>"},{"location":"models/model-optimization/#53-databricksspark-optimization","title":"5.3 Databricks/Spark Optimization","text":""},{"location":"models/model-optimization/#partitioning_1","title":"Partitioning","text":"<p>Partition by date and other dimensions:</p> <pre><code>MODEL (\n  name analytics.events,\n  partitioned_by (event_date, event_type),  -- Multi-column partition\n  storage_format 'delta'\n);\n</code></pre> <p>Partition guidelines:</p> <ul> <li>Date columns: Always partition by date for time-series</li> <li>Low cardinality: Event type, region (avoid high cardinality)</li> <li>Limit partitions: Too many partitions = performance degradation</li> </ul>"},{"location":"models/model-optimization/#delta-lake-optimization","title":"Delta Lake Optimization","text":"<p>Enable auto-optimization:</p> <pre><code>MODEL (\n  name analytics.events,\n  physical_properties (\n    delta.autoOptimize.optimizeWrite = true,  -- Optimize writes\n    delta.autoOptimize.autoCompact = true     -- Auto-compact files\n  ),\n  partitioned_by event_date\n);\n</code></pre> <p>Benefits:</p> <ul> <li>Optimize writes: Coalesces small files</li> <li>Auto-compact: Reduces file count</li> <li>Better performance: Faster queries</li> </ul>"},{"location":"models/model-optimization/#z-ordering","title":"Z-Ordering","text":"<p>Use Z-ordering for multi-column queries:</p> <pre><code>MODEL (\n  name analytics.orders,\n  partitioned_by order_date,\n  -- Z-order by common filter columns (Databricks-specific)\n  -- Configured via physical_properties or post_statements\n);\n</code></pre> <p>Z-ordering example:</p> <pre><code>-- Post-statement to Z-order\nMODEL (\n  name analytics.orders,\n  post_statements [\n    'OPTIMIZE analytics.orders ZORDER BY (customer_id, product_id)'\n  ]\n);\n</code></pre>"},{"location":"models/model-optimization/#resource-allocation","title":"Resource Allocation","text":"<p>Configure Spark resources:</p> <pre><code>MODEL (\n  name analytics.heavy_processing,\n  session_properties (\n    'spark.executor.cores' = 4,\n    'spark.executor.memory' = '8G',\n    'spark.sql.shuffle.partitions' = 200\n  )\n);\n</code></pre> <p>Resource guidelines:</p> <ul> <li>Executor cores: 2-8 per executor</li> <li>Executor memory: 4-16GB per executor</li> <li>Shuffle partitions: 200-400 (adjust based on data size)</li> </ul>"},{"location":"models/model-optimization/#54-postgres-optimization","title":"5.4 Postgres Optimization","text":""},{"location":"models/model-optimization/#indexes","title":"Indexes","text":"<p>Create indexes on filter and join columns:</p> <pre><code>MODEL (\n  name analytics.orders,\n  post_statements [\n    'CREATE INDEX idx_customer_id ON analytics.orders(customer_id)',\n    'CREATE INDEX idx_order_date ON analytics.orders(order_date)',\n    'CREATE INDEX idx_customer_date ON analytics.orders(customer_id, order_date)'\n  ]\n);\n</code></pre> <p>Index types:</p> <ul> <li>B-tree: Default, good for most queries</li> <li>Hash: Equality lookups only</li> <li>GIN: Full-text search, arrays</li> <li>GiST: Geometric data, full-text search</li> </ul>"},{"location":"models/model-optimization/#partitioning_2","title":"Partitioning","text":"<p>Partition large tables:</p> <pre><code>MODEL (\n  name analytics.events,\n  partitioned_by event_date  -- Postgres supports date partitioning\n);\n</code></pre> <p>Partition strategies:</p> <ul> <li>Range partitioning: By date ranges</li> <li>List partitioning: By discrete values</li> <li>Hash partitioning: Distribute data evenly</li> </ul>"},{"location":"models/model-optimization/#vacuum-and-analyze","title":"Vacuum and Analyze","text":"<p>Maintain table statistics:</p> <pre><code>MODEL (\n  name analytics.orders,\n  post_statements [\n    'ANALYZE analytics.orders'  -- Update statistics for query planner\n  ]\n);\n</code></pre> <p>Benefits:</p> <ul> <li>Better query plans</li> <li>Accurate row estimates</li> <li>Optimal join order</li> </ul>"},{"location":"models/model-optimization/#55-duckdb-optimization","title":"5.5 DuckDB Optimization","text":""},{"location":"models/model-optimization/#columnar-storage","title":"Columnar Storage","text":"<p>DuckDB is columnar by default - optimize for columnar access:</p> <pre><code>-- \u2705 Good: Columnar-friendly queries\nSELECT \n  customer_id,\n  SUM(amount) as total\nFROM orders\nGROUP BY customer_id;\n\n-- \u274c Bad: Row-by-row processing\nSELECT * FROM orders WHERE complex_function(column);\n</code></pre>"},{"location":"models/model-optimization/#memory-configuration","title":"Memory Configuration","text":"<p>Configure memory limits:</p> <pre><code>MODEL (\n  name analytics.local_processing,\n  session_properties (\n    'memory_limit' = '8GB'  -- Limit memory usage\n  )\n);\n</code></pre> <p>Use cases:</p> <ul> <li>Local development</li> <li>Small to medium datasets</li> <li>Fast analytical queries</li> </ul> <p>\u2191 Back to Top</p>"},{"location":"models/model-optimization/#6-advanced-properties-optimization","title":"6. Advanced Properties Optimization","text":""},{"location":"models/model-optimization/#61-batch-size-optimization","title":"6.1 Batch Size Optimization","text":"<p>Optimize <code>batch_size</code> for your data:</p> <pre><code>MODEL (\n  name analytics.hourly_events,\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column event_date,\n    batch_size 24  -- Process 24 hours per batch\n  ),\n  cron '@hourly'\n);\n</code></pre> <p>Batch size calculation:</p> <pre><code>Optimal batch_size = \n  (Query timeout limit) / (Time per interval) * 0.8\n</code></pre> <p>Example:</p> <ul> <li>Query timeout: 1 hour</li> <li>Time per interval: 2 minutes</li> <li>Optimal batch_size: (60 min / 2 min) * 0.8 = 24 intervals</li> </ul> <p>Adjust based on performance:</p> <pre><code>-- Start conservative\nbatch_size 12\n\n-- Increase if stable\nbatch_size 24\n\n-- Decrease if timeouts occur\nbatch_size 6\n</code></pre>"},{"location":"models/model-optimization/#62-batch-concurrency-optimization","title":"6.2 Batch Concurrency Optimization","text":"<p>Control parallel execution:</p> <pre><code>MODEL (\n  name analytics.events,\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column event_date,\n    batch_size 24,\n    batch_concurrency 5  -- Max 5 batches in parallel\n  )\n);\n</code></pre> <p>Concurrency guidelines:</p> Warehouse Recommended Concurrency Snowflake 5-10 per warehouse BigQuery 20-50 (slot-dependent) Databricks 10-20 per cluster Postgres 5-10 per database <p>Monitor and adjust:</p> <pre><code># Check warehouse utilization\nvulcan info\n\n# If queries queue: Increase concurrency\n# If timeouts: Decrease concurrency\n</code></pre>"},{"location":"models/model-optimization/#63-lookback-optimization","title":"6.3 Lookback Optimization","text":"<p>Balance late data vs performance:</p> <pre><code>MODEL (\n  name analytics.orders,\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column order_date,\n    lookback 3  -- Reprocess last 3 days\n  )\n);\n</code></pre> <p>Lookback impact:</p> <pre><code>Without lookback: Processes 1 interval\nWith lookback 7: Processes 8 intervals\nCost: ~8x more expensive\n</code></pre> <p>Optimization strategy:</p> <ol> <li>Start with 0: <code>lookback 0</code></li> <li>Monitor late arrivals: Check for data arriving after processing</li> <li>Increase gradually: <code>lookback 1</code>, then <code>lookback 3</code>, etc.</li> <li>Monitor performance: Ensure lookback doesn't cause timeouts</li> </ol> <p>Measure late-arriving data:</p> <pre><code>-- Check for late arrivals\nSELECT \n  order_date,\n  COUNT(*) as late_arrivals,\n  MAX(created_at) as latest_arrival\nFROM raw.orders\nWHERE order_date &lt; CURRENT_DATE - INTERVAL '7 days'\n  AND created_at &gt; CURRENT_DATE - INTERVAL '1 day'\nGROUP BY order_date\nORDER BY late_arrivals DESC;\n</code></pre>"},{"location":"models/model-optimization/#64-forward-only-optimization","title":"6.4 Forward-Only Optimization","text":"<p>Use forward-only for very large tables:</p> <pre><code>MODEL (\n  name analytics.huge_table,\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column event_date,\n    forward_only TRUE  -- Never rebuild historical data\n  )\n);\n</code></pre> <p>When to use:</p> <ul> <li>\u2705 Tables with billions of rows</li> <li>\u2705 Years of historical data</li> <li>\u2705 Expensive to rebuild</li> <li>\u2705 Rarely need historical reprocessing</li> </ul> <p>Tradeoffs:</p> <ul> <li>\u2705 Faster deployments: No backfills</li> <li>\u2705 Lower costs: No historical reprocessing</li> <li>\u274c Less flexible: Can't easily fix historical data</li> <li>\u274c Schema changes: Limited by <code>on_destructive_change</code></li> </ul> <p>Schema change handling:</p> <pre><code>MODEL (\n  name analytics.huge_table,\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column event_date,\n    forward_only TRUE,\n    on_destructive_change 'warn',  -- Warn but allow\n    on_additive_change 'allow'     -- Allow new columns\n  )\n);\n</code></pre>"},{"location":"models/model-optimization/#65-allow-partials-optimization","title":"6.5 Allow Partials Optimization","text":"<p>Process incomplete intervals:</p> <pre><code>MODEL (\n  name analytics.realtime_metrics,\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column event_date\n  ),\n  allow_partials TRUE  -- Process today even if incomplete\n);\n</code></pre> <p>Use cases:</p> <ul> <li>Real-time dashboards</li> <li>Always-on metrics</li> <li>Force model to run every time</li> </ul> <p>Combined with <code>--ignore-cron</code>:</p> <pre><code># Force run even if cron hasn't elapsed\nvulcan run --ignore-cron\n</code></pre> <p>Performance consideration:</p> <ul> <li>Processes incomplete data (may need reprocessing later)</li> <li>Useful for real-time use cases</li> <li>May cause slight data inconsistencies</li> </ul>"},{"location":"models/model-optimization/#66-disable-restatement","title":"6.6 Disable Restatement","text":"<p>Prevent accidental restatements:</p> <pre><code>MODEL (\n  name analytics.append_only_log,\n  kind INCREMENTAL_BY_UNIQUE_KEY (\n    unique_key log_id,\n    disable_restatement TRUE  -- Never reprocess history\n  )\n);\n</code></pre> <p>Use for:</p> <ul> <li>Append-only tables</li> <li>Audit logs</li> <li>Immutable data</li> </ul> <p>Benefits:</p> <ul> <li>Prevents accidental data loss</li> <li>Protects historical data</li> <li>Enforces append-only pattern</li> </ul> <p>\u2191 Back to Top</p>"},{"location":"models/model-optimization/#7-cost-optimization","title":"7. Cost Optimization","text":""},{"location":"models/model-optimization/#71-warehouse-cost-factors","title":"7.1 Warehouse Cost Factors","text":"<p>Cost components:</p> <ol> <li>Compute costs: Query execution time</li> <li>Storage costs: Table storage</li> <li>Data transfer costs: Moving data between systems</li> </ol> <p>Optimization targets:</p> <ul> <li>Reduce compute time (faster queries)</li> <li>Reduce data scanned (partitioning, filtering)</li> <li>Reduce storage (partition expiration, compression)</li> </ul>"},{"location":"models/model-optimization/#72-compute-cost-optimization","title":"7.2 Compute Cost Optimization","text":""},{"location":"models/model-optimization/#reduce-query-execution-time","title":"Reduce Query Execution Time","text":"<p>Use incremental models:</p> <pre><code>-- \u274c Expensive: Full refresh daily\nkind FULL  -- Scans 100M rows daily\n\n-- \u2705 Cheap: Incremental daily\nkind INCREMENTAL_BY_TIME_RANGE  -- Scans 1M rows daily\n</code></pre> <p>Filter early:</p> <pre><code>-- \u2705 Good: Filters before expensive operations\nSELECT *\nFROM (\n  SELECT * FROM large_table \n  WHERE event_date = '2024-01-15'  -- Filter first\n) filtered\nJOIN huge_table h ON filtered.id = h.id;\n</code></pre>"},{"location":"models/model-optimization/#optimize-aggregations","title":"Optimize Aggregations","text":"<p>Pre-aggregate when possible:</p> <pre><code>-- \u274c Expensive: Aggregating billions of events\nSELECT \n  customer_id,\n  event_date,\n  COUNT(*) as event_count\nFROM raw.events  -- Billions of rows\nGROUP BY customer_id, event_date;\n\n-- \u2705 Cheap: Pre-aggregated\nSELECT \n  customer_id,\n  event_date,\n  event_count  -- Pre-computed\nFROM analytics.daily_event_summary;  -- Millions of rows\n</code></pre>"},{"location":"models/model-optimization/#use-appropriate-warehouse-size","title":"Use Appropriate Warehouse Size","text":"<p>Right-size warehouses:</p> <pre><code>-- \u274c Expensive: Over-provisioned\nphysical_properties (\n  warehouse = 'X-LARGE_WH'  -- Too big for workload\n)\n\n-- \u2705 Optimal: Right-sized\nphysical_properties (\n  warehouse = 'MEDIUM_WH'  -- Appropriate for workload\n)\n</code></pre>"},{"location":"models/model-optimization/#73-storage-cost-optimization","title":"7.3 Storage Cost Optimization","text":""},{"location":"models/model-optimization/#partition-expiration","title":"Partition Expiration","text":"<p>Auto-delete old partitions:</p> <pre><code>MODEL (\n  name analytics.events,\n  partitioned_by event_date,\n  physical_properties (\n    partition_expiration_days = 90  -- Delete partitions older than 90 days\n  )\n);\n</code></pre> <p>Benefits:</p> <ul> <li>Automatic cleanup</li> <li>Lower storage costs</li> <li>No manual maintenance</li> </ul>"},{"location":"models/model-optimization/#transient-tables_1","title":"Transient Tables","text":"<p>Use transient tables for temporary data:</p> <pre><code>MODEL (\n  name analytics.temp_metrics,\n  physical_properties (\n    creatable_type = TRANSIENT,  -- Lower cost, no fail-safe\n    data_retention_time_in_days = 0  -- No Time Travel\n  )\n);\n</code></pre> <p>When to use:</p> <ul> <li>Intermediate models</li> <li>Temporary aggregations</li> <li>Models rebuilt frequently</li> </ul>"},{"location":"models/model-optimization/#compression","title":"Compression","text":"<p>Enable compression (warehouse-specific):</p> <pre><code>-- BigQuery: Automatic compression\n-- Snowflake: Automatic compression\n-- Databricks: Parquet compression\nMODEL (\n  name analytics.events,\n  storage_format 'parquet'  -- Compressed format\n);\n</code></pre>"},{"location":"models/model-optimization/#74-data-transfer-cost-optimization","title":"7.4 Data Transfer Cost Optimization","text":""},{"location":"models/model-optimization/#minimize-data-movement","title":"Minimize Data Movement","text":"<p>Process data where it lives:</p> <pre><code>-- \u2705 Good: Process in same warehouse\nSELECT * FROM warehouse_a.table1\nJOIN warehouse_a.table2 ON table1.id = table2.id;\n\n-- \u274c Bad: Cross-warehouse joins (if possible)\nSELECT * FROM warehouse_a.table1\nJOIN warehouse_b.table2 ON table1.id = table2.id;\n</code></pre>"},{"location":"models/model-optimization/#use-columnar-formats","title":"Use Columnar Formats","text":"<p>Columnar formats reduce transfer:</p> <pre><code>MODEL (\n  name analytics.events,\n  storage_format 'parquet'  -- Columnar, compressed\n);\n</code></pre> <p>Benefits:</p> <ul> <li>Smaller file sizes</li> <li>Faster transfers</li> <li>Better compression</li> </ul>"},{"location":"models/model-optimization/#75-cost-monitoring","title":"7.5 Cost Monitoring","text":"<p>Track costs by model:</p> <pre><code>-- Snowflake: Use query tags\nMODEL (\n  name analytics.customer_metrics,\n  session_properties (\n    query_tag = 'analytics_pipeline_customer'\n  )\n);\n\n-- Query Snowflake query history\nSELECT \n  query_tag,\n  SUM(total_elapsed_time) as total_time,\n  SUM(credits_used) as total_credits\nFROM snowflake.account_usage.query_history\nWHERE query_tag = 'analytics_pipeline_customer'\nGROUP BY query_tag;\n</code></pre> <p>Monitor expensive queries:</p> <pre><code># Check model execution times\nvulcan info --select analytics.customer_metrics\n\n# Identify slow models\nvulcan dag --select analytics.* --show-execution-times\n</code></pre> <p>\u2191 Back to Top</p>"},{"location":"models/model-optimization/#8-troubleshooting-performance","title":"8. Troubleshooting Performance","text":""},{"location":"models/model-optimization/#81-identifying-performance-issues","title":"8.1 Identifying Performance Issues","text":""},{"location":"models/model-optimization/#slow-query-symptoms","title":"Slow Query Symptoms","text":"<p>Common signs:</p> <ul> <li>Query execution time &gt; 10 minutes</li> <li>Timeout errors</li> <li>High warehouse utilization</li> <li>Downstream models waiting</li> </ul>"},{"location":"models/model-optimization/#diagnostic-queries","title":"Diagnostic Queries","text":"<p>Check model execution times:</p> <pre><code># View execution history\nvulcan info --select analytics.slow_model\n\n# Check for timeouts\nvulcan run --select analytics.slow_model --verbose\n</code></pre> <p>Query warehouse query history:</p> <pre><code>-- Snowflake\nSELECT \n  query_text,\n  total_elapsed_time,\n  bytes_scanned,\n  partitions_scanned,\n  partitions_total\nFROM snowflake.account_usage.query_history\nWHERE query_text LIKE '%analytics.slow_model%'\nORDER BY total_elapsed_time DESC\nLIMIT 10;\n\n-- BigQuery\nSELECT \n  job_id,\n  creation_time,\n  total_bytes_processed,\n  total_slot_ms\nFROM `region-us`.INFORMATION_SCHEMA.JOBS_BY_PROJECT\nWHERE statement_type = 'SELECT'\n  AND creation_time &gt; TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 DAY)\nORDER BY total_slot_ms DESC\nLIMIT 10;\n</code></pre>"},{"location":"models/model-optimization/#82-common-performance-issues","title":"8.2 Common Performance Issues","text":""},{"location":"models/model-optimization/#issue-1-full-table-scans","title":"Issue 1: Full Table Scans","text":"<p>Symptoms: - Query scans entire table - High bytes scanned - Slow execution</p> <p>Solution:</p> <pre><code>-- \u274c Problem: No partition filter\nSELECT * FROM analytics.events;\n\n-- \u2705 Fix: Add partition filter\nSELECT * FROM analytics.events\nWHERE event_date BETWEEN @start_ds AND @end_ds;\n</code></pre> <p>Prevention:</p> <pre><code>MODEL (\n  name analytics.events,\n  partitioned_by event_date,\n  physical_properties (\n    require_partition_filter = TRUE  -- Force partition filtering\n  )\n);\n</code></pre>"},{"location":"models/model-optimization/#issue-2-large-backfills","title":"Issue 2: Large Backfills","text":"<p>Symptoms: - Timeout errors - Memory issues - Long execution times</p> <p>Solution:</p> <pre><code>-- \u274c Problem: No batching\nMODEL (\n  kind INCREMENTAL_BY_TIME_RANGE (time_column event_date)\n  -- Processes all missing intervals in one job\n);\n\n-- \u2705 Fix: Add batch_size\nMODEL (\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column event_date,\n    batch_size 7  -- Process 7 days per batch\n  )\n);\n</code></pre>"},{"location":"models/model-optimization/#issue-3-inefficient-joins","title":"Issue 3: Inefficient Joins","text":"<p>Symptoms: - Cartesian products - Slow join operations - High memory usage</p> <p>Solution:</p> <pre><code>-- \u274c Problem: Missing join condition\nSELECT *\nFROM table1 t1\nJOIN table2 t2;  -- Cartesian product!\n\n-- \u2705 Fix: Add join condition\nSELECT *\nFROM table1 t1\nJOIN table2 t2 ON t1.id = t2.id;\n\n-- \u2705 Better: Filter before join\nSELECT *\nFROM (\n  SELECT * FROM table1 WHERE filter_condition\n) t1\nJOIN table2 t2 ON t1.id = t2.id;\n</code></pre>"},{"location":"models/model-optimization/#issue-4-too-much-lookback","title":"Issue 4: Too Much Lookback","text":"<p>Symptoms: - Processes too many intervals - High costs - Slow execution</p> <p>Solution:</p> <pre><code>-- \u274c Problem: Excessive lookback\nlookback 30  -- Reprocesses 30 days every run\n\n-- \u2705 Fix: Reduce lookback\nlookback 3  -- Only reprocess last 3 days\n\n-- \u2705 Better: Monitor late arrivals first\n-- Only add lookback if needed\n</code></pre>"},{"location":"models/model-optimization/#issue-5-resource-contention","title":"Issue 5: Resource Contention","text":"<p>Symptoms: - Queries queuing - Timeouts - Warehouse overload</p> <p>Solution:</p> <pre><code>-- \u274c Problem: Too much concurrency\nbatch_concurrency 20  -- Overloads warehouse\n\n-- \u2705 Fix: Reduce concurrency\nbatch_concurrency 5  -- Appropriate for warehouse size\n</code></pre>"},{"location":"models/model-optimization/#83-performance-debugging-workflow","title":"8.3 Performance Debugging Workflow","text":"<p>Step 1: Identify slow models</p> <pre><code># Check execution times\nvulcan info --select analytics.*\n\n# Find slowest models\nvulcan dag --show-execution-times | sort -k2 -rn\n</code></pre> <p>Step 2: Analyze query plans</p> <pre><code># View optimized SQL\nvulcan render analytics.slow_model &gt; slow_model.sql\n\n# Check query plan in warehouse\n-- Run EXPLAIN PLAN in warehouse\n</code></pre> <p>Step 3: Check warehouse metrics</p> <pre><code>-- Snowflake: Check warehouse utilization\nSELECT \n  warehouse_name,\n  AVG(avg_running) as avg_queries_running,\n  AVG(avg_queued) as avg_queries_queued\nFROM snowflake.account_usage.warehouse_load_history\nWHERE start_time &gt; CURRENT_TIMESTAMP - INTERVAL '1 day'\nGROUP BY warehouse_name;\n</code></pre> <p>Step 4: Optimize incrementally</p> <ol> <li>Add partitioning (if missing)</li> <li>Add batch_size (if large backfills)</li> <li>Reduce lookback (if excessive)</li> <li>Optimize queries (filter early, efficient joins)</li> <li>Add indexes (if supported)</li> </ol> <p>Step 5: Monitor improvements</p> <pre><code># Re-run and compare\nvulcan run --select analytics.slow_model\n\n# Check execution time improvement\nvulcan info --select analytics.slow_model\n</code></pre>"},{"location":"models/model-optimization/#84-performance-testing","title":"8.4 Performance Testing","text":"<p>Test optimizations in development:</p> <pre><code># Create dev environment\nvulcan plan dev\n\n# Test with limited data\nvulcan run dev --start '30 days ago' --end 'today'\n\n# Compare execution times\nvulcan info dev --select analytics.test_model\n</code></pre> <p>Benchmark before/after:</p> <pre><code># Before optimization\ntime vulcan run --select analytics.slow_model\n# Result: 45 minutes\n\n# After optimization\ntime vulcan run --select analytics.slow_model\n# Result: 5 minutes (9x improvement!)\n</code></pre> <p>\u2191 Back to Top</p>"},{"location":"models/model-optimization/#9-best-practices","title":"9. Best Practices","text":""},{"location":"models/model-optimization/#91-model-design-best-practices","title":"9.1 Model Design Best Practices","text":""},{"location":"models/model-optimization/#start-with-incremental","title":"Start with Incremental","text":"<p>Default to incremental for time-series:</p> <pre><code>-- \u2705 Good: Incremental by default\nMODEL (\n  name analytics.events,\n  kind INCREMENTAL_BY_TIME_RANGE (time_column event_date)\n);\n\n-- \u274c Bad: FULL unless necessary\nMODEL (\n  name analytics.events,\n  kind FULL  -- Only if &lt; 1M rows or non-temporal\n);\n</code></pre>"},{"location":"models/model-optimization/#partition-by-time","title":"Partition by Time","text":"<p>Always partition time-series tables:</p> <pre><code>MODEL (\n  name analytics.events,\n  kind INCREMENTAL_BY_TIME_RANGE (time_column event_date),\n  partitioned_by event_date  -- Essential for performance\n);\n</code></pre>"},{"location":"models/model-optimization/#filter-early","title":"Filter Early","text":"<p>Always filter in WHERE clause:</p> <pre><code>-- \u2705 Good: Filter in query\nSELECT *\nFROM raw.events\nWHERE event_date BETWEEN @start_ds AND @end_ds;\n\n-- \u274c Bad: No filter\nSELECT * FROM raw.events;\n</code></pre>"},{"location":"models/model-optimization/#92-property-optimization-best-practices","title":"9.2 Property Optimization Best Practices","text":""},{"location":"models/model-optimization/#conservative-defaults","title":"Conservative Defaults","text":"<p>Start conservative, optimize based on data:</p> <pre><code>-- Start with defaults\nMODEL (\n  kind INCREMENTAL_BY_TIME_RANGE (time_column event_date)\n  -- No batch_size, no lookback\n);\n\n-- Add optimizations as needed\nMODEL (\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column event_date,\n    batch_size 7,      -- Add if timeouts occur\n    lookback 3         -- Add if late data issues\n  )\n);\n</code></pre>"},{"location":"models/model-optimization/#monitor-and-adjust","title":"Monitor and Adjust","text":"<p>Regular performance reviews:</p> <ol> <li>Weekly: Check execution times</li> <li>Monthly: Review costs</li> <li>Quarterly: Optimize slow models</li> </ol> <p>Performance checklist:</p> <ul> <li> Execution time &lt; 10 minutes</li> <li> No timeout errors</li> <li> Appropriate batch_size</li> <li> Lookback not excessive</li> <li> Partitioning enabled</li> <li> Queries use partition filters</li> </ul>"},{"location":"models/model-optimization/#93-warehouse-specific-best-practices","title":"9.3 Warehouse-Specific Best Practices","text":""},{"location":"models/model-optimization/#snowflake","title":"Snowflake","text":"<ul> <li>\u2705 Use appropriate warehouse size</li> <li>\u2705 Enable query tagging for monitoring</li> <li>\u2705 Use transient tables for temp data</li> <li>\u2705 Cluster by high-cardinality columns</li> </ul>"},{"location":"models/model-optimization/#bigquery","title":"BigQuery","text":"<ul> <li>\u2705 Always partition time-series tables</li> <li>\u2705 Require partition filters</li> <li>\u2705 Cluster by filter columns</li> <li>\u2705 Set partition expiration</li> </ul>"},{"location":"models/model-optimization/#databricks","title":"Databricks","text":"<ul> <li>\u2705 Enable Delta Lake auto-optimization</li> <li>\u2705 Partition by date</li> <li>\u2705 Z-order by filter columns</li> <li>\u2705 Configure Spark resources appropriately</li> </ul>"},{"location":"models/model-optimization/#94-cost-optimization-best-practices","title":"9.4 Cost Optimization Best Practices","text":""},{"location":"models/model-optimization/#right-size-resources","title":"Right-Size Resources","text":"<p>Use smallest warehouse that meets needs:</p> <pre><code>-- \u274c Over-provisioned\nphysical_properties (warehouse = 'X-LARGE_WH')\n\n-- \u2705 Right-sized\nphysical_properties (warehouse = 'MEDIUM_WH')\n</code></pre>"},{"location":"models/model-optimization/#monitor-costs","title":"Monitor Costs","text":"<p>Track costs by model/pipeline:</p> <pre><code>-- Tag queries\nsession_properties (query_tag = 'pipeline_name')\n\n-- Query cost history\nSELECT \n  query_tag,\n  SUM(credits_used) as total_cost\nFROM query_history\nGROUP BY query_tag;\n</code></pre>"},{"location":"models/model-optimization/#use-incremental-models","title":"Use Incremental Models","text":"<p>Biggest cost savings:</p> <pre><code>-- \u274c Expensive: Full refresh\nkind FULL  -- Scans entire table daily\n\n-- \u2705 Cheap: Incremental\nkind INCREMENTAL_BY_TIME_RANGE  -- Scans only new data\n</code></pre>"},{"location":"models/model-optimization/#95-production-optimization-checklist","title":"9.5 Production Optimization Checklist","text":"<p>Before deploying to production:</p> <ul> <li> Model uses appropriate <code>kind</code> (incremental for time-series)</li> <li> Partitioning enabled (for time-series)</li> <li> WHERE clause filters by time range</li> <li> <code>batch_size</code> set (if large backfills)</li> <li> <code>batch_concurrency</code> appropriate for warehouse</li> <li> <code>lookback</code> not excessive</li> <li> Query execution time &lt; 10 minutes</li> <li> No timeout errors in testing</li> <li> Cost monitoring enabled (query tags)</li> <li> Performance tested in dev environment</li> </ul> <p>Ongoing optimization:</p> <ul> <li> Weekly performance review</li> <li> Monthly cost review</li> <li> Quarterly optimization pass</li> <li> Monitor for slow queries</li> <li> Adjust batch_size/lookback as needed</li> </ul> <p>\u2191 Back to Top</p>"},{"location":"models/model-optimization/#10-summary-and-next-steps","title":"10. Summary and Next Steps","text":""},{"location":"models/model-optimization/#what-youve-learned","title":"What You've Learned","text":"<p>This chapter covered comprehensive model optimization strategies:</p> <ol> <li>Performance Fundamentals: Understanding bottlenecks, incremental vs full refresh, batch processing</li> <li>Model Kinds Optimization: Choosing and optimizing each model kind</li> <li>Query Optimization: SQL best practices, SQLGlot optimizer, CTEs, subqueries</li> <li>Warehouse-Specific Optimization: Snowflake, BigQuery, Databricks, Postgres, DuckDB</li> <li>Advanced Properties Optimization: batch_size, batch_concurrency, lookback, forward_only</li> <li>Cost Optimization: Compute, storage, data transfer costs</li> <li>Troubleshooting Performance: Identifying and fixing common issues</li> <li>Best Practices: Production optimization checklist</li> </ol>"},{"location":"models/model-optimization/#key-takeaways","title":"Key Takeaways","text":"<p>1. Use Incremental Models - 10-100x faster than full refresh - 10-100x lower costs - Essential for time-series data</p> <p>2. Partition by Time - Always partition time-series tables - Enables partition pruning - Reduces data scanned</p> <p>3. Filter Early - Always filter in WHERE clause - Filter before joins - Use partition filters</p> <p>4. Right-Size Resources - Appropriate warehouse size - Appropriate batch_size - Appropriate batch_concurrency</p> <p>5. Monitor and Optimize - Track execution times - Monitor costs - Adjust based on data</p>"},{"location":"models/model-optimization/#next-steps","title":"Next Steps","text":"<p>Immediate: 1. Review your models for optimization opportunities 2. Add partitioning to time-series models 3. Optimize slow models (add batch_size, reduce lookback) 4. Enable cost monitoring (query tags)</p> <p>Short-term: 5. Optimize warehouse-specific settings 6. Review and optimize queries 7. Set up performance monitoring 8. Document optimization decisions</p> <p>Long-term: 9. Regular performance reviews 10. Cost optimization initiatives 11. Warehouse migration optimization 12. Advanced optimization techniques</p>"},{"location":"models/model-optimization/#related-chapters","title":"Related Chapters","text":"<ul> <li>Chapter 2: Models - Foundation concepts</li> <li>Chapter 2A: Model Properties - Complete property reference</li> <li>Chapter 2C: Model Operations - Advanced patterns</li> </ul> <p>Ready to optimize your models? Start by reviewing your slowest models and applying the optimization strategies from this chapter.</p> <p>\u2191 Back to Top</p>"},{"location":"models/model-properties/","title":"Chapter 2A: Model Properties","text":"<p>Complete reference for all MODEL DDL properties - Every property explained with examples, defaults, and use cases.</p>"},{"location":"models/model-properties/#prerequisites","title":"Prerequisites","text":"<p>Before diving into this chapter, you should have:</p>"},{"location":"models/model-properties/#required-knowledge","title":"Required Knowledge","text":"<p>Chapter 2: Models - Understanding of: - Basic MODEL DDL syntax - Model kinds overview - Essential properties (<code>name</code>, <code>kind</code>, <code>cron</code>, <code>grain</code>)</p> <p>SQL Proficiency - Basic SQL syntax - Understanding of data types</p>"},{"location":"models/model-properties/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Introduction</li> <li>Required Properties</li> <li>Scheduling &amp; Temporal Properties</li> <li>Incremental Model Properties</li> <li>Data Quality Properties</li> <li>Metadata Properties</li> <li>Schema &amp; Type Properties</li> <li>Warehouse-Specific Properties</li> <li>Execution Control Properties</li> <li>Pre/Post Statements</li> <li>Property Quick Reference</li> <li>Examples by Use Case</li> </ol>"},{"location":"models/model-properties/#1-introduction","title":"1. Introduction","text":""},{"location":"models/model-properties/#11-what-are-model-properties","title":"1.1 What Are Model Properties?","text":"<p>Model properties are configuration options that control how Vulcan models behave, how they're scheduled, how they're stored, and how they're validated.</p> <p>Properties are specified in the MODEL DDL:</p> <pre><code>MODEL (\n  name analytics.customers,        -- Property: name\n  kind FULL,                        -- Property: kind\n  cron '@daily',                    -- Property: cron\n  owner 'data-team',                -- Property: owner\n  description 'Customer dimension table'  -- Property: description\n);\n\nSELECT * FROM raw.customers;\n</code></pre>"},{"location":"models/model-properties/#12-property-categories","title":"1.2 Property Categories","text":"<p>Properties are organized into categories:</p> Category Purpose Examples Required Must be specified <code>name</code>, <code>kind</code> Scheduling When models run <code>cron</code>, <code>start</code>, <code>end</code>, <code>interval_unit</code> Incremental Incremental behavior <code>time_column</code>, <code>lookback</code>, <code>batch_size</code> Data Quality Validation &amp; relationships <code>grain</code>, <code>references</code>, <code>audits</code> Metadata Documentation <code>description</code>, <code>owner</code>, <code>tags</code> Schema Column definitions <code>columns</code>, <code>dialect</code> Warehouse Engine-specific <code>partitioned_by</code>, <code>physical_properties</code> Execution Runtime control <code>enabled</code>, <code>gateway</code>, <code>optimize_query</code> Statements Pre/post hooks <code>pre_statements</code>, <code>post_statements</code>"},{"location":"models/model-properties/#13-property-inheritance","title":"1.3 Property Inheritance","text":"<p>Properties can be set at multiple levels:</p> <p>1. Project Defaults (<code>config.yaml</code>): <pre><code>model_defaults:\n  dialect: snowflake\n  start: '2022-01-01'\n  owner: 'data-team'\n</code></pre></p> <p>2. Model-Specific (overrides defaults): <pre><code>MODEL (\n  name analytics.customers,\n  owner 'analytics-team',  -- Overrides project default\n  dialect bigquery         -- Overrides project default\n);\n</code></pre></p> <p>3. Property Merging: - <code>physical_properties</code>, <code>virtual_properties</code>, <code>session_properties</code> are merged (not replaced) - Model-level properties take precedence over project defaults - Set to <code>None</code> to unset a project-level property</p> <p>Example: <pre><code># config.yaml\nmodel_defaults:\n  physical_properties:\n    partition_expiration_days: 7\n    require_partition_filter: true\n</code></pre></p> <pre><code>-- models/customers.sql\nMODEL (\n  name analytics.customers,\n  physical_properties (\n    partition_expiration_days = 14,  -- Override: 7 \u2192 14\n    require_partition_filter = None,  -- Unset: remove from model\n    creatable_type = TRANSIENT        -- Add: new property\n  )\n);\n</code></pre>"},{"location":"models/model-properties/#14-property-defaults","title":"1.4 Property Defaults","text":"<p>Most properties are optional and have sensible defaults:</p> Property Default Notes <code>kind</code> <code>VIEW</code> (SQL) / <code>FULL</code> (Python) Depends on model type <code>cron</code> <code>@daily</code> Run once per day <code>start</code> <code>yesterday</code> Historical backfill start <code>enabled</code> <code>true</code> Model is active <code>optimize_query</code> <code>true</code> SQLGlot optimization enabled <code>formatting</code> <code>true</code> Format with <code>vulcan format</code> <code>allow_partials</code> <code>false</code> Only process complete intervals <code>forward_only</code> <code>false</code> Changes trigger rebuilds <code>disable_restatement</code> <code>false</code> Restatement allowed <code>on_destructive_change</code> <code>error</code> Block breaking changes <code>on_additive_change</code> <code>allow</code> Allow new columns <p>For comprehensive defaults, see Property Quick Reference</p> <p>\u2191 Back to Top</p>"},{"location":"models/model-properties/#2-required-properties","title":"2. Required Properties","text":""},{"location":"models/model-properties/#21-name","title":"2.1 <code>name</code>","text":"<p>Type: <code>string</code> Required: Yes (unless <code>infer_names</code> is enabled) Default: None</p> <p>The fully qualified model name, typically <code>schema.table</code> format.</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.customers  -- schema.table\n);\n</code></pre></p> <p>Rules: - Must include at least schema (<code>schema.table</code>) - Can include catalog (<code>catalog.schema.table</code>) - Must be unique within project - Case-sensitive</p> <p>Examples: <pre><code>-- Simple schema.table\nMODEL (name analytics.customers);\n\n-- With catalog (BigQuery, Snowflake)\nMODEL (name my_project.analytics.customers);\n\n-- Simple table name (uses default schema)\nMODEL (name customers);  -- Requires infer_names or default schema\n</code></pre></p> <p>Name Inference:</p> <p>If <code>infer_names</code> is enabled in <code>config.yaml</code>: <pre><code>models:\n  infer_names: true\n</code></pre></p> <p>Model names are inferred from file path: <pre><code>models/\n\u251c\u2500\u2500 analytics/\n\u2502   \u2514\u2500\u2500 customers.sql  \u2192 name: analytics.customers\n\u2514\u2500\u2500 staging/\n    \u2514\u2500\u2500 orders.sql     \u2192 name: staging.orders\n</code></pre></p>"},{"location":"models/model-properties/#22-kind","title":"2.2 <code>kind</code>","text":"<p>Type: <code>string</code> or <code>dict</code> Required: Yes Default: <code>VIEW</code> (SQL models), <code>FULL</code> (Python models)</p> <p>The model kind determines how data is materialized and refreshed.</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.customers,\n  kind FULL  -- Simple kind\n);\n\n-- Or with parameters:\nMODEL (\n  name analytics.daily_events,\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column event_date,\n    lookback 3\n  )\n);\n</code></pre></p> <p>Supported Kinds:</p> Kind Description Default For <code>VIEW</code> Query-time view SQL models <code>FULL</code> Complete refresh Python models <code>INCREMENTAL_BY_TIME_RANGE</code> Time-partitioned incremental - <code>INCREMENTAL_BY_UNIQUE_KEY</code> Upsert-based incremental - <code>INCREMENTAL_BY_PARTITION</code> Partition-based incremental - <code>SCD_TYPE_2</code> Slowly changing dimension - <code>SEED</code> CSV file loader - <code>EXTERNAL</code> External table metadata - <code>EMBEDDED</code> Inline subquery - <code>MANAGED</code> Engine-managed table - <p>For detailed model kind documentation, see Chapter 2: Models</p> <p>Python Models:</p> <pre><code>from vulcan import model\n\n# Simple kind\n@model(\"analytics.customers\", kind=\"FULL\")\n\n# Incremental with parameters\n@model(\n    \"analytics.daily_events\",\n    kind={\n        \"name\": \"INCREMENTAL_BY_TIME_RANGE\",\n        \"time_column\": \"event_date\",\n        \"lookback\": 3\n    }\n)\n</code></pre> <p>\u2191 Back to Top</p>"},{"location":"models/model-properties/#3-scheduling-temporal-properties","title":"3. Scheduling &amp; Temporal Properties","text":"<p>These properties control when models run and how time intervals are calculated.</p>"},{"location":"models/model-properties/#31-cron","title":"3.1 <code>cron</code>","text":"<p>Type: <code>string</code> Required: No Default: <code>@daily</code></p> <p>The cron expression specifying how often the model should be refreshed.</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.daily_metrics,\n  cron '@daily'  -- Simple frequency\n);\n\n-- Or cron expression:\nMODEL (\n  name analytics.hourly_events,\n  cron '0 * * * *'  -- Every hour at minute 0\n);\n</code></pre></p> <p>Supported Formats:</p> <p>1. Simple Frequencies: - <code>@hourly</code> - Run every hour at minute 0 - <code>@daily</code> - Run every day at midnight UTC - <code>@weekly</code> - Run every week on Sunday at midnight UTC - <code>@monthly</code> - Run on the 1<sup>st</sup> of each month at midnight UTC</p> <p>2. Cron Expressions:</p> <p>Standard cron format: <code>minute hour day month weekday</code></p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 minute (0 - 59)\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 hour (0 - 23)\n\u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 day of month (1 - 31)\n\u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 month (1 - 12)\n\u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 day of week (0 - 6) (Sunday to Saturday)\n\u2502 \u2502 \u2502 \u2502 \u2502\n* * * * *\n</code></pre> <p>Common Cron Examples:</p> Expression Description <code>0 * * * *</code> Every hour at minute 0 <code>0 9 * * *</code> Every day at 9:00 AM UTC <code>0 9 * * 1-5</code> Every weekday at 9:00 AM UTC <code>0 0 1 * *</code> First day of each month at midnight <code>*/15 * * * *</code> Every 15 minutes <code>0 0,12 * * *</code> Twice daily (midnight and noon) <p>Timezone:</p> <p>By default, all cron times are in UTC. Use <code>cron_tz</code> to specify a different timezone for scheduling (but data intervals remain UTC).</p> <p>Examples:</p> <pre><code>-- Daily at midnight UTC\nMODEL (\n  name analytics.daily_summary,\n  cron '@daily'\n);\n\n-- Daily at 9 AM Pacific Time\nMODEL (\n  name analytics.daily_summary_pst,\n  cron '@daily',\n  cron_tz 'America/Los_Angeles'\n);\n\n-- Every hour\nMODEL (\n  name analytics.hourly_metrics,\n  cron '@hourly'\n);\n\n-- Custom: Every 6 hours\nMODEL (\n  name analytics.six_hourly_updates,\n  cron '0 */6 * * *'\n);\n</code></pre> <p>Python Models:</p> <pre><code>@model(\n    \"analytics.daily_metrics\",\n    cron=\"@daily\"\n)\n\n# Or with timezone\n@model(\n    \"analytics.daily_metrics_pst\",\n    cron=\"@daily\",\n    cron_tz=\"America/Los_Angeles\"\n)\n</code></pre>"},{"location":"models/model-properties/#32-cron_tz","title":"3.2 <code>cron_tz</code>","text":"<p>Type: <code>string</code> (timezone name) Required: No Default: <code>UTC</code></p> <p>The timezone for the cron schedule. Important: This only affects when the model runs, not the time intervals processed.</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.daily_summary,\n  cron '@daily',\n  cron_tz 'America/Los_Angeles'  -- Run at midnight Pacific Time\n);\n</code></pre></p> <p>Key Points:</p> <ol> <li>Scheduling Only: <code>cron_tz</code> affects when the model runs, not data intervals</li> <li>Data Intervals Stay UTC: <code>@start_ds</code> and <code>@end_ds</code> variables are always UTC</li> <li>Timezone Names: Use IANA timezone database names (e.g., <code>America/New_York</code>, <code>Europe/London</code>)</li> </ol> <p>Example:</p> <pre><code>MODEL (\n  name analytics.daily_summary,\n  kind INCREMENTAL_BY_TIME_RANGE (time_column event_date),\n  cron '@daily',\n  cron_tz 'America/Los_Angeles',  -- Runs at 12:00 AM Pacific\n  start '2024-01-01'\n);\n\nSELECT *\nFROM raw.events\nWHERE event_date BETWEEN @start_ds AND @end_ds;\n-- @start_ds and @end_ds are UTC dates, regardless of cron_tz\n</code></pre> <p>What happens: - Model runs at 12:00 AM Pacific Time (8:00 AM UTC the next day) - But <code>@start_ds</code> and <code>@end_ds</code> represent UTC date boundaries - Your <code>time_column</code> should be in UTC (see time_column)</p> <p>Common Timezones:</p> Timezone IANA Name Pacific Time <code>America/Los_Angeles</code> Mountain Time <code>America/Denver</code> Central Time <code>America/Chicago</code> Eastern Time <code>America/New_York</code> UTC <code>UTC</code> (default) London <code>Europe/London</code> Tokyo <code>Asia/Tokyo</code>"},{"location":"models/model-properties/#33-interval_unit","title":"3.3 <code>interval_unit</code>","text":"<p>Type: <code>string</code> Required: No Default: Inferred from <code>cron</code></p> <p>The temporal granularity with which time intervals are calculated for the model.</p> <p>Supported Values: - <code>year</code> - <code>month</code> - <code>day</code> - <code>hour</code> - <code>half_hour</code> (30 minutes) - <code>quarter_hour</code> (15 minutes) - <code>five_minute</code> (5 minutes)</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.daily_events,\n  kind INCREMENTAL_BY_TIME_RANGE (time_column event_date),\n  cron '@daily',\n  interval_unit 'day'  -- Explicitly set\n);\n</code></pre></p> <p>How It's Determined:</p> <p>1. From Simple Frequencies: - <code>@hourly</code> \u2192 <code>interval_unit: hour</code> - <code>@daily</code> \u2192 <code>interval_unit: day</code> - <code>@weekly</code> \u2192 <code>interval_unit: day</code> (weekly runs, but daily granularity) - <code>@monthly</code> \u2192 <code>interval_unit: month</code></p> <p>2. From Cron Expressions:</p> <p>Vulcan analyzes the cron expression: 1. Generates next 5 run times 2. Calculates minimum duration between runs 3. Sets <code>interval_unit</code> to largest unit \u2264 minimum duration</p> <p>Example: - Cron: <code>*/43 * * * *</code> (every 43 minutes) - Minimum duration: 43 minutes - <code>interval_unit</code>: <code>half_hour</code> (30 minutes is largest unit \u2264 43 minutes)</p> <p>3. Explicit Specification:</p> <p>You can override the inferred value:</p> <pre><code>MODEL (\n  name analytics.up_until_7am,\n  kind INCREMENTAL_BY_TIME_RANGE (time_column event_date),\n  cron '30 7 * * *',      -- Run at 7:30 AM daily\n  interval_unit 'hour',   -- Process hourly intervals, not daily\n  start '2024-01-01'\n);\n</code></pre> <p>Why specify explicitly?</p> <p>Use Case: Run daily, but process hourly data</p> <pre><code>MODEL (\n  name analytics.daily_summary,\n  kind INCREMENTAL_BY_TIME_RANGE (time_column event_date),\n  cron '@daily',           -- Run once per day\n  interval_unit 'hour',    -- But process hourly intervals\n  start '2024-01-01'\n);\n\nSELECT *\nFROM raw.events\nWHERE event_date BETWEEN @start_ds AND @end_ds;\n-- Processes all hours from start of day to end of day\n</code></pre> <p>Use Case: Run hourly, process daily intervals</p> <pre><code>MODEL (\n  name analytics.hourly_backfill,\n  kind INCREMENTAL_BY_TIME_RANGE (time_column event_date),\n  cron '@hourly',          -- Run every hour\n  interval_unit 'day',     -- But process daily intervals\n  allow_partials true,     -- Allow partial days\n  start '2024-01-01'\n);\n</code></pre> <p>Relationship to <code>lookback</code>:</p> <p><code>lookback</code> is calculated in <code>interval_unit</code>s:</p> <pre><code>MODEL (\n  kind INCREMENTAL_BY_TIME_RANGE (time_column event_date),\n  cron '@daily',\n  interval_unit 'day',\n  lookback 7  -- Reprocess last 7 days\n);\n\n-- If interval_unit was 'hour':\n-- lookback 7 would mean last 7 hours\n</code></pre>"},{"location":"models/model-properties/#34-start","title":"3.4 <code>start</code>","text":"<p>Type: <code>string</code> or <code>integer</code> (epoch milliseconds) Required: No Default: <code>yesterday</code></p> <p>The earliest date/time interval that should be processed by the model.</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.historical_data,\n  start '2022-01-01'  -- Absolute date\n);\n\n-- Or relative:\nMODEL (\n  name analytics.recent_data,\n  start '1 year ago'  -- Relative date\n);\n</code></pre></p> <p>Supported Formats:</p> <p>1. Absolute Dates: - <code>'2022-01-01'</code> - Date only - <code>'2022-01-01 00:00:00'</code> - Date and time - <code>1640995200000</code> - Epoch milliseconds</p> <p>2. Relative Dates: - <code>'1 year ago'</code> - <code>'6 months ago'</code> - <code>'30 days ago'</code> - <code>'yesterday'</code> (default)</p> <p>Examples:</p> <pre><code>-- Start from specific date\nMODEL (\n  name analytics.customers,\n  start '2020-01-01'\n);\n\n-- Start from 1 year ago\nMODEL (\n  name analytics.recent_customers,\n  start '1 year ago'\n);\n\n-- Start from yesterday (default)\nMODEL (\n  name analytics.daily_metrics\n  -- start defaults to 'yesterday'\n);\n</code></pre> <p>Use Cases:</p> <p>1. Historical Backfill: <pre><code>MODEL (\n  name analytics.all_time_revenue,\n  start '2010-01-01'  -- Process 14+ years of data\n);\n</code></pre></p> <p>2. Recent Data Only: <pre><code>MODEL (\n  name analytics.recent_events,\n  start '30 days ago'  -- Only last 30 days\n);\n</code></pre></p> <p>3. Project Default: <pre><code># config.yaml\nmodel_defaults:\n  start: '2022-01-01'  -- All models start from this date\n</code></pre></p>"},{"location":"models/model-properties/#35-end","title":"3.5 <code>end</code>","text":"<p>Type: <code>string</code> or <code>integer</code> (epoch milliseconds) Required: No Default: None (process indefinitely)</p> <p>The latest date/time interval that should be processed by the model.</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.historical_snapshot,\n  start '2022-01-01',\n  end '2023-12-31'  -- Stop processing after this date\n);\n</code></pre></p> <p>Use Cases:</p> <p>1. Historical Snapshot: <pre><code>MODEL (\n  name analytics.2023_data,\n  start '2023-01-01',\n  end '2023-12-31'  -- Only process 2023 data\n);\n</code></pre></p> <p>2. Temporary Models: <pre><code>MODEL (\n  name analytics.temp_analysis,\n  start '2024-01-01',\n  end '2024-06-30'  -- Stop after June 2024\n);\n</code></pre></p> <p>3. Relative End: <pre><code>MODEL (\n  name analytics.past_year,\n  start '1 year ago',\n  end 'yesterday'  -- Up to yesterday\n);\n</code></pre></p> <p>Note: Models with <code>end</code> set will stop processing new intervals after the end date. This is useful for: - Historical snapshots - Temporary analysis models - Deprecated models being phased out</p>"},{"location":"models/model-properties/#36-allow_partials","title":"3.6 <code>allow_partials</code>","text":"<p>Type: <code>boolean</code> Required: No Default: <code>false</code></p> <p>Whether this model can process partial (incomplete) data intervals.</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.real_time_metrics,\n  kind INCREMENTAL_BY_TIME_RANGE (time_column event_date),\n  cron '@hourly',\n  allow_partials true  -- Process incomplete intervals\n);\n</code></pre></p> <p>Default Behavior (<code>allow_partials: false</code>):</p> <p>Models only process complete intervals:</p> <pre><code>MODEL (\n  name analytics.daily_summary,\n  kind INCREMENTAL_BY_TIME_RANGE (time_column event_date),\n  cron '@daily',\n  interval_unit 'day',\n  -- allow_partials: false (default)\n);\n</code></pre> <p>What happens: - Model runs at midnight UTC - Only processes data from completed days (yesterday and earlier) - Today's data is not processed until tomorrow (when today is complete)</p> <p>With <code>allow_partials: true</code>:</p> <pre><code>MODEL (\n  name analytics.real_time_summary,\n  kind INCREMENTAL_BY_TIME_RANGE (time_column event_date),\n  cron '@hourly',        -- Run every hour\n  interval_unit 'day',   -- Process daily intervals\n  allow_partials true    -- But allow partial days\n);\n</code></pre> <p>What happens: - Model runs every hour - Processes today's data as it accumulates - Data is temporary - will be reprocessed when the day is complete</p> <p>\u26a0\ufe0f Warning:</p> <p>Use <code>allow_partials</code> with caution:</p> <ol> <li>Data Completeness: Partial intervals may be incomplete</li> <li>Debugging Difficulty: Hard to distinguish between:</li> <li>Missing data (pipeline issue)</li> <li>Partial data (expected behavior)</li> <li>Reprocessing: Partial data is temporary and will be reprocessed</li> </ol> <p>Recommended Use Cases:</p> <p>\u2705 Good: - Real-time dashboards (stale data acceptable) - Monitoring systems (need current state) - High-frequency models (hourly runs, daily intervals)</p> <p>\u274c Avoid: - Financial reporting (need complete data) - Critical business metrics (accuracy required) - Models feeding downstream critical systems</p> <p>Example: Real-Time Dashboard</p> <pre><code>MODEL (\n  name analytics.real_time_dashboard,\n  kind INCREMENTAL_BY_TIME_RANGE (time_column event_date),\n  cron '@hourly',        -- Update every hour\n  interval_unit 'day',   -- Daily metrics\n  allow_partials true,   -- Show today's partial data\n  start '2024-01-01'\n);\n\nSELECT\n  DATE_TRUNC('day', event_date) as metric_date,\n  COUNT(*) as event_count,\n  SUM(revenue) as daily_revenue\nFROM raw.events\nWHERE event_date BETWEEN @start_ds AND @end_ds\nGROUP BY 1;\n-- Shows today's partial data, updates hourly\n</code></pre> <p>Combining with <code>--ignore-cron</code>:</p> <p>To force a model to run every time (ignoring cron schedule):</p> <pre><code>vulcan run --ignore-cron\n</code></pre> <p>Requirements: - <code>allow_partials: true</code> must be set - <code>--ignore-cron</code> flag must be used - Both are required for guaranteed execution</p> <p>Why both? - <code>allow_partials: true</code> allows partial intervals - <code>--ignore-cron</code> ignores schedule timing - Together: model runs every time, processes partial data</p> <p>\u2191 Back to Top</p>"},{"location":"models/model-properties/#4-incremental-model-properties","title":"4. Incremental Model Properties","text":"<p>These properties control incremental model behavior. They are specified within the <code>kind</code> definition for incremental models.</p>"},{"location":"models/model-properties/#41-properties-for-all-incremental-models","title":"4.1 Properties for All Incremental Models","text":"<p>These properties apply to all incremental model kinds (<code>INCREMENTAL_BY_TIME_RANGE</code>, <code>INCREMENTAL_BY_UNIQUE_KEY</code>, <code>INCREMENTAL_BY_PARTITION</code>, <code>SCD_TYPE_2</code>):</p>"},{"location":"models/model-properties/#forward_only","title":"<code>forward_only</code>","text":"<p>Type: <code>boolean</code> Required: No Default: <code>false</code></p> <p>Whether all changes to this model should be forward-only (no rebuilds).</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.large_table,\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column event_date,\n    forward_only true  -- Changes don't trigger rebuilds\n  )\n);\n</code></pre></p> <p>What it does: - Changes are classified as forward-only - No automatic rebuilds when model changes - Useful for very large tables where rebuilds are expensive</p> <p>\u26a0\ufe0f Warning: Forward-only models can't be restated easily. Use with caution.</p>"},{"location":"models/model-properties/#on_destructive_change","title":"<code>on_destructive_change</code>","text":"<p>Type: <code>string</code> Required: No Default: <code>error</code></p> <p>What happens when a forward-only model has a destructive schema change (dropping columns, incompatible type changes).</p> <p>Valid Values: - <code>error</code> (default) - Block the change - <code>warn</code> - Allow but warn - <code>allow</code> - Allow silently - <code>ignore</code> - Ignore the check</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.customers,\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column event_date,\n    forward_only true,\n    on_destructive_change 'error'  -- Block breaking changes\n  )\n);\n</code></pre></p> <p>Example Destructive Changes: - Dropping a column - Changing column type incompatibly (<code>INT</code> \u2192 <code>VARCHAR</code>) - Making nullable column non-nullable</p>"},{"location":"models/model-properties/#on_additive_change","title":"<code>on_additive_change</code>","text":"<p>Type: <code>string</code> Required: No Default: <code>allow</code></p> <p>What happens when a forward-only model has an additive schema change (adding columns, compatible type changes).</p> <p>Valid Values: - <code>allow</code> (default) - Allow silently - <code>warn</code> - Allow but warn - <code>error</code> - Block the change - <code>ignore</code> - Ignore the check</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.customers,\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column event_date,\n    forward_only true,\n    on_additive_change 'allow'  -- Allow new columns\n  )\n);\n</code></pre></p> <p>Example Additive Changes: - Adding a new column - Making non-nullable column nullable - Widening column types (<code>INT</code> \u2192 <code>BIGINT</code>)</p>"},{"location":"models/model-properties/#disable_restatement","title":"<code>disable_restatement</code>","text":"<p>Type: <code>boolean</code> Required: No Default: <code>false</code></p> <p>Whether restatement (reprocessing historical data) is disabled for this model.</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.append_only_log,\n  kind INCREMENTAL_BY_UNIQUE_KEY (\n    unique_key log_id,\n    disable_restatement true  -- Never reprocess history\n  )\n);\n</code></pre></p> <p>Use Cases: - Append-only tables (can't reprocess) - Audit logs (must preserve history) - Event streams (idempotency concerns)</p> <p>\u26a0\ufe0f Warning: Once set, historical data cannot be reprocessed. Use with caution.</p>"},{"location":"models/model-properties/#42-properties-for-incremental_by_time_range","title":"4.2 Properties for INCREMENTAL_BY_TIME_RANGE","text":""},{"location":"models/model-properties/#time_column","title":"<code>time_column</code>","text":"<p>Type: <code>string</code> Required: Yes Default: None</p> <p>The column containing the timestamp/date for each row. Must be in UTC timezone.</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.daily_events,\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column event_date  -- Required\n  )\n);\n</code></pre></p> <p>With Format String:</p> <p>If your time column has a non-standard format:</p> <pre><code>MODEL (\n  name analytics.events,\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column event_timestamp,\n    format '%Y-%m-%d %H:%M:%S'  -- Custom format\n  )\n);\n</code></pre> <p>Format String Syntax:</p> <p>Uses Python <code>strftime</code> format codes:</p> Code Meaning Example <code>%Y</code> 4-digit year <code>2024</code> <code>%m</code> Month (01-12) <code>01</code> <code>%d</code> Day (01-31) <code>15</code> <code>%H</code> Hour (00-23) <code>14</code> <code>%M</code> Minute (00-59) <code>30</code> <code>%S</code> Second (00-59) <code>45</code> <p>Default Format: <code>%Y-%m-%d</code> (for DATE columns)</p> <p>\u26a0\ufe0f Important: UTC Requirement</p> <p>The <code>time_column</code> must be in UTC timezone. This ensures: - Correct interval calculations - Proper interaction with <code>@start_ds</code> and <code>@end_ds</code> macros - Consistent behavior across timezones</p> <p>Example: <pre><code>MODEL (\n  name analytics.events,\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column event_timestamp_utc  -- Must be UTC\n  )\n);\n\nSELECT\n  event_id,\n  CONVERT_TIMEZONE('America/New_York', 'UTC', event_timestamp) as event_timestamp_utc,\n  event_data\nFROM raw.events\nWHERE event_timestamp_utc BETWEEN @start_ds AND @end_ds;\n</code></pre></p>"},{"location":"models/model-properties/#lookback","title":"<code>lookback</code>","text":"<p>Type: <code>integer</code> Required: No Default: <code>0</code></p> <p>The number of <code>interval_unit</code>s prior to the current interval that should be reprocessed (for late-arriving data).</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.daily_revenue,\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column revenue_date,\n    lookback 3  -- Reprocess last 3 days\n  ),\n  cron '@daily',\n  interval_unit 'day'\n);\n</code></pre></p> <p>How It Works:</p> <p>Without lookback (<code>lookback: 0</code>): - Processes only the current interval - Late-arriving data from previous intervals is ignored</p> <p>With lookback (<code>lookback: 3</code>): - Processes current interval plus last 3 intervals - Catches late-arriving data from previous days</p> <p>Example:</p> <pre><code>MODEL (\n  name analytics.daily_orders,\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column order_date,\n    lookback 7  -- Reprocess last 7 days\n  ),\n  cron '@daily',\n  interval_unit 'day'\n);\n\nSELECT *\nFROM raw.orders\nWHERE order_date BETWEEN @start_ds AND @end_ds;\n-- Processes: today + last 7 days (8 days total)\n</code></pre> <p>Lookback Calculation:</p> <p>Lookback is calculated in <code>interval_unit</code>s:</p> <code>interval_unit</code> <code>lookback: 3</code> means <code>day</code> Last 3 days <code>hour</code> Last 3 hours <code>month</code> Last 3 months <p>Use Cases:</p> <p>\u2705 Good for: - Late-arriving data (orders arrive days after event) - Dimension updates (customer data changes retroactively) - Data corrections (fixing historical errors)</p> <p>\u274c Avoid: - Real-time data (no late arrivals) - Append-only logs (no updates) - Very large tables (performance impact)</p> <p>Performance Impact:</p> <ul> <li><code>lookback: 0</code> - Processes 1 interval</li> <li><code>lookback: 7</code> - Processes 8 intervals (7 + current)</li> <li><code>lookback: 30</code> - Processes 31 intervals</li> </ul> <p>Recommendation: Start with <code>lookback: 0</code>, increase if you see late-arriving data issues.</p>"},{"location":"models/model-properties/#batch_size","title":"<code>batch_size</code>","text":"<p>Type: <code>integer</code> Required: No Default: <code>None</code> (process all intervals in one job)</p> <p>The maximum number of <code>interval_unit</code>s to process in a single backfill job.</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.hourly_events,\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column event_date,\n    batch_size 24  -- Process 24 hours per batch\n  ),\n  cron '@hourly',\n  interval_unit 'hour'\n);\n</code></pre></p> <p>Why Use Batch Size?</p> <p>When backfilling large amounts of data, processing all intervals in one job can: - Exceed query timeout limits - Consume too much memory - Fail and lose progress</p> <p>Example Calculation:</p> <p>Scenario: Model hasn't run in 3 days, <code>cron: @hourly</code>, <code>interval_unit: hour</code></p> <ul> <li>Total intervals: 3 days \u00d7 24 hours = 72 intervals</li> </ul> <p>Without <code>batch_size</code>: - 1 job processes all 72 intervals - Risk: Timeout or memory issues</p> <p>With <code>batch_size: 12</code>: - 72 intervals \u00f7 12 = 6 jobs - Each job processes 12 hours - More reliable, can retry individual batches</p> <p>Batch Size Examples:</p> <pre><code>-- Daily model, backfill 30 days\nMODEL (\n  kind INCREMENTAL_BY_TIME_RANGE (time_column event_date),\n  cron '@daily',\n  interval_unit 'day',\n  batch_size 7  -- Process 7 days per batch\n);\n-- 30 days \u00f7 7 = ~5 batches\n\n-- Hourly model, backfill 1 week\nMODEL (\n  kind INCREMENTAL_BY_TIME_RANGE (time_column event_date),\n  cron '@hourly',\n  interval_unit 'hour',\n  batch_size 24  -- Process 24 hours per batch\n);\n-- 168 hours \u00f7 24 = 7 batches\n</code></pre> <p>Recommendation: - Start without <code>batch_size</code> (let Vulcan handle it) - Add if you see timeout/memory issues - Typical values: 7-30 days for daily models, 12-48 hours for hourly models</p>"},{"location":"models/model-properties/#batch_concurrency","title":"<code>batch_concurrency</code>","text":"<p>Type: <code>integer</code> Required: No Default: Connection setting (typically 5-10)</p> <p>The maximum number of batches that can run concurrently for this model.</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.hourly_events,\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column event_date,\n    batch_size 12,\n    batch_concurrency 3  -- Max 3 batches in parallel\n  ),\n  cron '@hourly'\n);\n</code></pre></p> <p>How It Works:</p> <p>With <code>batch_size: 12</code> and <code>batch_concurrency: 3</code>: - Creates batches of 12 intervals each - Runs up to 3 batches simultaneously - When one completes, starts the next</p> <p>Example:</p> <p>72 intervals, <code>batch_size: 12</code>, <code>batch_concurrency: 3</code>:</p> <pre><code>Batch 1: Intervals 1-12   [Running]\nBatch 2: Intervals 13-24  [Running]\nBatch 3: Intervals 25-36  [Running]\nBatch 4: Intervals 37-48  [Waiting]\nBatch 5: Intervals 49-60  [Waiting]\nBatch 6: Intervals 61-72  [Waiting]\n\nWhen Batch 1 completes \u2192 Batch 4 starts\n</code></pre> <p>Tuning:</p> <p>Higher concurrency: - \u2705 Faster backfills - \u274c More warehouse resources - \u274c May hit connection limits</p> <p>Lower concurrency: - \u2705 Less resource usage - \u274c Slower backfills - \u2705 More reliable</p> <p>Recommendation: - Start with default (connection setting) - Increase if backfills are too slow - Decrease if hitting resource limits</p> <p>Note: <code>INCREMENTAL_BY_UNIQUE_KEY</code> models cannot use <code>batch_concurrency</code> (they can't run in parallel safely).</p>"},{"location":"models/model-properties/#43-properties-for-incremental_by_unique_key","title":"4.3 Properties for INCREMENTAL_BY_UNIQUE_KEY","text":""},{"location":"models/model-properties/#unique_key","title":"<code>unique_key</code>","text":"<p>Type: <code>string</code> or <code>array[string]</code> Required: Yes Default: None</p> <p>The column(s) that uniquely identify each row (used for upsert logic).</p> <p>Syntax: <pre><code>-- Single column key\nMODEL (\n  name analytics.customers,\n  kind INCREMENTAL_BY_UNIQUE_KEY (\n    unique_key customer_id\n  )\n);\n\n-- Composite key\nMODEL (\n  name analytics.customer_products,\n  kind INCREMENTAL_BY_UNIQUE_KEY (\n    unique_key (customer_id, product_id)\n  )\n);\n</code></pre></p> <p>How It Works:</p> <p>Vulcan uses <code>MERGE</code> (or equivalent) to: 1. Insert new rows (key doesn't exist) 2. Update existing rows (key matches)</p> <p>Example:</p> <pre><code>MODEL (\n  name analytics.customers,\n  kind INCREMENTAL_BY_UNIQUE_KEY (\n    unique_key customer_id\n  ),\n  cron '@daily'\n);\n\nSELECT\n  customer_id,\n  customer_name,\n  email,\n  updated_at\nFROM raw.customers\nWHERE updated_at &gt;= @start_ds;\n-- Upserts based on customer_id\n</code></pre> <p>Composite Keys:</p> <pre><code>MODEL (\n  name analytics.order_line_items,\n  kind INCREMENTAL_BY_UNIQUE_KEY (\n    unique_key (order_id, line_item_id)\n  )\n);\n</code></pre> <p>\u26a0\ufe0f Important: - <code>unique_key</code> must be unique in source data - Use <code>grain</code> property to declare uniqueness - Add <code>unique_values</code> audit to validate</p>"},{"location":"models/model-properties/#when_matched","title":"<code>when_matched</code>","text":"<p>Type: <code>string</code> (SQL expression) Required: No Default: Update all columns</p> <p>Custom SQL logic for updating columns when a match occurs (MERGE UPDATE clause).</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.customers,\n  kind INCREMENTAL_BY_UNIQUE_KEY (\n    unique_key customer_id,\n    when_matched 'UPDATE SET name = source.name, email = source.email, updated_at = source.updated_at'\n  )\n);\n</code></pre></p> <p>Default Behavior:</p> <p>Without <code>when_matched</code>, all columns are updated: <pre><code>-- Equivalent to:\nUPDATE SET \n  name = source.name,\n  email = source.email,\n  updated_at = source.updated_at,\n  -- ... all columns\n</code></pre></p> <p>Custom Logic:</p> <p>Example: Only update if source is newer: <pre><code>MODEL (\n  name analytics.customers,\n  kind INCREMENTAL_BY_UNIQUE_KEY (\n    unique_key customer_id,\n    when_matched 'UPDATE SET \n      name = source.name,\n      email = source.email,\n      updated_at = source.updated_at\n      WHERE target.updated_at &lt; source.updated_at'\n  )\n);\n</code></pre></p> <p>Example: Preserve certain columns: <pre><code>MODEL (\n  name analytics.customers,\n  kind INCREMENTAL_BY_UNIQUE_KEY (\n    unique_key customer_id,\n    when_matched 'UPDATE SET \n      email = source.email,\n      updated_at = source.updated_at\n      -- name column preserved (not updated)'\n  )\n);\n</code></pre></p> <p>\u26a0\ufe0f Note: <code>when_matched</code> is only available on engines that support <code>MERGE</code> (Snowflake, BigQuery, Spark). Other engines use INSERT ... ON CONFLICT or equivalent.</p>"},{"location":"models/model-properties/#merge_filter","title":"<code>merge_filter</code>","text":"<p>Type: <code>string</code> (SQL predicate) Required: No Default: None</p> <p>Additional filter condition for the MERGE ON clause (beyond key matching).</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.customers,\n  kind INCREMENTAL_BY_UNIQUE_KEY (\n    unique_key customer_id,\n    merge_filter 'source.status != ''deleted'''\n  )\n);\n</code></pre></p> <p>Use Cases:</p> <p>1. Filter Deleted Records: <pre><code>MODEL (\n  name analytics.active_customers,\n  kind INCREMENTAL_BY_UNIQUE_KEY (\n    unique_key customer_id,\n    merge_filter 'source.status != ''deleted'''\n  )\n);\n-- Only merge if source record is not deleted\n</code></pre></p> <p>2. Conditional Updates: <pre><code>MODEL (\n  name analytics.customers,\n  kind INCREMENTAL_BY_UNIQUE_KEY (\n    unique_key customer_id,\n    merge_filter 'source.updated_at &gt; target.updated_at'\n  )\n);\n-- Only merge if source is newer\n</code></pre></p> <p>3. Status-Based Filtering: <pre><code>MODEL (\n  name analytics.valid_orders,\n  kind INCREMENTAL_BY_UNIQUE_KEY (\n    unique_key order_id,\n    merge_filter 'source.status IN (''pending'', ''completed'')'\n  )\n);\n-- Only merge orders in specific statuses\n</code></pre></p> <p>\u26a0\ufe0f Note: <code>merge_filter</code> is only available on engines that support <code>MERGE</code>.</p>"},{"location":"models/model-properties/#44-properties-for-scd_type_2","title":"4.4 Properties for SCD_TYPE_2","text":""},{"location":"models/model-properties/#unique_key-scd-type-2","title":"<code>unique_key</code> (SCD Type 2)","text":"<p>Type: <code>array[string]</code> Required: Yes Default: None</p> <p>The column(s) that uniquely identify the business entity (not the row - rows can have same key with different validity periods).</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.customer_history,\n  kind SCD_TYPE_2 (\n    unique_key (customer_id)\n  )\n);\n</code></pre></p> <p>Note: For SCD Type 2, <code>unique_key</code> is always an array (even for single columns).</p>"},{"location":"models/model-properties/#valid_from_name","title":"<code>valid_from_name</code>","text":"<p>Type: <code>string</code> Required: No Default: <code>valid_from</code></p> <p>The name of the column storing when the row became valid.</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.customer_history,\n  kind SCD_TYPE_2 (\n    unique_key (customer_id),\n    valid_from_name 'effective_date'  -- Custom column name\n  )\n);\n</code></pre></p>"},{"location":"models/model-properties/#valid_to_name","title":"<code>valid_to_name</code>","text":"<p>Type: <code>string</code> Required: No Default: <code>valid_to</code></p> <p>The name of the column storing when the row became invalid (NULL for current rows).</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.customer_history,\n  kind SCD_TYPE_2 (\n    unique_key (customer_id),\n    valid_to_name 'expiry_date'  -- Custom column name\n  )\n);\n</code></pre></p>"},{"location":"models/model-properties/#invalidate_hard_deletes","title":"<code>invalidate_hard_deletes</code>","text":"<p>Type: <code>boolean</code> Required: No Default: <code>true</code></p> <p>Whether records missing from source should be marked as invalid (soft delete).</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.customer_history,\n  kind SCD_TYPE_2 (\n    unique_key (customer_id),\n    invalidate_hard_deletes true  -- Mark deleted records as invalid\n  )\n);\n</code></pre></p> <p>Behavior:</p> <p><code>invalidate_hard_deletes: true</code> (default): - Source record deleted \u2192 Set <code>valid_to</code> to current timestamp - Preserves historical record - Current query filters out invalid records</p> <p><code>invalidate_hard_deletes: false</code>: - Source record deleted \u2192 No change - Historical record remains valid - Use when deletions shouldn't affect history</p>"},{"location":"models/model-properties/#scd_type_2_by_time-properties","title":"SCD_TYPE_2_BY_TIME Properties","text":""},{"location":"models/model-properties/#updated_at_name","title":"<code>updated_at_name</code>","text":"<p>Type: <code>string</code> Required: No Default: <code>updated_at</code></p> <p>The column name storing when the source record was last updated.</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.customer_history,\n  kind SCD_TYPE_2_BY_TIME (\n    unique_key (customer_id),\n    updated_at_name 'last_modified'  -- Custom column name\n  )\n);\n</code></pre></p>"},{"location":"models/model-properties/#updated_at_as_valid_from","title":"<code>updated_at_as_valid_from</code>","text":"<p>Type: <code>boolean</code> Required: No Default: <code>false</code></p> <p>Whether to use <code>updated_at</code> value as <code>valid_from</code> (instead of 1970-01-01).</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.customer_history,\n  kind SCD_TYPE_2_BY_TIME (\n    unique_key (customer_id),\n    updated_at_as_valid_from true  -- Use actual update time\n  )\n);\n</code></pre></p> <p>Behavior:</p> <p><code>updated_at_as_valid_from: false</code> (default): - New rows: <code>valid_from = 1970-01-01 00:00:00</code> - Historical rows: <code>valid_from = previous valid_to</code></p> <p><code>updated_at_as_valid_from: true</code>: - New rows: <code>valid_from = updated_at</code> value - More accurate historical tracking</p>"},{"location":"models/model-properties/#scd_type_2_by_column-properties","title":"SCD_TYPE_2_BY_COLUMN Properties","text":""},{"location":"models/model-properties/#columns","title":"<code>columns</code>","text":"<p>Type: <code>string</code> or <code>array[string]</code> Required: Yes Default: None</p> <p>Columns whose changes trigger a new SCD Type 2 row. Use <code>*</code> to track all columns.</p> <p>Syntax: <pre><code>-- Track specific columns\nMODEL (\n  name analytics.customer_history,\n  kind SCD_TYPE_2_BY_COLUMN (\n    unique_key (customer_id),\n    columns (name, email, tier)  -- Track changes to these\n  )\n);\n\n-- Track all columns\nMODEL (\n  name analytics.customer_history,\n  kind SCD_TYPE_2_BY_COLUMN (\n    unique_key (customer_id),\n    columns '*'  -- Track any column change\n  )\n);\n</code></pre></p>"},{"location":"models/model-properties/#execution_time_as_valid_from","title":"<code>execution_time_as_valid_from</code>","text":"<p>Type: <code>boolean</code> Required: No Default: <code>false</code></p> <p>Whether to use execution time as <code>valid_from</code> (instead of 1970-01-01).</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.customer_history,\n  kind SCD_TYPE_2_BY_COLUMN (\n    unique_key (customer_id),\n    columns '*',\n    execution_time_as_valid_from true  -- Use pipeline execution time\n  )\n);\n</code></pre></p> <p>Behavior:</p> <p><code>execution_time_as_valid_from: false</code> (default): - New rows: <code>valid_from = 1970-01-01 00:00:00</code> - Historical rows: <code>valid_from = previous valid_to</code></p> <p><code>execution_time_as_valid_from: true</code>: - New rows: <code>valid_from = execution_time</code> (when pipeline ran) - More accurate for column-based change detection</p>"},{"location":"models/model-properties/#45-auto-restatement-properties","title":"4.5 Auto-Restatement Properties","text":""},{"location":"models/model-properties/#auto_restatement_cron","title":"<code>auto_restatement_cron</code>","text":"<p>Type: <code>string</code> (cron expression) Required: No Default: None</p> <p>Cron expression determining when to automatically restate this model.</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.daily_revenue,\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column revenue_date,\n    auto_restatement_cron '@weekly'  -- Restate weekly\n  ),\n  cron '@daily'\n);\n</code></pre></p> <p>How It Works:</p> <ul> <li>Model runs on its normal <code>cron</code> schedule (<code>@daily</code>)</li> <li>Additionally, restates on <code>auto_restatement_cron</code> schedule (<code>@weekly</code>)</li> <li>Restatement reprocesses historical data (see <code>auto_restatement_intervals</code>)</li> </ul> <p>\u26a0\ufe0f Warning:</p> <p>Not Recommended: Auto-restatement often indicates: - Data quality issues (late-arriving data) - Model design problems (should use <code>lookback</code> instead) - Dependency chain issues</p> <p>Prefer <code>lookback</code> Instead:</p> <pre><code>-- \u274c Not recommended\nMODEL (\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column event_date,\n    auto_restatement_cron '@weekly'\n  )\n);\n\n-- \u2705 Better approach\nMODEL (\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column event_date,\n    lookback 7  -- Reprocess last 7 days on each run\n  )\n);\n</code></pre> <p>Use Cases:</p> <p>\u2705 Valid Use Cases: - Dimension table updates (customer data changes retroactively) - Data corrections (fixing historical errors) - Periodic full refresh (less frequent than model cron)</p> <p>Note: Models with <code>auto_restatement_cron</code> can only be previewed in dev (data not reused in production).</p>"},{"location":"models/model-properties/#auto_restatement_intervals","title":"<code>auto_restatement_intervals</code>","text":"<p>Type: <code>integer</code> Required: No Default: None (restate entire model)</p> <p>The number of last intervals to restate (only for <code>INCREMENTAL_BY_TIME_RANGE</code>).</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.daily_revenue,\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column revenue_date,\n    auto_restatement_cron '@weekly',\n    auto_restatement_intervals 7  -- Restate last 7 days\n  ),\n  cron '@daily'\n);\n</code></pre></p> <p>Behavior:</p> <p>Without <code>auto_restatement_intervals</code>: - Restates entire model (all historical data) - Expensive for large tables</p> <p>With <code>auto_restatement_intervals: 7</code>: - Restates only last 7 intervals - More efficient, targeted restatement</p> <p>Example:</p> <pre><code>MODEL (\n  name analytics.daily_revenue,\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column revenue_date,\n    auto_restatement_cron '@weekly',  -- Every Sunday\n    auto_restatement_intervals 7       -- Last 7 days\n  ),\n  cron '@daily'\n);\n</code></pre> <p>What happens: - Daily: Processes new day (normal incremental) - Weekly: Reprocesses last 7 days (restatement)</p> <p>\u26a0\ufe0f Note: Only supported for <code>INCREMENTAL_BY_TIME_RANGE</code>. Other kinds restate entire model.</p> <p>\u2191 Back to Top</p>"},{"location":"models/model-properties/#5-data-quality-properties","title":"5. Data Quality Properties","text":"<p>These properties define data relationships, uniqueness, and validation rules.</p>"},{"location":"models/model-properties/#51-grain","title":"5.1 <code>grain</code>","text":"<p>Type: <code>string</code> or <code>array[string]</code> Required: No Default: None</p> <p>The column(s) that uniquely identify each row (primary key).</p> <p>Syntax: <pre><code>-- Single column grain\nMODEL (\n  name analytics.customers,\n  grain customer_id\n);\n\n-- Composite grain\nMODEL (\n  name analytics.daily_customer_metrics,\n  grain (customer_id, metric_date)\n);\n</code></pre></p> <p>What It Does:</p> <ol> <li>Declares Uniqueness: Documents the primary key</li> <li>Enables Tools: Simplifies <code>vulcan table_diff</code> and other tools</li> <li>Semantic Layer: Used for joins in semantic layer</li> <li>Validation: Should be paired with <code>unique_values</code> audit</li> </ol> <p>Example:</p> <pre><code>MODEL (\n  name analytics.orders,\n  grain order_id,\n  assertions (\n    not_null(columns := (order_id)),\n    unique_values(columns := (order_id))  -- Enforce grain uniqueness\n  )\n);\n\nSELECT\n  order_id,  -- Grain column\n  customer_id,\n  order_date,\n  amount\nFROM raw.orders;\n</code></pre> <p>Composite Grain:</p> <pre><code>MODEL (\n  name analytics.daily_revenue,\n  grain (customer_id, revenue_date),\n  assertions (\n    unique_combination_of_columns(columns := (customer_id, revenue_date))\n  )\n);\n</code></pre> <p>Relationship to Audits:</p> <p>Always pair <code>grain</code> with uniqueness audits:</p> <pre><code>MODEL (\n  name analytics.customers,\n  grain customer_id,\n  assertions (\n    not_null(columns := (customer_id)),      -- Required\n    unique_values(columns := (customer_id))   -- Unique\n  )\n);\n</code></pre>"},{"location":"models/model-properties/#52-grains","title":"5.2 <code>grains</code>","text":"<p>Type: <code>array[string]</code> or <code>array[array[string]]</code> Required: No Default: None</p> <p>Multiple grains if a model has more than one unique key.</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.customer_products,\n  grains (\n    (customer_id),           -- Customer is unique\n    (product_id),            -- Product is unique\n    (customer_id, product_id)  -- Customer-product combination is unique\n  )\n);\n</code></pre></p> <p>Use Cases:</p> <ul> <li>Models with multiple natural keys</li> <li>Fact tables with multiple unique identifiers</li> <li>Bridge tables with multiple relationships</li> </ul> <p>Example:</p> <pre><code>MODEL (\n  name analytics.order_line_items,\n  grains (\n    (order_id, line_item_id),  -- Primary key\n    (order_id),                 -- Order is unique per order_id\n    (product_id)                -- Product appears in multiple orders\n  )\n);\n</code></pre>"},{"location":"models/model-properties/#53-references","title":"5.3 <code>references</code>","text":"<p>Type: <code>string</code> or <code>array[string]</code> Required: No Default: None</p> <p>Non-unique columns that identify join relationships to other models (foreign keys).</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.orders,\n  grain order_id,\n  references (customer_id)  -- Foreign key to customers table\n);\n</code></pre></p> <p>What It Does:</p> <ol> <li>Documents Relationships: Declares foreign key relationships</li> <li>Helps with Join Detection: Assists semantic layer in detecting join relationships (but grains are required for joins)</li> <li>Join Safety: Can join <code>references</code> \u2192 <code>grain</code> (many-to-one), but cannot join <code>references</code> \u2192 <code>references</code> (many-to-many, unsafe)</li> </ol> <p>Rules:</p> <ul> <li>\u2705 Can join <code>references</code> \u2192 <code>grain</code> (many-to-one)</li> <li>\u274c Cannot join <code>references</code> \u2192 <code>references</code> (many-to-many, unsafe)</li> </ul> <p>Example:</p> <pre><code>-- Customers table (grain)\nMODEL (\n  name analytics.customers,\n  grain customer_id\n);\n\n-- Orders table (references customer_id)\nMODEL (\n  name analytics.orders,\n  grain order_id,\n  references (customer_id)  -- Can join to customers.customer_id\n);\n\n-- Order line items (references order_id)\nMODEL (\n  name analytics.order_line_items,\n  grain (order_id, line_item_id),\n  references (order_id)  -- Can join to orders.order_id\n);\n</code></pre> <p>Column Aliasing:</p> <p>If column names differ, alias to common entity name:</p> <pre><code>MODEL (\n  name analytics.guest_orders,\n  grain order_id,\n  references (guest_id AS customer_id)  -- Alias to match customers.grain\n);\n-- Can now join to analytics.customers (grain: customer_id)\n</code></pre> <p>Multiple References:</p> <pre><code>MODEL (\n  name analytics.order_line_items,\n  grain (order_id, line_item_id),\n  references (order_id, product_id)  -- Multiple foreign keys\n);\n</code></pre>"},{"location":"models/model-properties/#54-assertions-formerly-audits","title":"5.4 <code>assertions</code> (formerly <code>audits</code>)","text":"<p>Type: <code>array</code> Required: No Default: None</p> <p>Audits that run after model execution to validate data quality.</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.orders,\n  assertions (\n    not_null(columns := (order_id, customer_id)),\n    unique_values(columns := (order_id)),\n    accepted_range(column := amount, min_v := 0, max_v := 1000000)\n  )\n);\n</code></pre></p> <p>Built-in Audits:</p> <p>Vulcan provides 29 built-in audits. Common ones:</p> Audit Purpose Example <code>not_null</code> No NULL values <code>not_null(columns := (id, email))</code> <code>unique_values</code> No duplicates <code>unique_values(columns := (id))</code> <code>accepted_values</code> Enum validation <code>accepted_values(column := status, is_in := ('A', 'B'))</code> <code>accepted_range</code> Numeric range <code>accepted_range(column := age, min_v := 0, max_v := 120)</code> <code>forall</code> Custom logic <code>forall(criteria := (amount &gt;= 0))</code> <p>Complete Audit Reference:</p> <p>For comprehensive audit documentation, see Chapter 4: Audits.</p> <p>Example:</p> <pre><code>MODEL (\n  name analytics.orders,\n  grain order_id,\n  references (customer_id),\n  assertions (\n    -- Completeness\n    not_null(columns := (order_id, customer_id, order_date, amount)),\n\n    -- Uniqueness\n    unique_values(columns := (order_id)),\n\n    -- Validity\n    accepted_values(\n      column := status,\n      is_in := ('pending', 'completed', 'cancelled')\n    ),\n    accepted_range(column := amount, min_v := 0, max_v := 1000000),\n\n    -- Business logic\n    forall(criteria := (\n      order_date &lt;= CURRENT_DATE,\n      shipped_date IS NULL OR shipped_date &gt;= order_date\n    ))\n  )\n);\n</code></pre> <p>Custom Audits:</p> <p>Reference audits defined in <code>audits/</code> directory:</p> <pre><code>MODEL (\n  name analytics.orders,\n  assertions (\n    not_null(columns := (order_id)),\n    custom_revenue_check,  -- Defined in audits/revenue.sql\n    valid_customer_reference  -- Defined in audits/referential.sql\n  )\n);\n</code></pre> <p>For comprehensive audit documentation, see Chapter 4: Audits</p>"},{"location":"models/model-properties/#55-depends_on","title":"5.5 <code>depends_on</code>","text":"<p>Type: <code>array[string]</code> Required: No Default: Inferred from model code</p> <p>Explicitly specify models this model depends on (in addition to auto-detected dependencies).</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.customer_summary,\n  depends_on (analytics.customers, analytics.orders)  -- Explicit dependencies\n);\n\nSELECT\n  c.customer_id,\n  COUNT(o.order_id) as order_count\nFROM analytics.customers c\nLEFT JOIN analytics.orders o ON c.customer_id = o.customer_id\nGROUP BY c.customer_id;\n</code></pre></p> <p>When to Use:</p> <p>1. Dynamic Dependencies:</p> <p>When dependencies aren't visible in SQL:</p> <pre><code>MODEL (\n  name analytics.dynamic_query,\n  depends_on (analytics.config_table)  -- Used in macro, not visible in SQL\n);\n\nSELECT * FROM @IF(@gateway = 'prod', analytics.config_table, analytics.config_table_dev);\n</code></pre> <p>2. Python Model Dependencies:</p> <p>Python models may have hidden dependencies:</p> <pre><code>@model(\n    \"analytics.ml_predictions\",\n    depends_on=[\"analytics.features\", \"analytics.model_weights\"]\n)\ndef execute(context, ...):\n    # Dependencies not visible in SQL\n    features = context.fetchdf(\"SELECT * FROM analytics.features\")\n    weights = context.fetchdf(\"SELECT * FROM analytics.model_weights\")\n    # ...\n</code></pre> <p>3. Override Auto-Detection:</p> <p>Force dependency order:</p> <pre><code>MODEL (\n  name analytics.final_summary,\n  depends_on (analytics.stage1, analytics.stage2)  -- Ensure order\n);\n</code></pre> <p>Note: Dependencies are usually auto-detected from SQL. Only use <code>depends_on</code> when necessary.</p> <p>\u2191 Back to Top</p>"},{"location":"models/model-properties/#6-metadata-properties","title":"6. Metadata Properties","text":"<p>These properties provide documentation and organization for models.</p>"},{"location":"models/model-properties/#61-description","title":"6.1 <code>description</code>","text":"<p>Type: <code>string</code> Required: No Default: None</p> <p>Human-readable description of the model. Automatically registered as table comment in the SQL engine.</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.customer_metrics,\n  description 'Daily aggregated customer metrics for BI dashboards'\n);\n</code></pre></p> <p>What It Does:</p> <ol> <li>Documentation: Describes model purpose</li> <li>Table Comments: Registered in SQL engine (if supported)</li> <li>Semantic Layer: Flows through to semantic layer</li> <li>Discovery: Helps users understand models</li> </ol> <p>Example:</p> <pre><code>MODEL (\n  name analytics.daily_revenue,\n  description 'Daily revenue aggregated by customer and product category. Includes completed orders only. Used for revenue reporting dashboards.'\n);\n</code></pre> <p>Best Practices:</p> <ul> <li>Write clear, concise descriptions</li> <li>Include business context</li> <li>Mention key filters or assumptions</li> <li>Note downstream consumers</li> </ul>"},{"location":"models/model-properties/#62-column_descriptions","title":"6.2 <code>column_descriptions</code>","text":"<p>Type: <code>dict</code> (key-value pairs) Required: No Default: None</p> <p>Column-level descriptions. Automatically registered as column comments in SQL engine.</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.customer_metrics,\n  column_descriptions (\n    customer_id = 'Unique customer identifier (integer)',\n    revenue = 'Total revenue in USD from completed orders',\n    order_count = 'Number of completed orders',\n    churn_risk_score = 'ML churn probability (0-1, higher = more risk)'\n  )\n);\n</code></pre></p> <p>What It Does:</p> <ol> <li>Column Documentation: Describes each column</li> <li>Column Comments: Registered in SQL engine</li> <li>Semantic Layer: Flows through to semantic layer dimensions</li> <li>BI Tools: Appears in BI tool metadata</li> </ol> <p>Example:</p> <pre><code>MODEL (\n  name analytics.customer_predictions,\n  column_descriptions (\n    customer_id = 'Foreign key to customers table',\n    churn_probability = 'Probability customer will churn in next 30 days (0-1 scale)',\n    predicted_ltv = 'Predicted lifetime value in USD',\n    prediction_date = 'Date when prediction was generated',\n    model_version = 'ML model version used (e.g., v2.3.1)'\n  )\n);\n</code></pre> <p>Best Practices:</p> <ul> <li>Explain business meaning, not just data type</li> <li>Include units (USD, percentage, etc.)</li> <li>Note calculation methods for derived columns</li> <li>Document special values (NULL meanings, etc.)</li> </ul> <p>Inline Comments Alternative:</p> <p>You can also use inline SQL comments (but <code>column_descriptions</code> takes precedence):</p> <pre><code>SELECT\n  customer_id,  -- Unique customer identifier\n  revenue,      -- Total revenue in USD\n  order_count   -- Number of orders\nFROM ...\n</code></pre>"},{"location":"models/model-properties/#63-owner","title":"6.3 <code>owner</code>","text":"<p>Type: <code>string</code> Required: No Default: Project default (if set)</p> <p>Team or person responsible for the model.</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.customer_metrics,\n  owner 'data-team'\n);\n\n-- Or individual\nMODEL (\n  name analytics.ml_predictions,\n  owner 'ml-team'\n);\n</code></pre></p> <p>What It Does:</p> <ol> <li>Ownership: Identifies responsible team/person</li> <li>Notifications: Used for alerting (if configured)</li> <li>Organization: Helps organize models by team</li> <li>Documentation: Makes it clear who to contact</li> </ol> <p>Example:</p> <pre><code>MODEL (\n  name analytics.revenue,\n  owner 'finance-data-team'\n);\n\nMODEL (\n  name analytics.customer_segments,\n  owner 'analytics-team'\n);\n\nMODEL (\n  name analytics.ml_churn_predictions,\n  owner 'ml-team'\n);\n</code></pre> <p>Project Default:</p> <p>Set default owner in <code>config.yaml</code>:</p> <pre><code>model_defaults:\n  owner: 'data-team'\n</code></pre> <p>Override per model:</p> <pre><code>MODEL (\n  name analytics.special_model,\n  owner 'special-team'  -- Overrides default\n);\n</code></pre>"},{"location":"models/model-properties/#64-tags","title":"6.4 <code>tags</code>","text":"<p>Type: <code>array[string]</code> Required: No Default: None</p> <p>Labels for organizing and categorizing models.</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.customer_metrics,\n  tags ('analytics', 'customer', 'revenue')\n);\n</code></pre></p> <p>What It Does:</p> <ol> <li>Organization: Group related models</li> <li>Filtering: Select models by tag (<code>vulcan run --select tag:analytics</code>)</li> <li>Documentation: Categorize models</li> <li>CI/CD: Run specific model groups</li> </ol> <p>Common Tag Patterns:</p> <p>By Domain: <pre><code>tags ('sales', 'revenue', 'orders')\ntags ('marketing', 'campaigns', 'attribution')\ntags ('finance', 'accounting', 'reconciliation')\n</code></pre></p> <p>By Layer: <pre><code>tags ('staging', 'raw')\ntags ('marts', 'analytics')\ntags ('semantic', 'metrics')\n</code></pre></p> <p>By Priority: <pre><code>tags ('critical', 'p0')\ntags ('important', 'p1')\ntags ('monitoring', 'p2')\n</code></pre></p> <p>By Data Type: <pre><code>tags ('pii', 'sensitive')\ntags ('public', 'shared')\ntags ('internal', 'confidential')\n</code></pre></p> <p>Example:</p> <pre><code>MODEL (\n  name analytics.daily_revenue,\n  tags ('analytics', 'revenue', 'critical', 'p0')\n);\n\nMODEL (\n  name analytics.customer_segments,\n  tags ('analytics', 'customer', 'ml', 'p1')\n);\n</code></pre> <p>Selecting by Tags:</p> <pre><code># Run all models with 'analytics' tag\nvulcan run --select tag:analytics\n\n# Run critical models\nvulcan run --select tag:critical\n\n# Run multiple tags\nvulcan run --select tag:analytics tag:revenue\n</code></pre>"},{"location":"models/model-properties/#65-project","title":"6.5 <code>project</code>","text":"<p>Type: <code>string</code> Required: No Default: None</p> <p>The project name this model belongs to (for multi-repo deployments).</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.customers,\n  project 'main-project'\n);\n</code></pre></p> <p>Use Cases:</p> <ul> <li>Multi-repo deployments</li> <li>Shared models across projects</li> <li>Project isolation</li> </ul> <p>Note: Most users don't need this property. Only use for multi-repo setups.</p>"},{"location":"models/model-properties/#66-stamp","title":"6.6 <code>stamp</code>","text":"<p>Type: <code>string</code> Required: No Default: None</p> <p>Arbitrary string to force a new model version without changing functional components.</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.customers,\n  stamp '2024-11-14-rebuild'  -- Force new version\n);\n</code></pre></p> <p>Use Cases:</p> <p>1. Force Rebuild:</p> <pre><code>MODEL (\n  name analytics.customers,\n  stamp 'rebuild-2024-11-14'  -- Forces rebuild even if query unchanged\n);\n</code></pre> <p>2. Version Tracking:</p> <pre><code>MODEL (\n  name analytics.customers,\n  stamp 'v2.3.1'  -- Track model version\n);\n</code></pre> <p>3. Temporary Changes:</p> <pre><code>MODEL (\n  name analytics.customers,\n  stamp 'temp-fix-2024-11-14'  -- Temporary version\n);\n</code></pre> <p>\u26a0\ufe0f Note: Changing <code>stamp</code> creates a new model version, triggering rebuilds. Use sparingly.</p> <p>\u2191 Back to Top</p>"},{"location":"models/model-properties/#7-schema-type-properties","title":"7. Schema &amp; Type Properties","text":"<p>These properties control column definitions and SQL dialect.</p>"},{"location":"models/model-properties/#71-columns","title":"7.1 <code>columns</code>","text":"<p>Type: <code>array[string]</code> (column definitions) Required: No (required for Python models) Default: Inferred from SQL query</p> <p>Explicit column names and data types. Disables automatic inference.</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.customers,\n  columns (\n    customer_id INT,\n    customer_name VARCHAR(255),\n    email VARCHAR(255),\n    created_at TIMESTAMP\n  )\n);\n\nSELECT\n  customer_id::INT,\n  customer_name::VARCHAR(255),\n  email::VARCHAR(255),\n  created_at::TIMESTAMP\nFROM raw.customers;\n</code></pre></p> <p>When to Use:</p> <p>1. Python Models (Required):</p> <p>Python models must specify columns (can't infer from DataFrame):</p> <pre><code>@model(\n    \"analytics.predictions\",\n    columns={\n        \"customer_id\": \"INT\",\n        \"prediction\": \"FLOAT\",\n        \"prediction_date\": \"DATE\"\n    }\n)\ndef execute(context, ...):\n    # ...\n    return df  # DataFrame columns must match column definitions\n</code></pre> <p>2. Seed Models:</p> <pre><code>MODEL (\n  name analytics.national_holidays,\n  kind SEED (path 'holidays.csv'),\n  columns (\n    holiday_name VARCHAR,\n    holiday_date DATE\n  )\n);\n</code></pre> <p>3. Override Inference:</p> <p>If automatic inference is wrong:</p> <pre><code>MODEL (\n  name analytics.events,\n  columns (\n    event_id VARCHAR(36),  -- UUID as string\n    event_date DATE,\n    event_data JSON\n  )\n);\n</code></pre> <p>\u26a0\ufe0f Warning:</p> <p>Vulcan may exhibit unexpected behavior if: - <code>columns</code> includes columns not returned by query - <code>columns</code> omits columns returned by query - Data types don't match query output</p> <p>Best Practice: Let Vulcan infer columns unless you have a specific reason to override.</p>"},{"location":"models/model-properties/#72-dialect","title":"7.2 <code>dialect</code>","text":"<p>Type: <code>string</code> Required: No Default: Project default (<code>model_defaults.dialect</code>)</p> <p>The SQL dialect for this model's query.</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.customers,\n  dialect snowflake  -- Override project default\n);\n</code></pre></p> <p>Supported Dialects:</p> <p>Vulcan supports all SQLGlot dialects: - <code>snowflake</code> - <code>bigquery</code> - <code>spark</code> - <code>postgres</code> - <code>duckdb</code> - <code>mysql</code> - <code>sqlite</code> - <code>redshift</code> - <code>databricks</code> - And more...</p> <p>When to Use:</p> <p>1. Multi-Warehouse Projects:</p> <pre><code>-- Snowflake model\nMODEL (\n  name analytics.snowflake_customers,\n  dialect snowflake\n);\n\n-- BigQuery model\nMODEL (\n  name analytics.bigquery_customers,\n  dialect bigquery\n);\n</code></pre> <p>2. Override Project Default:</p> <pre><code># config.yaml\nmodel_defaults:\n  dialect: snowflake\n</code></pre> <pre><code>-- Most models use Snowflake (default)\nMODEL (name analytics.customers);\n\n-- This one uses BigQuery\nMODEL (\n  name analytics.bigquery_events,\n  dialect bigquery  -- Override\n);\n</code></pre> <p>3. Dialect-Specific Syntax:</p> <pre><code>MODEL (\n  name analytics.events,\n  dialect bigquery  -- Uses BigQuery-specific functions\n);\n\nSELECT\n  event_id,\n  PARSE_TIMESTAMP('%Y-%m-%d', event_date) as event_timestamp,  -- BigQuery syntax\n  event_data\nFROM raw.events;\n</code></pre> <p>Project Default:</p> <p>Always set in <code>config.yaml</code>:</p> <pre><code>model_defaults:\n  dialect: snowflake  # Required\n</code></pre> <p>\u2191 Back to Top</p>"},{"location":"models/model-properties/#8-warehouse-specific-properties","title":"8. Warehouse-Specific Properties","text":"<p>These properties control physical table structure and engine-specific features.</p>"},{"location":"models/model-properties/#81-partitioned_by","title":"8.1 <code>partitioned_by</code>","text":"<p>Type: <code>string</code> or <code>array[string]</code> Required: No (required for <code>INCREMENTAL_BY_PARTITION</code>) Default: None</p> <p>Column(s) or expressions used for table partitioning.</p> <p>Syntax: <pre><code>-- Single column partition\nMODEL (\n  name analytics.events,\n  partitioned_by event_date\n);\n\n-- Multi-column partition\nMODEL (\n  name analytics.events,\n  partitioned_by (year, month, day)\n);\n\n-- Expression partition (BigQuery)\nMODEL (\n  name analytics.events,\n  partitioned_by 'DATE_TRUNC(event_timestamp, DAY)'\n);\n</code></pre></p> <p>Supported Engines:</p> <ul> <li>BigQuery: Partition by DATE, TIMESTAMP, INTEGER, or DATE_TRUNC expression</li> <li>Spark/Databricks: Partition by columns</li> <li>Snowflake: Clustering (not partitioning)</li> <li>Postgres: Partition by columns (if supported)</li> </ul> <p>Examples:</p> <p>BigQuery Date Partitioning:</p> <pre><code>MODEL (\n  name analytics.daily_events,\n  partitioned_by event_date,  -- Partition by DATE column\n  physical_properties (\n    partition_expiration_days = 90,\n    require_partition_filter = true\n  )\n);\n</code></pre> <p>BigQuery Timestamp Partitioning:</p> <pre><code>MODEL (\n  name analytics.events,\n  partitioned_by 'DATE_TRUNC(event_timestamp, DAY)',  -- Partition by day\n  physical_properties (\n    partition_expiration_days = 365\n  )\n);\n</code></pre> <p>Spark Partitioning:</p> <pre><code>MODEL (\n  name analytics.events,\n  partitioned_by (year, month, day),  -- Multi-column partition\n  storage_format 'parquet'\n);\n</code></pre> <p>Performance Benefits:</p> <ul> <li>\u2705 Faster queries (partition pruning)</li> <li>\u2705 Lower costs (scan less data)</li> <li>\u2705 Better maintenance (drop old partitions)</li> </ul> <p>For INCREMENTAL_BY_PARTITION:</p> <p><code>partitioned_by</code> is required and defines the partition key:</p> <pre><code>MODEL (\n  name analytics.events,\n  kind INCREMENTAL_BY_PARTITION,\n  partitioned_by event_date  -- Required for this kind\n);\n</code></pre>"},{"location":"models/model-properties/#82-clustered_by","title":"8.2 <code>clustered_by</code>","text":"<p>Type: <code>string</code> or <code>array[string]</code> Required: No Default: None</p> <p>Column(s) used for table clustering (BigQuery, Snowflake).</p> <p>Syntax: <pre><code>-- Single column clustering\nMODEL (\n  name analytics.orders,\n  clustered_by customer_id\n);\n\n-- Multi-column clustering\nMODEL (\n  name analytics.events,\n  clustered_by (customer_id, event_type)\n);\n</code></pre></p> <p>Supported Engines:</p> <ul> <li>BigQuery: Clustering by columns</li> <li>Snowflake: Clustering by columns (automatic, but can specify)</li> </ul> <p>Examples:</p> <p>BigQuery Clustering:</p> <pre><code>MODEL (\n  name analytics.orders,\n  partitioned_by order_date,\n  clustered_by (customer_id, product_id),  -- Cluster by common filter columns\n  physical_properties (\n    require_partition_filter = true\n  )\n);\n</code></pre> <p>Snowflake Clustering:</p> <pre><code>MODEL (\n  name analytics.events,\n  clustered_by (customer_id, event_date)  -- Optimize for common queries\n);\n</code></pre> <p>Performance Benefits:</p> <ul> <li>\u2705 Faster queries (co-located data)</li> <li>\u2705 Better compression</li> <li>\u2705 Reduced scan costs</li> </ul> <p>Best Practices:</p> <ul> <li>Cluster by columns frequently used in WHERE clauses</li> <li>Limit to 1-4 columns (more has diminishing returns)</li> <li>Combine with partitioning for best performance</li> </ul>"},{"location":"models/model-properties/#83-table_format","title":"8.3 <code>table_format</code>","text":"<p>Type: <code>string</code> Required: No Default: Engine default</p> <p>Table format for engines supporting multiple formats (Spark, Athena).</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.events,\n  table_format 'iceberg',  -- Iceberg table format\n  storage_format 'parquet'  -- Parquet file format\n);\n</code></pre></p> <p>Supported Formats:</p> <ul> <li><code>iceberg</code> - Apache Iceberg</li> <li><code>delta</code> - Delta Lake</li> <li><code>hive</code> - Hive format</li> </ul> <p>Examples:</p> <p>Iceberg Table:</p> <pre><code>MODEL (\n  name analytics.events,\n  table_format 'iceberg',\n  storage_format 'parquet',\n  partitioned_by event_date\n);\n</code></pre> <p>Delta Lake:</p> <pre><code>MODEL (\n  name analytics.events,\n  table_format 'delta',\n  partitioned_by event_date\n);\n</code></pre> <p>Note: Not all engines support <code>table_format</code>. For engines that don't distinguish (e.g., BigQuery, Snowflake), use <code>storage_format</code> instead.</p>"},{"location":"models/model-properties/#84-storage_format","title":"8.4 <code>storage_format</code>","text":"<p>Type: <code>string</code> Required: No Default: Engine default</p> <p>File storage format (Spark, Hive, Athena).</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.events,\n  storage_format 'parquet'  -- Parquet files\n);\n</code></pre></p> <p>Supported Formats:</p> <ul> <li><code>parquet</code> - Apache Parquet (recommended)</li> <li><code>orc</code> - Optimized Row Columnar</li> <li><code>avro</code> - Apache Avro</li> <li><code>json</code> - JSON files</li> <li><code>csv</code> - CSV files</li> </ul> <p>Examples:</p> <p>Parquet (Recommended):</p> <pre><code>MODEL (\n  name analytics.events,\n  storage_format 'parquet',  -- Best compression and performance\n  partitioned_by event_date\n);\n</code></pre> <p>ORC:</p> <pre><code>MODEL (\n  name analytics.events,\n  storage_format 'orc',  -- Alternative to Parquet\n  partitioned_by event_date\n);\n</code></pre> <p>Recommendation: Use <code>parquet</code> for best performance and compression.</p>"},{"location":"models/model-properties/#85-physical_properties","title":"8.5 <code>physical_properties</code>","text":"<p>Type: <code>dict</code> (key-value pairs) Required: No Default: Project defaults (merged)</p> <p>Engine-specific properties applied to the physical table/view.</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.events,\n  physical_properties (\n    partition_expiration_days = 90,\n    require_partition_filter = true,\n    creatable_type = TRANSIENT\n  )\n);\n</code></pre></p> <p>Common Properties by Engine:</p> <p>BigQuery:</p> <pre><code>MODEL (\n  name analytics.events,\n  partitioned_by event_date,\n  physical_properties (\n    partition_expiration_days = 90,        -- Auto-delete old partitions\n    require_partition_filter = true,       -- Require partition filter\n    description = 'Event data table'       -- Table description\n  )\n);\n</code></pre> <p>Snowflake:</p> <pre><code>MODEL (\n  name analytics.events,\n  physical_properties (\n    warehouse = 'COMPUTE_WH',              -- Warehouse for Dynamic Tables\n    creatable_type = TRANSIENT,             -- Transient table (lower cost)\n    data_retention_time_in_days = 0        -- No time travel\n  )\n);\n</code></pre> <p>Spark/Databricks:</p> <pre><code>MODEL (\n  name analytics.events,\n  physical_properties (\n    'delta.autoOptimize.optimizeWrite' = true,\n    'delta.autoOptimize.autoCompact' = true\n  )\n);\n</code></pre> <p>Property Merging:</p> <p>Project defaults are merged with model-specific:</p> <pre><code># config.yaml\nmodel_defaults:\n  physical_properties:\n    partition_expiration_days: 7\n    require_partition_filter: true\n</code></pre> <pre><code>-- Model inherits defaults, adds new property\nMODEL (\n  name analytics.events,\n  physical_properties (\n    creatable_type = TRANSIENT  -- Adds to defaults\n  )\n);\n-- Result: partition_expiration_days=7, require_partition_filter=true, creatable_type=TRANSIENT\n</code></pre> <p>Unsetting Properties:</p> <p>Set to <code>None</code> to remove project-level property:</p> <pre><code>MODEL (\n  name analytics.events,\n  physical_properties (\n    partition_expiration_days = None,  -- Remove project default\n    creatable_type = TRANSIENT\n  )\n);\n</code></pre>"},{"location":"models/model-properties/#86-virtual_properties","title":"8.6 <code>virtual_properties</code>","text":"<p>Type: <code>dict</code> (key-value pairs) Required: No Default: Project defaults (merged)</p> <p>Engine-specific properties applied to the virtual view (development environments).</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.events,\n  virtual_properties (\n    creatable_type = SECURE,  -- Secure view\n    labels = [('environment', 'dev')]\n  )\n);\n</code></pre></p> <p>Common Use Cases:</p> <p>Secure Views (Snowflake):</p> <pre><code>MODEL (\n  name analytics.sensitive_data,\n  virtual_properties (\n    creatable_type = SECURE  -- Secure view in dev\n  )\n);\n</code></pre> <p>View Labels (BigQuery):</p> <pre><code>MODEL (\n  name analytics.events,\n  virtual_properties (\n    labels = [('environment', 'dev'), ('team', 'analytics')]\n  )\n);\n</code></pre> <p>Property Merging:</p> <p>Same merging behavior as <code>physical_properties</code>:</p> <pre><code># config.yaml\nmodel_defaults:\n  virtual_properties:\n    creatable_type: SECURE\n</code></pre> <pre><code>MODEL (\n  name analytics.events,\n  virtual_properties (\n    labels = [('team', 'analytics')]  -- Adds to defaults\n  )\n);\n</code></pre>"},{"location":"models/model-properties/#87-session_properties","title":"8.7 <code>session_properties</code>","text":"<p>Type: <code>dict</code> (key-value pairs) Required: No Default: Project defaults (merged)</p> <p>Engine-specific session properties (query-level configuration).</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.large_query,\n  session_properties (\n    'spark.executor.cores' = 4,\n    'spark.executor.memory' = '8G'\n  )\n);\n</code></pre></p> <p>Common Use Cases:</p> <p>Spark/Databricks Resource Control:</p> <pre><code>MODEL (\n  name analytics.large_aggregation,\n  session_properties (\n    'spark.executor.cores' = 8,\n    'spark.executor.memory' = '16G',\n    'spark.sql.shuffle.partitions' = 200\n  )\n);\n</code></pre> <p>Snowflake Session Settings:</p> <pre><code>MODEL (\n  name analytics.complex_query,\n  session_properties (\n    'QUERY_TAG' = 'analytics.large_query',\n    'STATEMENT_TIMEOUT_IN_SECONDS' = 3600\n  )\n);\n</code></pre> <p>BigQuery Settings:</p> <pre><code>MODEL (\n  name analytics.large_query,\n  session_properties (\n    'maximum_bytes_billed' = '1000000000'  -- 1GB limit\n  )\n);\n</code></pre> <p>Property Merging:</p> <p>Session properties are merged per-key:</p> <pre><code># config.yaml\nmodel_defaults:\n  session_properties:\n    'spark.executor.cores': 4\n    'spark.executor.memory': '8G'\n</code></pre> <pre><code>MODEL (\n  name analytics.events,\n  session_properties (\n    'spark.executor.cores' = 8  -- Overrides: 4 \u2192 8\n    -- 'spark.executor.memory' inherits: '8G'\n  )\n);\n</code></pre> <p>\u2191 Back to Top</p>"},{"location":"models/model-properties/#9-execution-control-properties","title":"9. Execution Control Properties","text":"<p>These properties control how models are executed and optimized.</p>"},{"location":"models/model-properties/#91-enabled","title":"9.1 <code>enabled</code>","text":"<p>Type: <code>boolean</code> Required: No Default: <code>true</code></p> <p>Whether the model is enabled (loaded and executed).</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.experimental_model,\n  enabled false  -- Disable this model\n);\n</code></pre></p> <p>Use Cases:</p> <p>1. Temporary Disable:</p> <pre><code>MODEL (\n  name analytics.deprecated_model,\n  enabled false  -- Don't run, but keep definition\n);\n</code></pre> <p>2. Feature Flags:</p> <pre><code>MODEL (\n  name analytics.new_feature,\n  enabled false  -- Disable until ready\n);\n</code></pre> <p>3. Conditional Models:</p> <pre><code>-- Disable in certain environments\nMODEL (\n  name analytics.test_model,\n  enabled \"@IF(@gateway = 'prod', false, true)\"  -- Disable in prod\n);\n</code></pre> <p>What Happens When Disabled:</p> <ul> <li>Model is not loaded by Vulcan</li> <li>Model is not executed in runs</li> <li>Dependencies are not resolved (downstream models may fail)</li> <li>Model definition is preserved (can re-enable later)</li> </ul> <p>\u26a0\ufe0f Warning: Disabling a model can break downstream models that depend on it.</p>"},{"location":"models/model-properties/#92-gateway","title":"9.2 <code>gateway</code>","text":"<p>Type: <code>string</code> Required: No Default: Default gateway</p> <p>The execution gateway/engine to use for this model.</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.spark_model,\n  gateway 'spark'  -- Use Spark gateway\n);\n\nMODEL (\n  name analytics.bigquery_model,\n  gateway 'bigquery'  -- Use BigQuery gateway\n);\n</code></pre></p> <p>Use Cases:</p> <p>Multi-Engine Projects:</p> <pre><code>-- Some models on Snowflake\nMODEL (\n  name analytics.snowflake_customers,\n  gateway 'snowflake'\n);\n\n-- Some models on BigQuery\nMODEL (\n  name analytics.bigquery_events,\n  gateway 'bigquery'\n);\n</code></pre> <p>Engine-Specific Features:</p> <pre><code>-- Use Spark for ML workloads\nMODEL (\n  name analytics.ml_features,\n  gateway 'spark',\n  session_properties (\n    'spark.ml.feature.scaler' = 'standard'\n  )\n);\n</code></pre> <p>Configuration:</p> <p>Gateways are configured in <code>config.yaml</code>:</p> <pre><code>gateways:\n  snowflake:\n    type: snowflake\n    connection: ...\n  bigquery:\n    type: bigquery\n    connection: ...\n</code></pre>"},{"location":"models/model-properties/#93-optimize_query","title":"9.3 <code>optimize_query</code>","text":"<p>Type: <code>boolean</code> Required: No Default: <code>true</code></p> <p>Whether to optimize the model's query using SQLGlot.</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.complex_query,\n  optimize_query false  -- Disable optimization\n);\n</code></pre></p> <p>What Optimization Does:</p> <p>SQLGlot optimization includes: - Query canonicalization - Expression simplification - Constant folding - Redundant operation removal</p> <p>When to Disable:</p> <p>1. Optimization Causes Errors:</p> <pre><code>MODEL (\n  name analytics.problematic_query,\n  optimize_query false  -- Disable if optimizer breaks query\n);\n</code></pre> <p>2. Text Limit Issues:</p> <pre><code>MODEL (\n  name analytics.large_query,\n  optimize_query false  -- If optimized query exceeds text limit\n);\n</code></pre> <p>\u26a0\ufe0f Warning:</p> <p>Disabling optimization may prevent: - Column-level lineage from working - Automatic <code>SELECT *</code> expansion - Query simplification benefits</p> <p>Recommendation: Keep enabled unless you encounter issues.</p>"},{"location":"models/model-properties/#94-ignored_rules","title":"9.4 <code>ignored_rules</code>","text":"<p>Type: <code>string</code> or <code>array[string]</code> Required: No Default: None</p> <p>Linter rules to ignore for this model.</p> <p>Syntax: <pre><code>-- Ignore specific rule\nMODEL (\n  name analytics.legacy_model,\n  ignored_rules 'noselectstar'  -- Allow SELECT *\n);\n\n-- Ignore multiple rules\nMODEL (\n  name analytics.complex_model,\n  ignored_rules ('noselectstar', 'noqualify')  -- Ignore multiple\n);\n\n-- Ignore all rules\nMODEL (\n  name analytics.experimental_model,\n  ignored_rules 'ALL'  -- Ignore all linter rules\n);\n</code></pre></p> <p>Common Rules:</p> <ul> <li><code>noselectstar</code> - Allow <code>SELECT *</code></li> <li><code>noqualify</code> - Allow unqualified columns</li> <li><code>nodistinct</code> - Allow <code>SELECT DISTINCT</code></li> <li>And more...</li> </ul> <p>Use Cases:</p> <p>1. Legacy Code:</p> <pre><code>MODEL (\n  name analytics.legacy_table,\n  ignored_rules 'noselectstar'  -- Legacy code uses SELECT *\n);\n</code></pre> <p>2. Complex Queries:</p> <pre><code>MODEL (\n  name analytics.complex_aggregation,\n  ignored_rules ('noselectstar', 'noqualify')  -- Complex query needs flexibility\n);\n</code></pre> <p>3. Experimental Models:</p> <pre><code>MODEL (\n  name analytics.experimental,\n  ignored_rules 'ALL'  -- Disable all checks during development\n);\n</code></pre> <p>\u26a0\ufe0f Note: Use sparingly. Linter rules catch real issues.</p>"},{"location":"models/model-properties/#95-formatting","title":"9.5 <code>formatting</code>","text":"<p>Type: <code>boolean</code> Required: No Default: <code>true</code></p> <p>Whether to format this model with <code>vulcan format</code>.</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.custom_format_model,\n  formatting false  -- Don't auto-format\n);\n</code></pre></p> <p>Use Cases:</p> <p>1. Preserve Custom Formatting:</p> <pre><code>MODEL (\n  name analytics.specially_formatted,\n  formatting false  -- Keep custom formatting\n);\n</code></pre> <p>2. Generated Code:</p> <pre><code>MODEL (\n  name analytics.generated_query,\n  formatting false  -- Don't reformat generated SQL\n);\n</code></pre> <p>Recommendation: Keep enabled for consistency. Only disable if you have specific formatting requirements.</p>"},{"location":"models/model-properties/#96-physical_version","title":"9.6 <code>physical_version</code>","text":"<p>Type: <code>string</code> Required: No Default: None</p> <p>Pin the physical table version (forward-only models only).</p> <p>Syntax: <pre><code>MODEL (\n  name analytics.large_table,\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column event_date,\n    forward_only true\n  ),\n  physical_version 'abc123'  -- Pin to specific version\n);\n</code></pre></p> <p>Use Cases:</p> <ul> <li>Lock table structure</li> <li>Prevent accidental changes</li> <li>Version control for physical tables</li> </ul> <p>\u26a0\ufe0f Note: Only available for forward-only models. Use with caution.</p> <p>\u2191 Back to Top</p>"},{"location":"models/model-properties/#10-prepost-statements","title":"10. Pre/Post Statements","text":"<p>These properties allow executing SQL statements before and after model execution.</p>"},{"location":"models/model-properties/#101-pre_statements","title":"10.1 <code>pre_statements</code>","text":"<p>Type: <code>array[string]</code> (SQL statements) Required: No Default: Project defaults (merged)</p> <p>SQL statements executed before the model query runs.</p> <p>Syntax (SQL Models):</p> <pre><code>MODEL (\n  name analytics.customers,\n  kind FULL\n);\n\n-- Pre-statements (before query)\nSET timezone = 'UTC';\nCACHE TABLE countries AS SELECT * FROM raw.countries;\n\n-- Model query\nSELECT\n  customer_id,\n  customer_name,\n  country\nFROM raw.customers\nJOIN countries ON ...\n</code></pre> <p>Syntax (Python Models):</p> <pre><code>@model(\n    \"analytics.customers\",\n    pre_statements=[\n        \"SET timezone = 'UTC'\",\n        \"CACHE TABLE countries AS SELECT * FROM raw.countries\"\n    ]\n)\ndef execute(context, ...):\n    # ...\n</code></pre> <p>Common Use Cases:</p> <p>1. Session Configuration:</p> <pre><code>MODEL (\n  name analytics.events,\n  kind FULL\n);\n\nSET timezone = 'UTC';\nSET query_timeout = 3600;\n\nSELECT * FROM raw.events;\n</code></pre> <p>2. Cache Temporary Tables:</p> <pre><code>MODEL (\n  name analytics.customers,\n  kind FULL\n);\n\nCACHE TABLE countries AS SELECT * FROM raw.countries;\nCACHE TABLE regions AS SELECT * FROM raw.regions;\n\nSELECT\n  c.*,\n  co.country,\n  r.region\nFROM raw.customers c\nJOIN countries co ON ...\nJOIN regions r ON ...\n</code></pre> <p>3. Load UDFs:</p> <pre><code>MODEL (\n  name analytics.ml_predictions,\n  kind FULL\n);\n\nADD JAR s3://special_udf.jar;\nCREATE TEMPORARY FUNCTION predict_churn AS 'com.example.ChurnPredictor';\n\nSELECT\n  customer_id,\n  predict_churn(features) as churn_probability\nFROM analytics.customer_features;\n</code></pre> <p>\u26a0\ufe0f Important:</p> <p>Pre-statements run TWICE: 1. When table is created 2. When query is evaluated</p> <p>Conditional Execution:</p> <p>Use <code>@runtime_stage</code> to conditionally execute:</p> <pre><code>MODEL (\n  name analytics.customers,\n  kind FULL\n);\n\n-- Only cache when creating table\n@IF(@runtime_stage = 'creating', CACHE TABLE countries AS SELECT * FROM raw.countries);\n\nSELECT * FROM raw.customers;\n</code></pre> <p>Runtime Stages:</p> <ul> <li><code>creating</code> - Table creation time</li> <li><code>evaluating</code> - Query evaluation time</li> </ul> <p>\u26a0\ufe0f Warning:</p> <p>Don't create physical tables in pre-statements:</p> <pre><code>-- \u274c BAD - Can conflict with concurrent model execution\nCREATE TABLE temp_data AS SELECT * FROM ...;\n\n-- \u2705 GOOD - Use CACHE or temporary objects\nCACHE TABLE temp_data AS SELECT * FROM ...;\n</code></pre> <p>Project-Level Defaults:</p> <p>Set defaults in <code>config.yaml</code>:</p> <pre><code>model_defaults:\n  pre_statements:\n    - \"SET timezone = 'UTC'\"\n    - \"SET query_timeout = 3600\"\n</code></pre> <p>Model-specific statements are merged (defaults first, then model-specific).</p>"},{"location":"models/model-properties/#102-post_statements","title":"10.2 <code>post_statements</code>","text":"<p>Type: <code>array[string]</code> (SQL statements) Required: No Default: Project defaults (merged)</p> <p>SQL statements executed after the model query completes.</p> <p>Syntax (SQL Models):</p> <pre><code>MODEL (\n  name analytics.customers,\n  kind FULL\n);\n\n-- Model query (must end with semicolon if post-statements exist)\nSELECT * FROM raw.customers;\n\n-- Post-statements (after query)\nUNCACHE TABLE countries;\nANALYZE TABLE analytics.customers;\n</code></pre> <p>Syntax (Python Models):</p> <pre><code>@model(\n    \"analytics.customers\",\n    post_statements=[\n        \"ANALYZE TABLE analytics.customers\",\n        \"@CREATE_INDEX(@this_model, customer_id)\"\n    ]\n)\ndef execute(context, ...):\n    # Must use yield (not return) for post-statements\n    yield df\n\n    # Post-statements execute after yield\n</code></pre> <p>Common Use Cases:</p> <p>1. Table Maintenance:</p> <pre><code>MODEL (\n  name analytics.customers,\n  kind FULL\n);\n\nSELECT * FROM raw.customers;\n\n-- Post-statements\nANALYZE TABLE analytics.customers;\nVACUUM TABLE analytics.customers;\n</code></pre> <p>2. Cleanup:</p> <pre><code>MODEL (\n  name analytics.customers,\n  kind FULL\n);\n\nCACHE TABLE countries AS SELECT * FROM raw.countries;\n\nSELECT * FROM raw.customers JOIN countries ...;\n\n-- Cleanup cached tables\nUNCACHE TABLE countries;\n</code></pre> <p>3. Create Indexes:</p> <pre><code>MODEL (\n  name analytics.orders,\n  kind FULL\n);\n\nSELECT * FROM raw.orders;\n\n-- Create indexes after table is populated\n@IF(@runtime_stage = 'evaluating',\n  CREATE INDEX idx_customer_id ON analytics.orders(customer_id);\n  CREATE INDEX idx_order_date ON analytics.orders(order_date);\n);\n</code></pre> <p>Conditional Execution:</p> <p>Always condition post-statements on <code>@runtime_stage</code>:</p> <pre><code>MODEL (\n  name analytics.customers,\n  kind FULL\n);\n\nSELECT * FROM raw.customers;\n\n-- Only run after query evaluation\n@IF(@runtime_stage = 'evaluating',\n  ANALYZE TABLE analytics.customers\n);\n</code></pre> <p>Why? Post-statements run twice (table creation + evaluation). Condition on <code>evaluating</code> to run only after query.</p> <p>Project-Level Defaults:</p> <pre><code>model_defaults:\n  post_statements:\n    - \"@IF(@runtime_stage = 'evaluating', ANALYZE @this_model)\"\n</code></pre>"},{"location":"models/model-properties/#103-on_virtual_update","title":"10.3 <code>on_virtual_update</code>","text":"<p>Type: <code>array[string]</code> (SQL statements) Required: No Default: Project defaults (merged)</p> <p>SQL statements executed after virtual update completes (when views are swapped in dev environments).</p> <p>Syntax (SQL Models):</p> <pre><code>MODEL (\n  name analytics.customers,\n  kind FULL\n);\n\nSELECT * FROM raw.customers;\n\nON_VIRTUAL_UPDATE_BEGIN;\nGRANT SELECT ON VIEW @this_model TO ROLE analyst_role;\nGRANT SELECT ON VIEW @this_model TO ROLE admin_role;\nON_VIRTUAL_UPDATE_END;\n</code></pre> <p>Syntax (Python Models):</p> <pre><code>@model(\n    \"analytics.customers\",\n    on_virtual_update=[\n        \"GRANT SELECT ON VIEW @this_model TO ROLE analyst_role\"\n    ]\n)\ndef execute(context, ...):\n    # ...\n</code></pre> <p>What Is Virtual Update?</p> <p>Virtual update is when Vulcan swaps view references (in dev environments) without recomputing data. <code>on_virtual_update</code> statements run after this swap.</p> <p>Use Cases:</p> <p>1. Grant Permissions:</p> <pre><code>MODEL (\n  name analytics.customers,\n  kind FULL\n);\n\nSELECT * FROM raw.customers;\n\nON_VIRTUAL_UPDATE_BEGIN;\nGRANT SELECT ON VIEW @this_model TO ROLE analyst_role;\nGRANT SELECT ON VIEW @this_model TO ROLE readonly_role;\nON_VIRTUAL_UPDATE_END;\n</code></pre> <p>2. Set View Properties:</p> <pre><code>MODEL (\n  name analytics.sensitive_data,\n  kind FULL\n);\n\nSELECT * FROM raw.customers;\n\nON_VIRTUAL_UPDATE_BEGIN;\nALTER VIEW @this_model SET COMMENT = 'Customer data - PII';\nON_VIRTUAL_UPDATE_END;\n</code></pre> <p>3. With Jinja Macros:</p> <pre><code>MODEL (\n  name analytics.customers,\n  kind FULL\n);\n\nSELECT * FROM raw.customers;\n\nON_VIRTUAL_UPDATE_BEGIN;\nGRANT SELECT ON VIEW @this_model TO ROLE analyst_role;\nJINJA_STATEMENT_BEGIN;\nGRANT SELECT ON VIEW {{ this_model }} TO ROLE admin;\nJINJA_END;\nON_VIRTUAL_UPDATE_END;\n</code></pre> <p>\u26a0\ufe0f Important:</p> <ul> <li>Table resolution occurs at virtual layer</li> <li><code>@this_model</code> resolves to view name (e.g., <code>db__dev.customers</code>)</li> <li>Not physical table name</li> </ul> <p>Project-Level Defaults:</p> <pre><code>model_defaults:\n  on_virtual_update:\n    - \"GRANT SELECT ON @this_model TO ROLE analyst_role\"\n</code></pre> <p>\u2191 Back to Top</p>"},{"location":"models/model-properties/#11-property-quick-reference","title":"11. Property Quick Reference","text":""},{"location":"models/model-properties/#111-all-properties-by-category","title":"11.1 All Properties by Category","text":""},{"location":"models/model-properties/#required-properties","title":"Required Properties","text":"Property Type Required Default Description <code>name</code> string Yes* None Fully qualified model name <code>kind</code> string/dict Yes <code>VIEW</code> (SQL) / <code>FULL</code> (Python) Model kind <p>*Required unless <code>infer_names</code> is enabled</p>"},{"location":"models/model-properties/#scheduling-temporal","title":"Scheduling &amp; Temporal","text":"Property Type Required Default Description <code>cron</code> string No <code>@daily</code> Schedule expression <code>cron_tz</code> string No <code>UTC</code> Cron timezone <code>interval_unit</code> string No Inferred Temporal granularity <code>start</code> string/int No <code>yesterday</code> Historical start <code>end</code> string/int No None Stop processing date <code>allow_partials</code> boolean No <code>false</code> Process incomplete intervals"},{"location":"models/model-properties/#incremental-model-properties","title":"Incremental Model Properties","text":"Property Type Required Default Applies To <code>time_column</code> string Yes* None INCREMENTAL_BY_TIME_RANGE <code>unique_key</code> string/array Yes* None INCREMENTAL_BY_UNIQUE_KEY, SCD_TYPE_2 <code>lookback</code> integer No <code>0</code> INCREMENTAL_BY_TIME_RANGE, INCREMENTAL_BY_UNIQUE_KEY <code>batch_size</code> integer No None INCREMENTAL_BY_TIME_RANGE, INCREMENTAL_BY_UNIQUE_KEY <code>batch_concurrency</code> integer No Connection setting INCREMENTAL_BY_TIME_RANGE <code>forward_only</code> boolean No <code>false</code> All incremental <code>on_destructive_change</code> string No <code>error</code> All incremental <code>on_additive_change</code> string No <code>allow</code> All incremental <code>disable_restatement</code> boolean No <code>false</code> All incremental <code>when_matched</code> string No Update all INCREMENTAL_BY_UNIQUE_KEY <code>merge_filter</code> string No None INCREMENTAL_BY_UNIQUE_KEY <code>auto_restatement_cron</code> string No None All incremental <code>auto_restatement_intervals</code> integer No None INCREMENTAL_BY_TIME_RANGE <p>*Required for specific model kinds</p>"},{"location":"models/model-properties/#data-quality","title":"Data Quality","text":"Property Type Required Default Description <code>grain</code> string/array No None Primary key column(s) <code>grains</code> array No None Multiple primary keys <code>references</code> string/array No None Foreign key column(s) <code>assertions</code> array No None Data quality audits <code>depends_on</code> array[string] No Inferred Explicit dependencies"},{"location":"models/model-properties/#metadata","title":"Metadata","text":"Property Type Required Default Description <code>description</code> string No None Model description <code>column_descriptions</code> dict No None Column descriptions <code>owner</code> string No Project default Model owner <code>tags</code> array[string] No None Organization tags <code>project</code> string No None Project name <code>stamp</code> string No None Version stamp"},{"location":"models/model-properties/#schema-type","title":"Schema &amp; Type","text":"Property Type Required Default Description <code>columns</code> array[string] No* Inferred Column definitions <code>dialect</code> string No Project default SQL dialect <p>*Required for Python models</p>"},{"location":"models/model-properties/#warehouse-specific","title":"Warehouse-Specific","text":"Property Type Required Default Description <code>partitioned_by</code> string/array No None Partition columns <code>clustered_by</code> string/array No None Cluster columns <code>table_format</code> string No Engine default Table format <code>storage_format</code> string No Engine default Storage format <code>physical_properties</code> dict No Merged Physical table properties <code>virtual_properties</code> dict No Merged Virtual view properties <code>session_properties</code> dict No Merged Session properties"},{"location":"models/model-properties/#execution-control","title":"Execution Control","text":"Property Type Required Default Description <code>enabled</code> boolean No <code>true</code> Enable/disable model <code>gateway</code> string No Default Execution gateway <code>optimize_query</code> boolean No <code>true</code> Enable query optimization <code>ignored_rules</code> string/array No None Linter rules to ignore <code>formatting</code> boolean No <code>true</code> Enable formatting <code>physical_version</code> string No None Pin table version"},{"location":"models/model-properties/#statements","title":"Statements","text":"Property Type Required Default Description <code>pre_statements</code> array[string] No Merged SQL before query <code>post_statements</code> array[string] No Merged SQL after query <code>on_virtual_update</code> array[string] No Merged SQL after virtual update"},{"location":"models/model-properties/#112-properties-by-model-kind","title":"11.2 Properties by Model Kind","text":""},{"location":"models/model-properties/#view-models","title":"VIEW Models","text":"<p>Supported Properties: - All general properties - <code>materialized</code> (kind-specific)</p>"},{"location":"models/model-properties/#full-models","title":"FULL Models","text":"<p>Supported Properties: - All general properties - No kind-specific properties</p>"},{"location":"models/model-properties/#incremental_by_time_range","title":"INCREMENTAL_BY_TIME_RANGE","text":"<p>Supported Properties: - All general properties - All incremental properties - <code>time_column</code> (required) - <code>lookback</code>, <code>batch_size</code>, <code>batch_concurrency</code> - <code>auto_restatement_intervals</code></p>"},{"location":"models/model-properties/#incremental_by_unique_key","title":"INCREMENTAL_BY_UNIQUE_KEY","text":"<p>Supported Properties: - All general properties - All incremental properties - <code>unique_key</code> (required) - <code>when_matched</code>, <code>merge_filter</code> - <code>lookback</code>, <code>batch_size</code> - No <code>batch_concurrency</code> (can't run in parallel)</p>"},{"location":"models/model-properties/#incremental_by_partition","title":"INCREMENTAL_BY_PARTITION","text":"<p>Supported Properties: - All general properties - All incremental properties - <code>partitioned_by</code> (required)</p>"},{"location":"models/model-properties/#scd_type_2","title":"SCD_TYPE_2","text":"<p>Supported Properties: - All general properties - All incremental properties - <code>unique_key</code> (required, array) - <code>valid_from_name</code>, <code>valid_to_name</code> - <code>invalidate_hard_deletes</code> - Plus BY_TIME or BY_COLUMN specific properties</p>"},{"location":"models/model-properties/#seed-models","title":"SEED Models","text":"<p>Supported Properties: - <code>name</code>, <code>kind</code> (must be SEED) - <code>columns</code>, <code>audits</code>, <code>owner</code>, <code>stamp</code>, <code>tags</code>, <code>description</code> - <code>path</code> (required, in kind) - <code>batch_size</code>, <code>csv_settings</code> (in kind)</p>"},{"location":"models/model-properties/#external-models","title":"EXTERNAL Models","text":"<p>Supported Properties: - Defined in YAML, not MODEL DDL - See Chapter 2: Models</p>"},{"location":"models/model-properties/#embedded-models","title":"EMBEDDED Models","text":"<p>Supported Properties: - All general properties (except materialization-related)</p>"},{"location":"models/model-properties/#managed-models","title":"MANAGED Models","text":"<p>Supported Properties: - All general properties - <code>physical_properties</code> (for engine-specific config)</p>"},{"location":"models/model-properties/#113-property-defaults-summary","title":"11.3 Property Defaults Summary","text":"Property Default Value <code>kind</code> <code>VIEW</code> (SQL) / <code>FULL</code> (Python) <code>cron</code> <code>@daily</code> <code>start</code> <code>yesterday</code> <code>enabled</code> <code>true</code> <code>optimize_query</code> <code>true</code> <code>formatting</code> <code>true</code> <code>allow_partials</code> <code>false</code> <code>forward_only</code> <code>false</code> <code>disable_restatement</code> <code>false</code> <code>on_destructive_change</code> <code>error</code> <code>on_additive_change</code> <code>allow</code> <code>lookback</code> <code>0</code> <code>invalidate_hard_deletes</code> <code>true</code> (SCD Type 2) <code>updated_at_as_valid_from</code> <code>false</code> (SCD Type 2 BY_TIME) <code>execution_time_as_valid_from</code> <code>false</code> (SCD Type 2 BY_COLUMN) <p>\u2191 Back to Top</p>"},{"location":"models/model-properties/#12-examples-by-use-case","title":"12. Examples by Use Case","text":""},{"location":"models/model-properties/#121-daily-incremental-model","title":"12.1 Daily Incremental Model","text":"<p>Use Case: Process daily time-series data with late-arriving data handling.</p> <pre><code>MODEL (\n  name analytics.daily_revenue,\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column revenue_date,\n    lookback 7,              -- Reprocess last 7 days\n    batch_size 30            -- Process 30 days per batch\n  ),\n  cron '@daily',\n  interval_unit 'day',\n  start '2020-01-01',\n  grain (customer_id, revenue_date),\n  references (customer_id),\n  owner 'analytics-team',\n  tags ('analytics', 'revenue', 'critical'),\n  description 'Daily revenue aggregated by customer',\n  column_descriptions (\n    customer_id = 'Foreign key to customers table',\n    revenue_date = 'Date of revenue (YYYY-MM-DD)',\n    revenue = 'Total revenue in USD from completed orders',\n    order_count = 'Number of completed orders'\n  ),\n  assertions (\n    not_null(columns := (customer_id, revenue_date, revenue)),\n    unique_combination_of_columns(columns := (customer_id, revenue_date)),\n    accepted_range(column := revenue, min_v := 0, max_v := 10000000)\n  ),\n  partitioned_by revenue_date,\n  clustered_by (customer_id)\n);\n\nSELECT\n  customer_id::INT,\n  order_date::DATE as revenue_date,\n  SUM(amount)::DECIMAL(10,2) as revenue,\n  COUNT(*)::INT as order_count\nFROM staging.orders\nWHERE order_date BETWEEN @start_ds AND @end_ds\n  AND status = 'completed'\nGROUP BY customer_id, order_date;\n</code></pre>"},{"location":"models/model-properties/#122-upsert-based-incremental-model","title":"12.2 Upsert-Based Incremental Model","text":"<p>Use Case: Slowly changing dimension table with upsert logic.</p> <pre><code>MODEL (\n  name analytics.customers,\n  kind INCREMENTAL_BY_UNIQUE_KEY (\n    unique_key customer_id,\n    when_matched 'UPDATE SET \n      name = source.name,\n      email = source.email,\n      updated_at = source.updated_at\n      WHERE target.updated_at &lt; source.updated_at',\n    merge_filter 'source.status != ''deleted'''\n  ),\n  cron '@daily',\n  grain customer_id,\n  owner 'data-team',\n  tags ('dimension', 'customer'),\n  description 'Customer dimension table with upsert logic',\n  assertions (\n    not_null(columns := (customer_id, name, email)),\n    unique_values(columns := (customer_id)),\n    valid_email(column := email)\n  )\n);\n\nSELECT\n  customer_id::INT,\n  customer_name::VARCHAR(255),\n  email::VARCHAR(255),\n  customer_tier::VARCHAR(50),\n  updated_at::TIMESTAMP\nFROM raw.customers\nWHERE updated_at &gt;= @start_ds;\n</code></pre>"},{"location":"models/model-properties/#123-scd-type-2-historical-tracking","title":"12.3 SCD Type 2 Historical Tracking","text":"<p>Use Case: Track historical changes to customer data.</p> <pre><code>MODEL (\n  name analytics.customer_history,\n  kind SCD_TYPE_2_BY_TIME (\n    unique_key (customer_id),\n    updated_at_name 'last_modified',\n    updated_at_as_valid_from true,\n    invalidate_hard_deletes true\n  ),\n  cron '@daily',\n  grain (customer_id, valid_from),\n  owner 'data-team',\n  tags ('scd', 'history', 'customer'),\n  description 'Historical customer data with SCD Type 2 tracking',\n  assertions (\n    not_null(columns := (customer_id, valid_from)),\n    unique_combination_of_columns(columns := (customer_id, valid_from))\n  )\n);\n\nSELECT\n  customer_id::INT,\n  customer_name::VARCHAR(255),\n  email::VARCHAR(255),\n  tier::VARCHAR(50),\n  last_modified::TIMESTAMP as updated_at\nFROM raw.customers\nWHERE last_modified &gt;= @start_ds;\n</code></pre>"},{"location":"models/model-properties/#124-python-ml-model","title":"12.4 Python ML Model","text":"<p>Use Case: Machine learning predictions using Python.</p> <pre><code>from vulcan import ExecutionContext, model\nimport pandas as pd\nimport typing as t\nfrom datetime import datetime\n\n@model(\n    \"analytics.customer_predictions\",\n    kind=\"FULL\",\n    cron=\"@daily\",\n    columns={\n        \"customer_id\": \"INT\",\n        \"churn_probability\": \"FLOAT\",\n        \"predicted_ltv\": \"DECIMAL(10,2)\",\n        \"prediction_date\": \"DATE\",\n    },\n    column_descriptions={\n        \"churn_probability\": \"Probability customer will churn in next 30 days (0-1)\",\n        \"predicted_ltv\": \"Predicted lifetime value in USD\",\n    },\n    owner=\"ml-team\",\n    tags=[\"ml\", \"predictions\", \"customer\"],\n    assertions=[\n        (\"not_null\", {\"columns\": [\"customer_id\"]}),\n        (\"accepted_range\", {\"column\": \"churn_probability\", \"min_v\": 0, \"max_v\": 1}),\n    ]\n)\ndef execute(\n    context: ExecutionContext,\n    start: datetime,\n    end: datetime,\n    execution_time: datetime,\n    **kwargs: t.Any,\n) -&gt; pd.DataFrame:\n    \"\"\"Generate customer churn predictions using ML model.\"\"\"\n\n    # Fetch data\n    customers = context.fetchdf(\"\"\"\n        SELECT \n            customer_id,\n            tenure_days,\n            total_spent,\n            engagement_score\n        FROM analytics.customers\n        WHERE status = 'active'\n    \"\"\")\n\n    # Load ML model\n    import joblib\n    model = joblib.load(\"models/churn_model.pkl\")\n\n    # Make predictions\n    features = customers[['tenure_days', 'total_spent', 'engagement_score']]\n    customers['churn_probability'] = model.predict_proba(features)[:, 1]\n    customers['predicted_ltv'] = customers['total_spent'] * (1 - customers['churn_probability']) * 2\n    customers['prediction_date'] = execution_time.date()\n\n    return customers[['customer_id', 'churn_probability', 'predicted_ltv', 'prediction_date']]\n</code></pre>"},{"location":"models/model-properties/#125-seed-model","title":"12.5 Seed Model","text":"<p>Use Case: Load static reference data from CSV.</p> <pre><code>MODEL (\n  name analytics.national_holidays,\n  kind SEED (\n    path 'national_holidays.csv',\n    batch_size 1000\n  ),\n  columns (\n    holiday_name VARCHAR(255),\n    holiday_date DATE\n  ),\n  owner 'data-team',\n  tags ('reference', 'static'),\n  description 'National holidays reference data',\n  assertions (\n    not_null(columns := (holiday_name, holiday_date)),\n    unique_values(columns := (holiday_date))\n  )\n);\n</code></pre>"},{"location":"models/model-properties/#126-multi-warehouse-model","title":"12.6 Multi-Warehouse Model","text":"<p>Use Case: Model that runs on different engines.</p> <pre><code>MODEL (\n  name analytics.events,\n  gateway 'snowflake',  -- Use Snowflake gateway\n  dialect snowflake,\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column event_date\n  ),\n  cron '@hourly',\n  physical_properties (\n    warehouse = 'COMPUTE_WH',\n    creatable_type = TRANSIENT\n  )\n);\n\nSELECT * FROM raw.events\nWHERE event_date BETWEEN @start_ds AND @end_ds;\n</code></pre>"},{"location":"models/model-properties/#127-forward-only-large-table","title":"12.7 Forward-Only Large Table","text":"<p>Use Case: Very large table where rebuilds are expensive.</p> <pre><code>MODEL (\n  name analytics.large_event_table,\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column event_date,\n    forward_only true,              -- No rebuilds\n    on_destructive_change 'error',  -- Block breaking changes\n    on_additive_change 'allow',     -- Allow new columns\n    batch_size 7,                   -- Process 7 days per batch\n    batch_concurrency 5             -- 5 batches in parallel\n  ),\n  cron '@daily',\n  start '2020-01-01',\n  partitioned_by event_date,\n  clustered_by (customer_id, event_type),\n  physical_properties (\n    partition_expiration_days = 365,\n    require_partition_filter = true\n  )\n);\n\nSELECT * FROM raw.events\nWHERE event_date BETWEEN @start_ds AND @end_ds;\n</code></pre>"},{"location":"models/model-properties/#128-model-with-prepost-statements","title":"12.8 Model with Pre/Post Statements","text":"<p>Use Case: Model requiring setup and cleanup.</p> <pre><code>MODEL (\n  name analytics.customers,\n  kind FULL,\n  owner 'data-team'\n);\n\n-- Pre-statements\nSET timezone = 'UTC';\nCACHE TABLE countries AS SELECT * FROM raw.countries;\n\n-- Model query\nSELECT\n  c.customer_id,\n  c.customer_name,\n  co.country\nFROM raw.customers c\nJOIN countries co ON c.country_id = co.country_id;\n\n-- Post-statements (conditional)\n@IF(@runtime_stage = 'evaluating',\n  ANALYZE TABLE analytics.customers;\n  UNCACHE TABLE countries;\n);\n</code></pre>"},{"location":"models/model-properties/#129-model-with-virtual-update-grants","title":"12.9 Model with Virtual Update Grants","text":"<p>Use Case: Model requiring permission grants in dev environments.</p> <pre><code>MODEL (\n  name analytics.sensitive_customers,\n  kind FULL,\n  owner 'data-team',\n  tags ('pii', 'sensitive')\n);\n\nSELECT * FROM raw.customers WHERE has_pii = true;\n\nON_VIRTUAL_UPDATE_BEGIN;\nGRANT SELECT ON VIEW @this_model TO ROLE analyst_role;\nGRANT SELECT ON VIEW @this_model TO ROLE readonly_role;\nON_VIRTUAL_UPDATE_END;\n</code></pre>"},{"location":"models/model-properties/#1210-complete-production-model","title":"12.10 Complete Production Model","text":"<p>Use Case: Production-ready model with all best practices.</p> <pre><code>MODEL (\n  name analytics.daily_customer_metrics,\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column metric_date,\n    lookback 3,\n    batch_size 30,\n    batch_concurrency 3\n  ),\n  cron '@daily',\n  cron_tz 'America/Los_Angeles',\n  interval_unit 'day',\n  start '2020-01-01',\n  grain (customer_id, metric_date),\n  references (customer_id),\n  owner 'analytics-team',\n  tags ('analytics', 'customer', 'metrics', 'critical', 'p0'),\n  description 'Daily customer metrics including revenue, orders, and engagement. Used for customer analytics dashboards.',\n  column_descriptions (\n    customer_id = 'Foreign key to customers table (INT)',\n    metric_date = 'Date of metrics (YYYY-MM-DD)',\n    revenue = 'Total revenue in USD from completed orders',\n    order_count = 'Number of completed orders',\n    engagement_score = 'Customer engagement score (0-100)',\n    churn_risk = 'Churn risk score from ML model (0-1)'\n  ),\n  assertions (\n    not_null(columns := (customer_id, metric_date, revenue)),\n    unique_combination_of_columns(columns := (customer_id, metric_date)),\n    accepted_range(column := revenue, min_v := 0, max_v := 10000000),\n    accepted_range(column := engagement_score, min_v := 0, max_v := 100),\n    accepted_range(column := churn_risk, min_v := 0, max_v := 1)\n  ),\n  partitioned_by metric_date,\n  clustered_by (customer_id),\n  physical_properties (\n    partition_expiration_days = 365,\n    require_partition_filter = true,\n    creatable_type = TRANSIENT\n  ),\n  optimize_query true,\n  formatting true\n);\n\nSELECT\n  customer_id::INT,\n  order_date::DATE as metric_date,\n  SUM(amount)::DECIMAL(10,2) as revenue,\n  COUNT(*)::INT as order_count,\n  AVG(engagement_score)::DECIMAL(5,2) as engagement_score,\n  AVG(churn_probability)::DECIMAL(3,2) as churn_risk\nFROM staging.orders o\nJOIN analytics.customer_features cf ON o.customer_id = cf.customer_id\nWHERE order_date BETWEEN @start_ds AND @end_ds\n  AND status = 'completed'\nGROUP BY customer_id, order_date;\n</code></pre> <p>\u2191 Back to Top</p>"},{"location":"models/model-properties/#summary","title":"Summary","text":"<p>You've learned about all MODEL DDL properties in Vulcan:</p>"},{"location":"models/model-properties/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>Property Categories:</li> <li>Required: <code>name</code>, <code>kind</code></li> <li>Scheduling: <code>cron</code>, <code>start</code>, <code>end</code>, <code>interval_unit</code></li> <li>Incremental: <code>time_column</code>, <code>lookback</code>, <code>batch_size</code></li> <li>Data Quality: <code>grain</code>, <code>references</code>, <code>assertions</code></li> <li>Metadata: <code>description</code>, <code>owner</code>, <code>tags</code></li> <li>Warehouse: <code>partitioned_by</code>, <code>physical_properties</code></li> <li>Execution: <code>enabled</code>, <code>gateway</code>, <code>optimize_query</code></li> <li> <p>Statements: <code>pre_statements</code>, <code>post_statements</code></p> </li> <li> <p>Property Inheritance:</p> </li> <li>Project defaults \u2192 Model-specific overrides</li> <li><code>physical_properties</code>, <code>virtual_properties</code>, <code>session_properties</code> are merged</li> <li> <p>Set to <code>None</code> to unset project-level properties</p> </li> <li> <p>Model Kind Specifics:</p> </li> <li>Each model kind supports different properties</li> <li>Incremental models have additional properties in <code>kind</code> definition</li> <li> <p>SEED models have limited property support</p> </li> <li> <p>Best Practices:</p> </li> <li>Start with defaults, override only when needed</li> <li>Use <code>grain</code> and <code>assertions</code> together</li> <li>Condition <code>post_statements</code> on <code>@runtime_stage</code></li> <li>Document with <code>description</code> and <code>column_descriptions</code></li> </ol>"},{"location":"models/model-properties/#related-topics","title":"Related Topics","text":"<ul> <li>Chapter 2: Models - Model basics and kinds</li> <li>Chapter 4: Audits - Comprehensive audit reference</li> <li>Chapter 2C: Model Operations - Advanced patterns using properties</li> </ul>"},{"location":"models/model-properties/#next-steps","title":"Next Steps","text":"<ol> <li>Review your existing models and add missing properties</li> <li>Set project defaults in <code>config.yaml</code></li> <li>Add <code>grain</code> and <code>assertions</code> to critical models</li> <li>Document models with <code>description</code> and <code>column_descriptions</code></li> </ol> <p>Congratulations! You've completed the Model Properties reference chapter.</p> <p>\u2191 Back to Top</p>"},{"location":"models/model-testing/","title":"Chapter 2B: Model Testing","text":"<p>Comprehensive guide to unit testing Vulcan models - Validate model logic with predefined inputs and expected outputs, catch regressions before deployment, and ensure data quality.</p>"},{"location":"models/model-testing/#prerequisites","title":"Prerequisites","text":"<p>Before diving into this chapter, you should have:</p>"},{"location":"models/model-testing/#required-knowledge","title":"Required Knowledge","text":"<p>Chapter 2: Models - Understanding of: - Basic MODEL DDL syntax - Model query structure - Model dependencies</p> <p>YAML Syntax - Basic YAML structure (dictionaries, lists) - Key-value pairs - Multi-line strings</p> <p>SQL Proficiency - SELECT statements - CTEs (Common Table Expressions) - Basic aggregations</p>"},{"location":"models/model-testing/#optional-but-helpful","title":"Optional but Helpful","text":"<p>Software Testing Concepts - Unit testing basics - Test-driven development (TDD) - Test fixtures</p>"},{"location":"models/model-testing/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Introduction</li> <li>Test Structure</li> <li>Input Data Formats</li> <li>Output Validation</li> <li>Testing Patterns</li> <li>Testing Incremental Models</li> <li>Testing Python Models</li> <li>Automatic Test Generation</li> <li>Running Tests</li> <li>Advanced Patterns</li> <li>Troubleshooting</li> <li>Best Practices</li> <li>Quick Reference</li> </ol>"},{"location":"models/model-testing/#1-introduction","title":"1. Introduction","text":""},{"location":"models/model-testing/#11-what-are-unit-tests","title":"1.1 What Are Unit Tests?","text":"<p>Unit tests validate model logic by comparing actual outputs against expected outputs for given inputs.</p> <p>Key characteristics: - Predefined inputs - You specify test data - Expected outputs - You define what should happen - Automatic validation - Vulcan compares actual vs expected - Fast execution - Run in-memory (DuckDB by default) - Isolated - Don't require production data</p>"},{"location":"models/model-testing/#12-tests-vs-audits-vs-checks","title":"1.2 Tests vs Audits vs Checks","text":"<p>Understanding the three validation mechanisms:</p> Feature Tests Audits Checks Purpose Validate logic Block bad data Monitor trends When runs Before deployment After execution Scheduled separately Configuration YAML files (<code>tests/</code>) MODEL assertions YAML files (<code>checks/</code>) Input Predefined fixtures Model output Model output Output Pass/fail Pass/fail (blocks) Pass/fail + history Best for Logic validation Data quality gates Trend monitoring <p>Use tests for: Logic validation before deployment Use audits for: Blocking invalid data (see Chapter 4) Use checks for: Monitoring over time (see Chapter 5)</p>"},{"location":"models/model-testing/#13-why-write-tests","title":"1.3 Why Write Tests?","text":"<p>Benefits:</p> <ol> <li>Catch Regressions Early</li> <li>Detect logic errors before deployment</li> <li>Prevent bad data from reaching production</li> <li> <p>Faster feedback than manual testing</p> </li> <li> <p>Document Expected Behavior</p> </li> <li>Tests serve as executable documentation</li> <li>Show how models should behave</li> <li> <p>Examples for other developers</p> </li> <li> <p>Enable Refactoring</p> </li> <li>Refactor with confidence</li> <li>Tests verify behavior unchanged</li> <li> <p>Safe to optimize queries</p> </li> <li> <p>CI/CD Integration</p> </li> <li>Run tests automatically in CI/CD</li> <li>Block deployments on test failures</li> <li>Ensure quality gates</li> </ol> <p>Example:</p> <pre><code>-- Model: analytics.daily_revenue\nSELECT\n  customer_id,\n  order_date,\n  SUM(amount) as revenue\nFROM staging.orders\nWHERE status = 'completed'\nGROUP BY customer_id, order_date;\n</code></pre> <p>Without tests: - Deploy \u2192 Discover bug \u2192 Fix \u2192 Redeploy - Risk: Bad data in production</p> <p>With tests: - Write test \u2192 Test fails \u2192 Fix \u2192 Test passes \u2192 Deploy - Result: Correct logic, no bad data</p>"},{"location":"models/model-testing/#14-when-to-write-tests","title":"1.4 When to Write Tests","text":"<p>\u2705 Write tests for: - Critical business logic (revenue, customer metrics) - Complex transformations (joins, aggregations) - Edge cases (NULL handling, empty inputs) - Models feeding downstream systems - Models with complex calculations</p> <p>\u274c Skip tests for: - Simple pass-through models (SELECT * FROM ...) - Models that are just filters (WHERE ...) - Very simple aggregations (COUNT, SUM) - Experimental models (test manually first)</p> <p>Test Coverage Strategy:</p> <ul> <li>Critical models: 100% test coverage</li> <li>Important models: Test main logic paths</li> <li>Simple models: Test edge cases only</li> <li>Experimental models: Test after stabilization</li> </ul> <p>\u2191 Back to Top</p>"},{"location":"models/model-testing/#2-test-structure","title":"2. Test Structure","text":""},{"location":"models/model-testing/#21-test-file-organization","title":"2.1 Test File Organization","text":"<p>Tests are YAML files in the <code>tests/</code> directory:</p> <pre><code>project/\n\u251c\u2500\u2500 models/\n\u2502   \u251c\u2500\u2500 analytics/\n\u2502   \u2502   \u2514\u2500\u2500 customers.sql\n\u2502   \u2514\u2500\u2500 staging/\n\u2502       \u2514\u2500\u2500 orders.sql\n\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 test_customers.yaml      # Tests for customers model\n\u2502   \u251c\u2500\u2500 test_orders.yaml         # Tests for orders model\n\u2502   \u2514\u2500\u2500 test_integration.yaml    # Integration tests\n\u2514\u2500\u2500 config.yaml\n</code></pre> <p>File Naming: - Must start with <code>test</code> - Must end with <code>.yaml</code> or <code>.yml</code> - Name doesn't matter (Vulcan reads all files) - Convention: <code>test_&lt;model_name&gt;.yaml</code></p>"},{"location":"models/model-testing/#22-basic-test-structure","title":"2.2 Basic Test Structure","text":"<p>Minimal test:</p> <pre><code>test_name:\n  model: schema.table_name\n  inputs:\n    upstream_model:\n      rows:\n        - column1: value1\n          column2: value2\n  outputs:\n    query:\n      rows:\n        - column1: expected_value1\n          column2: expected_value2\n</code></pre> <p>Complete test structure:</p> <pre><code>test_name:\n  model: schema.table_name          # Required: Model to test\n  gateway: gateway_name             # Optional: Testing gateway\n  inputs:                           # Required: Input data\n    upstream_model1:\n      rows:\n        - col1: val1\n          col2: val2\n    upstream_model2:\n      query: SELECT ...\n  outputs:                          # Required: Expected outputs\n    query:                          # Query output\n      rows:\n        - col1: expected_val1\n    ctes:                           # Optional: CTE outputs\n      cte_name:\n        rows:\n          - col1: expected_val1\n  vars:                             # Optional: Macro variables\n    execution_time: '2024-01-01 12:00:00'\n    start: '2024-01-01'\n  description: 'Test description'   # Optional: Documentation\n  schema: custom_schema_name        # Optional: Custom schema\n</code></pre>"},{"location":"models/model-testing/#23-test-components","title":"2.3 Test Components","text":"<p>1. Test Name</p> <pre><code>test_customer_revenue:  # Unique test name\n  model: ...\n</code></pre> <p>Naming conventions: - <code>test_&lt;model_name&gt;</code> - Basic test - <code>test_&lt;model_name&gt;_&lt;scenario&gt;</code> - Specific scenario - <code>test_&lt;model_name&gt;_edge_case</code> - Edge case test</p> <p>Examples: <pre><code>test_customers:                    # Basic test\ntest_customers_empty_input:       # Edge case\ntest_customers_null_handling:     # Specific scenario\ntest_customers_multiple_orders:   # Multiple orders scenario\n</code></pre></p> <p>2. Model Reference</p> <pre><code>test_name:\n  model: analytics.customers  # Fully qualified model name\n</code></pre> <p>3. Inputs</p> <p>Define data for upstream models:</p> <pre><code>inputs:\n  staging.orders:\n    rows:\n      - order_id: 1\n        customer_id: 100\n        amount: 50.00\n</code></pre> <p>4. Outputs</p> <p>Define expected results:</p> <pre><code>outputs:\n  query:\n    rows:\n      - customer_id: 100\n        total_revenue: 50.00\n</code></pre> <p>5. Variables</p> <p>Set macro variables:</p> <pre><code>vars:\n  execution_time: '2024-01-01 12:00:00'\n  start: '2024-01-01'\n  end: '2024-01-02'\n</code></pre>"},{"location":"models/model-testing/#24-multiple-tests-in-one-file","title":"2.4 Multiple Tests in One File","text":"<p>You can define multiple tests in a single YAML file:</p> <pre><code># tests/test_customers.yaml\n\ntest_customers_basic:\n  model: analytics.customers\n  inputs:\n    staging.orders:\n      rows:\n        - order_id: 1\n          customer_id: 100\n          amount: 50.00\n  outputs:\n    query:\n      rows:\n        - customer_id: 100\n          total_revenue: 50.00\n\ntest_customers_empty_input:\n  model: analytics.customers\n  inputs:\n    staging.orders:\n      rows: []  # Empty input\n  outputs:\n    query:\n      rows: []  # Empty output expected\n\ntest_customers_multiple_orders:\n  model: analytics.customers\n  inputs:\n    staging.orders:\n      rows:\n        - order_id: 1\n          customer_id: 100\n          amount: 50.00\n        - order_id: 2\n          customer_id: 100\n          amount: 75.00\n  outputs:\n    query:\n      rows:\n        - customer_id: 100\n          total_revenue: 125.00\n</code></pre> <p>Organization:</p> <ul> <li>One file per model: <code>test_customers.yaml</code> contains all customer tests</li> <li>One file per domain: <code>test_revenue.yaml</code> contains all revenue-related tests</li> <li>One file per scenario: <code>test_edge_cases.yaml</code> contains edge case tests</li> </ul> <p>Recommendation: Start with one file per model, split when files get large (&gt;500 lines).</p> <p>\u2191 Back to Top</p>"},{"location":"models/model-testing/#3-input-data-formats","title":"3. Input Data Formats","text":"<p>Vulcan supports three ways to define input data for tests.</p>"},{"location":"models/model-testing/#31-yaml-dictionaries-default","title":"3.1 YAML Dictionaries (Default)","text":"<p>Format: List of dictionaries where each dictionary is a row.</p> <p>Syntax: <pre><code>inputs:\n  staging.orders:\n    rows:\n      - order_id: 1\n        customer_id: 100\n        amount: 50.00\n        order_date: '2024-01-01'\n      - order_id: 2\n        customer_id: 100\n        amount: 75.00\n        order_date: '2024-01-02'\n</code></pre></p> <p>Example:</p> <pre><code>test_customer_revenue:\n  model: analytics.customer_revenue\n  inputs:\n    staging.orders:\n      rows:\n        - order_id: 1\n          customer_id: 100\n          amount: 50.00\n          status: 'completed'\n        - order_id: 2\n          customer_id: 100\n          amount: 75.00\n          status: 'completed'\n        - order_id: 3\n          customer_id: 200\n          amount: 100.00\n          status: 'completed'\n  outputs:\n    query:\n      rows:\n        - customer_id: 100\n          total_revenue: 125.00\n        - customer_id: 200\n          total_revenue: 100.00\n</code></pre> <p>Data Types:</p> <p>Vulcan infers types from model definitions. Common types:</p> YAML Value SQL Type Example <code>123</code> INT <code>order_id: 123</code> <code>123.45</code> DECIMAL/FLOAT <code>amount: 123.45</code> <code>'text'</code> VARCHAR/TEXT <code>status: 'completed'</code> <code>'2024-01-01'</code> DATE <code>order_date: '2024-01-01'</code> <code>'2024-01-01 12:00:00'</code> TIMESTAMP <code>created_at: '2024-01-01 12:00:00'</code> <code>true</code> / <code>false</code> BOOLEAN <code>is_active: true</code> <code>null</code> NULL <code>deleted_at: null</code> <p>Omitting Columns:</p> <p>Missing columns are treated as <code>NULL</code>:</p> <pre><code>inputs:\n  staging.orders:\n    rows:\n      - order_id: 1\n        customer_id: 100\n        amount: 50.00\n        # status omitted \u2192 NULL\n        # order_date omitted \u2192 NULL\n</code></pre>"},{"location":"models/model-testing/#32-csv-format","title":"3.2 CSV Format","text":"<p>Format: Comma-separated values with header row.</p> <p>Syntax: <pre><code>inputs:\n  staging.orders:\n    format: csv\n    rows: |\n      order_id,customer_id,amount,order_date\n      1,100,50.00,2024-01-01\n      2,100,75.00,2024-01-02\n      3,200,100.00,2024-01-03\n</code></pre></p> <p>Example:</p> <pre><code>test_customer_revenue:\n  model: analytics.customer_revenue\n  inputs:\n    staging.orders:\n      format: csv\n      rows: |\n        order_id,customer_id,amount,status,order_date\n        1,100,50.00,completed,2024-01-01\n        2,100,75.00,completed,2024-01-02\n        3,200,100.00,completed,2024-01-03\n  outputs:\n    query:\n      rows:\n        - customer_id: 100\n          total_revenue: 125.00\n        - customer_id: 200\n          total_revenue: 100.00\n</code></pre> <p>When to Use CSV:</p> <p>\u2705 Good for: - Large datasets (easier to read) - Copy-paste from spreadsheets - Data with many columns - Reusing test data across tests</p> <p>\u274c Avoid for: - Small datasets (YAML is clearer) - Complex nested data - Data requiring type precision</p> <p>Multi-line CSV:</p> <pre><code>inputs:\n  staging.orders:\n    format: csv\n    rows: |\n      order_id,customer_id,amount,order_date\n      1,100,50.00,2024-01-01\n      2,100,75.00,2024-01-02\n      3,200,100.00,2024-01-03\n      4,200,25.00,2024-01-04\n      5,300,150.00,2024-01-05\n</code></pre>"},{"location":"models/model-testing/#33-sql-query-format","title":"3.3 SQL Query Format","text":"<p>Format: SQL query that generates input data.</p> <p>Syntax: <pre><code>inputs:\n  staging.orders:\n    query: |\n      SELECT 1 AS order_id, 100 AS customer_id, 50.00 AS amount, '2024-01-01'::DATE AS order_date\n      UNION ALL\n      SELECT 2, 100, 75.00, '2024-01-02'::DATE\n      UNION ALL\n      SELECT 3, 200, 100.00, '2024-01-03'::DATE\n</code></pre></p> <p>Example:</p> <pre><code>test_customer_revenue:\n  model: analytics.customer_revenue\n  inputs:\n    staging.orders:\n      query: |\n        SELECT \n          1 AS order_id,\n          100 AS customer_id,\n          50.00 AS amount,\n          'completed' AS status,\n          '2024-01-01'::DATE AS order_date\n        UNION ALL\n        SELECT 2, 100, 75.00, 'completed', '2024-01-02'::DATE\n        UNION ALL\n        SELECT 3, 200, 100.00, 'completed', '2024-01-03'::DATE\n  outputs:\n    query:\n      rows:\n        - customer_id: 100\n          total_revenue: 125.00\n        - customer_id: 200\n          total_revenue: 100.00\n</code></pre> <p>When to Use SQL:</p> <p>\u2705 Good for: - Complex data generation - Dynamic test data - Reusing existing queries - Testing with realistic data distributions</p> <p>\u274c Avoid for: - Simple test data (YAML is clearer) - Tests that need to be portable - Data that changes frequently</p> <p>Using VALUES:</p> <pre><code>inputs:\n  staging.orders:\n    query: |\n      SELECT * FROM (VALUES\n        (1, 100, 50.00, 'completed', '2024-01-01'::DATE),\n        (2, 100, 75.00, 'completed', '2024-01-02'::DATE),\n        (3, 200, 100.00, 'completed', '2024-01-03'::DATE)\n      ) AS t(order_id, customer_id, amount, status, order_date)\n</code></pre>"},{"location":"models/model-testing/#34-external-files","title":"3.4 External Files","text":"<p>Format: Load data from external CSV or YAML files.</p> <p>Syntax: <pre><code>inputs:\n  staging.orders:\n    format: csv\n    path: fixtures/orders_test_data.csv\n</code></pre></p> <p>File Structure:</p> <pre><code>project/\n\u251c\u2500\u2500 models/\n\u251c\u2500\u2500 tests/\n\u2502   \u2514\u2500\u2500 test_customers.yaml\n\u2514\u2500\u2500 fixtures/\n    \u251c\u2500\u2500 orders_test_data.csv\n    \u2514\u2500\u2500 customers_test_data.yaml\n</code></pre> <p>CSV File:</p> <pre><code>order_id,customer_id,amount,status,order_date\n1,100,50.00,completed,2024-01-01\n2,100,75.00,completed,2024-01-02\n3,200,100.00,completed,2024-01-03\n</code></pre> <p>YAML File:</p> <pre><code># fixtures/orders_test_data.yaml\n- order_id: 1\n  customer_id: 100\n  amount: 50.00\n  status: completed\n  order_date: '2024-01-01'\n- order_id: 2\n  customer_id: 100\n  amount: 75.00\n  status: completed\n  order_date: '2024-01-02'\n</code></pre> <p>Test Reference:</p> <pre><code>test_customer_revenue:\n  model: analytics.customer_revenue\n  inputs:\n    staging.orders:\n      format: csv\n      path: fixtures/orders_test_data.csv\n  outputs:\n    query:\n      rows:\n        - customer_id: 100\n          total_revenue: 125.00\n        - customer_id: 200\n          total_revenue: 100.00\n</code></pre> <p>When to Use External Files:</p> <p>\u2705 Good for: - Large test datasets - Reusing data across multiple tests - Data maintained separately - Real-world sample data</p> <p>\u274c Avoid for: - Small, simple test data - Tests that should be self-contained - Data that changes frequently</p>"},{"location":"models/model-testing/#35-multiple-input-models","title":"3.5 Multiple Input Models","text":"<p>Tests can specify inputs for multiple upstream models:</p> <pre><code>test_customer_summary:\n  model: analytics.customer_summary\n  inputs:\n    staging.orders:\n      rows:\n        - order_id: 1\n          customer_id: 100\n          amount: 50.00\n        - order_id: 2\n          customer_id: 100\n          amount: 75.00\n    staging.customers:\n      rows:\n        - customer_id: 100\n          customer_name: 'Alice'\n          signup_date: '2023-01-01'\n  outputs:\n    query:\n      rows:\n        - customer_id: 100\n          customer_name: 'Alice'\n          total_revenue: 125.00\n          order_count: 2\n</code></pre> <p>Input Order:</p> <p>Input models are processed in the order they appear. Dependencies are automatically resolved.</p> <p>\u2191 Back to Top</p>"},{"location":"models/model-testing/#4-output-validation","title":"4. Output Validation","text":""},{"location":"models/model-testing/#41-query-output-validation","title":"4.1 Query Output Validation","text":"<p>Basic syntax:</p> <pre><code>outputs:\n  query:\n    rows:\n      - column1: expected_value1\n        column2: expected_value2\n</code></pre> <p>Example:</p> <pre><code>test_customer_revenue:\n  model: analytics.customer_revenue\n  inputs:\n    staging.orders:\n      rows:\n        - order_id: 1\n          customer_id: 100\n          amount: 50.00\n        - order_id: 2\n          customer_id: 100\n          amount: 75.00\n  outputs:\n    query:\n      rows:\n        - customer_id: 100\n          total_revenue: 125.00\n          order_count: 2\n</code></pre> <p>Row Order:</p> <p>By default, row order does not matter. Vulcan compares sets, not sequences.</p> <p>To enforce order:</p> <pre><code>outputs:\n  query:\n    sort_by: customer_id  # Sort before comparison\n    rows:\n      - customer_id: 100\n        total_revenue: 125.00\n      - customer_id: 200\n        total_revenue: 100.00\n</code></pre>"},{"location":"models/model-testing/#42-cte-output-validation","title":"4.2 CTE Output Validation","text":"<p>Test individual CTEs within the model query:</p> <p>Model:</p> <pre><code>MODEL (\n  name analytics.customer_metrics,\n  kind FULL\n);\n\nWITH filtered_orders AS (\n  SELECT *\n  FROM staging.orders\n  WHERE status = 'completed'\n),\ncustomer_totals AS (\n  SELECT\n    customer_id,\n    SUM(amount) as total_revenue,\n    COUNT(*) as order_count\n  FROM filtered_orders\n  GROUP BY customer_id\n)\nSELECT * FROM customer_totals;\n</code></pre> <p>Test:</p> <pre><code>test_customer_metrics:\n  model: analytics.customer_metrics\n  inputs:\n    staging.orders:\n      rows:\n        - order_id: 1\n          customer_id: 100\n          amount: 50.00\n          status: 'completed'\n        - order_id: 2\n          customer_id: 100\n          amount: 75.00\n          status: 'pending'  # Filtered out\n        - order_id: 3\n          customer_id: 200\n          amount: 100.00\n          status: 'completed'\n  outputs:\n    ctes:\n      filtered_orders:\n        rows:\n          - order_id: 1\n            customer_id: 100\n            amount: 50.00\n            status: 'completed'\n          - order_id: 3\n            customer_id: 200\n            amount: 100.00\n            status: 'completed'\n      customer_totals:\n        rows:\n          - customer_id: 100\n            total_revenue: 50.00\n            order_count: 1\n          - customer_id: 200\n            total_revenue: 100.00\n            order_count: 1\n    query:\n      rows:\n        - customer_id: 100\n          total_revenue: 50.00\n          order_count: 1\n        - customer_id: 200\n          total_revenue: 100.00\n          order_count: 1\n</code></pre> <p>When to Test CTEs:</p> <p>\u2705 Test CTEs when: - CTE logic is complex - Debugging specific CTE issues - Validating intermediate transformations - Documenting CTE behavior</p> <p>\u274c Skip CTE testing when: - CTEs are simple (just filters) - Testing final output is sufficient - CTEs are implementation details</p>"},{"location":"models/model-testing/#43-partial-validation","title":"4.3 Partial Validation","text":"<p>Test only a subset of output columns:</p> <p>Syntax:</p> <pre><code>outputs:\n  query:\n    partial: true  # Only validate specified columns\n    rows:\n      - customer_id: 100\n        total_revenue: 125.00\n        # Other columns ignored\n</code></pre> <p>Example:</p> <pre><code>test_customer_revenue_partial:\n  model: analytics.customer_summary\n  inputs:\n    staging.orders:\n      rows:\n        - order_id: 1\n          customer_id: 100\n          amount: 50.00\n  outputs:\n    query:\n      partial: true  # Only validate revenue, ignore other columns\n      rows:\n        - customer_id: 100\n          total_revenue: 125.00\n          # order_count, avg_order_value, etc. ignored\n</code></pre> <p>When to Use Partial Validation:</p> <p>\u2705 Good for: - Wide tables (many columns) - Testing specific calculations - Ignoring non-deterministic columns (timestamps) - Focusing on critical columns</p> <p>\u274c Avoid for: - Narrow tables (few columns) - Need to validate all columns - Critical data quality checks</p> <p>Apply to All Outputs:</p> <pre><code>outputs:\n  partial: true  # Applies to all outputs (query and CTEs)\n  query:\n    rows:\n      - customer_id: 100\n        total_revenue: 125.00\n  ctes:\n    filtered_orders:\n      rows:\n        - order_id: 1\n          customer_id: 100\n</code></pre>"},{"location":"models/model-testing/#44-omitting-columns","title":"4.4 Omitting Columns","text":"<p>Missing columns in expected output:</p> <p>If a column is missing from expected output, Vulcan ignores it (doesn't validate):</p> <pre><code>outputs:\n  query:\n    rows:\n      - customer_id: 100\n        total_revenue: 125.00\n        # order_count omitted \u2192 not validated\n</code></pre> <p>Missing columns in actual output:</p> <p>If actual output has extra columns, test fails (unless <code>partial: true</code>):</p> <pre><code># Model returns: customer_id, total_revenue, order_count\n# Test expects: customer_id, total_revenue\n# Result: FAIL (unless partial: true)\n</code></pre> <p>Best Practice:</p> <p>Include all columns you care about in expected output:</p> <pre><code>outputs:\n  query:\n    rows:\n      - customer_id: 100\n        total_revenue: 125.00\n        order_count: 2  # Explicitly validate\n</code></pre>"},{"location":"models/model-testing/#45-type-validation","title":"4.5 Type Validation","text":"<p>Vulcan validates both values and types:</p> <p>Type Mismatch Example:</p> <pre><code># Model returns: total_revenue DECIMAL(10,2) = 125.00\n# Test expects: total_revenue: 125 (INT)\n# Result: FAIL (type mismatch)\n</code></pre> <p>Correct:</p> <pre><code>outputs:\n  query:\n    rows:\n      - customer_id: 100\n        total_revenue: 125.00  # DECIMAL, matches model\n</code></pre> <p>Type Inference:</p> <p>Vulcan infers types from: 1. Model <code>columns</code> property (if specified) 2. Model query output (if not specified) 3. External model definitions (for external models)</p> <p>Explicit Type Specification:</p> <p>If types are ambiguous, specify in model:</p> <pre><code>MODEL (\n  name analytics.customer_revenue,\n  columns (\n    customer_id INT,\n    total_revenue DECIMAL(10,2),\n    order_count INT\n  )\n);\n</code></pre> <p>\u2191 Back to Top</p>"},{"location":"models/model-testing/#5-testing-patterns","title":"5. Testing Patterns","text":""},{"location":"models/model-testing/#51-basic-aggregation-test","title":"5.1 Basic Aggregation Test","text":"<p>Model:</p> <pre><code>MODEL (\n  name analytics.customer_revenue,\n  kind FULL\n);\n\nSELECT\n  customer_id,\n  SUM(amount) as total_revenue,\n  COUNT(*) as order_count\nFROM staging.orders\nWHERE status = 'completed'\nGROUP BY customer_id;\n</code></pre> <p>Test:</p> <pre><code>test_customer_revenue_basic:\n  model: analytics.customer_revenue\n  inputs:\n    staging.orders:\n      rows:\n        - order_id: 1\n          customer_id: 100\n          amount: 50.00\n          status: 'completed'\n        - order_id: 2\n          customer_id: 100\n          amount: 75.00\n          status: 'completed'\n        - order_id: 3\n          customer_id: 200\n          amount: 100.00\n          status: 'completed'\n        - order_id: 4\n          customer_id: 100\n          amount: 25.00\n          status: 'pending'  # Filtered out\n  outputs:\n    query:\n      rows:\n        - customer_id: 100\n          total_revenue: 125.00\n          order_count: 2\n        - customer_id: 200\n          total_revenue: 100.00\n          order_count: 1\n</code></pre>"},{"location":"models/model-testing/#52-join-test","title":"5.2 Join Test","text":"<p>Model:</p> <pre><code>MODEL (\n  name analytics.customer_summary,\n  kind FULL\n);\n\nSELECT\n  c.customer_id,\n  c.customer_name,\n  COALESCE(SUM(o.amount), 0) as total_revenue,\n  COUNT(o.order_id) as order_count\nFROM staging.customers c\nLEFT JOIN staging.orders o ON c.customer_id = o.customer_id\nWHERE o.status = 'completed' OR o.status IS NULL\nGROUP BY c.customer_id, c.customer_name;\n</code></pre> <p>Test:</p> <pre><code>test_customer_summary_join:\n  model: analytics.customer_summary\n  inputs:\n    staging.customers:\n      rows:\n        - customer_id: 100\n          customer_name: 'Alice'\n        - customer_id: 200\n          customer_name: 'Bob'\n        - customer_id: 300\n          customer_name: 'Charlie'  # No orders\n    staging.orders:\n      rows:\n        - order_id: 1\n          customer_id: 100\n          amount: 50.00\n          status: 'completed'\n        - order_id: 2\n          customer_id: 100\n          amount: 75.00\n          status: 'completed'\n        - order_id: 3\n          customer_id: 200\n          amount: 100.00\n          status: 'completed'\n  outputs:\n    query:\n      rows:\n        - customer_id: 100\n          customer_name: 'Alice'\n          total_revenue: 125.00\n          order_count: 2\n        - customer_id: 200\n          customer_name: 'Bob'\n          total_revenue: 100.00\n          order_count: 1\n        - customer_id: 300\n          customer_name: 'Charlie'\n          total_revenue: 0.00\n          order_count: 0\n</code></pre>"},{"location":"models/model-testing/#53-null-handling-test","title":"5.3 NULL Handling Test","text":"<p>Model:</p> <pre><code>MODEL (\n  name analytics.customer_metrics,\n  kind FULL\n);\n\nSELECT\n  customer_id,\n  COUNT(*) as total_orders,\n  COUNT(email) as orders_with_email,  -- NULLs excluded\n  SUM(COALESCE(amount, 0)) as total_revenue\nFROM staging.orders\nGROUP BY customer_id;\n</code></pre> <p>Test:</p> <pre><code>test_null_handling:\n  model: analytics.customer_metrics\n  inputs:\n    staging.orders:\n      rows:\n        - order_id: 1\n          customer_id: 100\n          amount: 50.00\n          email: 'alice@example.com'\n        - order_id: 2\n          customer_id: 100\n          amount: null  # NULL amount\n          email: 'alice@example.com'\n        - order_id: 3\n          customer_id: 100\n          amount: 75.00\n          email: null  # NULL email\n  outputs:\n    query:\n      rows:\n        - customer_id: 100\n          total_orders: 3\n          orders_with_email: 2  # NULL email excluded\n          total_revenue: 125.00  # NULL amount treated as 0\n</code></pre>"},{"location":"models/model-testing/#54-edge-case-tests","title":"5.4 Edge Case Tests","text":"<p>Empty Input:</p> <pre><code>test_empty_input:\n  model: analytics.customer_revenue\n  inputs:\n    staging.orders:\n      rows: []  # Empty input\n  outputs:\n    query:\n      rows: []  # Empty output expected\n</code></pre> <p>Single Row:</p> <pre><code>test_single_row:\n  model: analytics.customer_revenue\n  inputs:\n    staging.orders:\n      rows:\n        - order_id: 1\n          customer_id: 100\n          amount: 50.00\n          status: 'completed'\n  outputs:\n    query:\n      rows:\n        - customer_id: 100\n          total_revenue: 50.00\n          order_count: 1\n</code></pre> <p>All NULLs:</p> <pre><code>test_all_nulls:\n  model: analytics.customer_revenue\n  inputs:\n    staging.orders:\n      rows:\n        - order_id: 1\n          customer_id: null\n          amount: null\n          status: null\n  outputs:\n    query:\n      rows:\n        - customer_id: null\n          total_revenue: null  # Or 0, depending on logic\n          order_count: 1\n</code></pre>"},{"location":"models/model-testing/#55-complex-calculation-test","title":"5.5 Complex Calculation Test","text":"<p>Model:</p> <pre><code>MODEL (\n  name analytics.order_metrics,\n  kind FULL\n);\n\nSELECT\n  order_id,\n  amount,\n  discount_amount,\n  tax_amount,\n  (amount - discount_amount + tax_amount) as total_amount,\n  CASE\n    WHEN amount &gt; 100 THEN 'high_value'\n    WHEN amount &gt; 50 THEN 'medium_value'\n    ELSE 'low_value'\n  END as order_tier\nFROM staging.orders;\n</code></pre> <p>Test:</p> <pre><code>test_order_metrics_calculation:\n  model: analytics.order_metrics\n  inputs:\n    staging.orders:\n      rows:\n        - order_id: 1\n          amount: 100.00\n          discount_amount: 10.00\n          tax_amount: 9.00\n        - order_id: 2\n          amount: 75.00\n          discount_amount: 5.00\n          tax_amount: 7.00\n        - order_id: 3\n          amount: 25.00\n          discount_amount: 0.00\n          tax_amount: 2.50\n  outputs:\n    query:\n      rows:\n        - order_id: 1\n          amount: 100.00\n          discount_amount: 10.00\n          tax_amount: 9.00\n          total_amount: 99.00  # 100 - 10 + 9\n          order_tier: 'high_value'\n        - order_id: 2\n          amount: 75.00\n          discount_amount: 5.00\n          tax_amount: 7.00\n          total_amount: 77.00  # 75 - 5 + 7\n          order_tier: 'medium_value'\n        - order_id: 3\n          amount: 25.00\n          discount_amount: 0.00\n          tax_amount: 2.50\n          total_amount: 27.50  # 25 - 0 + 2.50\n          order_tier: 'low_value'\n</code></pre>"},{"location":"models/model-testing/#56-window-function-test","title":"5.6 Window Function Test","text":"<p>Model:</p> <pre><code>MODEL (\n  name analytics.customer_order_rank,\n  kind FULL\n);\n\nSELECT\n  customer_id,\n  order_id,\n  amount,\n  ROW_NUMBER() OVER (PARTITION BY customer_id ORDER BY amount DESC) as order_rank\nFROM staging.orders;\n</code></pre> <p>Test:</p> <pre><code>test_window_function:\n  model: analytics.customer_order_rank\n  inputs:\n    staging.orders:\n      rows:\n        - order_id: 1\n          customer_id: 100\n          amount: 50.00\n        - order_id: 2\n          customer_id: 100\n          amount: 100.00  # Highest for customer 100\n        - order_id: 3\n          customer_id: 100\n          amount: 25.00\n        - order_id: 4\n          customer_id: 200\n          amount: 75.00  # Only order for customer 200\n  outputs:\n    query:\n      sort_by: customer_id, order_rank\n      rows:\n        - customer_id: 100\n          order_id: 2\n          amount: 100.00\n          order_rank: 1\n        - customer_id: 100\n          order_id: 1\n          amount: 50.00\n          order_rank: 2\n        - customer_id: 100\n          order_id: 3\n          amount: 25.00\n          order_rank: 3\n        - customer_id: 200\n          order_id: 4\n          amount: 75.00\n          order_rank: 1\n</code></pre> <p>\u2191 Back to Top</p>"},{"location":"models/model-testing/#6-testing-incremental-models","title":"6. Testing Incremental Models","text":""},{"location":"models/model-testing/#61-testing-with-time-variables","title":"6.1 Testing with Time Variables","text":"<p>Incremental models use <code>@start_ds</code> and <code>@end_ds</code> macros. Set these in test <code>vars</code>:</p> <p>Model:</p> <pre><code>MODEL (\n  name analytics.daily_revenue,\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column revenue_date\n  ),\n  cron '@daily'\n);\n\nSELECT\n  customer_id,\n  order_date as revenue_date,\n  SUM(amount) as revenue\nFROM staging.orders\nWHERE order_date BETWEEN @start_ds AND @end_ds\nGROUP BY customer_id, order_date;\n</code></pre> <p>Test:</p> <pre><code>test_daily_revenue_incremental:\n  model: analytics.daily_revenue\n  vars:\n    start: '2024-01-01'  # @start_ds\n    end: '2024-01-03'     # @end_ds\n  inputs:\n    staging.orders:\n      rows:\n        - order_id: 1\n          customer_id: 100\n          amount: 50.00\n          order_date: '2024-01-01'  # Within range\n        - order_id: 2\n          customer_id: 100\n          amount: 75.00\n          order_date: '2024-01-02'  # Within range\n        - order_id: 3\n          customer_id: 200\n          amount: 100.00\n          order_date: '2024-01-03'  # Within range\n        - order_id: 4\n          customer_id: 100\n          amount: 25.00\n          order_date: '2023-12-31'  # Outside range (filtered)\n        - order_id: 5\n          customer_id: 200\n          amount: 50.00\n          order_date: '2024-01-04'  # Outside range (filtered)\n  outputs:\n    query:\n      rows:\n        - customer_id: 100\n          revenue_date: '2024-01-01'\n          revenue: 50.00\n        - customer_id: 100\n          revenue_date: '2024-01-02'\n          revenue: 75.00\n        - customer_id: 200\n          revenue_date: '2024-01-03'\n          revenue: 100.00\n</code></pre>"},{"location":"models/model-testing/#62-testing-lookback","title":"6.2 Testing Lookback","text":"<p>Models with <code>lookback</code> reprocess previous intervals:</p> <p>Model:</p> <pre><code>MODEL (\n  name analytics.daily_revenue,\n  kind INCREMENTAL_BY_TIME_RANGE (\n    time_column revenue_date,\n    lookback 2  -- Reprocess last 2 days\n  ),\n  cron '@daily'\n);\n\nSELECT\n  customer_id,\n  order_date as revenue_date,\n  SUM(amount) as revenue\nFROM staging.orders\nWHERE order_date BETWEEN @start_ds AND @end_ds\nGROUP BY customer_id, order_date;\n</code></pre> <p>Test:</p> <pre><code>test_daily_revenue_lookback:\n  model: analytics.daily_revenue\n  vars:\n    start: '2024-01-01'  # Processes: 2024-01-01, 2024-01-02, 2024-01-03\n    end: '2024-01-03'     # (current day + 2 days lookback)\n  inputs:\n    staging.orders:\n      rows:\n        - order_id: 1\n          customer_id: 100\n          amount: 50.00\n          order_date: '2024-01-01'\n        - order_id: 2\n          customer_id: 100\n          amount: 75.00\n          order_date: '2024-01-02'\n        - order_id: 3\n          customer_id: 200\n          amount: 100.00\n          order_date: '2024-01-03'\n  outputs:\n    query:\n      rows:\n        - customer_id: 100\n          revenue_date: '2024-01-01'\n          revenue: 50.00\n        - customer_id: 100\n          revenue_date: '2024-01-02'\n          revenue: 75.00\n        - customer_id: 200\n          revenue_date: '2024-01-03'\n          revenue: 100.00\n</code></pre>"},{"location":"models/model-testing/#63-testing-incremental_by_unique_key","title":"6.3 Testing INCREMENTAL_BY_UNIQUE_KEY","text":"<p>Model:</p> <pre><code>MODEL (\n  name analytics.customers,\n  kind INCREMENTAL_BY_UNIQUE_KEY (\n    unique_key customer_id\n  ),\n  cron '@daily'\n);\n\nSELECT\n  customer_id,\n  customer_name,\n  email,\n  updated_at\nFROM staging.customers\nWHERE updated_at &gt;= @start_ds;\n</code></pre> <p>Test:</p> <pre><code>test_customers_upsert:\n  model: analytics.customers\n  vars:\n    start: '2024-01-01'\n  inputs:\n    staging.customers:\n      rows:\n        - customer_id: 100\n          customer_name: 'Alice'\n          email: 'alice@example.com'\n          updated_at: '2024-01-01'\n        - customer_id: 200\n          customer_name: 'Bob'\n          email: 'bob@example.com'\n          updated_at: '2024-01-01'\n  outputs:\n    query:\n      rows:\n        - customer_id: 100\n          customer_name: 'Alice'\n          email: 'alice@example.com'\n          updated_at: '2024-01-01'\n        - customer_id: 200\n          customer_name: 'Bob'\n          email: 'bob@example.com'\n          updated_at: '2024-01-01'\n</code></pre> <p>Note: Upsert logic (INSERT vs UPDATE) is tested by Vulcan's execution engine, not unit tests. Unit tests validate the query logic.</p> <p>\u2191 Back to Top</p>"},{"location":"models/model-testing/#7-testing-python-models","title":"7. Testing Python Models","text":""},{"location":"models/model-testing/#71-basic-python-model-test","title":"7.1 Basic Python Model Test","text":"<p>Model:</p> <pre><code>from vulcan import ExecutionContext, model\nimport pandas as pd\nfrom datetime import datetime\nimport typing as t\n\n@model(\n    \"analytics.customer_predictions\",\n    columns={\n        \"customer_id\": \"INT\",\n        \"churn_probability\": \"FLOAT\",\n        \"prediction_date\": \"DATE\"\n    }\n)\ndef execute(\n    context: ExecutionContext,\n    start: datetime,\n    end: datetime,\n    execution_time: datetime,\n    **kwargs: t.Any,\n) -&gt; pd.DataFrame:\n    customers = context.fetchdf(\"SELECT customer_id FROM analytics.customers\")\n\n    # Simple prediction logic\n    customers['churn_probability'] = 0.1  # Placeholder\n    customers['prediction_date'] = execution_time.date()\n\n    return customers[['customer_id', 'churn_probability', 'prediction_date']]\n</code></pre> <p>Test:</p> <pre><code>test_customer_predictions:\n  model: analytics.customer_predictions\n  vars:\n    execution_time: '2024-01-01 12:00:00'\n  inputs:\n    analytics.customers:\n      rows:\n        - customer_id: 100\n          customer_name: 'Alice'\n        - customer_id: 200\n          customer_name: 'Bob'\n  outputs:\n    query:\n      rows:\n        - customer_id: 100\n          churn_probability: 0.1\n          prediction_date: '2024-01-01'\n        - customer_id: 200\n          churn_probability: 0.1\n          prediction_date: '2024-01-01'\n</code></pre>"},{"location":"models/model-testing/#72-python-model-with-complex-logic","title":"7.2 Python Model with Complex Logic","text":"<p>Model:</p> <pre><code>@model(\n    \"analytics.customer_segments\",\n    columns={\n        \"customer_id\": \"INT\",\n        \"segment\": \"VARCHAR(50)\",\n        \"lifetime_value\": \"DECIMAL(10,2)\"\n    }\n)\ndef execute(context, start, end, execution_time, **kwargs):\n    customers = context.fetchdf(\"\"\"\n        SELECT \n            customer_id,\n            total_revenue,\n            order_count\n        FROM analytics.customer_metrics\n    \"\"\")\n\n    # Segment logic\n    customers['segment'] = customers.apply(\n        lambda row: 'high_value' if row['total_revenue'] &gt; 1000 \n                   else 'medium_value' if row['total_revenue'] &gt; 500 \n                   else 'low_value',\n        axis=1\n    )\n\n    customers['lifetime_value'] = customers['total_revenue'] * 2\n\n    return customers[['customer_id', 'segment', 'lifetime_value']]\n</code></pre> <p>Test:</p> <pre><code>test_customer_segments:\n  model: analytics.customer_segments\n  inputs:\n    analytics.customer_metrics:\n      rows:\n        - customer_id: 100\n          total_revenue: 1500.00\n          order_count: 10\n        - customer_id: 200\n          total_revenue: 750.00\n          order_count: 5\n        - customer_id: 300\n          total_revenue: 250.00\n          order_count: 2\n  outputs:\n    query:\n      rows:\n        - customer_id: 100\n          segment: 'high_value'\n          lifetime_value: 3000.00\n        - customer_id: 200\n          segment: 'medium_value'\n          lifetime_value: 1500.00\n        - customer_id: 300\n          segment: 'low_value'\n          lifetime_value: 500.00\n</code></pre>"},{"location":"models/model-testing/#73-python-model-with-multiple-dependencies","title":"7.3 Python Model with Multiple Dependencies","text":"<p>Model:</p> <pre><code>@model(\n    \"analytics.customer_analysis\",\n    columns={\n        \"customer_id\": \"INT\",\n        \"revenue_score\": \"FLOAT\",\n        \"engagement_score\": \"FLOAT\",\n        \"combined_score\": \"FLOAT\"\n    }\n)\ndef execute(context, start, end, execution_time, **kwargs):\n    revenue = context.fetchdf(\"SELECT customer_id, total_revenue FROM analytics.revenue\")\n    engagement = context.fetchdf(\"SELECT customer_id, engagement_score FROM analytics.engagement\")\n\n    # Merge and calculate\n    merged = revenue.merge(engagement, on='customer_id', how='outer')\n    merged['revenue_score'] = merged['total_revenue'] / 1000.0\n    merged['engagement_score'] = merged['engagement_score'].fillna(0)\n    merged['combined_score'] = merged['revenue_score'] * 0.6 + merged['engagement_score'] * 0.4\n\n    return merged[['customer_id', 'revenue_score', 'engagement_score', 'combined_score']]\n</code></pre> <p>Test:</p> <pre><code>test_customer_analysis:\n  model: analytics.customer_analysis\n  inputs:\n    analytics.revenue:\n      rows:\n        - customer_id: 100\n          total_revenue: 2000.00\n        - customer_id: 200\n          total_revenue: 500.00\n    analytics.engagement:\n      rows:\n        - customer_id: 100\n          engagement_score: 0.8\n        - customer_id: 200\n          engagement_score: 0.5\n  outputs:\n    query:\n      rows:\n        - customer_id: 100\n          revenue_score: 2.0\n          engagement_score: 0.8\n          combined_score: 1.52  # 2.0 * 0.6 + 0.8 * 0.4\n        - customer_id: 200\n          revenue_score: 0.5\n          engagement_score: 0.5\n          combined_score: 0.5  # 0.5 * 0.6 + 0.5 * 0.4\n</code></pre> <p>\u2191 Back to Top</p>"},{"location":"models/model-testing/#8-automatic-test-generation","title":"8. Automatic Test Generation","text":""},{"location":"models/model-testing/#81-using-vulcan-create_test","title":"8.1 Using <code>vulcan create_test</code>","text":"<p>Generate tests automatically from live data:</p> <p>Command:</p> <pre><code>vulcan create_test analytics.daily_revenue \\\n  --query staging.orders \"SELECT * FROM staging.orders WHERE order_date BETWEEN '2024-01-01' AND '2024-01-03' LIMIT 10\" \\\n  --var start '2024-01-01' \\\n  --var end '2024-01-03'\n</code></pre> <p>What It Does:</p> <ol> <li>Executes query against data warehouse</li> <li>Fetches input data for upstream models</li> <li>Runs model with test data</li> <li>Captures actual output</li> <li>Generates complete test YAML</li> </ol> <p>Generated Test:</p> <pre><code>test_daily_revenue:\n  model: analytics.daily_revenue\n  vars:\n    start: '2024-01-01'\n    end: '2024-01-03'\n  inputs:\n    staging.orders:\n      rows:\n        - order_id: 1\n          customer_id: 100\n          amount: 50.00\n          order_date: '2024-01-01'\n        # ... more rows from query\n  outputs:\n    query:\n      rows:\n        - customer_id: 100\n          revenue_date: '2024-01-01'\n          revenue: 50.00\n        # ... expected output\n</code></pre>"},{"location":"models/model-testing/#82-best-practices-for-test-generation","title":"8.2 Best Practices for Test Generation","text":"<p>1. Use Representative Data:</p> <pre><code># \u2705 Good: Representative sample\nvulcan create_test analytics.daily_revenue \\\n  --query staging.orders \"SELECT * FROM staging.orders WHERE order_date BETWEEN '2024-01-01' AND '2024-01-07' ORDER BY RANDOM() LIMIT 100\"\n\n# \u274c Avoid: Too small or biased\nvulcan create_test analytics.daily_revenue \\\n  --query staging.orders \"SELECT * FROM staging.orders LIMIT 1\"\n</code></pre> <p>2. Set Macro Variables:</p> <p>Always set <code>start</code>, <code>end</code>, <code>execution_time</code> for incremental models:</p> <pre><code>vulcan create_test analytics.daily_revenue \\\n  --var start '2024-01-01' \\\n  --var end '2024-01-07' \\\n  --var execution_time '2024-01-07 12:00:00'\n</code></pre> <p>3. Review Generated Tests:</p> <ul> <li>Verify inputs are representative</li> <li>Check expected outputs are correct</li> <li>Add edge cases manually</li> <li>Remove unnecessary complexity</li> </ul> <p>4. Edit Generated Tests:</p> <p>Generated tests are starting points. Enhance them:</p> <pre><code># Generated test (basic)\ntest_daily_revenue:\n  model: analytics.daily_revenue\n  # ... basic test\n\n# Enhanced test (add edge cases)\ntest_daily_revenue_empty:\n  model: analytics.daily_revenue\n  # ... empty input test\n\ntest_daily_revenue_null_handling:\n  model: analytics.daily_revenue\n  # ... NULL handling test\n</code></pre>"},{"location":"models/model-testing/#83-limitations","title":"8.3 Limitations","text":"<p>Automatic generation: - \u2705 Good for initial test creation - \u2705 Captures current behavior - \u274c Doesn't test edge cases - \u274c Doesn't test error conditions - \u274c May include production data (review carefully)</p> <p>Recommendation: Use <code>create_test</code> to bootstrap, then add manual tests for edge cases.</p> <p>\u2191 Back to Top</p>"},{"location":"models/model-testing/#9-running-tests","title":"9. Running Tests","text":""},{"location":"models/model-testing/#91-cli-commands","title":"9.1 CLI Commands","text":"<p>Run all tests:</p> <pre><code>vulcan test\n</code></pre> <p>Output: <pre><code>.\n----------------------------------------------------------------------\nRan 1 test in 0.042s\n\nOK\n</code></pre></p> <p>Run specific test:</p> <pre><code>vulcan test tests/test_customers.yaml::test_customer_revenue\n</code></pre> <p>Run tests matching pattern:</p> <pre><code>vulcan test tests/test_customer*\nvulcan test tests/test_*_revenue.yaml\n</code></pre> <p>Verbose output:</p> <pre><code>vulcan test -v\n</code></pre> <p>Preserve fixtures (for debugging):</p> <pre><code>vulcan test --preserve-fixtures\n</code></pre>"},{"location":"models/model-testing/#92-test-execution-in-plans","title":"9.2 Test Execution in Plans","text":"<p>Tests run automatically when creating plans:</p> <pre><code>vulcan plan\n</code></pre> <p>What happens: 1. Plan is created 2. Tests run automatically 3. If tests fail \u2192 Plan creation halts 4. If tests pass \u2192 Plan continues</p> <p>Skip tests (not recommended):</p> <pre><code>vulcan plan --skip-tests\n</code></pre>"},{"location":"models/model-testing/#93-notebook-magics","title":"9.3 Notebook Magics","text":"<p>Run tests in Jupyter:</p> <pre><code>import vulcan\n\n%run_test\n</code></pre> <p>Run specific test:</p> <pre><code>%run_test tests/test_customers.yaml::test_customer_revenue\n</code></pre> <p>Verbose output:</p> <pre><code>%run_test -v\n</code></pre>"},{"location":"models/model-testing/#94-cicd-integration","title":"9.4 CI/CD Integration","text":"<p>GitHub Actions Example:</p> <pre><code>name: Test Models\n\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - name: Set up Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: '3.9'\n      - name: Install dependencies\n        run: |\n          pip install vulcan\n      - name: Run tests\n        run: |\n          vulcan test\n</code></pre> <p>Exit Codes:</p> <ul> <li><code>0</code> - All tests passed</li> <li><code>1</code> - Tests failed</li> </ul> <p>Use in CI/CD:</p> <pre><code>#!/bin/bash\nset -e  # Exit on error\n\nvulcan test\n# If tests fail, script exits with code 1\n# CI/CD pipeline halts\n</code></pre> <p>\u2191 Back to Top</p>"},{"location":"models/model-testing/#10-advanced-patterns","title":"10. Advanced Patterns","text":""},{"location":"models/model-testing/#101-testing-with-macros","title":"10.1 Testing with Macros","text":"<p>Model with macros:</p> <pre><code>MODEL (\n  name analytics.daily_revenue,\n  kind INCREMENTAL_BY_TIME_RANGE (time_column revenue_date),\n  cron '@daily'\n);\n\nSELECT\n  customer_id,\n  @start_ds as revenue_date,\n  SUM(amount) as revenue\nFROM staging.orders\nWHERE order_date BETWEEN @start_ds AND @end_ds\n  AND @IF(@gateway = 'prod', status = 'completed', status IN ('completed', 'pending'))\nGROUP BY customer_id;\n</code></pre> <p>Test with macro variables:</p> <pre><code>test_daily_revenue_with_macros:\n  model: analytics.daily_revenue\n  vars:\n    start: '2024-01-01'\n    end: '2024-01-01'\n    gateway: 'dev'  # Test dev behavior\n  inputs:\n    staging.orders:\n      rows:\n        - order_id: 1\n          customer_id: 100\n          amount: 50.00\n          status: 'completed'\n        - order_id: 2\n          customer_id: 100\n          amount: 75.00\n          status: 'pending'  # Included in dev\n  outputs:\n    query:\n      rows:\n        - customer_id: 100\n          revenue_date: '2024-01-01'\n          revenue: 125.00  # Includes pending in dev\n</code></pre>"},{"location":"models/model-testing/#102-testing-with-execution-time","title":"10.2 Testing with Execution Time","text":"<p>Model:</p> <pre><code>MODEL (\n  name analytics.daily_snapshot,\n  kind FULL\n);\n\nSELECT\n  customer_id,\n  CURRENT_DATE as snapshot_date,\n  CURRENT_TIMESTAMP as snapshot_timestamp\nFROM staging.customers;\n</code></pre> <p>Test with frozen time:</p> <pre><code>test_daily_snapshot_time:\n  model: analytics.daily_snapshot\n  vars:\n    execution_time: '2024-01-15 14:30:00'  # Freeze time\n  inputs:\n    staging.customers:\n      rows:\n        - customer_id: 100\n          customer_name: 'Alice'\n  outputs:\n    query:\n      rows:\n        - customer_id: 100\n          snapshot_date: '2024-01-15'      # Matches execution_time date\n          snapshot_timestamp: '2024-01-15 14:30:00'  # Matches execution_time\n</code></pre>"},{"location":"models/model-testing/#103-testing-parameterized-model-names","title":"10.3 Testing Parameterized Model Names","text":"<p>Model:</p> <pre><code>MODEL (\n  name @{schema}.customers,\n  kind FULL\n);\n\nSELECT * FROM @{schema}.raw_customers;\n</code></pre> <p>Test:</p> <pre><code>test_parameterized_model:\n  model: \"{{ var('schema') }}.customers\"  # Jinja syntax\n  vars:\n    schema: 'analytics'  # Set schema variable\n  inputs:\n    analytics.raw_customers:\n      rows:\n        - customer_id: 100\n          customer_name: 'Alice'\n  outputs:\n    query:\n      rows:\n        - customer_id: 100\n          customer_name: 'Alice'\n</code></pre>"},{"location":"models/model-testing/#104-testing-with-different-gateways","title":"10.4 Testing with Different Gateways","text":"<p>Test using specific gateway:</p> <pre><code>test_customers_spark:\n  gateway: spark_testing  # Use Spark gateway\n  model: analytics.customers\n  inputs:\n    staging.orders:\n      rows:\n        - order_id: 1\n          customer_id: 100\n  outputs:\n    query:\n      rows:\n        - customer_id: 100\n</code></pre> <p>Gateway Configuration:</p> <pre><code># config.yaml\ngateways:\n  spark_testing:\n    test_connection:\n      type: spark\n      config:\n        \"spark.master\": \"local\"\n</code></pre>"},{"location":"models/model-testing/#105-testing-external-models","title":"10.5 Testing External Models","text":"<p>External model definition:</p> <pre><code># external_models.yaml\n- name: external.third_party_data\n  columns:\n    id: INT\n    value: TEXT\n</code></pre> <p>Test:</p> <pre><code>test_with_external_model:\n  model: analytics.enriched_data\n  inputs:\n    external.third_party_data:\n      rows:\n        - id: 1\n          value: 'test'\n    staging.orders:\n      rows:\n        - order_id: 1\n          external_id: 1\n  outputs:\n    query:\n      rows:\n        - order_id: 1\n          external_value: 'test'\n</code></pre>"},{"location":"models/model-testing/#106-testing-with-custom-schema","title":"10.6 Testing with Custom Schema","text":"<p>Test with custom schema name:</p> <pre><code>test_customers:\n  model: analytics.customers\n  schema: my_test_schema  # Custom schema for fixtures\n  inputs:\n    staging.orders:\n      rows:\n        - order_id: 1\n          customer_id: 100\n  outputs:\n    query:\n      rows:\n        - customer_id: 100\n</code></pre> <p>Use case: Isolate test fixtures, avoid conflicts.</p> <p>\u2191 Back to Top</p>"},{"location":"models/model-testing/#11-troubleshooting","title":"11. Troubleshooting","text":""},{"location":"models/model-testing/#111-test-failures","title":"11.1 Test Failures","text":"<p>Common failure: Data mismatch</p> <pre><code>FAIL: test_customer_revenue (tests/test_customers.yaml)\n----------------------------------------------------------------------\nAssertionError: Data mismatch (exp: expected, act: actual)\n\n  total_revenue\n         exp  act\n0     125.00  150.00\n</code></pre> <p>Debugging steps:</p> <ol> <li> <p>Check input data: <pre><code># Verify inputs are correct\ninputs:\n  staging.orders:\n    rows:\n      - order_id: 1\n        amount: 50.00\n</code></pre></p> </li> <li> <p>Check model logic: <pre><code>-- Review model query\nSELECT customer_id, SUM(amount) as total_revenue\nFROM staging.orders\nGROUP BY customer_id;\n</code></pre></p> </li> <li> <p>Check expected output: <pre><code># Verify expected values are correct\noutputs:\n  query:\n    rows:\n      - customer_id: 100\n        total_revenue: 125.00  # Is this correct?\n</code></pre></p> </li> <li> <p>Use verbose output: <pre><code>vulcan test -v\n</code></pre></p> </li> </ol>"},{"location":"models/model-testing/#112-type-mismatches","title":"11.2 Type Mismatches","text":"<p>Error: Type mismatch between expected and actual.</p> <p>Solution 1: Specify types in model:</p> <pre><code>MODEL (\n  name analytics.customer_revenue,\n  columns (\n    customer_id INT,\n    total_revenue DECIMAL(10,2)  # Explicit type\n  )\n);\n</code></pre> <p>Solution 2: Specify types in test:</p> <pre><code>inputs:\n  staging.orders:\n    columns:\n      order_id: INT\n      amount: DECIMAL(10,2)\n    rows:\n      - order_id: 1\n        amount: 50.00\n</code></pre> <p>Solution 3: Use SQL query:</p> <pre><code>inputs:\n  staging.orders:\n    query: |\n      SELECT \n        1::INT AS order_id,\n        50.00::DECIMAL(10,2) AS amount\n</code></pre>"},{"location":"models/model-testing/#113-preserving-fixtures","title":"11.3 Preserving Fixtures","text":"<p>Debug test failures:</p> <pre><code>vulcan test --preserve-fixtures\n</code></pre> <p>What it does: - Keeps test fixtures (views) after test completes - Allows querying fixtures directly - Helps debug input data issues</p> <p>Query fixtures:</p> <pre><code>-- After running test with --preserve-fixtures\nSELECT * FROM vulcan_test_&lt;random_id&gt;.staging_orders;\n</code></pre> <p>Schema name:</p> <p>Fixtures are in schema: <code>vulcan_test_&lt;random_id&gt;</code></p> <p>Custom schema:</p> <pre><code>test_customers:\n  model: analytics.customers\n  schema: debug_test  # Custom schema name\n  # ...\n</code></pre>"},{"location":"models/model-testing/#114-common-issues","title":"11.4 Common Issues","text":"<p>Issue 1: Missing columns in expected output</p> <p>Error: Test fails because actual output has extra columns.</p> <p>Solution: Use <code>partial: true</code>:</p> <pre><code>outputs:\n  query:\n    partial: true  # Ignore extra columns\n    rows:\n      - customer_id: 100\n        total_revenue: 125.00\n</code></pre> <p>Issue 2: Row order matters</p> <p>Error: Test fails due to row order.</p> <p>Solution: Use <code>sort_by</code>:</p> <pre><code>outputs:\n  query:\n    sort_by: customer_id\n    rows:\n      - customer_id: 100\n        total_revenue: 125.00\n      - customer_id: 200\n        total_revenue: 100.00\n</code></pre> <p>Issue 3: NULL handling</p> <p>Error: NULL values not handled correctly.</p> <p>Solution: Explicitly test NULLs:</p> <pre><code>inputs:\n  staging.orders:\n    rows:\n      - order_id: 1\n        customer_id: null  # Explicit NULL\n        amount: 50.00\n</code></pre> <p>Issue 4: Floating point precision</p> <p>Error: Decimal comparison fails due to precision.</p> <p>Solution: Round in model or use approximate comparison:</p> <pre><code>-- In model\nSELECT ROUND(total_revenue, 2) as total_revenue\n</code></pre>"},{"location":"models/model-testing/#115-debugging-tips","title":"11.5 Debugging Tips","text":"<p>1. Start simple:</p> <pre><code># Start with minimal test\ntest_minimal:\n  model: analytics.customers\n  inputs:\n    staging.orders:\n      rows:\n        - order_id: 1\n          customer_id: 100\n  outputs:\n    query:\n      rows:\n        - customer_id: 100\n</code></pre> <p>2. Add complexity gradually:</p> <pre><code># Add more rows\n# Add more columns\n# Add more upstream models\n</code></pre> <p>3. Test CTEs separately:</p> <pre><code>outputs:\n  ctes:\n    filtered_orders:\n      rows:\n        - order_id: 1\n  query:\n    rows:\n      - customer_id: 100\n</code></pre> <p>4. Use SQL queries for complex data:</p> <pre><code>inputs:\n  staging.orders:\n    query: |\n      -- Complex data generation\n      WITH generated_data AS (\n        SELECT * FROM (VALUES\n          (1, 100, 50.00),\n          (2, 100, 75.00)\n        ) AS t(order_id, customer_id, amount)\n      )\n      SELECT * FROM generated_data\n</code></pre> <p>\u2191 Back to Top</p>"},{"location":"models/model-testing/#12-best-practices","title":"12. Best Practices","text":""},{"location":"models/model-testing/#121-test-coverage-strategy","title":"12.1 Test Coverage Strategy","text":"<p>Critical models: 100% coverage - All business logic paths - All edge cases - All error conditions</p> <p>Important models: Main paths - Happy path - Common edge cases - Critical calculations</p> <p>Simple models: Edge cases only - NULL handling - Empty inputs - Boundary conditions</p>"},{"location":"models/model-testing/#122-test-organization","title":"12.2 Test Organization","text":"<p>By model:</p> <pre><code>tests/\n\u251c\u2500\u2500 test_customers.yaml      # All customer tests\n\u251c\u2500\u2500 test_orders.yaml          # All order tests\n\u2514\u2500\u2500 test_revenue.yaml         # All revenue tests\n</code></pre> <p>By domain:</p> <pre><code>tests/\n\u251c\u2500\u2500 customers/\n\u2502   \u251c\u2500\u2500 test_customer_revenue.yaml\n\u2502   \u251c\u2500\u2500 test_customer_segments.yaml\n\u2502   \u2514\u2500\u2500 test_customer_metrics.yaml\n\u251c\u2500\u2500 orders/\n\u2502   \u251c\u2500\u2500 test_order_aggregation.yaml\n\u2502   \u2514\u2500\u2500 test_order_validation.yaml\n</code></pre> <p>By scenario:</p> <pre><code>tests/\n\u251c\u2500\u2500 test_happy_path.yaml      # Happy path tests\n\u251c\u2500\u2500 test_edge_cases.yaml       # Edge case tests\n\u2514\u2500\u2500 test_integration.yaml      # Integration tests\n</code></pre> <p>Recommendation: Start with one file per model, split when files get large.</p>"},{"location":"models/model-testing/#123-test-naming","title":"12.3 Test Naming","text":"<p>Conventions:</p> <ul> <li><code>test_&lt;model_name&gt;</code> - Basic test</li> <li><code>test_&lt;model_name&gt;_&lt;scenario&gt;</code> - Specific scenario</li> <li><code>test_&lt;model_name&gt;_edge_case</code> - Edge case</li> </ul> <p>Examples:</p> <pre><code>test_customer_revenue:              # Basic test\ntest_customer_revenue_empty:        # Empty input\ntest_customer_revenue_null:         # NULL handling\ntest_customer_revenue_multiple:     # Multiple orders\ntest_customer_revenue_high_value:   # High value scenario\n</code></pre>"},{"location":"models/model-testing/#124-test-data","title":"12.4 Test Data","text":"<p>Use realistic data:</p> <pre><code># \u2705 Good: Realistic values\ninputs:\n  staging.orders:\n    rows:\n      - order_id: 1\n        customer_id: 100\n        amount: 49.99\n        status: 'completed'\n\n# \u274c Avoid: Unrealistic values\ninputs:\n  staging.orders:\n    rows:\n      - order_id: 999999\n        customer_id: 0\n        amount: 999999.99\n</code></pre> <p>Keep tests small:</p> <pre><code># \u2705 Good: Minimal data\ninputs:\n  staging.orders:\n    rows:\n      - order_id: 1\n        customer_id: 100\n        amount: 50.00\n\n# \u274c Avoid: Too much data\ninputs:\n  staging.orders:\n    rows:\n      # ... 100+ rows\n</code></pre> <p>Document test data:</p> <pre><code>test_customer_revenue:\n  description: 'Tests revenue aggregation with multiple orders per customer'\n  model: analytics.customer_revenue\n  inputs:\n    staging.orders:\n      rows:\n        # Customer 100: 2 orders totaling $125\n        - order_id: 1\n          customer_id: 100\n          amount: 50.00\n        - order_id: 2\n          customer_id: 100\n          amount: 75.00\n        # Customer 200: 1 order totaling $100\n        - order_id: 3\n          customer_id: 200\n          amount: 100.00\n  outputs:\n    query:\n      rows:\n        - customer_id: 100\n          total_revenue: 125.00\n        - customer_id: 200\n          total_revenue: 100.00\n</code></pre>"},{"location":"models/model-testing/#125-test-maintenance","title":"12.5 Test Maintenance","text":"<p>Keep tests up to date:</p> <ul> <li>Update tests when model logic changes</li> <li>Remove obsolete tests</li> <li>Refactor duplicate test code</li> </ul> <p>Review test failures:</p> <ul> <li>Don't ignore failures</li> <li>Fix tests or fix models</li> <li>Understand why tests fail</li> </ul> <p>Test performance:</p> <ul> <li>Keep tests fast (&lt; 1 second each)</li> <li>Use minimal data</li> <li>Avoid expensive operations</li> </ul>"},{"location":"models/model-testing/#126-what-to-test","title":"12.6 What to Test","text":"<p>\u2705 Test:</p> <ul> <li>Business logic (calculations, aggregations)</li> <li>Edge cases (NULLs, empty inputs, boundaries)</li> <li>Filter logic (WHERE clauses)</li> <li>Join logic (LEFT, INNER, etc.)</li> <li>Transformations (CASE statements, functions)</li> </ul> <p>\u274c Don't test:</p> <ul> <li>Simple pass-through (SELECT * FROM ...)</li> <li>Trivial filters (WHERE status = 'active')</li> <li>Database functions (use database tests)</li> <li>Performance (use benchmarks)</li> </ul>"},{"location":"models/model-testing/#127-test-independence","title":"12.7 Test Independence","text":"<p>Each test should:</p> <ul> <li>Be independent (no shared state)</li> <li>Be repeatable (same result every time)</li> <li>Be isolated (doesn't affect other tests)</li> </ul> <p>Avoid:</p> <ul> <li>Tests that depend on execution order</li> <li>Tests that modify shared fixtures</li> <li>Tests that depend on external state</li> </ul> <p>\u2191 Back to Top</p>"},{"location":"models/model-testing/#13-quick-reference","title":"13. Quick Reference","text":""},{"location":"models/model-testing/#131-test-structure-cheat-sheet","title":"13.1 Test Structure Cheat Sheet","text":"<pre><code>test_name:\n  model: schema.table_name          # Required\n  gateway: gateway_name             # Optional\n  schema: custom_schema             # Optional\n  description: 'Test description'  # Optional\n  inputs:                           # Required (if model has dependencies)\n    upstream_model:\n      rows:                         # YAML dictionaries\n        - col1: val1\n      format: csv                   # Or CSV format\n      query: SELECT ...             # Or SQL query\n      path: fixtures/data.csv       # Or external file\n      columns:                      # Optional type hints\n        col1: INT\n  outputs:                          # Required\n    partial: true                   # Optional: partial validation\n    query:                          # Query output\n      rows:\n        - col1: expected_val1\n      partial: true                 # Optional: partial for query only\n    ctes:                           # Optional: CTE outputs\n      cte_name:\n        rows:\n          - col1: expected_val1\n  vars:                             # Optional: Macro variables\n    execution_time: '2024-01-01 12:00:00'\n    start: '2024-01-01'\n    end: '2024-01-02'\n    gateway: 'dev'\n</code></pre>"},{"location":"models/model-testing/#132-common-test-patterns","title":"13.2 Common Test Patterns","text":"<p>Basic test:</p> <pre><code>test_basic:\n  model: analytics.customers\n  inputs:\n    staging.orders:\n      rows:\n        - order_id: 1\n          customer_id: 100\n  outputs:\n    query:\n      rows:\n        - customer_id: 100\n</code></pre> <p>Incremental test:</p> <pre><code>test_incremental:\n  model: analytics.daily_revenue\n  vars:\n    start: '2024-01-01'\n    end: '2024-01-01'\n  inputs:\n    staging.orders:\n      rows:\n        - order_id: 1\n          order_date: '2024-01-01'\n  outputs:\n    query:\n      rows:\n        - revenue_date: '2024-01-01'\n</code></pre> <p>CTE test:</p> <pre><code>test_with_cte:\n  model: analytics.customers\n  inputs:\n    staging.orders:\n      rows:\n        - order_id: 1\n  outputs:\n    ctes:\n      filtered_orders:\n        rows:\n          - order_id: 1\n    query:\n      rows:\n        - customer_id: 100\n</code></pre> <p>Partial validation:</p> <pre><code>test_partial:\n  model: analytics.customers\n  outputs:\n    query:\n      partial: true\n      rows:\n        - customer_id: 100\n          # Other columns ignored\n</code></pre>"},{"location":"models/model-testing/#133-cli-commands","title":"13.3 CLI Commands","text":"<pre><code># Run all tests\nvulcan test\n\n# Run specific test\nvulcan test tests/test_customers.yaml::test_customer_revenue\n\n# Run tests matching pattern\nvulcan test tests/test_customer*\n\n# Verbose output\nvulcan test -v\n\n# Preserve fixtures\nvulcan test --preserve-fixtures\n\n# Generate test\nvulcan create_test analytics.customers \\\n  --query staging.orders \"SELECT * FROM staging.orders LIMIT 10\" \\\n  --var start '2024-01-01' \\\n  --var end '2024-01-01'\n</code></pre>"},{"location":"models/model-testing/#134-decision-tree","title":"13.4 Decision Tree","text":"<pre><code>Need to test a model?\n\u2502\n\u251c\u2500 Model has complex logic?\n\u2502  \u2514\u2500 YES \u2192 Write comprehensive tests\n\u2502     \u251c\u2500 Test happy path\n\u2502     \u251c\u2500 Test edge cases\n\u2502     \u2514\u2500 Test error conditions\n\u2502\n\u251c\u2500 Model is simple (pass-through)?\n\u2502  \u2514\u2500 YES \u2192 Skip tests or test edge cases only\n\u2502\n\u251c\u2500 Model feeds critical downstream?\n\u2502  \u2514\u2500 YES \u2192 Write tests (prevent breaking changes)\n\u2502\n\u2514\u2500 Model is experimental?\n   \u2514\u2500 YES \u2192 Test after stabilization\n</code></pre>"},{"location":"models/model-testing/#135-test-checklist","title":"13.5 Test Checklist","text":"<p>Before writing test:</p> <ul> <li> Understand model logic</li> <li> Identify edge cases</li> <li> Determine test data needs</li> <li> Plan test scenarios</li> </ul> <p>Writing test:</p> <ul> <li> Use realistic test data</li> <li> Test happy path</li> <li> Test edge cases (NULLs, empty, boundaries)</li> <li> Validate all important columns</li> <li> Add description</li> </ul> <p>After writing test:</p> <ul> <li> Test passes</li> <li> Test is readable</li> <li> Test is maintainable</li> <li> Test is fast (&lt; 1 second)</li> </ul> <p>\u2191 Back to Top</p>"},{"location":"models/model-testing/#summary","title":"Summary","text":"<p>You've learned comprehensive unit testing for Vulcan models:</p>"},{"location":"models/model-testing/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>Test Structure:</li> <li>YAML files in <code>tests/</code> directory</li> <li><code>inputs</code> for upstream models</li> <li><code>outputs</code> for expected results</li> <li> <p><code>vars</code> for macro variables</p> </li> <li> <p>Input Formats:</p> </li> <li>YAML dictionaries (default)</li> <li>CSV format</li> <li>SQL queries</li> <li> <p>External files</p> </li> <li> <p>Output Validation:</p> </li> <li>Query output</li> <li>CTE output</li> <li>Partial validation</li> <li> <p>Type checking</p> </li> <li> <p>Testing Patterns:</p> </li> <li>Basic aggregations</li> <li>Joins</li> <li>NULL handling</li> <li>Edge cases</li> <li> <p>Complex calculations</p> </li> <li> <p>Incremental Models:</p> </li> <li>Set <code>start</code>, <code>end</code> in <code>vars</code></li> <li>Test time filtering logic</li> <li> <p>Test lookback behavior</p> </li> <li> <p>Python Models:</p> </li> <li>Test DataFrame outputs</li> <li>Test complex logic</li> <li> <p>Test multiple dependencies</p> </li> <li> <p>Best Practices:</p> </li> <li>Test critical models thoroughly</li> <li>Keep tests small and fast</li> <li>Use realistic data</li> <li>Maintain tests over time</li> </ol>"},{"location":"models/model-testing/#related-topics","title":"Related Topics","text":"<ul> <li>Chapter 2: Models - Model basics</li> <li>Chapter 4: Audits - Data quality validation</li> <li>Chapter 5: Quality Checks - Monitoring and trends</li> </ul>"},{"location":"models/model-testing/#next-steps","title":"Next Steps","text":"<ol> <li>Write tests for your critical models</li> <li>Add tests to CI/CD pipeline</li> <li>Use <code>vulcan create_test</code> to bootstrap tests</li> <li>Review and maintain tests regularly</li> </ol> <p>Congratulations! You've completed the Model Testing chapter.</p> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/","title":"Chapter 03: Semantic Layer","text":"<p>Add business context to your data models - The semantic layer bridges the gap between physical tables and business understanding, making your data accessible to business users and analytics tools without requiring SQL knowledge.</p>"},{"location":"semantic-layer/#prerequisites","title":"Prerequisites","text":"<p>Before diving into this chapter, you should have:</p>"},{"location":"semantic-layer/#required-knowledge","title":"Required Knowledge","text":"<p>Chapter 2: Models - Understanding of: - How Vulcan models work - Model structure and properties - Model columns and schemas - Basic SQL transformations</p> <p>YAML Syntax - Basic YAML structure (dictionaries, lists) - Multi-line strings (<code>|</code> syntax) - Indentation rules</p> <p>SQL Proficiency - Level 2 - Aggregations (<code>COUNT</code>, <code>SUM</code>, <code>AVG</code>, <code>MAX</code>, <code>MIN</code>) - <code>GROUP BY</code> clauses - Basic <code>WHERE</code> conditions - SQL expressions and calculations</p> <p>Dimensional Modeling Concepts (helpful but not required) - Star schema basics - Fact tables vs dimension tables - Measures vs dimensions</p>"},{"location":"semantic-layer/#optional-but-helpful","title":"Optional but Helpful","text":"<p>Analytics Tools - Understanding of how BI tools query data - Familiarity with metrics/KPIs concepts - API usage (for querying semantic layer)</p> <p>If you're coming from other semantic layers (like Cube.js, LookML, or dbt metrics), you'll find Vulcan's semantic layer familiar but with tighter integration to the data transformation layer.</p>"},{"location":"semantic-layer/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Introduction</li> <li>Quick Start</li> <li>Semantic Models &amp; Aliases</li> <li>Dimensions</li> <li>Measures</li> <li>Segments</li> <li>Joins</li> <li>Business Metrics</li> <li>Validation Overview</li> <li>Best Practices</li> <li>Quick Reference</li> <li>Summary and Next Steps</li> </ol>"},{"location":"semantic-layer/#1-introduction","title":"1. Introduction","text":""},{"location":"semantic-layer/#11-what-is-the-semantic-layer","title":"1.1 What is the Semantic Layer?","text":"<p>The semantic layer adds business context to your Vulcan data models. It transforms technical table structures into business-friendly definitions that can be queried without SQL knowledge.</p> <p>Key Insight: Your Vulcan model columns automatically become dimensions. The semantic layer adds measures, segments, joins, and metrics on top.</p>"},{"location":"semantic-layer/#12-core-concepts","title":"1.2 Core Concepts","text":"<p>Semantic Models - Map physical Vulcan models to business concepts - Reference your <code>models/*.sql</code> files - Provide business-friendly aliases - Expose dimensions, measures, segments, and joins</p> <p>Dimensions - Attributes for grouping and filtering - Automatically exposed from model columns - Answer \"by what?\" questions - Examples: <code>customer_tier</code>, <code>country</code>, <code>order_date</code></p> <p>Measures - Aggregated calculations - Answer \"how much?\" or \"how many?\" questions - SQL expressions like <code>SUM(amount)</code>, <code>COUNT(*)</code> - Examples: <code>total_revenue</code>, <code>customer_count</code>, <code>avg_order_value</code></p> <p>Segments - Reusable filter conditions - Define meaningful subsets of data - Answer \"which ones?\" questions - Examples: <code>active_customers</code>, <code>high_value</code>, <code>recent_signups</code></p> <p>Joins - Relationships between models - Connect semantic models together - Enable cross-model analysis - Examples: <code>orders \u2192 customers</code>, <code>subscriptions \u2192 customers</code></p> <p>Business Metrics - Complete analytical definitions - Combine measures with dimensions and time - Ready for time-series analysis - Examples: <code>monthly_revenue_by_tier</code>, <code>daily_active_users</code></p>"},{"location":"semantic-layer/#13-why-use-the-semantic-layer","title":"1.3 Why Use the Semantic Layer?","text":"<p>Without Semantic Layer: <pre><code>-- Business users must write SQL\nSELECT \n  DATE_TRUNC('month', order_date) as month,\n  customer_tier,\n  SUM(CASE WHEN status = 'completed' THEN amount ELSE 0 END) as revenue\nFROM orders o\nJOIN customers c ON o.customer_id = c.customer_id\nWHERE order_date &gt;= '2024-01-01'\nGROUP BY 1, 2;\n</code></pre></p> <p>With Semantic Layer: <pre><code># Define once in YAML\nmeasures:\n  total_revenue:\n    type: sum\n    expression: \"SUM(amount)\"\n    filters:\n      - \"status = 'completed'\"\n\n# Business users query via API\nGET /api/metrics/revenue?\n  time=order_date\n  &amp;dimensions=customer_tier\n  &amp;granularity=month\n  &amp;start=2024-01-01\n</code></pre></p> <p>Benefits:</p> <p>For Developers: - \u2705 Define metrics once, use everywhere - \u2705 Automatic validation catches errors early - \u2705 Version-controlled business logic - \u2705 Consistent calculations across tools</p> <p>For Business Users: - \u2705 Self-service analytics without SQL - \u2705 Consistent metric definitions - \u2705 Trusted, validated data - \u2705 Works across BI tools and APIs</p> <p>For Organizations: - \u2705 Single source of truth for metrics - \u2705 Faster time to insights - \u2705 Reduced data team bottleneck - \u2705 Better data governance</p>"},{"location":"semantic-layer/#14-file-organization","title":"1.4 File Organization","text":"<p>Semantic layer definitions are YAML files in the <code>semantics/</code> directory:</p> <pre><code>project/\n\u251c\u2500\u2500 models/           # Vulcan data models (.sql files)\n\u2502   \u251c\u2500\u2500 customers.sql\n\u2502   \u251c\u2500\u2500 orders.sql\n\u2502   \u2514\u2500\u2500 events.sql\n\u2502\n\u251c\u2500\u2500 semantics/        # Semantic layer definitions (YAML)\n\u2502   \u251c\u2500\u2500 customers.yml\n\u2502   \u251c\u2500\u2500 orders.yml\n\u2502   \u2514\u2500\u2500 metrics.yml\n\u2502\n\u2514\u2500\u2500 config.yaml\n</code></pre> <p>Loading: Vulcan automatically merges all YAML files in <code>semantics/</code> directory.</p> <p>File naming: Use any name ending in <code>.yml</code> or <code>.yaml</code>. Organize by domain or model for clarity.</p> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/#2-quick-start","title":"2. Quick Start","text":""},{"location":"semantic-layer/#21-your-first-semantic-model","title":"2.1 Your First Semantic Model","text":"<p>Start with a simple model that references your Vulcan data model:</p> <pre><code># semantics/customers.yml\nmodels:\n  analytics.customers:  # Physical model name (dictionary key)\n    alias: customers     # Business-friendly semantic alias\n</code></pre> <p>What happens: - All columns from <code>analytics.customers</code> become dimensions automatically - You can query <code>customers.customer_id</code>, <code>customers.customer_tier</code>, etc. - No additional configuration needed for basic use</p>"},{"location":"semantic-layer/#22-your-first-measure","title":"2.2 Your First Measure","text":"<p>Add a measure to calculate aggregations:</p> <pre><code>models:\n  analytics.customers:\n    alias: customers\n\n    measures:\n      total_customers:\n        type: count\n        expression: \"COUNT(*)\"\n        description: \"Total number of customers\"\n</code></pre> <p>Usage: <pre><code>GET /api/query?\n  model=customers\n  &amp;measures=total_customers\n</code></pre></p>"},{"location":"semantic-layer/#23-your-first-segment","title":"2.3 Your First Segment","text":"<p>Create a reusable filter:</p> <pre><code>models:\n  analytics.customers:\n    alias: customers\n\n    segments:\n      active_customers:\n        expression: \"status = 'active'\"\n        description: \"Customers with active subscriptions\"\n</code></pre> <p>Usage: <pre><code>GET /api/query?\n  model=customers\n  &amp;measures=total_customers\n  &amp;segments=active_customers\n</code></pre></p>"},{"location":"semantic-layer/#24-your-first-join","title":"2.4 Your First Join","text":"<p>Connect two models:</p> <pre><code># semantics/orders.yml\nmodels:\n  analytics.orders:\n    alias: orders\n\n    joins:\n      customers:\n        type: many_to_one\n        expression: \"orders.customer_id = customers.customer_id\"\n\n    measures:\n      total_revenue:\n        type: sum\n        expression: \"SUM(orders.amount)\"\n\n      enterprise_revenue:\n        type: sum\n        expression: \"SUM(orders.amount)\"\n        filters:\n          - \"customers.customer_tier = 'Enterprise'\"\n</code></pre>"},{"location":"semantic-layer/#25-your-first-business-metric","title":"2.5 Your First Business Metric","text":"<p>Combine measure, time, and dimensions:</p> <pre><code># semantics/metrics.yml\nmetrics:\n  monthly_revenue:\n    measure: orders.total_revenue\n    time: orders.order_date\n    dimensions:\n      - customers.customer_tier\n    description: \"Monthly revenue trends by customer tier\"\n</code></pre> <p>Usage: <pre><code>GET /api/metrics/monthly_revenue?\n  granularity=month\n  &amp;start=2024-01-01\n</code></pre></p>"},{"location":"semantic-layer/#26-complete-quick-start-example","title":"2.6 Complete Quick Start Example","text":"<pre><code># semantics/customers.yml\nmodels:\n  analytics.customers:\n    alias: customers\n\n    dimensions:\n      excludes:\n        - password_hash\n        - internal_notes\n\n    measures:\n      total_customers:\n        type: count\n        expression: \"COUNT(*)\"\n\n      active_customers:\n        type: count\n        expression: \"COUNT(*)\"\n        filters:\n          - \"status = 'active'\"\n\n    segments:\n      high_value:\n        expression: \"total_spent &gt; 10000\"\n</code></pre> <p>Run validation: <pre><code>vulcan plan\n</code></pre></p> <p>Vulcan automatically validates your semantic layer definitions.</p> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/#3-semantic-models-aliases","title":"3. Semantic Models &amp; Aliases","text":""},{"location":"semantic-layer/#31-basic-structure","title":"3.1 Basic Structure","text":"<p>Every semantic model references a physical Vulcan model:</p> <pre><code>models:\n  &lt;physical_model_name&gt;:          # REQUIRED: Dictionary key\n    name: &lt;business_name&gt;         # Required for schema.table format (or use 'alias:')\n    dimensions: ...               # Optional\n    measures: ...                 # Optional\n    segments: ...                 # Optional\n    joins: ...                    # Optional\n</code></pre>"},{"location":"semantic-layer/#32-model-name-physical-reference","title":"3.2 Model Name: Physical Reference","text":"<p>The <code>name</code> field must match your Vulcan model exactly:</p> <pre><code>models:\n  analytics.customers:  # References models/customers.sql\n    alias: customers\n  raw.orders:          # References external or raw model\n    alias: orders\n  events:              # Simple table name (no schema)\n    alias: events\n</code></pre> <p>Rules: - Must match exact Vulcan model name (case-sensitive) - Can be <code>schema.table</code> or just <code>table</code> - Model must exist in your Vulcan project</p>"},{"location":"semantic-layer/#33-alias-business-name","title":"3.3 Alias: Business Name","text":"<p>The <code>alias</code> provides a consumer-friendly name:</p> <pre><code>models:\n  # With schema prefix - name/alias REQUIRED\n  analytics.dim_customers:\n    alias: customers  # \u2705 Hide technical naming\n\n  # Simple table name - name optional (defaults to model name)\n  events:\n    # No name needed, 'events' is already clean\n</code></pre> <p>Why Aliases Matter: - Hides technical schemas and prefixes (<code>dim_</code>, <code>fact_</code>, etc.) - Provides stable API as physical names change - Makes metrics and joins readable</p> <p>Alias Requirements: - \u2705 Required for <code>schema.table</code> format - \u2705 Must be alphanumeric with underscores: <code>users</code>, <code>order_items</code> - \u274c Cannot contain: dots (<code>.</code>), hyphens (<code>-</code>), spaces - \u2705 Keep it consumer-friendly</p>"},{"location":"semantic-layer/#34-using-aliases-in-references","title":"3.4 Using Aliases in References","text":"<p>Once defined, use aliases everywhere:</p> <p>In Joins: <pre><code>joins:\n  customers:  # \u2705 Use alias\n    type: many_to_one\n    expression: \"orders.customer_id = customers.customer_id\"\n</code></pre></p> <p>In Metrics: <pre><code>metrics:\n  revenue_by_tier:\n    measure: orders.total_revenue     # Use alias\n    time: orders.order_date\n    dimensions:\n      - customers.customer_tier       # Use alias\n</code></pre></p> <p>In APIs: <pre><code>GET /api/query?\n  model=customers              # Use alias\n  &amp;measures=total_customers\n  &amp;dimensions=customer_tier\n</code></pre></p>"},{"location":"semantic-layer/#35-multiple-models-in-one-file","title":"3.5 Multiple Models in One File","text":"<p>You can define multiple semantic models in one YAML file:</p> <pre><code># semantics/sales.yml\nmodels:\n  analytics.customers:\n    alias: customers\n    measures: {...}\n\n  analytics.orders:\n    alias: orders\n    measures: {...}\n\n  analytics.products:\n    alias: products\n    measures: {...}\n</code></pre> <p>Or organize by domain in separate files - Vulcan merges them all automatically.</p>"},{"location":"semantic-layer/#36-complete-example","title":"3.6 Complete Example","text":"<pre><code># semantics/b2b_saas.yml\nmodels:\n  # Customer model\n  analytics.dim_customers:\n    alias: customers\n\n    dimensions:\n      includes:\n        - customer_id\n        - customer_tier\n        - signup_date\n\n    measures:\n      total_customers:\n        type: count\n        expression: \"COUNT(*)\"\n\n    segments:\n      active:\n        expression: \"status = 'active'\"\n\n  # Subscription model\n  analytics.fact_subscriptions:\n    alias: subscriptions\n\n    measures:\n      total_mrr:\n        type: sum\n        expression: \"SUM(mrr)\"\n        format: currency\n\n    joins:\n      customers:\n        type: many_to_one\n        expression: \"subscriptions.customer_id = customers.customer_id\"\n</code></pre> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/#4-dimensions","title":"4. Dimensions","text":"<p>Dimensions are columns you can filter and group by. By default, all columns from your Vulcan model become dimensions automatically.</p>"},{"location":"semantic-layer/#41-default-behavior","title":"4.1 Default Behavior","text":"<pre><code>-- Your Vulcan model\nMODEL (name analytics.customers);\nSELECT\n  customer_id,\n  email,\n  customer_tier,\n  signup_date,\n  company_name\nFROM raw.customers;\n</code></pre> <pre><code># Semantic model - all columns available as dimensions\nmodels:\n  analytics.customers:\n    alias: customers\n    # No dimensions block needed!\n    # All 5 columns are automatically dimensions:\n    # - customers.customer_id\n    # - customers.email\n    # - customers.customer_tier\n    # - customers.signup_date\n    # - customers.company_name\n</code></pre> <p>Key Point: You don't need to configure dimensions unless you want to hide columns or add metadata.</p>"},{"location":"semantic-layer/#42-column-selection","title":"4.2 Column Selection","text":"<p>Control which columns are exposed:</p>"},{"location":"semantic-layer/#option-1-exclude-columns-most-common","title":"Option 1: Exclude Columns (Most Common)","text":"<pre><code>dimensions:\n  excludes:\n    - password_hash       # Hide sensitive data\n    - internal_notes\n    - deleted_at\n</code></pre> <p>Use when: You want most columns, but need to hide a few sensitive ones.</p>"},{"location":"semantic-layer/#option-2-include-only-specific-columns","title":"Option 2: Include Only Specific Columns","text":"<pre><code>dimensions:\n  includes:\n    - customer_id\n    - customer_tier\n    - signup_date\n    - company_name\n</code></pre> <p>Use when: Working with sensitive data models where you only expose specific columns.</p> <p>\u26a0\ufe0f Important: Cannot use both <code>includes</code> and <code>excludes</code> - they're mutually exclusive.</p>"},{"location":"semantic-layer/#43-column-overrides","title":"4.3 Column Overrides","text":"<p>Add business context to important dimensions:</p> <pre><code>dimensions:\n  excludes:\n    - internal_id\n\n  overrides:\n    customer_tier:\n      tags:\n        - segmentation\n        - marketing\n      meta:\n        business_owner: \"Marketing Team\"\n        display_name: \"Customer Tier\"\n        sort_order: [\"Free\", \"Pro\", \"Enterprise\"]\n\n    signup_date:\n      tags:\n        - temporal\n        - acquisition\n      meta:\n        business_owner: \"Growth Team\"\n        format: \"YYYY-MM-DD\"\n</code></pre> <p>What You Can Add: - <code>tags</code> - Categorization labels (array) - <code>meta</code> - Free-form metadata (dictionary)</p> <p>Common Tags: - Domain: <code>sales</code>, <code>marketing</code>, <code>finance</code>, <code>product</code> - Type: <code>temporal</code>, <code>geographic</code>, <code>categorical</code>, <code>identifier</code> - Sensitivity: <code>pii</code>, <code>sensitive</code>, <code>public</code> - Usage: <code>high_priority</code>, <code>deprecated</code>, <code>experimental</code></p> <p>Common Metadata Fields: - <code>business_owner</code> - Team responsible - <code>display_name</code> - UI-friendly name - <code>possible_values</code> - Valid values for enums - <code>format</code> - Display format hints - Custom fields as needed</p>"},{"location":"semantic-layer/#44-dimension-proxies-cross-model-dimensions","title":"4.4 Dimension Proxies (Cross-Model Dimensions)","text":"<p>When you need to use a measure from a joined model as a dimension, use dimension proxies:</p> <pre><code>models:\n  analytics.customers:\n    alias: customers\n\n    joins:\n      orders:\n        type: one_to_many\n        expression: \"customers.customer_id = orders.customer_id\"\n\n    dimensions:\n      proxies:\n        order_count_dim:\n          measure: orders.total_orders  # Reference: model.measure\n\n    segments:\n      has_orders:\n        expression: \"{order_count_dim} &gt; 0\"  # Use in segments\n</code></pre> <p>Use Case: Segments can only reference columns from their own model. Dimension proxies let you use measures from joined models in segment expressions.</p> <p>Syntax: Reference dimension proxies with <code>{proxy_name}</code> in segment expressions.</p>"},{"location":"semantic-layer/#45-complete-example","title":"4.5 Complete Example","text":"<pre><code>models:\n  analytics.customers:\n    alias: customers\n\n    dimensions:\n      # Hide sensitive columns\n      excludes:\n        - ssn\n        - password_hash\n        - internal_notes\n\n      # Add context to key dimensions\n      overrides:\n        customer_tier:\n          tags:\n            - segmentation\n            - revenue\n            - core_dimension\n          meta:\n            business_owner: \"Revenue Team\"\n            display_name: \"Customer Tier\"\n            sort_order: [\"Free\", \"Starter\", \"Pro\", \"Enterprise\"]\n\n        signup_date:\n          tags:\n            - temporal\n            - acquisition\n          meta:\n            business_owner: \"Growth Team\"\n            timezone: \"UTC\"\n</code></pre>"},{"location":"semantic-layer/#46-best-practices","title":"4.6 Best Practices","text":"<p>1. Minimize Excludes</p> <pre><code># \u274c Bad: Excluding too much\ndimensions:\n  excludes:\n    - col1, col2, col3, col4, col5, col6, col7, col8\n\n# \u2705 Good: Design models with right columns\n# Fix in Vulcan model instead:\nSELECT\n  customer_id,\n  email,\n  customer_tier\nFROM customers;  -- Only select needed columns\n</code></pre> <p>2. Tag Consistently</p> <pre><code># \u2705 Good: Consistent tagging across models\n# In customers.yml\n- name: customer_tier\n  tags: [segmentation, revenue]\n\n# In subscriptions.yml\n- name: plan_type\n  tags: [segmentation, revenue]  # Same tags\n\n# Now easy to find all segmentation dimensions\n</code></pre> <p>3. Document Business Logic</p> <pre><code>- name: customer_status\n  tags: [lifecycle, critical]\n  meta:\n    business_owner: \"Operations\"\n    logic: \"active = has subscription, churned = cancelled &gt; 30 days\"\n</code></pre> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/#5-measures","title":"5. Measures","text":"<p>Measures are aggregations that calculate metrics from your data. They answer \"how much?\" or \"how many?\" questions.</p>"},{"location":"semantic-layer/#51-basic-structure","title":"5.1 Basic Structure","text":"<pre><code>measures:\n  measure_name:                  # REQUIRED: Dictionary key\n    type: count                  # REQUIRED: count, sum, avg, count_distinct, etc.\n    expression: \"SQL_EXPRESSION\" # REQUIRED\n    description: \"...\"           # Recommended\n    filters: []                  # Optional\n    format: currency             # Optional\n    tags: []                     # Optional\n    meta: {}                     # Optional\n</code></pre>"},{"location":"semantic-layer/#52-simple-measures","title":"5.2 Simple Measures","text":"<pre><code>measures:\n  total_customers:\n    type: count\n    expression: \"COUNT(*)\"\n    description: \"Total number of customers\"\n\n  total_revenue:\n    type: sum\n    expression: \"SUM(amount)\"\n    description: \"Sum of all order amounts\"\n\n  avg_order_value:\n    type: avg\n    expression: \"AVG(amount)\"\n    description: \"Average order value\"\n</code></pre>"},{"location":"semantic-layer/#53-measures-with-filters","title":"5.3 Measures with Filters","text":"<p>Apply conditions to focus calculations:</p> <pre><code>measures:\n  completed_revenue:\n    type: sum\n    expression: \"SUM(amount)\"\n    filters:\n      - \"status = 'completed'\"\n    description: \"Revenue from completed orders only\"\n\n  active_customers_30d:\n    type: count_distinct\n    expression: \"customer_id\"\n    filters:\n      - \"last_activity_date &gt;= CURRENT_DATE - INTERVAL '30 days'\"\n    description: \"Customers active in last 30 days\"\n\n  enterprise_revenue:\n    type: sum\n    expression: \"SUM(mrr)\"\n    filters:\n      - \"plan_type = 'Enterprise'\"\n      - \"status = 'active'\"\n    description: \"MRR from active Enterprise customers\"\n</code></pre> <p>Multiple filters are combined with AND logic.</p>"},{"location":"semantic-layer/#54-referencing-other-measures","title":"5.4 Referencing Other Measures","text":"<p>Build measures on top of other measures:</p> <pre><code>measures:\n  total_revenue:\n    type: sum\n    expression: \"SUM(amount)\"\n\n  total_orders:\n    type: count\n    expression: \"COUNT(*)\"\n\n  avg_order_value:\n    type: expression\n    expression: \"total_revenue / NULLIF(total_orders, 0)\"\n    description: \"Average order value (revenue per order)\"\n</code></pre> <p>Vulcan automatically resolves dependencies.</p> <p>\u26a0\ufe0f Important: Always handle division by zero with <code>NULLIF</code>:</p> <pre><code># \u274c Bad: Can cause division by zero\n- name: avg_value\n  expression: \"SUM(amount) / COUNT(*)\"\n\n# \u2705 Good: Use NULLIF\n- name: avg_value\n  expression: \"SUM(amount) / NULLIF(COUNT(*), 0)\"\n</code></pre>"},{"location":"semantic-layer/#55-cross-model-measures","title":"5.5 Cross-Model Measures","text":"<p>Reference columns from joined models:</p> <pre><code>models:\n  analytics.orders:\n    alias: orders\n\n    joins:\n      customers:  # Define join first\n        type: many_to_one\n        expression: \"orders.customer_id = customers.customer_id\"\n\n    measures:\n      enterprise_revenue:\n        type: sum\n        expression: \"SUM(orders.amount)\"\n        filters:\n          - \"customers.customer_tier = 'Enterprise'\"\n        description: \"Revenue from Enterprise customers\"\n</code></pre> <p>\u26a0\ufe0f Requirement: Join must be defined before referencing other model's columns.</p>"},{"location":"semantic-layer/#56-measure-formats","title":"5.6 Measure Formats","text":"<p>Hint at how values should be displayed:</p> <pre><code>measures:\n  total_revenue:\n    type: sum\n    expression: \"SUM(amount)\"\n    format: currency\n    description: \"Total revenue in USD\"\n\n  conversion_rate:\n    type: expression\n    expression: \"...\"\n    format: percentage\n    description: \"Conversion rate as percentage\"\n\n  avg_response_time:\n    type: avg\n    expression: \"AVG(response_ms)\"\n    format: duration_ms\n    description: \"Average response time in milliseconds\"\n</code></pre> <p>Common formats: <code>currency</code>, <code>percentage</code>, <code>number</code>, <code>duration_ms</code>, <code>bytes</code></p>"},{"location":"semantic-layer/#57-common-patterns","title":"5.7 Common Patterns","text":""},{"location":"semantic-layer/#pattern-1-distinct-counts","title":"Pattern 1: Distinct Counts","text":"<pre><code>measures:\n  unique_customers:\n    type: count_distinct\n    expression: \"COUNT(DISTINCT customer_id)\"\n\n  unique_products_sold:\n    type: count_distinct\n    expression: \"COUNT(DISTINCT product_id)\"\n</code></pre>"},{"location":"semantic-layer/#pattern-2-ratios-and-percentages","title":"Pattern 2: Ratios and Percentages","text":"<pre><code>measures:\n  conversion_rate:\n    type: expression\n    expression: |\n      COUNT(DISTINCT CASE WHEN converted THEN user_id END) * 100.0 \n      / NULLIF(COUNT(DISTINCT user_id), 0)\n    format: percentage\n</code></pre>"},{"location":"semantic-layer/#pattern-3-conditional-aggregations","title":"Pattern 3: Conditional Aggregations","text":"<pre><code>measures:\n  high_value_revenue:\n    type: sum\n    expression: |\n      SUM(CASE \n        WHEN amount &gt; 1000 THEN amount \n        ELSE 0 \n      END)\n</code></pre> <p>TIP: Use filters instead of CASE when possible:</p> <pre><code># \u274c Less clear\n- name: active_revenue\n  expression: \"SUM(CASE WHEN status = 'active' THEN amount ELSE 0 END)\"\n\n# \u2705 More clear\n- name: active_revenue\n  expression: \"SUM(amount)\"\n  filters:\n    - \"status = 'active'\"\n</code></pre>"},{"location":"semantic-layer/#58-complete-example","title":"5.8 Complete Example","text":"<pre><code>models:\n  analytics.subscriptions:\n    alias: subscriptions\n\n    joins:\n      customers:\n        type: many_to_one\n        expression: \"subscriptions.customer_id = customers.customer_id\"\n\n    measures:\n      # Basic aggregations\n      total_subscriptions:\n        type: count\n        expression: \"COUNT(*)\"\n        description: \"Total number of subscriptions\"\n        tags: [count, subscription]\n\n      total_mrr:\n        type: sum\n        expression: \"SUM(mrr)\"\n        description: \"Monthly Recurring Revenue\"\n        format: currency\n        tags: [revenue, financial, kpi]\n\n      # Filtered measures\n      active_mrr:\n        type: sum\n        expression: \"SUM(mrr)\"\n        filters:\n          - \"status = 'active'\"\n        description: \"MRR from active subscriptions only\"\n        format: currency\n\n      # Complex calculations\n      avg_mrr_per_customer:\n        type: number\n        expression: \"SUM(mrr) / NULLIF(COUNT(DISTINCT customer_id), 0)\"\n        description: \"Average MRR per customer\"\n        format: currency\n\n      # Cross-model measures\n      revenue_per_tier:\n        type: expression\n        expression: \"SUM(subscriptions.mrr) / NULLIF(COUNT(DISTINCT customers.customer_tier), 0)\"\n        description: \"Average revenue per customer tier\"\n        format: currency\n</code></pre>"},{"location":"semantic-layer/#59-best-practices","title":"5.9 Best Practices","text":"<p>1. Always Handle Division by Zero</p> <pre><code># \u2705 Good: Use NULLIF\n- name: avg_value\n  expression: \"SUM(amount) / NULLIF(COUNT(*), 0)\"\n</code></pre> <p>2. Use Filters Instead of CASE</p> <pre><code># \u2705 Good: More readable\n- name: active_revenue\n  expression: \"SUM(amount)\"\n  filters:\n    - \"status = 'active'\"\n</code></pre> <p>3. Document Business Logic</p> <pre><code>- name: net_revenue\n  expression: \"SUM(amount) - SUM(refund_amount)\"\n  description: \"Gross revenue minus refunds\"\n  meta:\n    business_owner: \"Finance Team\"\n    calculation_rules: \"Excludes cancelled orders, includes partial refunds\"\n</code></pre> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/#6-segments","title":"6. Segments","text":"<p>Segments are reusable filter conditions that define meaningful subsets of your data. They answer \"which ones?\" questions.</p>"},{"location":"semantic-layer/#61-basic-structure","title":"6.1 Basic Structure","text":"<pre><code>segments:\n  segment_name:                  # REQUIRED: Dictionary key\n    expression: \"WHERE_CLAUSE\"   # REQUIRED (without WHERE keyword)\n    description: \"...\"           # Recommended\n    tags: []                     # Optional\n    meta: {}                     # Optional\n</code></pre>"},{"location":"semantic-layer/#62-simple-segments","title":"6.2 Simple Segments","text":"<pre><code>segments:\n  active_customers:\n    expression: \"status = 'active'\"\n    description: \"Customers with active subscriptions\"\n\n  high_value:\n    expression: \"total_spent &gt; 10000\"\n    description: \"Customers who spent over $10K\"\n\n  recent_signups:\n    expression: \"signup_date &gt;= CURRENT_DATE - INTERVAL '30 days'\"\n    description: \"Customers who signed up in last 30 days\"\n</code></pre>"},{"location":"semantic-layer/#63-complex-segments","title":"6.3 Complex Segments","text":"<p>Use boolean logic for sophisticated filters:</p> <pre><code>segments:\n  at_risk_customers:\n    expression: |\n      status = 'active' \n      AND plan_type = 'Free'\n      AND signup_date &lt; CURRENT_DATE - INTERVAL '90 days'\n      AND last_activity_date &lt; CURRENT_DATE - INTERVAL '14 days'\n    description: \"Free users inactive for 14+ days (churn risk)\"\n\n  enterprise_segment:\n    expression: |\n      (plan_type = 'Enterprise' OR plan_type = 'Business')\n      AND seats &gt; 50\n      AND mrr &gt; 5000\n    description: \"Large enterprise accounts\"\n</code></pre>"},{"location":"semantic-layer/#64-segments-are-model-scoped","title":"6.4 Segments are Model-Scoped","text":"<p>\u26a0\ufe0f Important: Segments can ONLY reference columns from their own model.</p> <pre><code>models:\n  analytics.customers:\n    alias: customers\n\n    segments:\n      # \u2705 Good: References own columns\n      high_value:\n        expression: \"total_spent &gt; 10000\"\n\n      # \u274c Bad: Cannot reference other models directly\n      has_orders:\n        expression: \"orders.order_count &gt; 0\"  # ERROR!\n</code></pre> <p>Solution: Use dimension proxies for cross-model segments (see Section 4.4).</p>"},{"location":"semantic-layer/#65-using-dimension-proxies","title":"6.5 Using Dimension Proxies","text":"<p>When you need to segment based on measures from joined models:</p> <pre><code>models:\n  analytics.customers:\n    alias: customers\n\n    joins:\n      orders:\n        type: one_to_many\n        expression: \"customers.customer_id = orders.customer_id\"\n\n    dimensions:\n      proxies:\n        order_count_dim:\n          measure: orders.total_orders\n\n    segments:\n      has_orders:\n        expression: \"{order_count_dim} &gt; 0\"\n        description: \"Customers with at least one order\"\n\n      frequent_buyers:\n        expression: \"{order_count_dim} &gt;= 10\"\n        description: \"Customers with 10+ orders\"\n</code></pre> <p>Syntax: Reference dimension proxies with <code>{proxy_name}</code> in segment expressions.</p>"},{"location":"semantic-layer/#66-common-patterns","title":"6.6 Common Patterns","text":""},{"location":"semantic-layer/#date-based-segments","title":"Date-Based Segments","text":"<pre><code>segments:\n  recent_signups:\n    expression: \"signup_date &gt;= CURRENT_DATE - INTERVAL '7 days'\"\n    description: \"Signed up in last 7 days\"\n\n  dormant_users:\n    expression: \"last_activity_date &lt; CURRENT_DATE - INTERVAL '90 days'\"\n    description: \"Inactive for 90+ days\"\n</code></pre>"},{"location":"semantic-layer/#enumcategory-segments","title":"Enum/Category Segments","text":"<pre><code>segments:\n  enterprise_and_business:\n    expression: \"plan_type IN ('Enterprise', 'Business')\"\n    description: \"Premium plan customers\"\n\n  paid_plans:\n    expression: \"plan_type != 'Free'\"\n    description: \"All paid subscription plans\"\n</code></pre>"},{"location":"semantic-layer/#numeric-range-segments","title":"Numeric Range Segments","text":"<pre><code>segments:\n  mid_market:\n    expression: \"mrr BETWEEN 1000 AND 10000\"\n    description: \"Mid-market segment ($1K-$10K MRR)\"\n\n  high_engagement:\n    expression: \"engagement_score &gt;= 0.7\"\n    description: \"Users with 70%+ engagement\"\n</code></pre>"},{"location":"semantic-layer/#67-complete-example","title":"6.7 Complete Example","text":"<pre><code>models:\n  analytics.customers:\n    alias: customers\n\n    joins:\n      subscriptions:\n        type: one_to_many\n        expression: \"customers.customer_id = subscriptions.customer_id\"\n\n    dimensions:\n      proxies:\n        subscription_count_dim:\n          measure: subscriptions.total_subscriptions\n\n    segments:\n      # Lifecycle segments\n      active:\n        expression: \"status = 'active'\"\n        description: \"Active customers\"\n        tags: [lifecycle, core]\n\n      # Value-based segments\n      high_value:\n        expression: \"total_spent &gt; 10000\"\n        description: \"Lifetime spend over $10K\"\n        tags: [segmentation, revenue]\n\n      # Behavior-based segments (using dimension proxies)\n      has_subscription:\n        expression: \"{subscription_count_dim} &gt; 0\"\n        description: \"Customers with at least one subscription\"\n        tags: [behavior, conversion]\n</code></pre>"},{"location":"semantic-layer/#68-best-practices","title":"6.8 Best Practices","text":"<p>1. Make Segments Mutually Exclusive (When Appropriate)</p> <pre><code># \u2705 Good: Clear lifecycle stages\nsegments:\n  trial:\n    expression: \"status = 'trial'\"\n\n  active:\n    expression: \"status = 'active'\"\n\n  churned:\n    expression: \"status = 'churned'\"\n</code></pre> <p>2. Document Business Logic</p> <pre><code>- name: at_risk\n  expression: \"...\"\n  description: \"Customers likely to churn based on engagement\"\n  meta:\n    business_owner: \"Customer Success\"\n    criteria: \"Active plan, no activity 14+ days, engagement score &lt; 0.3\"\n</code></pre> <p>3. Use Descriptive Names</p> <pre><code># \u274c Bad: Unclear\n- name: seg_1\n  expression: \"...\"\n\n# \u2705 Good: Self-explanatory\n- name: high_value_at_risk\n  expression: \"...\"\n</code></pre> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/#7-joins","title":"7. Joins","text":"<p>Joins define relationships between semantic models, enabling cross-model measures and dimensions.</p>"},{"location":"semantic-layer/#71-basic-structure","title":"7.1 Basic Structure","text":"<pre><code>joins:\n  &lt;target_model_alias&gt;:           # REQUIRED: Dictionary key\n    type: &lt;relationship_type&gt;    # REQUIRED: one_to_many, many_to_one, one_to_one\n    expression: \"JOIN_CONDITION\"  # REQUIRED\n    description: \"...\"            # Optional\n    meta: {}                      # Optional\n</code></pre>"},{"location":"semantic-layer/#72-relationship-types","title":"7.2 Relationship Types","text":"Relationship Meaning Example <code>one_to_many</code> 1 \u2192 N Customer \u2192 Orders (1 customer, many orders) <code>many_to_one</code> N \u2192 1 Orders \u2192 Customer (many orders, 1 customer) <code>one_to_one</code> 1 \u2192 1 User \u2192 Profile (1 user, 1 profile)"},{"location":"semantic-layer/#73-simple-join","title":"7.3 Simple Join","text":"<pre><code>models:\n  analytics.orders:\n    alias: orders\n\n    joins:\n      customers:  # Target semantic model alias (dictionary key)\n        type: many_to_one\n        expression: \"orders.customer_id = customers.customer_id\"\n        description: \"Orders belong to one customer\"\n</code></pre>"},{"location":"semantic-layer/#74-join-expression-rules","title":"7.4 Join Expression Rules","text":"<p>\u2705 Complete SQL with full model references:</p> <pre><code># \u2705 Good: Full model.column syntax\nexpression: \"orders.customer_id = customers.customer_id\"\n\n# \u274c Bad: Incomplete\nexpression: \"customer_id = customer_id\"  # Which table?\n\n# \u274c Bad: Column only\nexpression: \"customer_id\"  # Not a join condition\n</code></pre> <p>Use semantic model aliases (not physical table names):</p> <pre><code># \u2705 Good: Use alias\n- name: customers  # Semantic alias\n  expression: \"orders.customer_id = customers.customer_id\"\n\n# \u274c Bad: Don't use physical name\n- name: analytics.dim_customers  # Physical name\n  expression: \"...\"\n</code></pre>"},{"location":"semantic-layer/#75-multiple-joins","title":"7.5 Multiple Joins","text":"<pre><code>models:\n  analytics.orders:\n    alias: orders\n\n    joins:\n      # Join to customers\n      customers:\n        type: many_to_one\n        expression: \"orders.customer_id = customers.customer_id\"\n        description: \"Order's customer\"\n\n      # Join to products\n      products:\n        type: many_to_one\n        expression: \"orders.product_id = products.product_id\"\n        description: \"Ordered product\"\n</code></pre>"},{"location":"semantic-layer/#76-using-joins-in-measures","title":"7.6 Using Joins in Measures","text":"<p>Once joined, reference other model's columns:</p> <pre><code>models:\n  analytics.orders:\n    alias: orders\n\n    joins:\n      customers:\n        type: many_to_one\n        expression: \"orders.customer_id = customers.customer_id\"\n\n    measures:\n      # Reference orders columns (same model)\n      total_revenue:\n        type: sum\n        expression: \"SUM(orders.amount)\"\n\n      # Reference customers columns (joined model)\n      enterprise_revenue:\n        type: sum\n        expression: \"SUM(orders.amount)\"\n        filters:\n          - \"customers.customer_tier = 'Enterprise'\"\n        description: \"Revenue from Enterprise customers\"\n</code></pre>"},{"location":"semantic-layer/#77-bidirectional-joins","title":"7.7 Bidirectional Joins","text":"<p>Define joins from both sides:</p> <pre><code># customers.yml\nmodels:\n  analytics.customers:\n    alias: customers\n\n    joins:\n      orders:\n        type: one_to_many\n        expression: \"customers.customer_id = orders.customer_id\"\n</code></pre> <pre><code># orders.yml\nmodels:\n  analytics.orders:\n    alias: orders\n\n    joins:\n      customers:\n        type: many_to_one\n        expression: \"orders.customer_id = customers.customer_id\"\n</code></pre> <p>Now you can start from either model.</p>"},{"location":"semantic-layer/#78-complete-example","title":"7.8 Complete Example","text":"<pre><code># orders.yml\nmodels:\n  analytics.orders:\n    alias: orders\n\n    joins:\n      # Customer relationship\n      customers:\n        type: many_to_one\n        expression: \"orders.customer_id = customers.customer_id\"\n        description: \"Customer who placed the order\"\n\n      # Product relationship\n      products:\n        type: many_to_one\n        expression: \"orders.product_id = products.product_id\"\n        description: \"Product that was ordered\"\n\n    measures:\n      # Order metrics\n      total_orders:\n        type: count\n        expression: \"COUNT(*)\"\n\n      total_revenue:\n        type: sum\n        expression: \"SUM(orders.amount)\"\n\n      # Customer-segmented metrics\n      enterprise_revenue:\n        type: sum\n        expression: \"SUM(orders.amount)\"\n        filters:\n          - \"customers.customer_tier = 'Enterprise'\"\n</code></pre>"},{"location":"semantic-layer/#79-best-practices","title":"7.9 Best Practices","text":"<p>1. Define Joins at Source of Foreign Key</p> <pre><code># \u2705 Good: Define in orders (has customer_id FK)\nmodels:\n  analytics.orders:\n    joins:\n      customers:\n        type: many_to_one\n        expression: \"orders.customer_id = customers.customer_id\"\n</code></pre> <p>2. Document Cardinality</p> <pre><code>joins:\n  customers:\n    type: many_to_one\n    description: \"Orders belong to one customer\"\n    meta:\n      cardinality: \"N:1\"\n      expected_match_rate: 0.99\n</code></pre> <p>3. Use Full Model.Column Syntax</p> <pre><code># \u2705 Good: Clear and explicit\nexpression: \"orders.customer_id = customers.customer_id\"\n\n# \u274c Bad: Ambiguous\nexpression: \"customer_id = customer_id\"\n</code></pre> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/#8-business-metrics","title":"8. Business Metrics","text":"<p>Business metrics combine measures with dimensions to create complete analytical definitions ready for time-series analysis.</p>"},{"location":"semantic-layer/#81-basic-structure","title":"8.1 Basic Structure","text":"<pre><code>metrics:\n  metric_name:                   # REQUIRED\n    measure: model.measure_name  # REQUIRED\n    time: model.date_column      # REQUIRED\n    dimensions: []               # Optional\n    description: \"...\"           # Optional\n    tags: []                     # Optional\n    meta: {}                     # Optional\n</code></pre>"},{"location":"semantic-layer/#82-simple-metric","title":"8.2 Simple Metric","text":"<pre><code>metrics:\n  monthly_revenue:\n    measure: orders.total_revenue      # Which measure to calculate\n    time: orders.order_date            # Time dimension for analysis\n    description: \"Monthly revenue trends\"\n</code></pre> <p>Usage: <pre><code>GET /api/metrics/monthly_revenue?\n  granularity=month\n  &amp;start=2024-01-01\n  &amp;end=2024-12-31\n</code></pre></p>"},{"location":"semantic-layer/#83-metric-with-dimensions","title":"8.3 Metric with Dimensions","text":"<p>Add dimensions for slicing and grouping:</p> <pre><code>metrics:\n  revenue_by_tier:\n    measure: orders.total_revenue\n    time: orders.order_date\n    dimensions:\n      - customers.customer_tier      # Group by tier\n      - customers.country            # And country\n    description: \"Revenue trends by customer tier and country\"\n</code></pre> <p>Usage: <pre><code>GET /api/metrics/revenue_by_tier?\n  granularity=month\n  &amp;dimensions=customer_tier,country\n  &amp;start=2024-01-01\n</code></pre></p>"},{"location":"semantic-layer/#84-cross-model-metrics","title":"8.4 Cross-Model Metrics","text":"<p>Combine measures and dimensions from multiple models:</p> <pre><code>metrics:\n  product_revenue_by_customer_segment:\n    measure: orders.total_revenue      # From orders\n    time: orders.order_date            # From orders\n    dimensions:\n      - products.category              # From products\n      - products.brand\n      - customers.customer_tier        # From customers\n      - customers.region\n    description: \"Product revenue segmented by customer demographics\"\n</code></pre> <p>\u26a0\ufe0f Requirement: Proper joins must be defined between models.</p>"},{"location":"semantic-layer/#85-reference-format","title":"8.5 Reference Format","text":"<p>Always use dot notation with semantic model aliases:</p> <pre><code># \u2705 Good: Use aliases\nmeasure: orders.total_revenue     # alias.measure_name\ntime: orders.order_date           # alias.column_name\ndimensions:\n  - customers.customer_tier       # alias.column_name\n\n# \u274c Bad: Don't use physical names\nmeasure: analytics.fact_orders.revenue\ntime: order_date  # Missing alias\n</code></pre>"},{"location":"semantic-layer/#86-time-granularity","title":"8.6 Time Granularity","text":"<p>Metrics support different time granularities at query time:</p> <pre><code>metrics:\n  revenue_trends:\n    measure: orders.total_revenue\n    time: orders.order_date\n    description: \"Revenue at any time granularity\"\n</code></pre> <p>Query with different granularities: <pre><code># Daily\nGET /api/metrics/revenue_trends?granularity=day\n\n# Weekly\nGET /api/metrics/revenue_trends?granularity=week\n\n# Monthly\nGET /api/metrics/revenue_trends?granularity=month\n\n# Quarterly\nGET /api/metrics/revenue_trends?granularity=quarter\n\n# Yearly\nGET /api/metrics/revenue_trends?granularity=year\n</code></pre></p>"},{"location":"semantic-layer/#87-complete-example","title":"8.7 Complete Example","text":"<pre><code>metrics:\n  # Simple revenue metric\n  daily_revenue:\n    measure: orders.total_revenue\n    time: orders.order_date\n    description: \"Daily revenue trends\"\n    tags: [revenue, financial, kpi]\n    meta:\n      business_owner: \"Finance Team\"\n      refresh_schedule: \"hourly\"\n\n  # Customer acquisition\n  customer_acquisition_trend:\n    measure: customers.new_signups\n    time: customers.signup_date\n    dimensions:\n      - customers.signup_channel\n      - customers.customer_tier\n      - customers.country\n    description: \"Customer acquisition by channel, tier, and geography\"\n    tags: [acquisition, growth, customer]\n\n  # Cross-model metric\n  product_performance:\n    measure: orders.total_revenue\n    time: orders.order_date\n    dimensions:\n      - products.category\n      - products.brand\n      - customers.customer_tier\n    description: \"Product revenue by category, brand, and customer segment\"\n    tags: [revenue, products, segmentation]\n</code></pre>"},{"location":"semantic-layer/#88-best-practices","title":"8.8 Best Practices","text":"<p>1. Name Metrics Descriptively</p> <pre><code># \u274c Bad: Vague\nmetrics:\n  metric_1: ...\n  rev: ...\n\n# \u2705 Good: Self-explanatory\nmetrics:\n  monthly_revenue_by_tier: ...\n  daily_active_users: ...\n</code></pre> <p>2. Include Essential Dimensions</p> <pre><code># \u274c Too few: Limited analysis\nmetrics:\n  revenue:\n    measure: orders.total_revenue\n    time: orders.order_date\n    # Missing dimensions\n\n# \u2705 Good: Key business dimensions\nmetrics:\n  revenue_analysis:\n    measure: orders.total_revenue\n    time: orders.order_date\n    dimensions:\n      - customers.customer_tier\n      - customers.region\n      - products.category\n</code></pre> <p>3. Document Business Context</p> <pre><code>metrics:\n  net_revenue_retention:\n    measure: subscriptions.nrr\n    time: subscriptions.cohort_month\n    description: \"Net Revenue Retention: expansion minus churn\"\n    meta:\n      business_owner: \"Finance Team\"\n      calculation: \"(Starting MRR + Expansion - Churn) / Starting MRR\"\n      benchmark: \"&gt;110% is good for SaaS\"\n</code></pre> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/#9-validation-overview","title":"9. Validation Overview","text":"<p>When you run <code>vulcan plan</code> or start your Vulcan project, all semantic models are automatically validated. This catches configuration errors before any queries run.</p>"},{"location":"semantic-layer/#91-what-gets-validated","title":"9.1 What Gets Validated","text":"<ul> <li>\u2705 All column references in measures exist</li> <li>\u2705 All column references in segments exist</li> <li>\u2705 Join expressions reference valid columns</li> <li>\u2705 Cross-model references have valid join paths</li> <li>\u2705 Metric references point to existing models</li> <li>\u2705 Semantic aliases are properly defined</li> </ul>"},{"location":"semantic-layer/#92-when-validation-fails","title":"9.2 When Validation Fails","text":"<p>Vulcan shows detailed error messages with: - File name and location - Which object has the error - What's wrong - How to fix it</p> <p>Example: <pre><code>Model `customers` (semantics/customers.yml)\nmeasure 'total_revenue' references unknown field 'amount_total'\n(must be a column or measure in current model)\n</code></pre></p>"},{"location":"semantic-layer/#93-common-validation-errors","title":"9.3 Common Validation Errors","text":""},{"location":"semantic-layer/#error-1-unknown-column","title":"Error 1: Unknown Column","text":"<p>Error: <pre><code>Model `customers` (semantics/customers.yml)\nmeasure 'bad_measure' references unknown field 'revenue_amount'\n</code></pre></p> <p>Fix: Check your Vulcan model's column names and update the semantic definition.</p>"},{"location":"semantic-layer/#error-2-missing-alias","title":"Error 2: Missing Alias","text":"<p>Error: <pre><code>Semantic model 'analytics.customers' must have a 'name' or 'alias' field\n</code></pre></p> <p>Fix: Add name/alias: <pre><code>models:\n  analytics.customers:\n    alias: customers  # \u2705 Add this\n</code></pre></p>"},{"location":"semantic-layer/#error-3-cross-model-reference-without-join","title":"Error 3: Cross-Model Reference Without Join","text":"<p>Error: <pre><code>Model `orders` (semantics/orders.yml)\nmeasure 'customer_revenue' references 'customers.total_spent' but no join path exists\n</code></pre></p> <p>Fix: Add join definition: <pre><code>models:\n  analytics.orders:\n    alias: orders\n\n    joins:\n      customers:  # \u2705 Define join\n        type: many_to_one\n        expression: \"orders.customer_id = customers.customer_id\"\n</code></pre></p>"},{"location":"semantic-layer/#error-4-segment-cross-model-reference","title":"Error 4: Segment Cross-Model Reference","text":"<p>Error: <pre><code>Model `customers` (semantics/customers.yml)\nsegment 'has_orders' references unknown identifier 'orders.order_count'\n</code></pre></p> <p>Fix: Use dimension proxies: <pre><code>dimensions:\n  proxies:\n    order_count_dim:\n      measure: orders.order_count\n\nsegments:\n  has_orders:\n    expression: \"{order_count_dim} &gt; 0\"  # \u2705 Use dimension proxy\n</code></pre></p>"},{"location":"semantic-layer/#94-validation-workflow","title":"9.4 Validation Workflow","text":"<pre><code>1. Write semantic YAML\n   \u2193\n2. Run: vulcan plan\n   \u2193\n3. Validation runs automatically\n   \u2193\n4a. \u2705 Valid \u2192 Success!\n   OR\n4b. \u274c Invalid \u2192 Error message with location\n   \u2193\n5. Fix error in YAML\n   \u2193\n6. Go to step 2\n</code></pre>"},{"location":"semantic-layer/#95-quick-troubleshooting-checklist","title":"9.5 Quick Troubleshooting Checklist","text":"<p>When you get a validation error:</p> <ul> <li> Check file path - Error shows which YAML file</li> <li> Check object name - Error shows which measure/segment/join</li> <li> Check column spelling - Verify exact column names in Vulcan model</li> <li> Check aliases - Use semantic aliases, not physical names</li> <li> Check joins - Cross-model refs need join definitions</li> <li> Check dimension proxies - Segments using cross-model measures need dimension proxies</li> </ul> <p>For complete validation reference: See Chapter 3D: Semantic Validation</p> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/#10-best-practices","title":"10. Best Practices","text":""},{"location":"semantic-layer/#101-naming-conventions","title":"10.1 Naming Conventions","text":"<p>Semantic Model Aliases: <pre><code># \u2705 Good: Consumer-friendly\nalias: customers\nalias: orders\nalias: subscriptions\n\n# \u274c Bad: Technical naming\nalias: dim_customers\nalias: fact_orders\n</code></pre></p> <p>Measures: <pre><code># \u2705 Good: Descriptive\n- name: total_revenue\n- name: active_customer_count\n- name: avg_order_value\n\n# \u274c Bad: Vague\n- name: rev\n- name: count1\n- name: avg\n</code></pre></p> <p>Segments: <pre><code># \u2705 Good: Self-explanatory\n- name: active_customers\n- name: high_value_at_risk\n- name: enterprise_segment\n\n# \u274c Bad: Unclear\n- name: seg1\n- name: active\n- name: hv\n</code></pre></p>"},{"location":"semantic-layer/#102-file-organization","title":"10.2 File Organization","text":"<p>By Domain: <pre><code>semantics/\n\u251c\u2500\u2500 customers.yml      # Customer-related models\n\u251c\u2500\u2500 orders.yml         # Order-related models\n\u251c\u2500\u2500 products.yml        # Product-related models\n\u2514\u2500\u2500 metrics.yml         # Business metrics\n</code></pre></p> <p>By Model: <pre><code>semantics/\n\u251c\u2500\u2500 customers.yml      # customers model + related\n\u251c\u2500\u2500 orders.yml         # orders model + related\n\u2514\u2500\u2500 subscriptions.yml  # subscriptions model + related\n</code></pre></p> <p>Vulcan merges all files - choose organization that makes sense for your team.</p>"},{"location":"semantic-layer/#103-when-to-use-what","title":"10.3 When to Use What","text":"<p>Use Dimensions When: - \u2705 You want to filter or group by a column - \u2705 Column is already in your model - \u2705 You need to add metadata/tags</p> <p>Use Measures When: - \u2705 You need to calculate aggregations - \u2705 You need to combine multiple columns - \u2705 You need filtered calculations</p> <p>Use Segments When: - \u2705 You have reusable filter conditions - \u2705 Business users need predefined subsets - \u2705 You want to document business logic</p> <p>Use Joins When: - \u2705 You need cross-model analysis - \u2705 You want to reference other model's columns - \u2705 You're building star/snowflake schemas</p> <p>Use Metrics When: - \u2705 You need time-series analysis - \u2705 You want complete analytical definitions - \u2705 You're exposing KPIs to business users</p>"},{"location":"semantic-layer/#104-integration-with-models","title":"10.4 Integration with Models","text":"<p>Design Models with Semantic Layer in Mind:</p> <pre><code>-- \u2705 Good: Clean column names, business-friendly\nMODEL (name analytics.customers);\nSELECT\n  customer_id,\n  customer_tier,      -- Good dimension name\n  signup_date,        -- Good time dimension\n  total_spent         -- Good for segments\nFROM raw.customers;\n\n-- \u274c Bad: Technical naming, hard to use semantically\nMODEL (name analytics.dim_cust);\nSELECT\n  cust_id,\n  tier_cd,\n  signup_dt,\n  tot_spent_amt\nFROM raw.customers;\n</code></pre> <p>Key Insight: Model columns automatically become dimensions. Design models with business users in mind.</p>"},{"location":"semantic-layer/#105-incremental-development","title":"10.5 Incremental Development","text":"<p>Start Simple:</p> <pre><code># Step 1: Basic model\nmodels:\n  analytics.customers:\n    alias: customers\n\n# Validate\n# Step 2: Add measures\nmodels:\n  analytics.customers:\n    alias: customers\n    measures:\n      total_customers:\n        type: count\n        expression: \"COUNT(*)\"\n\n# Validate\n# Step 3: Add segments, joins, etc.\n</code></pre> <p>Build incrementally - validate after each change.</p>"},{"location":"semantic-layer/#106-documentation","title":"10.6 Documentation","text":"<p>Always Add Descriptions:</p> <pre><code>measures:\n  total_revenue:\n    type: sum\n    expression: \"SUM(amount)\"\n    description: \"Total revenue from all completed orders\"  # \u2705 Always include\n    meta:\n      business_owner: \"Finance Team\"\n      calculation_method: \"Sum of order amounts excluding refunds\"\n</code></pre> <p>Document Business Logic:</p> <pre><code>segments:\n  at_risk:\n    expression: \"...\"\n    description: \"Customers likely to churn\"\n    meta:\n      business_owner: \"Customer Success\"\n      criteria: \"Active plan, no activity 14+ days, engagement score &lt; 0.3\"\n      action: \"Trigger outreach campaign\"\n</code></pre> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/#11-quick-reference","title":"11. Quick Reference","text":""},{"location":"semantic-layer/#111-syntax-cheat-sheet","title":"11.1 Syntax Cheat Sheet","text":"<p>Semantic Model: <pre><code>models:\n  &lt;physical_model&gt;:  # REQUIRED (e.g., analytics.customers)\n    name: &lt;business_name&gt;  # Required for schema.table (e.g., customers)\n    dimensions: ...\n    measures: ...\n    segments: ...\n    joins: ...\n</code></pre></p> <p>Dimensions: <pre><code>dimensions:\n  excludes: [...]           # Hide columns\n  includes: [...]           # Show only these\n  proxies:                  # Cross-model measures as dimensions\n    &lt;proxy_name&gt;:\n      measure: &lt;model.measure&gt;\n  overrides:                # Add tags/meta\n    &lt;column&gt;:\n      tags: [...]\n      meta: {...}\n</code></pre></p> <p>Measures: <pre><code>measures:\n  &lt;name&gt;:                  # REQUIRED (dictionary key)\n    type: &lt;type&gt;           # REQUIRED (count, sum, avg, expression, etc.)\n    expression: \"&lt;SQL&gt;\"     # REQUIRED\n    filters: [...]          # Optional\n    format: currency        # Optional\n    description: \"...\"      # Recommended\n</code></pre></p> <p>Segments: <pre><code>segments:\n  &lt;name&gt;:                  # REQUIRED (dictionary key)\n    expression: \"&lt;WHERE&gt;\"   # REQUIRED (no WHERE keyword)\n    description: \"...\"      # Recommended\n</code></pre></p> <p>Joins: <pre><code>joins:\n  &lt;target_alias&gt;:          # REQUIRED (dictionary key)\n    type: &lt;type&gt;           # REQUIRED (one_to_one, one_to_many, many_to_one)\n    expression: \"&lt;JOIN&gt;\"    # REQUIRED (model.column = model.column)\n</code></pre></p> <p>Business Metrics: <pre><code>metrics:\n  &lt;metric_name&gt;:           # REQUIRED\n    measure: &lt;model.measure&gt;  # REQUIRED\n    time: &lt;model.column&gt;       # REQUIRED\n    dimensions: [...]         # Optional\n</code></pre></p>"},{"location":"semantic-layer/#112-decision-trees","title":"11.2 Decision Trees","text":"<p>Which Component Should I Use?</p> <pre><code>Need to filter/group by column?\n\u251c\u2500 YES \u2192 Use DIMENSION\n\u2502\nNeed to calculate aggregation?\n\u251c\u2500 YES \u2192 Use MEASURE\n\u2502\nNeed reusable filter condition?\n\u251c\u2500 YES \u2192 Use SEGMENT\n\u2502\nNeed to connect models?\n\u251c\u2500 YES \u2192 Use JOIN\n\u2502\nNeed time-series analysis?\n\u2514\u2500 YES \u2192 Use METRIC\n</code></pre> <p>Do I Need an Alias?</p> <pre><code>Physical model name format?\n\u251c\u2500 schema.table \u2192 YES, alias REQUIRED\n\u2514\u2500 table \u2192 NO, alias optional\n</code></pre> <p>Can Segments Reference Other Models?</p> <pre><code>Need cross-model segment?\n\u251c\u2500 YES \u2192 Use DIMENSION PROXY\n\u2502  1. Define join\n\u2502  2. Create dimension proxy\n\u2502  3. Use {proxy_name} in segment\n\u2514\u2500 NO \u2192 Use model columns directly\n</code></pre>"},{"location":"semantic-layer/#113-common-patterns","title":"11.3 Common Patterns","text":"<p>Pattern 1: Basic Model <pre><code>models:\n  analytics.customers:\n    alias: customers\n    measures:\n      total_customers:\n        type: count\n        expression: \"COUNT(*)\"\n</code></pre></p> <p>Pattern 2: Filtered Measure <pre><code>measures:\n  active_revenue:\n    type: sum\n    expression: \"SUM(amount)\"\n    filters:\n      - \"status = 'active'\"\n</code></pre></p> <p>Pattern 3: Cross-Model Measure <pre><code>joins:\n  customers:\n    type: many_to_one\n    expression: \"orders.customer_id = customers.customer_id\"\n\nmeasures:\n  enterprise_revenue:\n    expression: \"SUM(orders.amount)\"\n    filters:\n      - \"customers.customer_tier = 'Enterprise'\"\n</code></pre></p> <p>Pattern 4: Dimension Proxy Segment <pre><code>dimensions:\n  proxies:\n    order_count_dim:\n      measure: orders.total_orders\n\nsegments:\n  has_orders:\n    expression: \"{order_count_dim} &gt; 0\"\n</code></pre></p> <p>Pattern 5: Time-Series Metric <pre><code>metrics:\n  monthly_revenue:\n    measure: orders.total_revenue\n    time: orders.order_date\n    dimensions:\n      - customers.customer_tier\n</code></pre></p>"},{"location":"semantic-layer/#114-reference-format-rules","title":"11.4 Reference Format Rules","text":"<p>Always Use Dot Notation: - Measures: <code>model.measure_name</code> - Dimensions: <code>model.column_name</code> - Time: <code>model.date_column</code></p> <p>Use Semantic Aliases: - \u2705 <code>customers.customer_tier</code> - \u274c <code>analytics.dim_customers.customer_tier</code></p> <p>Cross-Model References: - \u2705 <code>customers.customer_tier</code> (requires join) - \u274c <code>customer_tier</code> (ambiguous)</p> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/#12-summary-and-next-steps","title":"12. Summary and Next Steps","text":""},{"location":"semantic-layer/#121-what-youve-learned","title":"12.1 What You've Learned","text":"<p>Core Concepts: 1. Semantic Models - Map physical models to business concepts 2. Dimensions - Columns for filtering and grouping (auto-exposed) 3. Measures - Aggregated calculations (<code>SUM</code>, <code>COUNT</code>, etc.) 4. Segments - Reusable filter conditions 5. Joins - Relationships between models 6. Business Metrics - Complete analytical definitions with time</p> <p>Key Principles: - Model columns automatically become dimensions - Use aliases for consumer-friendly names - Segments are model-scoped (use dimension proxies for cross-model) - Always use dot notation: <code>model.field</code> - Validation catches errors automatically</p>"},{"location":"semantic-layer/#122-next-steps","title":"12.2 Next Steps","text":"<p>Continue Learning:</p> <ul> <li>Chapter 3A: YAML Reference - Complete syntax reference, all options</li> <li>Chapter 3B: Advanced Measures - Complex expressions, patterns, performance</li> <li>Chapter 3C: Advanced Joins - Cross-model analysis, complex relationships</li> <li>Chapter 3D: Semantic Validation - Complete validation rules, troubleshooting</li> </ul> <p>Related Chapters:</p> <ul> <li>Chapter 2: Models - Understanding model structure</li> <li>Chapter 6: APIs - Querying semantic layer via APIs</li> </ul>"},{"location":"semantic-layer/#123-additional-resources","title":"12.3 Additional Resources","text":"<ul> <li>Examples - <code>examples/b2b_saas/semantics/</code> in your Vulcan installation</li> <li>Validation Reference - <code>readings/SEMANTIC_VALIDATIONS.md</code></li> <li>API Documentation - See Chapter 6 for querying semantic layer</li> </ul> <p>Congratulations! You now have a solid foundation in Vulcan's semantic layer. You can: - \u2705 Create semantic models with measures and dimensions - \u2705 Build reusable segments - \u2705 Connect models with joins - \u2705 Define business metrics for time-series analysis - \u2705 Understand validation and troubleshooting basics</p> <p>Happy modeling!</p> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/joins/","title":"Chapter 3C: Advanced Joins","text":"<p>Cross-model analysis patterns and advanced join techniques - Multi-model joins, complex join conditions, join path optimization, and cross-model analytical patterns.</p>"},{"location":"semantic-layer/joins/#prerequisites","title":"Prerequisites","text":"<p>Before diving into this chapter, you should have:</p>"},{"location":"semantic-layer/joins/#required-knowledge","title":"Required Knowledge","text":"<p>Chapter 3: Semantic Layer - Understanding of: - Basic join syntax - Relationship types (one_to_one, one_to_many, many_to_one) - Cross-model references</p> <p>Chapter 3A: YAML Reference - Understanding of: - Complete join field reference - Join expression format</p> <p>SQL Proficiency - Level 3 - JOIN syntax and types - Multi-table joins - Join optimization concepts</p>"},{"location":"semantic-layer/joins/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Introduction</li> <li>Join Relationship Patterns</li> <li>Multi-Model Joins</li> <li>Complex Join Conditions</li> <li>Join Path Optimization</li> <li>Cross-Model Analysis Patterns</li> <li>Join Graph Management</li> <li>Best Practices</li> <li>Troubleshooting</li> <li>Summary</li> </ol>"},{"location":"semantic-layer/joins/#1-introduction","title":"1. Introduction","text":""},{"location":"semantic-layer/joins/#11-what-are-advanced-joins","title":"1.1 What Are Advanced Joins?","text":"<p>Advanced joins enable sophisticated cross-model analysis:</p> <ul> <li>Multi-model joins - Connecting 3+ models in a single query</li> <li>Complex join conditions - Multi-column joins, conditional joins</li> <li>Join path optimization - Efficient traversal of join graphs</li> <li>Cross-model measures - Aggregations spanning multiple models</li> <li>Join graph management - Organizing and validating join relationships</li> </ul>"},{"location":"semantic-layer/joins/#12-join-graph-concepts","title":"1.2 Join Graph Concepts","text":"<p>Join Graph: - Network of models connected by joins - Models are nodes, joins are edges - Must be acyclic (no circular dependencies) - Determines which models can be queried together</p> <p>Join Path: - Sequence of joins connecting two models - Used to resolve cross-model references - Optimized for query performance</p> <p>Example Join Graph: <pre><code>customers \u2190\u2192 orders \u2190\u2192 products\n     \u2193\nsubscriptions \u2190\u2192 plans\n</code></pre></p> <p>From this graph: - <code>customers</code> can join to <code>orders</code>, <code>subscriptions</code> - <code>orders</code> can join to <code>customers</code>, <code>products</code> - <code>customers</code> can reach <code>products</code> via <code>orders</code> (2-hop path)</p>"},{"location":"semantic-layer/joins/#13-when-to-use-advanced-joins","title":"1.3 When to Use Advanced Joins","text":"<p>Use advanced joins when:</p> <ul> <li>Need to analyze data across multiple models</li> <li>Building complex analytical queries</li> <li>Creating cross-model measures and dimensions</li> <li>Optimizing query performance</li> <li>Organizing large semantic layers</li> </ul> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/joins/#2-join-relationship-patterns","title":"2. Join Relationship Patterns","text":""},{"location":"semantic-layer/joins/#21-one-to-many-pattern","title":"2.1 One-to-Many Pattern","text":"<p>Pattern: Parent \u2192 Children</p> <pre><code>models:\n  analytics.customers:\n    alias: customers\n\n    joins:\n      orders:\n        type: one_to_many\n        expression: \"customers.customer_id = orders.customer_id\"\n        description: \"Customer's orders\"\n</code></pre> <p>Use when: - One parent record has many child records - Examples: Customer \u2192 Orders, Product \u2192 Line Items, User \u2192 Sessions</p> <p>Query pattern: - Start from parent, aggregate children - Example: \"Total revenue per customer\"</p>"},{"location":"semantic-layer/joins/#22-many-to-one-pattern","title":"2.2 Many-to-One Pattern","text":"<p>Pattern: Children \u2192 Parent</p> <pre><code>models:\n  analytics.orders:\n    alias: orders\n\n    joins:\n      customers:\n        type: many_to_one\n        expression: \"orders.customer_id = customers.customer_id\"\n        description: \"Order's customer\"\n</code></pre> <p>Use when: - Many child records belong to one parent - Examples: Orders \u2192 Customer, Line Items \u2192 Product, Sessions \u2192 User</p> <p>Query pattern: - Start from children, enrich with parent attributes - Example: \"Orders with customer tier\"</p>"},{"location":"semantic-layer/joins/#23-one-to-one-pattern","title":"2.3 One-to-One Pattern","text":"<p>Pattern: Entity \u2194 Extension</p> <pre><code>models:\n  analytics.users:\n    alias: users\n\n    joins:\n      user_profiles:\n        type: one_to_one\n        expression: \"users.user_id = user_profiles.user_id\"\n        description: \"User's profile\"\n</code></pre> <p>Use when: - One record matches exactly one record - Examples: User \u2192 Profile, Order \u2192 Invoice, Product \u2192 Details</p> <p>Query pattern: - Enrich entity with extension attributes - Example: \"Users with profile completion status\"</p>"},{"location":"semantic-layer/joins/#24-many-to-many-pattern","title":"2.4 Many-to-Many Pattern","text":"<p>Pattern: Bridge Table</p> <pre><code>models:\n  analytics.orders:\n    alias: orders\n\n    joins:\n      products:\n        type: many_to_many\n        expression: |\n          orders.order_id = order_items.order_id\n          AND order_items.product_id = products.product_id\n        description: \"Products in order (via order_items)\"\n</code></pre> <p>Use when: - Many records relate to many records - Requires bridge/join table - Examples: Orders \u2194 Products (via order_items), Users \u2194 Groups (via memberships)</p> <p>Query pattern: - Aggregate across bridge table - Example: \"Total revenue by product category\"</p> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/joins/#3-multi-model-joins","title":"3. Multi-Model Joins","text":""},{"location":"semantic-layer/joins/#31-three-model-joins","title":"3.1 Three-Model Joins","text":"<p>Pattern: Chain Joins</p> <pre><code>models:\n  analytics.orders:\n    alias: orders\n\n    joins:\n      customers:\n        type: many_to_one\n        expression: \"orders.customer_id = customers.customer_id\"\n\n      products:\n        type: many_to_one\n        expression: \"orders.product_id = products.product_id\"\n\n    measures:\n      revenue_by_tier_and_category:\n        type: expression\n        expression: |\n          SUM(orders.amount) / \n          COUNT(DISTINCT customers.customer_tier) /\n          COUNT(DISTINCT products.category)\n        description: \"Average revenue per tier-category combination\"\n</code></pre> <p>Join path: <code>orders \u2192 customers</code> and <code>orders \u2192 products</code></p> <p>Query capabilities: - Filter orders by customer tier - Filter orders by product category - Aggregate across both dimensions</p>"},{"location":"semantic-layer/joins/#32-four-model-joins","title":"3.2 Four+ Model Joins","text":"<p>Pattern: Star Schema</p> <pre><code>models:\n  analytics.orders:\n    alias: orders\n\n    joins:\n      customers:\n        type: many_to_one\n        expression: \"orders.customer_id = customers.customer_id\"\n\n      products:\n        type: many_to_one\n        expression: \"orders.product_id = products.product_id\"\n\n      sales_reps:\n        type: many_to_one\n        expression: \"orders.sales_rep_id = sales_reps.rep_id\"\n\n      regions:\n        type: many_to_one\n        expression: \"orders.region_id = regions.region_id\"\n\n    measures:\n      revenue_by_all_dimensions:\n        type: sum\n        expression: \"SUM(orders.amount)\"\n        description: \"Revenue aggregatable by customer, product, rep, region\"\n</code></pre> <p>Join path: All models join directly to <code>orders</code> (fact table)</p> <p>Query capabilities: - Multi-dimensional analysis - Slice and dice across all dimensions - Complex filtering combinations</p>"},{"location":"semantic-layer/joins/#33-multi-hop-joins","title":"3.3 Multi-Hop Joins","text":"<p>Pattern: Transitive Joins</p> <pre><code>models:\n  analytics.customers:\n    alias: customers\n\n    joins:\n      orders:\n        type: one_to_many\n        expression: \"customers.customer_id = orders.customer_id\"\n\n      subscriptions:\n        type: one_to_many\n        expression: \"customers.customer_id = subscriptions.customer_id\"\n\nmodels:\n  analytics.orders:\n    alias: orders\n\n    joins:\n      products:\n        type: many_to_one\n        expression: \"orders.product_id = products.product_id\"\n</code></pre> <p>Join path: <code>customers \u2192 orders \u2192 products</code> (2 hops)</p> <p>Query capabilities: - From customers, can reach products via orders - Example: \"Customer's product categories\"</p> <p>Note: System automatically resolves multi-hop paths</p>"},{"location":"semantic-layer/joins/#34-bidirectional-joins","title":"3.4 Bidirectional Joins","text":"<p>Pattern: Define from Both Sides</p> <pre><code># customers.yml\nmodels:\n  analytics.customers:\n    alias: customers\n\n    joins:\n      orders:\n        type: one_to_many\n        expression: \"customers.customer_id = orders.customer_id\"\n\n# orders.yml\nmodels:\n  analytics.orders:\n    alias: orders\n\n    joins:\n      customers:\n        type: many_to_one\n        expression: \"orders.customer_id = customers.customer_id\"\n</code></pre> <p>Benefits: - Can start queries from either model - Clearer intent (relationship direction) - Better query optimization hints</p> <p>Best practice: Define bidirectional joins for commonly traversed relationships</p> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/joins/#4-complex-join-conditions","title":"4. Complex Join Conditions","text":""},{"location":"semantic-layer/joins/#41-multi-column-joins","title":"4.1 Multi-Column Joins","text":"<p>Pattern: Composite Keys</p> <pre><code>models:\n  analytics.inventory:\n    alias: inventory\n\n    joins:\n      product_locations:\n        type: many_to_one\n        expression: |\n          inventory.product_id = product_locations.product_id\n          AND inventory.warehouse_id = product_locations.warehouse_id\n        description: \"Product location details\"\n</code></pre> <p>Use when: - Join requires multiple columns - Composite primary/foreign keys - Multi-part relationships</p>"},{"location":"semantic-layer/joins/#42-conditional-joins","title":"4.2 Conditional Joins","text":"<p>Pattern: Join with Additional Conditions</p> <pre><code>models:\n  analytics.customers:\n    alias: customers\n\n    joins:\n      active_subscriptions:\n        type: one_to_many\n        expression: |\n          customers.customer_id = subscriptions.customer_id\n          AND subscriptions.status = 'active'\n        description: \"Customer's active subscriptions only\"\n\n      recent_orders:\n        type: one_to_many\n        expression: |\n          customers.customer_id = orders.customer_id\n          AND orders.order_date &gt;= CURRENT_DATE - INTERVAL '90 days'\n        description: \"Customer's orders in last 90 days\"\n</code></pre> <p>Use when: - Need filtered subset of joined data - Time-based joins - Status-based joins</p> <p>Note: Conditions are applied during join, not after</p>"},{"location":"semantic-layer/joins/#43-self-joins-via-separate-models","title":"4.3 Self-Joins (Via Separate Models)","text":"<p>Pattern: Hierarchical Relationships</p> <pre><code>models:\n  analytics.categories:\n    alias: categories\n\n    joins:\n      parent_categories:\n        type: many_to_one\n        expression: \"categories.parent_category_id = parent_categories.category_id\"\n        description: \"Parent category\"\n</code></pre> <p>Use when: - Hierarchical data structures - Self-referential relationships - Tree/graph structures</p> <p>Note: Requires separate model definition for parent entity</p>"},{"location":"semantic-layer/joins/#44-date-based-joins","title":"4.4 Date-Based Joins","text":"<p>Pattern: Temporal Relationships</p> <pre><code>models:\n  analytics.subscriptions:\n    alias: subscriptions\n\n    joins:\n      pricing_plans:\n        type: many_to_one\n        expression: |\n          subscriptions.plan_id = pricing_plans.plan_id\n          AND subscriptions.start_date &gt;= pricing_plans.effective_date\n          AND (subscriptions.end_date IS NULL OR subscriptions.end_date &lt;= pricing_plans.expiry_date)\n        description: \"Pricing plan active during subscription period\"\n</code></pre> <p>Use when: - Time-varying relationships - Historical data joins - Versioned dimension tables</p> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/joins/#5-join-path-optimization","title":"5. Join Path Optimization","text":""},{"location":"semantic-layer/joins/#51-direct-vs-indirect-paths","title":"5.1 Direct vs Indirect Paths","text":"<p>Pattern: Prefer Direct Joins</p> <pre><code># \u2705 Good: Direct join\nmodels:\n  analytics.orders:\n    alias: orders\n\n    joins:\n      products:\n        type: many_to_one\n        expression: \"orders.product_id = products.product_id\"\n\n# \u274c Less optimal: Indirect path\n# Would require: orders \u2192 line_items \u2192 products\n</code></pre> <p>Why: Direct joins are faster and simpler</p>"},{"location":"semantic-layer/joins/#52-fact-table-as-hub","title":"5.2 Fact Table as Hub","text":"<p>Pattern: Star Schema</p> <pre><code># Fact table (hub)\nmodels:\n  analytics.orders:\n    alias: orders\n\n    joins:\n      customers:      # Dimension 1\n        type: many_to_one\n        expression: \"...\"\n      products:       # Dimension 2\n        type: many_to_one\n        expression: \"...\"\n      sales_reps:     # Dimension 3\n        type: many_to_one\n        expression: \"...\"\n      regions:        # Dimension 4\n        type: many_to_one\n        expression: \"...\"\n</code></pre> <p>Benefits: - All dimensions join directly to fact - Short join paths (1 hop) - Optimal query performance - Clear data model structure</p>"},{"location":"semantic-layer/joins/#53-minimize-join-depth","title":"5.3 Minimize Join Depth","text":"<p>Pattern: Keep Paths Short</p> <pre><code># \u2705 Good: 1-hop paths\ncustomers \u2192 orders \u2192 products  # 2 hops max\n\n# \u274c Avoid: Deep paths\ncustomers \u2192 orders \u2192 line_items \u2192 products \u2192 categories \u2192 parent_categories  # 5 hops\n</code></pre> <p>Why: Each hop adds query complexity and cost</p> <p>Solution: Denormalize or create bridge models for common paths</p>"},{"location":"semantic-layer/joins/#54-join-cardinality-hints","title":"5.4 Join Cardinality Hints","text":"<p>Pattern: Accurate Relationship Types</p> <pre><code>joins:\n  orders:\n    type: one_to_many  # Accurate cardinality\n    expression: \"customers.customer_id = orders.customer_id\"\n</code></pre> <p>Why: Helps query optimizer choose join algorithms</p> <p>Best practice: Always specify correct relationship type</p> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/joins/#6-cross-model-analysis-patterns","title":"6. Cross-Model Analysis Patterns","text":""},{"location":"semantic-layer/joins/#61-customer-order-product-analysis","title":"6.1 Customer-Order-Product Analysis","text":"<p>Pattern: Three-Model Star</p> <pre><code>models:\n  analytics.orders:\n    alias: orders\n\n    joins:\n      customers:\n        type: many_to_one\n        expression: \"orders.customer_id = customers.customer_id\"\n\n      products:\n        type: many_to_one\n        expression: \"orders.product_id = products.product_id\"\n\n    measures:\n      revenue_by_tier_and_category:\n        type: sum\n        expression: \"SUM(orders.amount)\"\n        description: \"Revenue by customer tier and product category\"\n\n      avg_order_value_by_tier:\n        type: expression\n        expression: |\n          SUM(orders.amount) / \n          NULLIF(COUNT(DISTINCT orders.order_id), 0)\n        filters:\n          - \"customers.customer_tier = 'Enterprise'\"\n        description: \"Average order value for Enterprise customers\"\n</code></pre> <p>Query capabilities: - Revenue by customer tier \u00d7 product category - Order patterns by customer segment - Product performance by customer type</p>"},{"location":"semantic-layer/joins/#62-subscription-customer-usage-analysis","title":"6.2 Subscription-Customer-Usage Analysis","text":"<p>Pattern: Subscription Hub</p> <pre><code>models:\n  analytics.subscriptions:\n    alias: subscriptions\n\n    joins:\n      customers:\n        type: many_to_one\n        expression: \"subscriptions.customer_id = customers.customer_id\"\n\n      usage_events:\n        type: one_to_many\n        expression: \"subscriptions.subscription_id = usage_events.subscription_id\"\n\n    measures:\n      mrr_by_tier_and_usage:\n        type: sum\n        expression: \"SUM(subscriptions.mrr)\"\n        description: \"MRR by customer tier and usage level\"\n\n      active_subscriptions_with_usage:\n        type: count_distinct\n        expression: \"COUNT(DISTINCT subscriptions.subscription_id)\"\n        filters:\n          - \"subscriptions.status = 'active'\"\n          - \"usage_events.event_count &gt; 100\"\n        description: \"Active subscriptions with high usage\"\n</code></pre>"},{"location":"semantic-layer/joins/#63-multi-fact-analysis","title":"6.3 Multi-Fact Analysis","text":"<p>Pattern: Multiple Fact Tables</p> <pre><code>models:\n  analytics.customers:\n    alias: customers\n\n    joins:\n      orders:\n        type: one_to_many\n        expression: \"customers.customer_id = orders.customer_id\"\n\n      subscriptions:\n        type: one_to_many\n        expression: \"customers.customer_id = subscriptions.customer_id\"\n\n      support_tickets:\n        type: one_to_many\n        expression: \"customers.customer_id = support_tickets.customer_id\"\n\n    measures:\n      total_customer_value:\n        type: expression\n        expression: |\n          COALESCE(SUM(orders.amount), 0) + \n          COALESCE(SUM(subscriptions.mrr), 0)\n        description: \"Combined value from orders and subscriptions\"\n\n      customers_with_issues:\n        type: count_distinct\n        expression: \"COUNT(DISTINCT customers.customer_id)\"\n        filters:\n          - \"support_tickets.status = 'open'\"\n        description: \"Customers with open support tickets\"\n</code></pre> <p>Use when: - Multiple fact tables share dimension - Need unified customer view - Cross-functional analysis</p>"},{"location":"semantic-layer/joins/#64-time-series-cross-model-analysis","title":"6.4 Time-Series Cross-Model Analysis","text":"<p>Pattern: Temporal Joins</p> <pre><code>models:\n  analytics.daily_metrics:\n    alias: daily_metrics\n\n    joins:\n      customers:\n        type: many_to_one\n        expression: \"daily_metrics.customer_id = customers.customer_id\"\n\n      campaigns:\n        type: many_to_one\n        expression: |\n          daily_metrics.customer_id = campaigns.target_customer_id\n          AND daily_metrics.date BETWEEN campaigns.start_date AND campaigns.end_date\n        description: \"Active campaign during metric date\"\n\n    measures:\n      metrics_by_campaign:\n        type: sum\n        expression: \"SUM(daily_metrics.value)\"\n        description: \"Metrics aggregated by active campaign\"\n</code></pre> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/joins/#7-join-graph-management","title":"7. Join Graph Management","text":""},{"location":"semantic-layer/joins/#71-join-graph-validation","title":"7.1 Join Graph Validation","text":"<p>Rule: No Circular Dependencies</p> <pre><code># \u274c Invalid: Circular dependency\nmodels:\n  analytics.customers:\n    alias: customers\n    joins:\n      orders:\n        type: one_to_many\n        expression: \"customers.customer_id = orders.customer_id\"\n\n  analytics.orders:\n    alias: orders\n    joins:\n      products:\n        type: many_to_one\n        expression: \"orders.product_id = products.product_id\"\n\n  analytics.products:\n    alias: products\n    joins:\n      customers:  # Creates cycle: customers \u2192 orders \u2192 products \u2192 customers\n        type: many_to_one\n        expression: \"products.vendor_id = customers.customer_id\"\n</code></pre> <p>Validation: - System checks for cycles during semantic layer load - Errors indicate which models form a cycle - Fix by removing or restructuring joins</p>"},{"location":"semantic-layer/joins/#72-join-path-resolution","title":"7.2 Join Path Resolution","text":"<p>How system resolves paths:</p> <ol> <li>Direct join: If models are directly joined, use that path</li> <li>Shortest path: If multiple paths exist, choose shortest</li> <li>Path validation: Ensure all intermediate models exist and are joined</li> </ol> <p>Example: <pre><code>customers \u2192 orders \u2192 products\ncustomers \u2192 subscriptions \u2192 plans\n</code></pre></p> <p>From customers to products: - Path 1: <code>customers \u2192 orders \u2192 products</code> (2 hops) - Path 2: <code>customers \u2192 subscriptions \u2192 plans \u2192 products</code> (3 hops) - if exists - System chooses Path 1 (shorter)</p>"},{"location":"semantic-layer/joins/#73-disconnected-models","title":"7.3 Disconnected Models","text":"<p>Rule: All models in a metric must be connected</p> <pre><code># \u274c Invalid: Disconnected models\nmetrics:\n  revenue_by_product:\n    measure: orders.total_revenue\n    time: orders.order_date\n    dimensions:\n      - products.category  # No join path from orders to products!\n</code></pre> <p>Solution: Add join between models</p> <pre><code>models:\n  analytics.orders:\n    alias: orders\n\n    joins:\n      products:  # Add this join\n        type: many_to_one\n        expression: \"orders.product_id = products.product_id\"\n</code></pre>"},{"location":"semantic-layer/joins/#74-join-graph-documentation","title":"7.4 Join Graph Documentation","text":"<p>Pattern: Document Join Relationships</p> <pre><code>joins:\n  customers:\n    type: many_to_one\n    expression: \"orders.customer_id = customers.customer_id\"\n    description: \"Order's customer (required relationship)\"\n    meta:\n      cardinality: \"N:1\"\n      required: true\n      match_rate: 0.98\n      data_quality: \"Foreign key validated\"\n      business_rule: \"All orders must have valid customer\"\n</code></pre> <p>Benefits: - Clear relationship documentation - Data quality tracking - Business rule documentation - Query optimization hints</p> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/joins/#8-best-practices","title":"8. Best Practices","text":""},{"location":"semantic-layer/joins/#81-join-design","title":"8.1 Join Design","text":"<p>\u2705 DO: - Use star schema when possible (fact table as hub) - Define bidirectional joins for common paths - Keep join paths short (1-2 hops max) - Specify accurate relationship types - Document join business rules</p> <p>\u274c DON'T: - Create circular dependencies - Use deep join paths unnecessarily - Omit relationship types - Create disconnected model groups - Join models without clear business need</p>"},{"location":"semantic-layer/joins/#82-performance-optimization","title":"8.2 Performance Optimization","text":"<p>\u2705 DO: - Prefer direct joins over indirect paths - Use fact table as join hub - Minimize cross-model aggregations - Test join performance with production data - Monitor query execution plans</p> <p>\u274c DON'T: - Create unnecessary multi-hop paths - Join large tables without filters - Ignore join cardinality - Assume joins scale without testing</p>"},{"location":"semantic-layer/joins/#83-organization","title":"8.3 Organization","text":"<p>\u2705 DO: - Group related joins together - Document join purposes - Use consistent naming conventions - Validate join graph regularly - Keep join definitions close to model definitions</p> <p>\u274c DON'T: - Scatter joins across multiple files - Create joins without documentation - Mix join patterns inconsistently - Ignore validation errors</p>"},{"location":"semantic-layer/joins/#84-cross-model-measures","title":"8.4 Cross-Model Measures","text":"<p>\u2705 DO: - Define measures close to primary model - Use filters for cross-model conditions - Reuse base measures when possible - Document cross-model dependencies</p> <p>\u274c DON'T: - Create measures that span too many models - Ignore join path performance - Create circular measure dependencies - Omit cross-model documentation</p> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/joins/#9-troubleshooting","title":"9. Troubleshooting","text":""},{"location":"semantic-layer/joins/#91-common-errors","title":"9.1 Common Errors","text":"<p>Error: \"Join target model not found\"</p> <p>Cause: Referencing non-existent model alias</p> <p>Solution: <pre><code># \u274c Error: 'non_existent_model' doesn't exist\njoins:\n  non_existent_model:\n    type: one_to_many\n    expression: \"...\"\n\n# \u2705 Fix: Use correct model alias\njoins:\n  customers:  # Must match alias in models array\n    type: one_to_many\n    expression: \"...\"\n</code></pre></p> <p>Error: \"Circular dependency detected\"</p> <p>Cause: Join graph contains a cycle</p> <p>Solution: <pre><code># \u274c Error: customers \u2192 orders \u2192 products \u2192 customers\n# Fix: Remove one join or restructure\n</code></pre></p> <p>Error: \"No join path found\"</p> <p>Cause: Models not connected in join graph</p> <p>Solution: <pre><code># Add missing join to connect models\njoins:\n  target_model:\n    type: ...\n    expression: \"...\"\n</code></pre></p>"},{"location":"semantic-layer/joins/#92-performance-issues","title":"9.2 Performance Issues","text":"<p>Issue: Slow cross-model queries</p> <p>Symptoms: - Queries take long time - High warehouse costs - Timeouts</p> <p>Solutions: 1. Check join path length (prefer shorter paths) 2. Verify join conditions use indexed columns 3. Review cross-model measure complexity 4. Consider denormalizing frequently joined data 5. Test with smaller date ranges first</p>"},{"location":"semantic-layer/joins/#93-join-expression-errors","title":"9.3 Join Expression Errors","text":"<p>Issue: Invalid join expression</p> <p>Cause: SQL syntax errors or missing columns</p> <p>Solution: - Test join SQL directly in warehouse - Verify column names match exactly - Check model.column format - Review dialect compatibility</p> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/joins/#10-summary","title":"10. Summary","text":""},{"location":"semantic-layer/joins/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>Join patterns enable cross-model analysis</li> <li>One-to-many, many-to-one, one-to-one relationships</li> <li>Multi-model joins for complex analysis</li> <li> <p>Complex join conditions for filtered relationships</p> </li> <li> <p>Join graph management</p> </li> <li>Must be acyclic (no circular dependencies)</li> <li>All models in queries must be connected</li> <li> <p>System resolves shortest join paths</p> </li> <li> <p>Performance optimization</p> </li> <li>Prefer direct joins over indirect paths</li> <li>Use fact table as hub (star schema)</li> <li> <p>Keep join paths short (1-2 hops)</p> </li> <li> <p>Best practices</p> </li> <li>Accurate relationship types</li> <li>Comprehensive documentation</li> <li>Clear business rules</li> <li>Performance testing</li> </ol>"},{"location":"semantic-layer/joins/#next-steps","title":"Next Steps","text":"<ul> <li>Chapter 3D: Validation - Complete validation rules</li> <li>Chapter 3: Semantic Layer - Foundation concepts</li> <li>Chapter 3A: YAML Reference - Complete syntax reference</li> </ul> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/measures/","title":"Chapter 3B: Advanced Measures","text":"<p>Complex measure patterns and advanced techniques - Build sophisticated aggregations, cross-model measures, measure dependencies, performance optimization, and measure pattern libraries.</p>"},{"location":"semantic-layer/measures/#prerequisites","title":"Prerequisites","text":"<p>Before diving into this chapter, you should have:</p>"},{"location":"semantic-layer/measures/#required-knowledge","title":"Required Knowledge","text":"<p>Chapter 3: Semantic Layer - Understanding of: - Basic measure syntax - Measure expressions and filters - Cross-model references</p> <p>Chapter 3A: YAML Reference - Understanding of: - Complete measure field reference - Reference format rules</p> <p>SQL Proficiency - Level 3 - Advanced aggregations - Window functions - CTEs and subqueries - SQL optimization concepts</p>"},{"location":"semantic-layer/measures/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Introduction</li> <li>Measure Expression Patterns</li> <li>Cross-Model Measures</li> <li>Measure Dependencies</li> <li>Window Functions and Advanced SQL</li> <li>Performance Optimization</li> <li>Measure Pattern Library</li> <li>Best Practices</li> <li>Troubleshooting</li> <li>Summary</li> </ol>"},{"location":"semantic-layer/measures/#1-introduction","title":"1. Introduction","text":""},{"location":"semantic-layer/measures/#11-what-are-advanced-measures","title":"1.1 What Are Advanced Measures?","text":"<p>Advanced measures go beyond simple <code>SUM()</code> and <code>COUNT()</code> aggregations. They include:</p> <ul> <li>Complex SQL expressions with multiple aggregations</li> <li>Cross-model calculations spanning multiple tables</li> <li>Measure dependencies (measures built on other measures)</li> <li>Window functions for running totals and rankings</li> <li>Conditional logic and case statements</li> <li>Performance-optimized patterns</li> </ul>"},{"location":"semantic-layer/measures/#12-when-to-use-advanced-measures","title":"1.2 When to Use Advanced Measures","text":"<p>Use advanced measures when:</p> <ul> <li>Simple aggregations don't capture your business logic</li> <li>You need calculations across multiple models</li> <li>You want reusable measure building blocks</li> <li>Performance is critical for large datasets</li> <li>You need sophisticated analytical calculations</li> </ul> <p>Start simple, then advance:</p> <ol> <li>Basic: <code>SUM(amount)</code>, <code>COUNT(*)</code></li> <li>Filtered: Add <code>filters:</code> array</li> <li>Complex: Multi-line expressions with CASE statements</li> <li>Cross-model: Reference joined models</li> <li>Dependent: Build on other measures</li> <li>Advanced: Window functions, CTEs, subqueries</li> </ol>"},{"location":"semantic-layer/measures/#13-measure-expression-capabilities","title":"1.3 Measure Expression Capabilities","text":"<p>What you can do in measure expressions:</p> <p>\u2705 Aggregations: - <code>SUM()</code>, <code>AVG()</code>, <code>COUNT()</code>, <code>MIN()</code>, <code>MAX()</code> - <code>COUNT(DISTINCT ...)</code> - Custom aggregations</p> <p>\u2705 SQL Functions: - Date functions: <code>DATE_TRUNC()</code>, <code>EXTRACT()</code>, <code>DATEDIFF()</code> - String functions: <code>CONCAT()</code>, <code>SUBSTRING()</code>, <code>UPPER()</code> - Math functions: <code>ROUND()</code>, <code>ABS()</code>, <code>POWER()</code> - Conditional: <code>CASE WHEN ... THEN ... ELSE ... END</code> - Null handling: <code>COALESCE()</code>, <code>NULLIF()</code>, <code>ISNULL()</code></p> <p>\u2705 References: - Current model columns and dimensions - Other measures (no self-reference) - Joined model columns and dimensions - Joined model measures</p> <p>\u2705 Advanced SQL: - Window functions: <code>OVER()</code>, <code>PARTITION BY</code>, <code>ORDER BY</code> - Subqueries: <code>(SELECT ...)</code> - CTEs: <code>WITH ... AS (...)</code></p> <p>Limitations: - Cannot reference the measure itself (no self-reference) - Must be valid SQL for your warehouse dialect - Performance considerations for complex expressions</p> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/measures/#2-measure-expression-patterns","title":"2. Measure Expression Patterns","text":""},{"location":"semantic-layer/measures/#21-conditional-aggregations","title":"2.1 Conditional Aggregations","text":"<p>Pattern: SUM with CASE</p> <p>Calculate different values based on conditions:</p> <pre><code>measures:\n  active_revenue:\n    type: sum\n    expression: |\n      SUM(CASE \n        WHEN status = 'active' THEN amount \n        ELSE 0 \n      END)\n    description: \"Revenue from active subscriptions only\"\n\n  high_value_revenue:\n    type: sum\n    expression: |\n      SUM(CASE \n        WHEN amount &gt; 1000 THEN amount \n        ELSE 0 \n      END)\n    description: \"Revenue from orders over $1000\"\n\n  tiered_revenue:\n    type: sum\n    expression: |\n      SUM(CASE \n        WHEN customer_tier = 'Enterprise' THEN amount * 1.1\n        WHEN customer_tier = 'Pro' THEN amount * 1.05\n        ELSE amount\n      END)\n    description: \"Revenue with tier-based multipliers\"\n</code></pre> <p>Alternative: Use filters instead</p> <pre><code># \u2705 Prefer filters for clarity\nmeasures:\n  active_revenue:\n    type: sum\n    expression: \"SUM(amount)\"\n    filters:\n      - \"status = 'active'\"\n    description: \"Revenue from active subscriptions only\"\n</code></pre> <p>When to use CASE vs filters: - Use CASE: When you need different calculations per condition - Use filters: When you're just filtering rows (simpler, clearer)</p>"},{"location":"semantic-layer/measures/#22-ratio-and-percentage-calculations","title":"2.2 Ratio and Percentage Calculations","text":"<p>Pattern: Division with NULLIF</p> <p>Always handle division by zero:</p> <pre><code>measures:\n  conversion_rate:\n    type: expression\n    expression: |\n      COUNT(DISTINCT CASE WHEN converted = true THEN user_id END) * 100.0 \n      / NULLIF(COUNT(DISTINCT user_id), 0)\n    format: percentage\n    description: \"Percentage of users who converted\"\n\n  avg_order_value:\n    type: expression\n    expression: \"SUM(amount) / NULLIF(COUNT(*), 0)\"\n    format: currency\n    description: \"Average order value\"\n\n  revenue_per_customer:\n    type: expression\n    expression: \"SUM(amount) / NULLIF(COUNT(DISTINCT customer_id), 0)\"\n    format: currency\n    description: \"Average revenue per customer\"\n</code></pre> <p>Pattern: Percentage of Total</p> <pre><code>measures:\n  enterprise_revenue_pct:\n    type: expression\n    expression: |\n      SUM(CASE WHEN customer_tier = 'Enterprise' THEN amount ELSE 0 END) * 100.0\n      / NULLIF(SUM(amount), 0)\n    format: percentage\n    description: \"Enterprise revenue as percentage of total\"\n</code></pre>"},{"location":"semantic-layer/measures/#23-distinct-count-patterns","title":"2.3 Distinct Count Patterns","text":"<p>Pattern: Count Distinct</p> <pre><code>measures:\n  unique_customers:\n    type: count_distinct\n    expression: \"COUNT(DISTINCT customer_id)\"\n    description: \"Number of unique customers\"\n\n  unique_products_sold:\n    type: count_distinct\n    expression: \"COUNT(DISTINCT product_id)\"\n    description: \"Number of distinct products sold\"\n\n  unique_active_users_30d:\n    type: count_distinct\n    expression: |\n      COUNT(DISTINCT CASE \n        WHEN last_activity_date &gt;= CURRENT_DATE - INTERVAL '30 days' \n        THEN user_id \n      END)\n    description: \"Unique users active in last 30 days\"\n</code></pre> <p>Pattern: Count Distinct with Multiple Columns</p> <pre><code>measures:\n  unique_customer_product_combinations:\n    type: count_distinct\n    expression: \"COUNT(DISTINCT customer_id || '-' || product_id)\"\n    description: \"Unique customer-product pairs\"\n</code></pre>"},{"location":"semantic-layer/measures/#24-weighted-averages","title":"2.4 Weighted Averages","text":"<p>Pattern: Weighted Average</p> <pre><code>measures:\n  weighted_avg_score:\n    type: expression\n    expression: \"SUM(score * weight) / NULLIF(SUM(weight), 0)\"\n    description: \"Weighted average of scores\"\n\n  weighted_avg_price:\n    type: expression\n    expression: \"SUM(price * quantity) / NULLIF(SUM(quantity), 0)\"\n    format: currency\n    description: \"Average price weighted by quantity sold\"\n</code></pre>"},{"location":"semantic-layer/measures/#25-time-based-calculations","title":"2.5 Time-Based Calculations","text":"<p>Pattern: Date Range Aggregations</p> <pre><code>measures:\n  revenue_last_30_days:\n    type: sum\n    expression: |\n      SUM(CASE \n        WHEN order_date &gt;= CURRENT_DATE - INTERVAL '30 days' \n        THEN amount \n        ELSE 0 \n      END)\n    description: \"Revenue from last 30 days\"\n\n  new_customers_this_month:\n    type: count_distinct\n    expression: |\n      COUNT(DISTINCT CASE \n        WHEN DATE_TRUNC('month', signup_date) = DATE_TRUNC('month', CURRENT_DATE)\n        THEN customer_id \n      END)\n    description: \"New customers signed up this month\"\n</code></pre> <p>Pattern: Year-over-Year</p> <pre><code>measures:\n  revenue_yoy_growth:\n    type: expression\n    expression: |\n      (SUM(CASE \n        WHEN EXTRACT(YEAR FROM order_date) = EXTRACT(YEAR FROM CURRENT_DATE)\n        THEN amount \n        ELSE 0 \n      END) - \n      SUM(CASE \n        WHEN EXTRACT(YEAR FROM order_date) = EXTRACT(YEAR FROM CURRENT_DATE) - 1\n        THEN amount \n        ELSE 0 \n      END)) * 100.0\n      / NULLIF(SUM(CASE \n        WHEN EXTRACT(YEAR FROM order_date) = EXTRACT(YEAR FROM CURRENT_DATE) - 1\n        THEN amount \n        ELSE 0 \n      END), 0)\n    format: percentage\n    description: \"Year-over-year revenue growth percentage\"\n</code></pre>"},{"location":"semantic-layer/measures/#26-percentile-and-statistical-measures","title":"2.6 Percentile and Statistical Measures","text":"<p>Pattern: Percentiles</p> <pre><code>measures:\n  p50_order_value:\n    type: expression\n    expression: \"PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY amount)\"\n    format: currency\n    description: \"Median order value\"\n\n  p95_order_value:\n    type: expression\n    expression: \"PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY amount)\"\n    format: currency\n    description: \"95th percentile order value\"\n\n  p99_response_time:\n    type: expression\n    expression: \"PERCENTILE_CONT(0.99) WITHIN GROUP (ORDER BY response_ms)\"\n    format: duration_ms\n    description: \"99th percentile response time\"\n</code></pre> <p>Pattern: Standard Deviation</p> <pre><code>measures:\n  revenue_stddev:\n    type: expression\n    expression: \"STDDEV(amount)\"\n    format: currency\n    description: \"Standard deviation of order amounts\"\n\n  avg_revenue_with_stddev:\n    type: expression\n    expression: |\n      AVG(amount) || ' \u00b1 ' || ROUND(STDDEV(amount), 2)\n    description: \"Average revenue with standard deviation\"\n</code></pre> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/measures/#3-cross-model-measures","title":"3. Cross-Model Measures","text":""},{"location":"semantic-layer/measures/#31-basic-cross-model-references","title":"3.1 Basic Cross-Model References","text":"<p>Pattern: Aggregate from Joined Model</p> <pre><code>models:\n  analytics.customers:\n    alias: customers\n\n    joins:\n      orders:\n        type: one_to_many\n        expression: \"customers.customer_id = orders.customer_id\"\n\n    measures:\n      customer_order_count:\n        type: count\n        expression: \"COUNT(orders.order_id)\"\n        description: \"Number of orders per customer\"\n\n      customer_total_spent:\n        type: sum\n        expression: \"SUM(orders.amount)\"\n        format: currency\n        description: \"Total amount spent by customer\"\n</code></pre> <p>Pattern: Filter by Joined Model</p> <pre><code>models:\n  analytics.orders:\n    alias: orders\n\n    joins:\n      customers:\n        type: many_to_one\n        expression: \"orders.customer_id = customers.customer_id\"\n\n    measures:\n      enterprise_order_revenue:\n        type: sum\n        expression: \"SUM(amount)\"\n        filters:\n          - \"customers.customer_tier = 'Enterprise'\"\n        description: \"Revenue from Enterprise customer orders\"\n</code></pre>"},{"location":"semantic-layer/measures/#32-multi-model-aggregations","title":"3.2 Multi-Model Aggregations","text":"<p>Pattern: Aggregate Across Multiple Models</p> <pre><code>models:\n  analytics.customers:\n    alias: customers\n\n    joins:\n      orders:\n        type: one_to_many\n        expression: \"customers.customer_id = orders.customer_id\"\n\n      subscriptions:\n        type: one_to_many\n        expression: \"customers.customer_id = subscriptions.customer_id\"\n\n    measures:\n      total_customer_value:\n        type: expression\n        expression: |\n          COALESCE(SUM(orders.amount), 0) + \n          COALESCE(SUM(subscriptions.mrr), 0)\n        format: currency\n        description: \"Combined value from orders and subscriptions\"\n</code></pre>"},{"location":"semantic-layer/measures/#33-cross-model-ratios","title":"3.3 Cross-Model Ratios","text":"<p>Pattern: Ratio Across Models</p> <pre><code>models:\n  analytics.orders:\n    alias: orders\n\n    joins:\n      customers:\n        type: many_to_one\n        expression: \"orders.customer_id = customers.customer_id\"\n\n    measures:\n      revenue_per_customer_tier:\n        type: expression\n        expression: |\n          SUM(orders.amount) / \n          NULLIF(COUNT(DISTINCT customers.customer_tier), 0)\n        format: currency\n        description: \"Average revenue per customer tier\"\n</code></pre>"},{"location":"semantic-layer/measures/#34-conditional-cross-model-logic","title":"3.4 Conditional Cross-Model Logic","text":"<p>Pattern: Conditional Aggregation Based on Joined Model</p> <pre><code>models:\n  analytics.orders:\n    alias: orders\n\n    joins:\n      customers:\n        type: many_to_one\n        expression: \"orders.customer_id = customers.customer_id\"\n\n    measures:\n      tier_adjusted_revenue:\n        type: sum\n        expression: |\n          SUM(CASE \n            WHEN customers.customer_tier = 'Enterprise' THEN orders.amount * 1.1\n            WHEN customers.customer_tier = 'Pro' THEN orders.amount * 1.05\n            ELSE orders.amount\n          END)\n        format: currency\n        description: \"Revenue adjusted by customer tier\"\n</code></pre> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/measures/#4-measure-dependencies","title":"4. Measure Dependencies","text":""},{"location":"semantic-layer/measures/#41-building-measures-on-other-measures","title":"4.1 Building Measures on Other Measures","text":"<p>Pattern: Simple Dependency</p> <pre><code>measures:\n  total_revenue:\n    type: sum\n    expression: \"SUM(amount)\"\n    description: \"Total revenue\"\n\n  total_orders:\n    type: count\n    expression: \"COUNT(*)\"\n    description: \"Total order count\"\n\n  avg_order_value:\n    type: expression\n    expression: \"total_revenue / NULLIF(total_orders, 0)\"\n    format: currency\n    description: \"Average order value (revenue per order)\"\n</code></pre> <p>How it works: - Vulcan automatically resolves measure dependencies - Measures are evaluated in dependency order - No need to specify order explicitly</p>"},{"location":"semantic-layer/measures/#42-complex-dependency-chains","title":"4.2 Complex Dependency Chains","text":"<p>Pattern: Multi-Level Dependencies</p> <pre><code>measures:\n  # Level 1: Base measures\n  total_revenue:\n    type: sum\n    expression: \"SUM(amount)\"\n\n  total_costs:\n    type: sum\n    expression: \"SUM(cost)\"\n\n  # Level 2: Derived measures\n  gross_profit:\n    type: expression\n    expression: \"total_revenue - total_costs\"\n    format: currency\n\n  total_orders:\n    type: count\n    expression: \"COUNT(*)\"\n\n  # Level 3: Final calculations\n  profit_margin:\n    type: expression\n    expression: \"gross_profit * 100.0 / NULLIF(total_revenue, 0)\"\n    format: percentage\n\n  profit_per_order:\n    type: expression\n    expression: \"gross_profit / NULLIF(total_orders, 0)\"\n    format: currency\n</code></pre> <p>Dependency graph: <pre><code>total_revenue \u2500\u2500\u2510\n                \u251c\u2500\u2500\u2192 gross_profit \u2500\u2500\u2510\ntotal_costs \u2500\u2500\u2500\u2500\u2518                   \u251c\u2500\u2500\u2192 profit_margin\n                                    \u2502\ntotal_orders \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2192 profit_per_order\n                                    \u2502\n                                    \u2514\u2500\u2500\u2192 profit_per_order\n</code></pre></p>"},{"location":"semantic-layer/measures/#43-circular-dependency-prevention","title":"4.3 Circular Dependency Prevention","text":"<p>Rule: Measures cannot reference themselves</p> <pre><code># \u274c Invalid: Self-reference\nmeasures:\n  revenue_growth:\n    type: expression\n    expression: \"revenue_growth * 1.1\"  # Cannot reference itself\n\n# \u2705 Valid: Reference other measures\nmeasures:\n  base_revenue:\n    type: sum\n    expression: \"SUM(amount)\"\n\n  revenue_with_growth:\n    type: expression\n    expression: \"base_revenue * 1.1\"  # References other measure\n</code></pre> <p>Rule: No circular dependencies between measures</p> <pre><code># \u274c Invalid: Circular dependency\nmeasures:\n  measure_a:\n    type: expression\n    expression: \"measure_b + 10\"\n\n  measure_b:\n    type: expression\n    expression: \"measure_a + 20\"  # Circular!\n\n# \u2705 Valid: Acyclic dependencies\nmeasures:\n  base_value:\n    type: sum\n    expression: \"SUM(amount)\"\n\n  adjusted_value:\n    type: expression\n    expression: \"base_value * 1.1\"\n\n  final_value:\n    type: expression\n    expression: \"adjusted_value + 100\"\n</code></pre>"},{"location":"semantic-layer/measures/#44-conditional-dependencies","title":"4.4 Conditional Dependencies","text":"<p>Pattern: Conditional Measure Selection</p> <pre><code>measures:\n  base_revenue:\n    type: sum\n    expression: \"SUM(amount)\"\n\n  discounted_revenue:\n    type: sum\n    expression: \"SUM(amount * 0.9)\"\n\n  effective_revenue:\n    type: expression\n    expression: |\n      CASE \n        WHEN COUNT(CASE WHEN has_discount = true THEN 1 END) &gt; 0\n        THEN discounted_revenue\n        ELSE base_revenue\n      END\n    description: \"Revenue with conditional discount application\"\n</code></pre> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/measures/#5-window-functions-and-advanced-sql","title":"5. Window Functions and Advanced SQL","text":""},{"location":"semantic-layer/measures/#51-running-totals","title":"5.1 Running Totals","text":"<p>Pattern: Cumulative Sum</p> <pre><code>measures:\n  cumulative_revenue:\n    type: expression\n    expression: |\n      SUM(SUM(amount)) OVER (\n        ORDER BY DATE_TRUNC('month', order_date)\n        ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n      )\n    format: currency\n    description: \"Running total of revenue by month\"\n</code></pre> <p>Pattern: Moving Average</p> <pre><code>measures:\n  revenue_30day_avg:\n    type: expression\n    expression: |\n      AVG(SUM(amount)) OVER (\n        ORDER BY order_date\n        ROWS BETWEEN 29 PRECEDING AND CURRENT ROW\n      )\n    format: currency\n    description: \"30-day moving average of revenue\"\n</code></pre>"},{"location":"semantic-layer/measures/#52-rankings-and-percentiles","title":"5.2 Rankings and Percentiles","text":"<p>Pattern: Rank by Value</p> <pre><code>measures:\n  customer_revenue_rank:\n    type: expression\n    expression: |\n      RANK() OVER (\n        PARTITION BY customer_tier\n        ORDER BY SUM(amount) DESC\n      )\n    description: \"Customer rank by revenue within tier\"\n</code></pre> <p>Pattern: Percentile Rank</p> <pre><code>measures:\n  order_value_percentile:\n    type: expression\n    expression: |\n      PERCENT_RANK() OVER (\n        ORDER BY amount\n      ) * 100\n    format: percentage\n    description: \"Percentile rank of order value\"\n</code></pre>"},{"location":"semantic-layer/measures/#53-period-over-period-comparisons","title":"5.3 Period-over-Period Comparisons","text":"<p>Pattern: Previous Period Comparison</p> <pre><code>measures:\n  revenue_vs_previous_month:\n    type: expression\n    expression: |\n      SUM(amount) - \n      LAG(SUM(amount)) OVER (\n        ORDER BY DATE_TRUNC('month', order_date)\n      )\n    format: currency\n    description: \"Revenue change vs previous month\"\n\n  revenue_growth_rate:\n    type: expression\n    expression: |\n      (SUM(amount) - \n       LAG(SUM(amount)) OVER (\n         ORDER BY DATE_TRUNC('month', order_date)\n       )) * 100.0\n      / NULLIF(LAG(SUM(amount)) OVER (\n        ORDER BY DATE_TRUNC('month', order_date)\n      ), 0)\n    format: percentage\n    description: \"Month-over-month revenue growth rate\"\n</code></pre>"},{"location":"semantic-layer/measures/#54-first-and-last-values","title":"5.4 First and Last Values","text":"<p>Pattern: First Value in Window</p> <pre><code>measures:\n  first_order_value:\n    type: expression\n    expression: |\n      FIRST_VALUE(amount) OVER (\n        PARTITION BY customer_id\n        ORDER BY order_date\n        ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING\n      )\n    format: currency\n    description: \"First order value per customer\"\n</code></pre> <p>Pattern: Last Value in Window</p> <pre><code>measures:\n  latest_customer_tier:\n    type: expression\n    expression: |\n      LAST_VALUE(customer_tier) OVER (\n        PARTITION BY customer_id\n        ORDER BY updated_at\n        ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING\n      )\n    description: \"Most recent customer tier\"\n</code></pre>"},{"location":"semantic-layer/measures/#55-advanced-window-functions","title":"5.5 Advanced Window Functions","text":"<p>Pattern: N-Tile Bucketing</p> <pre><code>measures:\n  revenue_quartile:\n    type: expression\n    expression: |\n      NTILE(4) OVER (\n        ORDER BY SUM(amount)\n      )\n    description: \"Revenue quartile (1-4)\"\n</code></pre> <p>Pattern: Lead and Lag</p> <pre><code>measures:\n  next_month_revenue:\n    type: expression\n    expression: |\n      LEAD(SUM(amount)) OVER (\n        ORDER BY DATE_TRUNC('month', order_date)\n      )\n    format: currency\n    description: \"Revenue for next month\"\n</code></pre> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/measures/#6-performance-optimization","title":"6. Performance Optimization","text":""},{"location":"semantic-layer/measures/#61-expression-simplification","title":"6.1 Expression Simplification","text":"<p>Pattern: Prefer Filters Over CASE</p> <pre><code># \u274c Slower: CASE in expression\nmeasures:\n  active_revenue:\n    type: sum\n    expression: \"SUM(CASE WHEN status = 'active' THEN amount ELSE 0 END)\"\n\n# \u2705 Faster: Filters\nmeasures:\n  active_revenue:\n    type: sum\n    expression: \"SUM(amount)\"\n    filters:\n      - \"status = 'active'\"\n</code></pre> <p>Why: Filters are applied before aggregation, reducing data scanned</p>"},{"location":"semantic-layer/measures/#62-avoid-redundant-calculations","title":"6.2 Avoid Redundant Calculations","text":"<p>Pattern: Reuse Base Measures</p> <pre><code># \u274c Bad: Redundant calculations\nmeasures:\n  total_revenue:\n    type: sum\n    expression: \"SUM(amount)\"\n\n  active_revenue:\n    type: sum\n    expression: \"SUM(amount)\"  # Redundant SUM\n    filters:\n      - \"status = 'active'\"\n\n  completed_revenue:\n    type: sum\n    expression: \"SUM(amount)\"  # Redundant SUM\n    filters:\n      - \"status = 'completed'\"\n\n# \u2705 Good: Base measure + filters\nmeasures:\n  total_revenue:\n    type: sum\n    expression: \"SUM(amount)\"\n\n  active_revenue:\n    type: expression\n    expression: \"total_revenue\"  # Reuse base\n    filters:\n      - \"status = 'active'\"\n\n  completed_revenue:\n    type: expression\n    expression: \"total_revenue\"  # Reuse base\n    filters:\n      - \"status = 'completed'\"\n</code></pre>"},{"location":"semantic-layer/measures/#63-limit-cross-model-aggregations","title":"6.3 Limit Cross-Model Aggregations","text":"<p>Pattern: Minimize Cross-Model Scans</p> <pre><code># \u274c Expensive: Multiple cross-model aggregations\nmeasures:\n  complex_calculation:\n    type: expression\n    expression: |\n      SUM(orders.amount) + \n      SUM(subscriptions.mrr) + \n      SUM(usage_events.event_count)\n    # Scans 3 joined models\n\n# \u2705 Better: Pre-aggregate in base models\n# Define measures in each model, then combine\nmeasures:\n  total_customer_value:\n    type: expression\n    expression: \"orders.total_revenue + subscriptions.total_mrr\"\n    # References pre-aggregated measures\n</code></pre>"},{"location":"semantic-layer/measures/#64-optimize-window-functions","title":"6.4 Optimize Window Functions","text":"<p>Pattern: Limit Window Size</p> <pre><code># \u274c Expensive: Unbounded window\nmeasures:\n  cumulative_all_time:\n    type: expression\n    expression: |\n      SUM(amount) OVER (\n        ORDER BY order_date\n        ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n      )\n\n# \u2705 Better: Bounded window\nmeasures:\n  cumulative_90days:\n    type: expression\n    expression: |\n      SUM(amount) OVER (\n        ORDER BY order_date\n        ROWS BETWEEN 89 PRECEDING AND CURRENT ROW\n      )\n</code></pre> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/measures/#7-measure-pattern-library","title":"7. Measure Pattern Library","text":""},{"location":"semantic-layer/measures/#71-revenue-patterns","title":"7.1 Revenue Patterns","text":"<p>Total Revenue: <pre><code>total_revenue:\n  type: sum\n  expression: \"SUM(amount)\"\n  format: currency\n  tags: [revenue, financial, kpi]\n</code></pre></p> <p>Net Revenue (after refunds): <pre><code>net_revenue:\n  type: expression\n  expression: \"SUM(amount) - SUM(COALESCE(refund_amount, 0))\"\n  format: currency\n  tags: [revenue, financial]\n</code></pre></p> <p>Recurring Revenue: <pre><code>mrr:\n  type: sum\n  expression: \"SUM(mrr)\"\n  format: currency\n  tags: [revenue, recurring, saas]\n</code></pre></p>"},{"location":"semantic-layer/measures/#72-count-patterns","title":"7.2 Count Patterns","text":"<p>Total Count: <pre><code>total_orders:\n  type: count\n  expression: \"COUNT(*)\"\n  tags: [count, orders]\n</code></pre></p> <p>Distinct Count: <pre><code>unique_customers:\n  type: count_distinct\n  expression: \"COUNT(DISTINCT customer_id)\"\n  tags: [count, customers, distinct]\n</code></pre></p> <p>Conditional Count: <pre><code>active_subscriptions:\n  type: count\n  expression: \"COUNT(CASE WHEN status = 'active' THEN 1 END)\"\n  tags: [count, subscriptions, active]\n</code></pre></p>"},{"location":"semantic-layer/measures/#73-average-patterns","title":"7.3 Average Patterns","text":"<p>Simple Average: <pre><code>avg_order_value:\n  type: avg\n  expression: \"AVG(amount)\"\n  format: currency\n  tags: [average, orders]\n</code></pre></p> <p>Weighted Average: <pre><code>weighted_avg_price:\n  type: expression\n  expression: \"SUM(price * quantity) / NULLIF(SUM(quantity), 0)\"\n  format: currency\n  tags: [average, weighted, price]\n</code></pre></p>"},{"location":"semantic-layer/measures/#74-rate-patterns","title":"7.4 Rate Patterns","text":"<p>Conversion Rate: <pre><code>conversion_rate:\n  type: expression\n  expression: |\n    COUNT(DISTINCT CASE WHEN converted = true THEN user_id END) * 100.0\n    / NULLIF(COUNT(DISTINCT user_id), 0)\n  format: percentage\n  tags: [rate, conversion]\n</code></pre></p> <p>Churn Rate: <pre><code>churn_rate:\n  type: expression\n  expression: |\n    COUNT(CASE WHEN status = 'cancelled' THEN 1 END) * 100.0\n    / NULLIF(COUNT(*), 0)\n  format: percentage\n  tags: [rate, churn, retention]\n</code></pre></p>"},{"location":"semantic-layer/measures/#75-growth-patterns","title":"7.5 Growth Patterns","text":"<p>Month-over-Month Growth: <pre><code>revenue_mom_growth:\n  type: expression\n  expression: |\n    (SUM(amount) - \n     LAG(SUM(amount)) OVER (ORDER BY DATE_TRUNC('month', order_date))) * 100.0\n    / NULLIF(LAG(SUM(amount)) OVER (ORDER BY DATE_TRUNC('month', order_date)), 0)\n  format: percentage\n  tags: [growth, mom]\n</code></pre></p> <p>Year-over-Year Growth: <pre><code>revenue_yoy_growth:\n  type: expression\n  expression: |\n    (SUM(CASE WHEN EXTRACT(YEAR FROM order_date) = EXTRACT(YEAR FROM CURRENT_DATE) THEN amount END) -\n     SUM(CASE WHEN EXTRACT(YEAR FROM order_date) = EXTRACT(YEAR FROM CURRENT_DATE) - 1 THEN amount END)) * 100.0\n    / NULLIF(SUM(CASE WHEN EXTRACT(YEAR FROM order_date) = EXTRACT(YEAR FROM CURRENT_DATE) - 1 THEN amount END), 0)\n  format: percentage\n  tags: [growth, yoy]\n</code></pre></p> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/measures/#8-best-practices","title":"8. Best Practices","text":""},{"location":"semantic-layer/measures/#81-expression-clarity","title":"8.1 Expression Clarity","text":"<p>\u2705 DO: - Use descriptive measure names - Add clear descriptions - Break complex expressions into multiple measures - Use filters instead of CASE when possible - Handle NULLs and division by zero</p> <p>\u274c DON'T: - Create overly complex single expressions - Omit descriptions - Use magic numbers without explanation - Ignore NULL handling - Create circular dependencies</p>"},{"location":"semantic-layer/measures/#82-performance-guidelines","title":"8.2 Performance Guidelines","text":"<p>\u2705 DO: - Use filters for row-level conditions - Reuse base measures for derived calculations - Limit window function ranges - Minimize cross-model aggregations - Test with production-scale data</p> <p>\u274c DON'T: - Use CASE when filters would work - Redundant calculations - Unbounded window functions unnecessarily - Excessive cross-model joins in single measure - Assume expressions scale without testing</p>"},{"location":"semantic-layer/measures/#83-dependency-management","title":"8.3 Dependency Management","text":"<p>\u2705 DO: - Build measures in logical layers - Document measure dependencies - Use clear naming conventions - Test dependency chains</p> <p>\u274c DON'T: - Create circular dependencies - Reference measures that don't exist - Create deep dependency chains (&gt;5 levels) - Mix dependency levels without organization</p>"},{"location":"semantic-layer/measures/#84-documentation","title":"8.4 Documentation","text":"<p>\u2705 DO: - Document business logic in descriptions - Explain calculation methods in meta - Tag measures for discovery - Note data sources and freshness</p> <p>\u274c DON'T: - Leave measures undocumented - Use unclear or technical descriptions - Omit business context - Forget to update documentation when logic changes</p> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/measures/#9-troubleshooting","title":"9. Troubleshooting","text":""},{"location":"semantic-layer/measures/#91-common-errors","title":"9.1 Common Errors","text":"<p>Error: \"Measure not found\"</p> <p>Cause: Referencing non-existent measure</p> <p>Solution: <pre><code># \u274c Error: measure_b doesn't exist\nmeasures:\n  measure_a:\n    type: expression\n    expression: \"measure_b + 10\"\n\n# \u2705 Fix: Define measure_b first\nmeasures:\n  measure_b:\n    type: sum\n    expression: \"SUM(amount)\"\n\n  measure_a:\n    type: expression\n    expression: \"measure_b + 10\"\n</code></pre></p> <p>Error: \"Circular dependency detected\"</p> <p>Cause: Measure references itself or creates cycle</p> <p>Solution: <pre><code># \u274c Error: Circular dependency\nmeasures:\n  measure_a:\n    type: expression\n    expression: \"measure_b + 10\"\n\n  measure_b:\n    type: expression\n    expression: \"measure_a + 20\"\n\n# \u2705 Fix: Break the cycle\nmeasures:\n  base_value:\n    type: sum\n    expression: \"SUM(amount)\"\n\n  measure_a:\n    type: expression\n    expression: \"base_value + 10\"\n\n  measure_b:\n    type: expression\n    expression: \"base_value + 20\"\n</code></pre></p> <p>Error: \"Column not found\"</p> <p>Cause: Referencing non-existent column or wrong model</p> <p>Solution: <pre><code># \u274c Error: Column doesn't exist\nmeasures:\n  - name: total\n    expression: \"SUM(non_existent_column)\"\n\n# \u2705 Fix: Use correct column name\nmeasures:\n  - name: total\n    expression: \"SUM(amount)\"\n</code></pre></p>"},{"location":"semantic-layer/measures/#92-performance-issues","title":"9.2 Performance Issues","text":"<p>Issue: Slow measure evaluation</p> <p>Symptoms: - Measures take long time to compute - Queries timeout - High warehouse costs</p> <p>Solutions: 1. Check for unbounded window functions 2. Verify filters are being applied 3. Review cross-model join complexity 4. Consider pre-aggregating in base models 5. Test with smaller date ranges first</p>"},{"location":"semantic-layer/measures/#93-validation-errors","title":"9.3 Validation Errors","text":"<p>Issue: SQL syntax errors</p> <p>Cause: Invalid SQL in expression</p> <p>Solution: - Test SQL directly in warehouse - Check dialect compatibility - Verify function names and syntax - Review window function syntax</p> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/measures/#10-summary","title":"10. Summary","text":""},{"location":"semantic-layer/measures/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>Advanced measures enable sophisticated analytics</li> <li>Complex SQL expressions</li> <li>Cross-model calculations</li> <li>Measure dependencies</li> <li> <p>Window functions</p> </li> <li> <p>Patterns for common use cases</p> </li> <li>Conditional aggregations</li> <li>Ratios and percentages</li> <li>Time-based calculations</li> <li> <p>Statistical measures</p> </li> <li> <p>Performance matters</p> </li> <li>Use filters instead of CASE when possible</li> <li>Reuse base measures</li> <li>Limit window function ranges</li> <li> <p>Minimize cross-model aggregations</p> </li> <li> <p>Best practices</p> </li> <li>Clear, descriptive names</li> <li>Comprehensive documentation</li> <li>Logical dependency organization</li> <li>Proper NULL handling</li> </ol>"},{"location":"semantic-layer/measures/#next-steps","title":"Next Steps","text":"<ul> <li>Chapter 3C: Advanced Joins - Cross-model analysis patterns</li> <li>Chapter 3D: Validation - Complete validation rules</li> <li>Chapter 3: Semantic Layer - Foundation concepts</li> </ul> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/validation/","title":"Chapter 3D: Semantic Layer Validation","text":"<p>Complete validation rules and error resolution - Understand every validation rule, common errors, and how to fix them.</p>"},{"location":"semantic-layer/validation/#prerequisites","title":"Prerequisites","text":"<p>Before diving into this chapter, you should have:</p>"},{"location":"semantic-layer/validation/#required-knowledge","title":"Required Knowledge","text":"<p>Chapter 3: Semantic Layer - Understanding of: - Semantic layer concepts - Models, dimensions, measures, segments, joins, metrics</p> <p>Chapter 3A: YAML Reference - Understanding of: - Complete YAML syntax - Field requirements and formats</p> <p>YAML Syntax - Basic YAML structure - Indentation and formatting</p>"},{"location":"semantic-layer/validation/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Introduction</li> <li>Naming and Uniqueness Rules</li> <li>Semantic Models Validation</li> <li>Dimensions Validation</li> <li>Measures Validation</li> <li>Segments Validation</li> <li>Joins Validation</li> <li>Metrics Validation</li> <li>Reference Validation</li> <li>Common Error Patterns</li> <li>Troubleshooting Guide</li> <li>Summary</li> </ol>"},{"location":"semantic-layer/validation/#1-introduction","title":"1. Introduction","text":""},{"location":"semantic-layer/validation/#11-what-is-validation","title":"1.1 What is Validation?","text":"<p>Semantic layer validation ensures your YAML definitions are:</p> <ul> <li>Syntactically correct - Valid YAML structure</li> <li>Semantically valid - References exist and are correct</li> <li>Logically consistent - No circular dependencies, valid relationships</li> <li>Complete - Required fields are present</li> </ul>"},{"location":"semantic-layer/validation/#12-when-validation-runs","title":"1.2 When Validation Runs","text":"<p>Validation occurs:</p> <ol> <li>On load - When semantic layer files are loaded</li> <li>On change - When files are modified</li> <li>Before queries - Before executing analytical queries</li> <li>Explicitly - Via <code>vulcan validate</code> command</li> </ol>"},{"location":"semantic-layer/validation/#13-validation-error-format","title":"1.3 Validation Error Format","text":"<p>Error message structure: <pre><code>ERROR: &lt;component&gt; '&lt;name&gt;': &lt;rule_violated&gt;\n  Location: &lt;file&gt;:&lt;line&gt;\n  Details: &lt;additional_info&gt;\n</code></pre></p> <p>Example: <pre><code>ERROR: Measure 'total_revenue': Circular dependency detected\n  Location: semantics/orders.yml:15\n  Details: Measure 'total_revenue' references 'avg_revenue' which references 'total_revenue'\n</code></pre></p>"},{"location":"semantic-layer/validation/#14-how-to-use-this-chapter","title":"1.4 How to Use This Chapter","text":"<p>For debugging: - Find the error message in relevant section - Review validation rules - Check examples and solutions</p> <p>For prevention: - Review validation rules before writing - Follow naming conventions - Validate frequently during development</p> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/validation/#2-naming-and-uniqueness-rules","title":"2. Naming and Uniqueness Rules","text":""},{"location":"semantic-layer/validation/#21-identifier-format-rules","title":"2.1 Identifier Format Rules","text":"<p>Applicable to: - Semantic model aliases (<code>alias</code>) - Measure names - Segment names - Join names (target model aliases) - Metric names - Dimension proxy names - Dimension override names</p> <p>Rules: - Must not be empty - Must start with a letter (<code>A\u2013Z</code> or <code>a\u2013z</code>) - After first character, may contain only:   - Letters (<code>A\u2013Z</code>, <code>a\u2013z</code>)   - Digits (<code>0\u20139</code>)   - Underscores (<code>_</code>) - Maximum length: 64 characters - Case-sensitive</p> <p>Valid examples: <pre><code># \u2705 Valid names\n- name: total_revenue\n- name: customer_count_30d\n- name: avg_order_value\n- name: monthly_revenue_by_tier\n- name: revenue_2024\n</code></pre></p> <p>Invalid examples: <pre><code># \u274c Invalid: Starts with digit\n- name: \"123revenue\"\n\n# \u274c Invalid: Contains hyphen\n- name: \"total-revenue\"\n\n# \u274c Invalid: Contains space\n- name: \"total revenue\"\n\n# \u274c Invalid: Contains dot (except in references)\n- name: \"total.revenue\"\n\n# \u274c Invalid: Empty\n- name: \"\"\n</code></pre></p> <p>Error messages: <pre><code>ERROR: Invalid identifier '123revenue': Must start with a letter\nERROR: Invalid identifier 'total-revenue': Invalid character '-' (only letters, digits, underscores allowed)\nERROR: Invalid identifier '': Identifier cannot be empty\n</code></pre></p>"},{"location":"semantic-layer/validation/#22-uniqueness-within-model","title":"2.2 Uniqueness Within Model","text":"<p>Rule: Within a single semantic model:</p> <ul> <li>Measure names must be unique</li> <li>Segment names must be unique</li> <li>Dimension proxy names must be unique</li> <li>Dimension override names must be unique</li> <li>No semantic field name should be reused across measures, segments, and dimension proxies</li> </ul> <p>Valid example: <pre><code>models:\n  analytics.customers:\n    alias: customers\n\n    measures:\n      total_customers:\n        type: count\n      active_customers:\n        type: count\n\n    segments:\n      active:\n        expression: \"...\"\n      high_value:\n        expression: \"...\"\n\n    dimensions:\n      proxies:\n        order_count_dim:\n          measure: \"...\"\n</code></pre></p> <p>Invalid examples: <pre><code># \u274c Error: Duplicate measure name\nmeasures:\n  total_revenue:\n    type: sum\n  total_revenue:  # Duplicate! (same key twice)\n    type: sum\n\n# \u274c Error: Measure and segment with same name\nmeasures:\n  active_users:\n    type: count\nsegments:\n  active_users:  # Conflicts with measure name\n    expression: \"...\"\n\n# \u274c Error: Measure and dimension proxy with same name\nmeasures:\n  order_count:\n    type: count\ndimensions:\n  proxies:\n    order_count:  # Conflicts with measure name\n      measure: \"...\"\n</code></pre></p> <p>Error messages: <pre><code>ERROR: Duplicate measure name 'total_revenue' in model 'customers'\nERROR: Name 'active_users' conflicts: used as both measure and segment in model 'customers'\nERROR: Name 'order_count' conflicts: used as both measure and dimension proxy in model 'customers'\n</code></pre></p>"},{"location":"semantic-layer/validation/#23-uniqueness-across-files","title":"2.3 Uniqueness Across Files","text":"<p>Rule: Across all semantic layer files:</p> <ul> <li>Metric names must be unique</li> <li>Model aliases must be unique</li> </ul> <p>Invalid example: <pre><code># In file1.yml:\nmetrics:\n  monthly_revenue: ...\n\n# In file2.yml:\nmetrics:\n  monthly_revenue: ...  # Duplicate metric name!\n</code></pre></p> <p>Error message: <pre><code>ERROR: Duplicate metric name 'monthly_revenue' (defined in both file1.yml and file2.yml)\n</code></pre></p> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/validation/#3-semantic-models-validation","title":"3. Semantic Models Validation","text":""},{"location":"semantic-layer/validation/#31-model-name-validation","title":"3.1 Model Name Validation","text":"<p>Rule: <code>name</code> field must match an existing Vulcan model</p> <p>Valid example: <pre><code>models:\n  analytics.customers:  # Matches Vulcan model (dictionary key)\n    alias: customers\n</code></pre></p> <p>Invalid examples: <pre><code># \u274c Error: Model doesn't exist\nmodels:\n  non_existent_model:\n    alias: customers\n\n# \u274c Error: Typo in model name\nmodels:\n  analytics.custmers:  # Should be 'customers'\n    alias: customers\n</code></pre></p> <p>Error messages: <pre><code>ERROR: Model 'non_existent_model' not found in Vulcan project\nERROR: Model 'analytics.custmers' not found (did you mean 'analytics.customers'?)\n</code></pre></p>"},{"location":"semantic-layer/validation/#32-alias-validation","title":"3.2 Alias Validation","text":"<p>Rule: <code>alias</code> is required when <code>name</code> is fully qualified (<code>schema.table</code>)</p> <p>Valid examples: <pre><code># \u2705 FQN with name/alias (required)\nmodels:\n  analytics.customers:\n    alias: customers\n\n# \u2705 Simple name (name/alias optional)\nmodels:\n  customers:\n    # name defaults to 'customers'\n</code></pre></p> <p>Invalid example: <pre><code># \u274c Error: FQN without name/alias\nmodels:\n  analytics.customers:\n    # Missing name field!\n</code></pre></p> <p>Error message: <pre><code>ERROR: Model 'analytics.customers': Alias required for fully qualified model name\n</code></pre></p> <p>Rule: Alias must follow identifier format rules</p> <p>Invalid example: <pre><code>models:\n  analytics.customers:\n    alias: \"customer-users\"  # Invalid: contains hyphen\n</code></pre></p> <p>Error message: <pre><code>ERROR: Invalid alias 'customer-users': Invalid character '-' (only letters, digits, underscores allowed)\n</code></pre></p>"},{"location":"semantic-layer/validation/#33-model-existence-for-references","title":"3.3 Model Existence for References","text":"<p>Rule: All referenced model aliases must exist</p> <p>Referenced in: - <code>joins:</code> - Join target names - Dimension proxy <code>measure</code> values - <code>model.measure</code> format - Metric <code>measure</code>, <code>time</code>, <code>dimensions</code> - <code>model.field</code> format</p> <p>Invalid example: <pre><code>joins:\n  non_existent_model:  # Model alias doesn't exist\n    type: one_to_many\n    expression: \"...\"\n</code></pre></p> <p>Error message: <pre><code>ERROR: Join target 'non_existent_model' not found (referenced in model 'customers')\n</code></pre></p> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/validation/#4-dimensions-validation","title":"4. Dimensions Validation","text":""},{"location":"semantic-layer/validation/#41-column-selection-validation","title":"4.1 Column Selection Validation","text":"<p>Rule: Cannot use both <code>includes</code> and <code>excludes</code></p> <p>Invalid example: <pre><code>dimensions:\n  includes: [col1, col2]\n  excludes: [col3]  # Error: mutually exclusive\n</code></pre></p> <p>Error message: <pre><code>ERROR: Cannot use both 'includes' and 'excludes' in dimensions (model 'customers')\n</code></pre></p> <p>Rule: All listed columns must exist in physical model</p> <p>Invalid example: <pre><code>dimensions:\n  includes:\n    - non_existent_column  # Column doesn't exist\n</code></pre></p> <p>Error message: <pre><code>ERROR: Column 'non_existent_column' not found in model 'analytics.customers'\n</code></pre></p>"},{"location":"semantic-layer/validation/#42-dimension-override-validation","title":"4.2 Dimension Override Validation","text":"<p>Rule: Override <code>name</code> must refer to existing column (after includes/excludes)</p> <p>Invalid example: <pre><code>dimensions:\n  excludes:\n    - email\n\n  overrides:\n    - name: email  # Error: excluded column\n      tags: [pii]\n</code></pre></p> <p>Error message: <pre><code>ERROR: Dimension override 'email' references excluded column (model 'customers')\n</code></pre></p> <p>Rule: <code>tags</code> must be array of strings</p> <p>Invalid example: <pre><code>overrides:\n  customer_tier:\n    tags: \"segmentation\"  # Should be array\n</code></pre></p> <p>Error message: <pre><code>ERROR: Dimension override 'customer_tier': 'tags' must be an array (model 'customers')\n</code></pre></p>"},{"location":"semantic-layer/validation/#43-dimension-proxy-validation","title":"4.3 Dimension Proxy Validation","text":"<p>Rule: Proxy <code>measure</code> must be in <code>model.measure</code> format (exactly one dot)</p> <p>Invalid examples: <pre><code>proxies:\n  # \u274c Error: Missing model prefix\n  order_count_dim:\n    measure: total_orders\n\n  # \u274c Error: Too many dots\n  order_count_dim_2:\n    measure: analytics.orders.total_orders\n</code></pre></p> <p>Error messages: <pre><code>ERROR: Dimension proxy 'order_count_dim': Measure reference must be in 'model.measure' format (got 'total_orders')\nERROR: Dimension proxy 'order_count_dim': Measure reference must have exactly one dot (got 'analytics.orders.total_orders')\n</code></pre></p> <p>Rule: Referenced model must exist and be reachable via joins</p> <p>Invalid example: <pre><code>dimensions:\n  proxies:\n    order_count_dim:\n      measure: orders.total_orders  # No join to 'orders' model\n</code></pre></p> <p>Error message: <pre><code>ERROR: Dimension proxy 'order_count_dim': Model 'orders' not reachable via joins (model 'customers')\n</code></pre></p> <p>Rule: Referenced measure must exist on target model</p> <p>Invalid example: <pre><code>dimensions:\n  proxies:\n    order_count_dim:\n      measure: orders.non_existent_measure  # Measure doesn't exist\n</code></pre></p> <p>Error message: <pre><code>ERROR: Dimension proxy 'order_count_dim': Measure 'non_existent_measure' not found in model 'orders'\n</code></pre></p> <p>Rule: Cannot reference current model (only joined models)</p> <p>Invalid example: <pre><code>models:\n  analytics.customers:\n    alias: customers\n\n    dimensions:\n      proxies:\n        customer_count_dim:\n          measure: customers.total_customers  # Cannot reference self\n</code></pre></p> <p>Error message: <pre><code>ERROR: Dimension proxy 'customer_count_dim': Cannot reference current model 'customers' (only joined models allowed)\n</code></pre></p> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/validation/#5-measures-validation","title":"5. Measures Validation","text":""},{"location":"semantic-layer/validation/#51-measure-name-validation","title":"5.1 Measure Name Validation","text":"<p>Rule: Measure name must follow identifier format rules</p> <p>Invalid example: <pre><code>measures:\n  \"total-revenue\":  # Invalid: contains hyphen\n    type: sum\n    expression: \"SUM(amount)\"\n</code></pre></p> <p>Error message: <pre><code>ERROR: Invalid measure name 'total-revenue': Invalid character '-' (only letters, digits, underscores allowed)\n</code></pre></p>"},{"location":"semantic-layer/validation/#52-measure-expression-validation","title":"5.2 Measure Expression Validation","text":"<p>Rule: Expression must be valid SQL</p> <p>Invalid example: <pre><code>measures:\n  total_revenue:\n    type: sum\n    expression: \"SUM(amount\"  # Missing closing parenthesis\n</code></pre></p> <p>Error message: <pre><code>ERROR: Measure 'total_revenue': Invalid SQL expression (syntax error at position 10)\n</code></pre></p> <p>Rule: Referenced columns must exist</p> <p>Invalid example: <pre><code>measures:\n  total_revenue:\n    type: sum\n    expression: \"SUM(non_existent_column)\"  # Column doesn't exist\n</code></pre></p> <p>Error message: <pre><code>ERROR: Measure 'total_revenue': Column 'non_existent_column' not found in model 'analytics.orders'\n</code></pre></p> <p>Rule: Other models must be connected via joins</p> <p>Invalid example: <pre><code>models:\n  analytics.orders:\n    alias: orders\n\n    measures:\n      customer_revenue:\n        type: sum\n        expression: \"SUM(customers.amount)\"  # No join to 'customers'\n</code></pre></p> <p>Error message: <pre><code>ERROR: Measure 'customer_revenue': Model 'customers' not reachable via joins (model 'orders')\n</code></pre></p> <p>Rule: Cannot reference the measure itself (no self-reference)</p> <p>Invalid example: <pre><code>measures:\n  total_revenue:\n    type: expression\n    expression: \"total_revenue * 1.1\"  # Self-reference\n</code></pre></p> <p>Error message: <pre><code>ERROR: Measure 'total_revenue': Cannot reference itself (circular dependency)\n</code></pre></p>"},{"location":"semantic-layer/validation/#53-measure-filter-validation","title":"5.3 Measure Filter Validation","text":"<p>Rule: Each filter must be valid SQL WHERE condition</p> <p>Invalid example: <pre><code>measures:\n  active_revenue:\n    type: sum\n    expression: \"SUM(amount)\"\n    filters:\n      - \"status = 'active'\"  # Missing closing quote\n</code></pre></p> <p>Error message: <pre><code>ERROR: Measure 'active_revenue': Invalid filter expression (syntax error)\n</code></pre></p> <p>Rule: Filters cannot reference measures</p> <p>Invalid example: <pre><code>measures:\n  high_revenue:\n    type: sum\n    expression: \"SUM(amount)\"\n    filters:\n      - \"total_revenue &gt; 1000\"  # Cannot reference measure\n</code></pre></p> <p>Error message: <pre><code>ERROR: Measure 'high_revenue': Filter cannot reference measure 'total_revenue' (only columns and dimensions allowed)\n</code></pre></p>"},{"location":"semantic-layer/validation/#54-measure-dependency-validation","title":"5.4 Measure Dependency Validation","text":"<p>Rule: Referenced measures must exist</p> <p>Invalid example: <pre><code>measures:\n  avg_revenue:\n    type: expression\n    expression: \"total_revenue / NULLIF(total_orders, 0)\"  # total_revenue doesn't exist\n</code></pre></p> <p>Error message: <pre><code>ERROR: Measure 'avg_revenue': Referenced measure 'total_revenue' not found\n</code></pre></p> <p>Rule: No circular dependencies</p> <p>Invalid example: <pre><code>measures:\n  measure_a:\n    type: expression\n    expression: \"measure_b + 10\"\n\n  measure_b:\n    type: expression\n    expression: \"measure_a + 20\"  # Circular dependency\n</code></pre></p> <p>Error message: <pre><code>ERROR: Circular dependency detected in measures: measure_a \u2192 measure_b \u2192 measure_a\n</code></pre></p> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/validation/#6-segments-validation","title":"6. Segments Validation","text":""},{"location":"semantic-layer/validation/#61-segment-name-validation","title":"6.1 Segment Name Validation","text":"<p>Rule: Segment name must follow identifier format rules</p> <p>Invalid example: <pre><code>segments:\n  \"active-users\":  # Invalid: contains hyphen\n    expression: \"status = 'active'\"\n</code></pre></p> <p>Error message: <pre><code>ERROR: Invalid segment name 'active-users': Invalid character '-' (only letters, digits, underscores allowed)\n</code></pre></p>"},{"location":"semantic-layer/validation/#62-segment-expression-validation","title":"6.2 Segment Expression Validation","text":"<p>Rule: Expression must be valid SQL WHERE condition</p> <p>Invalid example: <pre><code>segments:\n  active:\n    expression: \"status = 'active\"  # Missing closing quote\n</code></pre></p> <p>Error message: <pre><code>ERROR: Segment 'active': Invalid expression (syntax error)\n</code></pre></p> <p>Rule: Can only reference current model columns</p> <p>Invalid example: <pre><code>models:\n  analytics.customers:\n    alias: customers\n\n    segments:\n      has_orders:\n        expression: \"orders.order_count &gt; 0\"  # Cannot reference other model\n</code></pre></p> <p>Error message: <pre><code>ERROR: Segment 'has_orders': Cannot reference other model 'orders' (only current model columns allowed)\n</code></pre></p> <p>Rule: Cannot reference measures</p> <p>Invalid example: <pre><code>segments:\n  high_value:\n    expression: \"total_revenue &gt; 1000\"  # Cannot reference measure\n</code></pre></p> <p>Error message: <pre><code>ERROR: Segment 'high_value': Cannot reference measure 'total_revenue' (only columns allowed)\n</code></pre></p> <p>Rule: Dimension proxies must use <code>{proxy_name}</code> syntax</p> <p>Invalid example: <pre><code>segments:\n  has_orders:\n    expression: \"order_count_dim &gt; 0\"  # Should use {order_count_dim}\n</code></pre></p> <p>Error message: <pre><code>ERROR: Segment 'has_orders': Dimension proxy 'order_count_dim' must be referenced as '{order_count_dim}'\n</code></pre></p> <p>Valid example: <pre><code>segments:\n  has_orders:\n    expression: \"{order_count_dim} &gt; 0\"  # Correct syntax\n</code></pre></p> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/validation/#7-joins-validation","title":"7. Joins Validation","text":""},{"location":"semantic-layer/validation/#71-join-name-validation","title":"7.1 Join Name Validation","text":"<p>Rule: Join <code>name</code> must be semantic model alias (not physical name)</p> <p>Invalid example: <pre><code>joins:\n  analytics.customers:  # Should be 'customers' (alias)\n    type: many_to_one\n    expression: \"...\"\n</code></pre></p> <p>Error message: <pre><code>ERROR: Join target 'analytics.customers' not found (use semantic alias 'customers')\n</code></pre></p>"},{"location":"semantic-layer/validation/#72-join-target-validation","title":"7.2 Join Target Validation","text":"<p>Rule: Target model must exist</p> <p>Invalid example: <pre><code>joins:\n  non_existent_model:\n    type: one_to_many\n    expression: \"...\"\n</code></pre></p> <p>Error message: <pre><code>ERROR: Join target 'non_existent_model' not found\n</code></pre></p>"},{"location":"semantic-layer/validation/#73-join-expression-validation","title":"7.3 Join Expression Validation","text":"<p>Rule: Expression must use <code>model.column</code> format</p> <p>Invalid examples: <pre><code>joins:\n  # \u274c Error: Unqualified column\n  customers:\n    type: many_to_one\n    expression: \"customer_id = customers.customer_id\"\n\n  # \u274c Error: Column doesn't exist\n  customers_2:\n    type: many_to_one\n    expression: \"orders.non_existent_col = customers.customer_id\"\n</code></pre></p> <p>Error messages: <pre><code>ERROR: Join expression: Column 'customer_id' must be qualified with model name (use 'orders.customer_id')\nERROR: Join expression: Column 'non_existent_col' not found in model 'analytics.orders'\n</code></pre></p> <p>Rule: Expression must be valid SQL join condition</p> <p>Invalid example: <pre><code>joins:\n  customers:\n    type: many_to_one\n    expression: \"orders.customer_id\"  # Not a join condition\n</code></pre></p> <p>Error message: <pre><code>ERROR: Join expression: Invalid join condition (must be comparison expression)\n</code></pre></p>"},{"location":"semantic-layer/validation/#74-join-graph-validation","title":"7.4 Join Graph Validation","text":"<p>Rule: No circular dependencies</p> <p>Invalid example: <pre><code># Creates cycle: customers \u2192 orders \u2192 products \u2192 customers\nmodels:\n  analytics.customers:\n    alias: customers\n    joins:\n      orders:\n        type: one_to_many\n        expression: \"customers.customer_id = orders.customer_id\"\n\n  analytics.orders:\n    alias: orders\n    joins:\n      products:\n        type: many_to_one\n        expression: \"orders.product_id = products.product_id\"\n\n  analytics.products:\n    alias: products\n    joins:\n      customers:  # Creates cycle\n        type: many_to_one\n        expression: \"products.vendor_id = customers.customer_id\"\n</code></pre></p> <p>Error message: <pre><code>ERROR: Circular dependency detected in join graph: customers \u2192 orders \u2192 products \u2192 customers\n</code></pre></p> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/validation/#8-metrics-validation","title":"8. Metrics Validation","text":""},{"location":"semantic-layer/validation/#81-metric-name-validation","title":"8.1 Metric Name Validation","text":"<p>Rule: Metric name must follow identifier format rules</p> <p>Invalid example: <pre><code>metrics:\n  \"monthly-revenue\":  # Invalid: contains hyphen\n    measure: orders.total_revenue\n    time: orders.order_date\n</code></pre></p> <p>Error message: <pre><code>ERROR: Invalid metric name 'monthly-revenue': Invalid character '-' (only letters, digits, underscores allowed)\n</code></pre></p>"},{"location":"semantic-layer/validation/#82-metric-measure-validation","title":"8.2 Metric Measure Validation","text":"<p>Rule: <code>measure</code> must be in <code>model.measure</code> format</p> <p>Invalid examples: <pre><code>metrics:\n  monthly_revenue:\n    # \u274c Error: Missing model prefix\n    measure: total_revenue\n\n    # \u274c Error: Too many dots\n    measure: analytics.orders.total_revenue\n</code></pre></p> <p>Error messages: <pre><code>ERROR: Metric 'monthly_revenue': Measure reference must be in 'model.measure' format (got 'total_revenue')\nERROR: Metric 'monthly_revenue': Measure reference must have exactly one dot (got 'analytics.orders.total_revenue')\n</code></pre></p> <p>Rule: Referenced measure must exist</p> <p>Invalid example: <pre><code>metrics:\n  monthly_revenue:\n    measure: orders.non_existent_measure\n    time: orders.order_date\n</code></pre></p> <p>Error message: <pre><code>ERROR: Metric 'monthly_revenue': Measure 'non_existent_measure' not found in model 'orders'\n</code></pre></p>"},{"location":"semantic-layer/validation/#83-metric-time-validation","title":"8.3 Metric Time Validation","text":"<p>Rule: <code>time</code> must be in <code>model.column</code> format</p> <p>Invalid example: <pre><code>metrics:\n  monthly_revenue:\n    measure: orders.total_revenue\n    time: order_date  # Missing model prefix\n</code></pre></p> <p>Error message: <pre><code>ERROR: Metric 'monthly_revenue': Time reference must be in 'model.column' format (got 'order_date')\n</code></pre></p> <p>Rule: Column must be timestamp/datetime type</p> <p>Invalid example: <pre><code>metrics:\n  monthly_revenue:\n    measure: orders.total_revenue\n    time: orders.status  # Not a timestamp column\n</code></pre></p> <p>Error message: <pre><code>ERROR: Metric 'monthly_revenue': Time column 'status' must be timestamp/datetime type (got VARCHAR)\n</code></pre></p> <p>Rule: Cannot be same field as measure (if same model)</p> <p>Invalid example: <pre><code>metrics:\n  revenue_over_time:\n    measure: orders.total_revenue\n    time: orders.total_revenue  # Same field as measure\n</code></pre></p> <p>Error message: <pre><code>ERROR: Metric 'revenue_over_time': Time and measure cannot reference same field 'total_revenue'\n</code></pre></p>"},{"location":"semantic-layer/validation/#84-metric-dimensions-validation","title":"8.4 Metric Dimensions Validation","text":"<p>Rule: All references must use <code>model.field</code> format</p> <p>Invalid example: <pre><code>metrics:\n  monthly_revenue:\n    measure: orders.total_revenue\n    time: orders.order_date\n    dimensions:\n      - customer_tier  # Missing model prefix\n</code></pre></p> <p>Error message: <pre><code>ERROR: Metric 'monthly_revenue': Dimension reference must be in 'model.field' format (got 'customer_tier')\n</code></pre></p> <p>Rule: No duplicate dimensions</p> <p>Invalid example: <pre><code>metrics:\n  monthly_revenue:\n    measure: orders.total_revenue\n    time: orders.order_date\n    dimensions:\n      - customers.customer_tier\n      - customers.customer_tier  # Duplicate\n</code></pre></p> <p>Error message: <pre><code>ERROR: Metric 'monthly_revenue': Duplicate dimension 'customers.customer_tier'\n</code></pre></p> <p>Rule: All models must be connected via joins</p> <p>Invalid example: <pre><code>metrics:\n  revenue_by_product:\n    measure: orders.total_revenue\n    time: orders.order_date\n    dimensions:\n      - products.category  # No join path from orders to products\n</code></pre></p> <p>Error message: <pre><code>ERROR: Metric 'revenue_by_product': No join path found from 'orders' to 'products'\n</code></pre></p> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/validation/#9-reference-validation","title":"9. Reference Validation","text":""},{"location":"semantic-layer/validation/#91-model-reference-format","title":"9.1 Model Reference Format","text":"<p>Rule: All model references must use semantic alias (not physical name)</p> <p>Invalid examples: <pre><code># \u274c Using physical name\nmeasure: analytics.orders.total_revenue\n\n# \u2705 Using semantic alias\nmeasure: orders.total_revenue\n</code></pre></p> <p>Error message: <pre><code>ERROR: Model reference 'analytics.orders' not found (use semantic alias 'orders')\n</code></pre></p>"},{"location":"semantic-layer/validation/#92-field-reference-format","title":"9.2 Field Reference Format","text":"<p>Rule: References must use <code>model.field</code> format (exactly one dot)</p> <p>Invalid examples: <pre><code># \u274c Missing model prefix\nmeasure: total_revenue\n\n# \u274c Too many dots\nmeasure: analytics.orders.total_revenue\n\n# \u2705 Correct\nmeasure: orders.total_revenue\n</code></pre></p> <p>Error messages: <pre><code>ERROR: Reference must include model prefix (use 'model.field' format)\nERROR: Reference must have exactly one dot (got 'analytics.orders.total_revenue')\n</code></pre></p>"},{"location":"semantic-layer/validation/#93-cross-model-reference-rules","title":"9.3 Cross-Model Reference Rules","text":"<p>What can reference what:</p> From Can Reference Cannot Reference Measure filter Current model columns/dimensions, Joined model dimensions Measures, Models without join Measure expression Current model columns/dimensions/measures, Joined model dimensions/measures Self-reference, Models without join Segment expression Current model columns only Other models, Measures, Dimension proxies (except <code>{proxy}</code> syntax) Join expression Source/target model columns Other models Metric measure/time/dims Measures/dimensions/columns across models Models without join path <p>Invalid examples: <pre><code># \u274c Measure filter referencing measure\nmeasures:\n  high_revenue:\n    type: sum\n    expression: \"SUM(amount)\"\n    filters:\n      - \"total_revenue &gt; 1000\"  # Cannot reference measure\n\n# \u274c Segment referencing other model\nsegments:\n  has_orders:\n    expression: \"orders.order_count &gt; 0\"  # Cannot reference other model\n\n# \u274c Metric with disconnected models\nmetrics:\n  revenue_by_product:\n    measure: orders.total_revenue\n    time: orders.order_date\n    dimensions:\n      - products.category  # No join path\n</code></pre></p> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/validation/#10-common-error-patterns","title":"10. Common Error Patterns","text":""},{"location":"semantic-layer/validation/#101-naming-errors","title":"10.1 Naming Errors","text":"<p>Pattern: Invalid characters</p> <pre><code># \u274c Common mistakes\n\"total-revenue\":     # Hyphen\n  type: sum\n\"total revenue\":     # Space\n  type: sum\n\"123revenue\":        # Starts with digit\n  type: sum\n\"total.revenue\":     # Dot\n  type: sum\n</code></pre> <p>Solution: Use only letters, digits, underscores, start with letter</p>"},{"location":"semantic-layer/validation/#102-reference-errors","title":"10.2 Reference Errors","text":"<p>Pattern: Missing model prefix</p> <pre><code># \u274c Common mistake\nmeasure: total_revenue  # Missing 'orders.' prefix\n\n# \u2705 Correct\nmeasure: orders.total_revenue\n</code></pre> <p>Pattern: Using physical name instead of alias</p> <pre><code># \u274c Common mistake\nmeasure: analytics.orders.total_revenue  # Physical name\n\n# \u2705 Correct\nmeasure: orders.total_revenue  # Semantic alias\n</code></pre>"},{"location":"semantic-layer/validation/#103-dependency-errors","title":"10.3 Dependency Errors","text":"<p>Pattern: Circular dependencies</p> <pre><code># \u274c Common mistake\nmeasures:\n  measure_a:\n    type: expression\n    expression: \"measure_b + 10\"\n  measure_b:\n    type: expression\n    expression: \"measure_a + 20\"  # Circular!\n</code></pre> <p>Solution: Break cycle with base measure</p>"},{"location":"semantic-layer/validation/#104-join-errors","title":"10.4 Join Errors","text":"<p>Pattern: Disconnected models</p> <pre><code># \u274c Common mistake\nmetrics:\n  revenue_by_product:\n    measure: orders.total_revenue\n    dimensions:\n      - products.category  # No join defined\n</code></pre> <p>Solution: Add join between models</p> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/validation/#11-troubleshooting-guide","title":"11. Troubleshooting Guide","text":""},{"location":"semantic-layer/validation/#111-step-by-step-debugging","title":"11.1 Step-by-Step Debugging","text":"<p>Step 1: Read the error message - Identify component (measure, segment, join, etc.) - Note the rule violated - Check file location</p> <p>Step 2: Locate the problematic definition - Open the file mentioned in error - Find the line number - Review the definition</p> <p>Step 3: Check validation rules - Refer to relevant section in this chapter - Verify field requirements - Check reference formats</p> <p>Step 4: Fix the issue - Apply the solution pattern - Validate syntax - Test the fix</p> <p>Step 5: Re-validate - Run <code>vulcan validate</code> again - Check for additional errors - Iterate until clean</p>"},{"location":"semantic-layer/validation/#112-common-fixes","title":"11.2 Common Fixes","text":"<p>Fix naming errors: <pre><code># Before\n\"total-revenue\":\n  type: sum\n\n# After\ntotal_revenue:\n  type: sum\n</code></pre></p> <p>Fix reference errors: <pre><code># Before\nmeasure: total_revenue\n\n# After\nmeasure: orders.total_revenue\n</code></pre></p> <p>Fix dependency errors: <pre><code># Before (circular)\nmeasures:\n  measure_a:\n    type: expression\n    expression: \"measure_b + 10\"\n  measure_b:\n    type: expression\n    expression: \"measure_a + 20\"\n\n# After (base measure)\nmeasures:\n  base_value:\n    type: sum\n    expression: \"SUM(amount)\"\n  measure_a:\n    type: expression\n    expression: \"base_value + 10\"\n  measure_b:\n    type: expression\n    expression: \"base_value + 20\"\n</code></pre></p> <p>Fix join errors: <pre><code># Before (missing join)\nmetrics:\n  revenue_by_product:\n    measure: orders.total_revenue\n    dimensions:\n      - products.category\n\n# After (add join)\nmodels:\n  analytics.orders:\n    alias: orders\n    joins:\n      products:\n        type: many_to_one\n        expression: \"orders.product_id = products.product_id\"\n</code></pre></p>"},{"location":"semantic-layer/validation/#113-validation-checklist","title":"11.3 Validation Checklist","text":"<p>Before submitting: - [ ] All names follow identifier rules - [ ] No duplicate names within models - [ ] No duplicate metric names across files - [ ] All model references use semantic aliases - [ ] All field references use <code>model.field</code> format - [ ] All referenced models exist - [ ] All referenced fields exist - [ ] All models in metrics are connected via joins - [ ] No circular dependencies - [ ] All required fields are present - [ ] SQL expressions are valid - [ ] YAML syntax is correct</p> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/validation/#12-summary","title":"12. Summary","text":""},{"location":"semantic-layer/validation/#key-validation-rules","title":"Key Validation Rules","text":"<ol> <li>Naming:</li> <li>Start with letter</li> <li>Only letters, digits, underscores</li> <li>Max 64 characters</li> <li> <p>Unique within scope</p> </li> <li> <p>References:</p> </li> <li>Always use <code>model.field</code> format</li> <li>Use semantic aliases (not physical names)</li> <li> <p>Exactly one dot in references</p> </li> <li> <p>Dependencies:</p> </li> <li>No circular dependencies</li> <li>All referenced entities must exist</li> <li> <p>Models must be connected via joins</p> </li> <li> <p>Field Requirements:</p> </li> <li>Required fields must be present</li> <li>Field types must match (e.g., timestamp for time)</li> <li>SQL expressions must be valid</li> </ol>"},{"location":"semantic-layer/validation/#validation-workflow","title":"Validation Workflow","text":"<ol> <li>Write definitions following syntax rules</li> <li>Validate frequently during development</li> <li>Read error messages carefully</li> <li>Fix issues systematically</li> <li>Re-validate until clean</li> </ol>"},{"location":"semantic-layer/validation/#next-steps","title":"Next Steps","text":"<ul> <li>Chapter 3: Semantic Layer - Foundation concepts</li> <li>Chapter 3A: YAML Reference - Complete syntax reference</li> <li>Chapter 3B: Advanced Measures - Complex measure patterns</li> <li>Chapter 3C: Advanced Joins - Cross-model analysis patterns</li> </ul> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/yaml-reference/","title":"Chapter 3A: Semantic Layer YAML Reference","text":"<p>Complete reference for all semantic layer YAML syntax - Every field, option, and pattern explained with examples, defaults, and validation rules.</p>"},{"location":"semantic-layer/yaml-reference/#prerequisites","title":"Prerequisites","text":"<p>Before diving into this chapter, you should have:</p>"},{"location":"semantic-layer/yaml-reference/#required-knowledge","title":"Required Knowledge","text":"<p>Chapter 3: Semantic Layer - Understanding of: - Basic semantic layer concepts - Models, dimensions, measures, segments, joins, metrics - How semantic layer maps to physical models</p> <p>YAML Syntax - Basic YAML structure (dictionaries, lists) - Multi-line strings (<code>|</code> syntax) - Indentation rules</p> <p>SQL Proficiency - Basic SQL expressions - Aggregations (<code>COUNT</code>, <code>SUM</code>, <code>AVG</code>) - <code>WHERE</code> clauses</p>"},{"location":"semantic-layer/yaml-reference/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Introduction</li> <li>Top-Level Structure</li> <li>Semantic Models</li> <li>Dimensions</li> <li>Measures</li> <li>Segments</li> <li>Joins</li> <li>Business Metrics</li> <li>Naming and Validation Rules</li> <li>YAML Formatting Best Practices</li> <li>Quick Reference</li> <li>Complete Examples</li> </ol>"},{"location":"semantic-layer/yaml-reference/#1-introduction","title":"1. Introduction","text":""},{"location":"semantic-layer/yaml-reference/#11-what-is-this-reference","title":"1.1 What is This Reference?","text":"<p>This chapter provides a complete, exhaustive reference for every field, option, and pattern in semantic layer YAML files. Use it when you need to:</p> <ul> <li>Understand what a specific field does</li> <li>Know what values are valid</li> <li>See examples of complex patterns</li> <li>Debug validation errors</li> <li>Find the exact syntax for a feature</li> </ul>"},{"location":"semantic-layer/yaml-reference/#12-how-to-use-this-reference","title":"1.2 How to Use This Reference","text":"<p>For Quick Lookups: - Jump to Quick Reference for syntax cheat sheets - Use the table of contents to find specific components</p> <p>For Deep Understanding: - Read each section in order - Study the examples - Review validation rules</p> <p>For Troubleshooting: - Check Naming and Validation Rules - Review field requirements - Verify syntax patterns</p>"},{"location":"semantic-layer/yaml-reference/#13-file-organization","title":"1.3 File Organization","text":"<p>Semantic layer definitions live in YAML files, typically:</p> <pre><code>project/\n\u251c\u2500\u2500 semantics/\n\u2502   \u251c\u2500\u2500 customers.yml      # Customer model definitions\n\u2502   \u251c\u2500\u2500 orders.yml         # Order model definitions\n\u2502   \u251c\u2500\u2500 products.yml       # Product model definitions\n\u2502   \u2514\u2500\u2500 metrics.yml        # Business metrics\n\u2514\u2500\u2500 config.yaml\n</code></pre> <p>File naming: - Must end with <code>.yml</code> or <code>.yaml</code> - Name doesn't matter (Vulcan reads all files) - Organize by domain or model for clarity</p> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/yaml-reference/#2-top-level-structure","title":"2. Top-Level Structure","text":""},{"location":"semantic-layer/yaml-reference/#21-root-keys","title":"2.1 Root Keys","text":"<p>Every semantic layer YAML file has two top-level keys:</p> <pre><code>models:      # Dictionary of semantic model definitions\n  &lt;physical_model&gt;:  # Dictionary key (physical model name)\n    name: ...        # Business-friendly alias\n    dimensions: ...\n    measures: ...\n    segments: ...\n    joins: ...\n\nmetrics:     # Dictionary of business metric definitions\n  metric_name: ...\n    measure: ...\n    time: ...\n    dimensions: ...\n</code></pre> <p>Both keys are optional: - File can contain only <code>models:</code> (no metrics) - File can contain only <code>metrics:</code> (no models) - File can contain both</p>"},{"location":"semantic-layer/yaml-reference/#22-models-dictionary","title":"2.2 Models Dictionary","text":"<p><code>models:</code> is a dictionary of semantic model definitions:</p> <pre><code>models:\n  analytics.customers:    # Physical model name (dictionary key)\n    alias: customers       # Business-friendly semantic alias\n    measures: {...}\n\n  analytics.orders:        # Physical model name (dictionary key)\n    alias: orders          # Business-friendly semantic alias\n    measures: {...}\n</code></pre> <p>Key points: - Each model is a dictionary key (physical model name) - <code>name:</code> field provides the business-friendly alias - Models are independent (can reference each other) - Order doesn't matter (Vulcan resolves dependencies)</p>"},{"location":"semantic-layer/yaml-reference/#23-metrics-dictionary","title":"2.3 Metrics Dictionary","text":"<p><code>metrics:</code> is a dictionary of business metric definitions:</p> <pre><code>metrics:\n  monthly_revenue:              # Metric name (key)\n    measure: orders.total_revenue\n    time: orders.order_date\n\n  customer_growth:               # Another metric (key)\n    measure: customers.total_customers\n    time: customers.signup_date\n</code></pre> <p>Key points: - Each metric is a dictionary key - Metric names must be unique across all files - Metrics reference models defined in <code>models:</code></p> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/yaml-reference/#3-semantic-models","title":"3. Semantic Models","text":""},{"location":"semantic-layer/yaml-reference/#31-model-structure","title":"3.1 Model Structure","text":"<p>A semantic model maps a physical Vulcan model to a semantic representation:</p> <pre><code>models:\n  &lt;physical_model_name&gt;:     # REQUIRED (dictionary key)\n    name: &lt;semantic_alias&gt;   # Required for schema.table format\n    description: \"...\"        # Optional\n    dimensions: {...}         # Optional\n    measures: {...}           # Optional\n    segments: {...}           # Optional\n    joins: {...}              # Optional\n</code></pre>"},{"location":"semantic-layer/yaml-reference/#32-name-required","title":"3.2 <code>name</code> (Required)","text":"<p>Purpose: References the physical Vulcan model</p> <p>Format: - Simple name: <code>customers</code> (no schema prefix) - Fully qualified: <code>analytics.customers</code> (schema.table format)</p> <p>Examples: <pre><code># Simple model name\ncustomers:\n  alias: customers\n\n# Fully qualified name (schema.table)\nanalytics.dim_customers:\n  alias: customers\n- name: sales.fact_orders\n</code></pre></p> <p>Validation: - Must match an existing Vulcan model name exactly - Case-sensitive - Must exist when semantic layer is loaded</p> <p>Error examples: <pre><code># \u274c Model doesn't exist\n- name: non_existent_model\n\n# \u274c Typo in name\n- name: analytics.custmers  # Should be 'customers'\n</code></pre></p>"},{"location":"semantic-layer/yaml-reference/#33-alias-required-for-fqn","title":"3.3 <code>alias</code> (Required for FQN)","text":"<p>Purpose: Consumer-facing name for the semantic model</p> <p>When required: - Required when <code>name</code> is fully qualified (<code>schema.table</code>) - Optional when <code>name</code> is simple (no schema prefix)</p> <p>Format: - Must follow identifier rules (see Naming Rules) - Letters, digits, underscores only - Starts with letter - Max 64 characters</p> <p>Examples: <pre><code># \u2705 FQN with alias (required)\n- name: analytics.dim_customers\n  alias: customers\n\n# \u2705 Simple name (alias optional, defaults to name)\n- name: customers\n  # alias defaults to 'customers'\n\n# \u2705 Simple name with explicit alias\n- name: customers\n  alias: users  # Override default\n</code></pre></p> <p>Usage: - Use <code>alias</code> in all references (joins, metrics, dimension proxies) - Never use physical model name (<code>analytics.customers</code>) in references - Always use semantic alias (<code>customers</code>) in references</p> <p>Error examples: <pre><code># \u274c FQN without alias\n- name: analytics.customers\n  # Missing alias!\n\n# \u274c Invalid alias format\n- name: analytics.customers\n  alias: \"customer-users\"  # Hyphens not allowed\n</code></pre></p>"},{"location":"semantic-layer/yaml-reference/#34-description-optional","title":"3.4 <code>description</code> (Optional)","text":"<p>Purpose: Human-readable description of the semantic model</p> <p>Format: - String (single or multi-line) - No length limit - Supports markdown (tool-dependent)</p> <p>Examples: <pre><code>- name: analytics.customers\n  alias: customers\n  description: \"Customer dimension table with subscription and profile data\"\n\n- name: analytics.orders\n  alias: orders\n  description: |\n    Fact table containing all customer orders.\n    Includes order details, amounts, and status.\n    Updated daily from transactional system.\n</code></pre></p> <p>Best practices: - Explain what the model represents - Note data freshness or update frequency - Mention key business use cases</p>"},{"location":"semantic-layer/yaml-reference/#35-model-sections","title":"3.5 Model Sections","text":"<p>Each semantic model can have four optional sections:</p> Section Purpose Required? <code>dimensions</code> Column selection and enhancement No <code>measures</code> Aggregated calculations No <code>segments</code> Reusable filter conditions No <code>joins</code> Relationships to other models No <p>All sections are optional: <pre><code># Minimal model (all columns as dimensions, no measures)\nanalytics.customers:\n  alias: customers\n\n# Model with measures only\nanalytics.orders:\n  alias: orders\n  measures:\n    total_revenue:\n      type: sum\n      expression: \"SUM(amount)\"\n\n# Complete model\nanalytics.customers:\n  alias: customers\n  dimensions: {...}\n  measures: {...}\n  segments: {...}\n  joins: {...}\n</code></pre></p> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/yaml-reference/#4-dimensions","title":"4. Dimensions","text":""},{"location":"semantic-layer/yaml-reference/#41-dimension-structure","title":"4.1 Dimension Structure","text":"<p>Dimensions control which columns are exposed and how they're enriched:</p> <pre><code>dimensions:\n  includes: [...]                # Option 1: Whitelist columns\n  excludes: [...]                # Option 2: Blacklist columns\n  overrides: [...]               # Add tags/meta to dimensions\n  proxies: [...]                 # Proxy joined model measures as dimensions\n</code></pre> <p>All fields are optional: - If <code>dimensions:</code> block is omitted, all columns are available - If <code>dimensions:</code> block exists, at least one field should be specified</p>"},{"location":"semantic-layer/yaml-reference/#42-includes-optional","title":"4.2 <code>includes</code> (Optional)","text":"<p>Purpose: Explicitly list columns to expose as dimensions</p> <p>Format: - Array of column names (strings) - Column names must exist in physical model - Case-sensitive</p> <p>Examples: <pre><code>dimensions:\n  includes:\n    - customer_id\n    - email\n    - customer_tier\n    - signup_date\n</code></pre></p> <p>Use when: - Working with sensitive data models - Only exposing specific columns - Tight control over exposed dimensions</p> <p>Validation: - All listed columns must exist in physical model - Cannot use both <code>includes</code> and <code>excludes</code> (mutually exclusive)</p> <p>Error examples: <pre><code># \u274c Column doesn't exist\ndimensions:\n  includes:\n    - non_existent_column\n\n# \u274c Using both includes and excludes\ndimensions:\n  includes: [col1, col2]\n  excludes: [col3]  # Error: mutually exclusive\n</code></pre></p>"},{"location":"semantic-layer/yaml-reference/#43-excludes-optional","title":"4.3 <code>excludes</code> (Optional)","text":"<p>Purpose: Hide specific columns from dimensions</p> <p>Format: - Array of column names (strings) - Column names must exist in physical model - Case-sensitive</p> <p>Examples: <pre><code>dimensions:\n  excludes:\n    - password_hash\n    - ssn\n    - internal_notes\n    - deleted_at\n</code></pre></p> <p>Use when: - Most columns are fine, but need to hide a few - Hiding sensitive or internal columns - Most common pattern</p> <p>Validation: - All listed columns must exist in physical model - Cannot use both <code>includes</code> and <code>excludes</code> (mutually exclusive)</p> <p>Default behavior: - If neither <code>includes</code> nor <code>excludes</code> is specified, all columns are available</p>"},{"location":"semantic-layer/yaml-reference/#44-overrides-optional","title":"4.4 <code>overrides</code> (Optional)","text":"<p>Purpose: Add tags and metadata to specific dimensions</p> <p>Format: - Array of dimension override objects - Each override has <code>name</code> (required) and optional <code>tags</code>/<code>meta</code></p> <p>Structure: <pre><code>overrides:\n  &lt;column_name&gt;:                 # REQUIRED (dictionary key)\n    tags: [...]                  # Optional: Array of strings\n    meta: {...}                  # Optional: Dictionary\n</code></pre></p> <p>Examples: <pre><code>dimensions:\n  excludes:\n    - password_hash\n\n  overrides:\n    customer_tier:\n      tags:\n        - segmentation\n        - revenue\n        - high_priority\n      meta:\n        business_owner: \"Product Team\"\n        display_name: \"Customer Tier\"\n        sort_order: [\"Free\", \"Pro\", \"Enterprise\"]\n\n    - name: signup_date\n      tags:\n        - temporal\n        - acquisition\n      meta:\n        business_owner: \"Growth Team\"\n        format: \"YYYY-MM-DD\"\n        timezone: \"UTC\"\n</code></pre></p> <p>Validation: - <code>name</code> must refer to an existing column (after includes/excludes are applied) - <code>tags</code> must be an array of strings - <code>meta</code> must be a dictionary (key-value pairs)</p> <p>Common metadata fields: - <code>business_owner</code> - Team responsible - <code>display_name</code> - UI-friendly name - <code>description</code> - Business definition - <code>possible_values</code> - Valid values for enums - <code>format</code> - Display format hints - <code>sort_order</code> - Preferred ordering - Custom fields as needed</p>"},{"location":"semantic-layer/yaml-reference/#45-proxies-optional","title":"4.5 <code>proxies</code> (Optional)","text":"<p>Purpose: Expose measures from joined models as dimensions on current model</p> <p>Format: - Array of proxy objects - Each proxy has <code>name</code> (required) and <code>measure</code> (required)</p> <p>Structure: <pre><code>proxies:\n  &lt;dimension_alias&gt;:              # REQUIRED (dictionary key)\n    measure: &lt;model_alias&gt;.&lt;measure_name&gt;  # REQUIRED\n</code></pre></p> <p>Examples: <pre><code>dimensions:\n  proxies:\n    order_count_dim:\n      measure: orders.total_orders\n\n    lifetime_value_dim:\n      measure: orders.total_revenue\n</code></pre></p> <p>Use when: - Need to filter/group by a measure from another model - Creating segments that reference cross-model measures - Enabling CubeJS-like functionality</p> <p>Validation: - <code>name</code> must follow identifier rules and be unique - <code>measure</code> must be in <code>model.measure</code> format (exactly one dot) - Referenced model must exist and be reachable via joins - Referenced measure must exist on target model - Cannot reference current model (only joined models)</p> <p>Error examples: <pre><code># \u274c Invalid measure format\nproxies:\n  order_count:\n    measure: total_orders  # Missing model prefix\n\n# \u274c Model doesn't exist\nproxies:\n  order_count:\n    measure: non_existent_model.total_orders\n\n# \u274c Measure doesn't exist\nproxies:\n  order_count:\n    measure: orders.non_existent_measure\n</code></pre></p> <p>Usage in segments: <pre><code>segments:\n  has_orders:\n    expression: \"{order_count_dim} &gt; 0\"  # Use proxy in segment\n</code></pre></p> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/yaml-reference/#5-measures","title":"5. Measures","text":""},{"location":"semantic-layer/yaml-reference/#51-measure-structure","title":"5.1 Measure Structure","text":"<p>Measures define aggregated values computed from your data:</p> <pre><code>measures:\n  &lt;measure_name&gt;:                # REQUIRED (dictionary key)\n    type: &lt;type&gt;                 # REQUIRED (count, sum, avg, expression, etc.)\n    expression: \"&lt;SQL_EXPRESSION&gt;\"  # REQUIRED\n    description: \"...\"         # Optional\n    filters: [...]               # Optional: Array of WHERE conditions\n    format: &lt;format_type&gt;        # Optional: Display hint\n    tags: [...]                  # Optional: Array of strings\n    meta: {...}                  # Optional: Dictionary\n</code></pre>"},{"location":"semantic-layer/yaml-reference/#52-name-required","title":"5.2 <code>name</code> (Required)","text":"<p>Purpose: Unique identifier for the measure</p> <p>Format: - Must follow identifier rules (see Naming Rules) - Letters, digits, underscores only - Starts with letter - Max 64 characters - Must be unique within model</p> <p>Examples: <pre><code>measures:\n  total_revenue:\n    type: sum\n  active_customers:\n    type: count\n  avg_order_value:\n    type: avg\n  customer_count_30d:\n    type: count\n</code></pre></p> <p>Validation: - Must be unique within model (cannot duplicate measure names) - Cannot conflict with segment names - Cannot conflict with dimension proxy names</p> <p>Error examples: <pre><code># \u274c Duplicate measure name\nmeasures:\n  total_revenue:\n    type: sum\n  total_revenue:  # Duplicate! (same key twice)\n\n# \u274c Invalid format\nmeasures:\n  \"total-revenue\":  # Hyphens not allowed\n    type: sum\n</code></pre></p>"},{"location":"semantic-layer/yaml-reference/#53-expression-required","title":"5.3 <code>expression</code> (Required)","text":"<p>Purpose: SQL expression that computes the measure value</p> <p>Format: - Valid SQL aggregation expression - Can reference columns, dimensions, other measures - Use <code>model.field</code> format for other models</p> <p>Basic examples: <pre><code>measures:\n  total_revenue:\n    type: sum\n    expression: \"SUM(amount)\"\n\n  order_count:\n    type: count\n    expression: \"COUNT(*)\"\n\n  avg_order_value:\n    type: avg\n    expression: \"AVG(order_total)\"\n\n  unique_customers:\n    type: count_distinct\n    expression: \"COUNT(DISTINCT customer_id)\"\n</code></pre></p> <p>Complex examples: <pre><code>measures:\n  active_revenue:\n    type: sum\n    expression: |\n      SUM(CASE \n        WHEN status = 'active' \n        THEN amount \n        ELSE 0 \n      END)\n\n  revenue_per_customer:\n    type: expression\n    expression: \"SUM(amount) / COUNT(DISTINCT customer_id)\"\n\n  conversion_rate:\n    type: expression\n    expression: |\n      COUNT(CASE WHEN converted = true THEN 1 END)::FLOAT / \n      NULLIF(COUNT(*), 0)\n</code></pre></p> <p>Cross-model references: <pre><code>measures:\n  customer_order_count:\n    type: count\n    expression: \"COUNT(orders.order_id)\"  # Reference joined model\n\n  total_customer_value:\n    type: sum\n    expression: \"SUM(orders.amount)\"  # Aggregate from joined model\n</code></pre></p> <p>What can be referenced: - \u2705 Current model columns: <code>amount</code>, <code>customer_id</code> - \u2705 Current model dimensions: <code>customer_tier</code>, <code>signup_date</code> - \u2705 Current model measures: <code>base_revenue</code> (no self-reference) - \u2705 Joined model dimensions: <code>users.country</code>, <code>products.category</code> - \u2705 Joined model measures: <code>subscriptions.mrr</code>, <code>usage.total_events</code></p> <p>Validation: - Must be valid SQL - Referenced fields must exist - Other models must be connected via joins - Cannot reference the measure itself (no self-reference)</p>"},{"location":"semantic-layer/yaml-reference/#54-filters-optional","title":"5.4 <code>filters</code> (Optional)","text":"<p>Purpose: Apply WHERE conditions to measure calculation</p> <p>Format: - Array of SQL WHERE conditions (strings) - Each filter is a separate condition - Conditions are combined with AND logic</p> <p>Examples: <pre><code>measures:\n  active_revenue:\n    type: sum\n    expression: \"SUM(amount)\"\n    filters:\n      - \"status = 'active'\"\n\n  recent_signups:\n    type: count\n    expression: \"COUNT(*)\"\n    filters:\n      - \"signup_date &gt;= CURRENT_DATE - INTERVAL '30 days'\"\n\n  enterprise_mrr:\n    type: sum\n    expression: \"SUM(mrr)\"\n    filters:\n      - \"plan_type = 'Enterprise'\"\n      - \"status = 'active'\"\n      - \"start_date &lt;= CURRENT_DATE\"\n</code></pre></p> <p>Filter logic: - All filters are combined with AND - Applied before aggregation - Can reference current model columns/dimensions - Can reference joined model dimensions (via <code>model.field</code>)</p> <p>Cross-model filters: <pre><code>measures:\n  us_customer_revenue:\n    type: sum\n    expression: \"SUM(amount)\"\n    filters:\n      - \"customers.country = 'US'\"  # Reference joined model\n      - \"status = 'completed'\"\n</code></pre></p> <p>What can be referenced: - \u2705 Current model columns: <code>status</code>, <code>amount</code> - \u2705 Current model dimensions: <code>customer_tier</code>, <code>signup_date</code> - \u2705 Current model dimension proxies: <code>order_count_dim</code> - \u2705 Joined model dimensions: <code>users.country</code>, <code>products.category</code> - \u274c Measures (current or other models)</p> <p>Validation: - Each filter must be valid SQL WHERE condition - Cannot be empty strings - Referenced fields must exist - Other models must be connected via joins</p>"},{"location":"semantic-layer/yaml-reference/#55-format-optional","title":"5.5 <code>format</code> (Optional)","text":"<p>Purpose: Display format hint for the measure</p> <p>Format: - String value from predefined list - Tool-dependent (may be ignored by some consumers)</p> <p>Valid values: - <code>currency</code> - Monetary values ($1,234.56) - <code>percentage</code> - Percentages (12.5%) - <code>number</code> - Numeric values (1,234.56) - <code>duration_ms</code> - Time duration in milliseconds - <code>bytes</code> - Byte sizes (1.5 MB)</p> <p>Examples: <pre><code>measures:\n  total_revenue:\n    type: sum\n    expression: \"SUM(amount)\"\n    format: currency\n\n  conversion_rate:\n    type: expression\n    expression: \"COUNT(converted) / COUNT(*)\"\n    format: percentage\n\n  avg_session_duration:\n    type: avg\n    expression: \"AVG(duration)\"\n    format: duration_ms\n</code></pre></p> <p>Note: Format is a hint only - actual formatting depends on consuming tool</p>"},{"location":"semantic-layer/yaml-reference/#56-description-optional","title":"5.6 <code>description</code> (Optional)","text":"<p>Purpose: Human-readable description of the measure</p> <p>Format: - String (single or multi-line) - No length limit - Supports markdown (tool-dependent)</p> <p>Examples: <pre><code>measures:\n  total_revenue:\n    type: sum\n    expression: \"SUM(amount)\"\n    description: \"Total revenue from all orders\"\n\n  active_mrr:\n    type: sum\n    expression: \"SUM(mrr)\"\n    description: |\n      Monthly Recurring Revenue from active subscriptions only.\n      Excludes cancelled, paused, or trial subscriptions.\n      Updated daily at 2 AM UTC.\n</code></pre></p> <p>Best practices: - Explain what the measure calculates - Note any filters or conditions - Mention update frequency if relevant</p>"},{"location":"semantic-layer/yaml-reference/#57-tags-optional","title":"5.7 <code>tags</code> (Optional)","text":"<p>Purpose: Categorize measures for discovery and organization</p> <p>Format: - Array of strings - No predefined values - Case-sensitive</p> <p>Examples: <pre><code>measures:\n  total_revenue:\n    type: sum\n    expression: \"SUM(amount)\"\n    tags:\n      - revenue\n      - financial\n      - kpi\n      - core_metric\n\n  active_customers:\n    type: count\n    expression: \"COUNT(*)\"\n    tags:\n      - count\n      - customers\n      - active\n</code></pre></p> <p>Common tag patterns: - Domain: <code>sales</code>, <code>marketing</code>, <code>finance</code>, <code>product</code> - Type: <code>revenue</code>, <code>count</code>, <code>rate</code>, <code>average</code> - Priority: <code>kpi</code>, <code>core_metric</code>, <code>experimental</code> - Status: <code>deprecated</code>, <code>certified</code>, <code>under_review</code></p>"},{"location":"semantic-layer/yaml-reference/#58-meta-optional","title":"5.8 <code>meta</code> (Optional)","text":"<p>Purpose: Free-form metadata dictionary</p> <p>Format: - Dictionary (key-value pairs) - Any keys allowed - Values can be strings, numbers, arrays, dictionaries</p> <p>Examples: <pre><code>measures:\n  total_revenue:\n    type: sum\n    expression: \"SUM(amount)\"\n    meta:\n      business_owner: \"Finance Team\"\n      certified: true\n      calculation_method: \"sum_of_order_amounts\"\n      data_source: \"orders table\"\n      last_updated: \"2024-01-15\"\n      kpi_target: 1000000\n</code></pre></p> <p>Common metadata fields: - <code>business_owner</code> - Team responsible - <code>certified</code> - Boolean indicating certification status - <code>calculation_method</code> - How measure is computed - <code>data_source</code> - Source table/model - <code>last_updated</code> - Update timestamp - Custom fields as needed</p> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/yaml-reference/#6-segments","title":"6. Segments","text":""},{"location":"semantic-layer/yaml-reference/#61-segment-structure","title":"6.1 Segment Structure","text":"<p>Segments define reusable filter conditions for the current model:</p> <pre><code>segments:\n  &lt;segment_name&gt;:                 # REQUIRED (dictionary key)\n    expression: \"&lt;WHERE_CONDITION&gt;\"  # REQUIRED (no WHERE keyword)\n    description: \"...\"            # Optional\n    tags: [...]                   # Optional: Array of strings\n    meta: {...}                   # Optional: Dictionary\n</code></pre>"},{"location":"semantic-layer/yaml-reference/#62-name-required","title":"6.2 <code>name</code> (Required)","text":"<p>Purpose: Unique identifier for the segment</p> <p>Format: - Must follow identifier rules (see Naming Rules) - Letters, digits, underscores only - Starts with letter - Max 64 characters - Must be unique within model</p> <p>Examples: <pre><code>segments:\n  active_users:\n    expression: \"...\"\n  high_value_customers:\n    expression: \"...\"\n  recent_signups:\n    expression: \"...\"\n  enterprise_tier:\n    expression: \"...\"\n</code></pre></p> <p>Validation: - Must be unique within model (cannot duplicate segment names) - Cannot conflict with measure names - Cannot conflict with dimension proxy names</p>"},{"location":"semantic-layer/yaml-reference/#63-expression-required","title":"6.3 <code>expression</code> (Required)","text":"<p>Purpose: SQL WHERE condition (without WHERE keyword)</p> <p>Format: - Valid SQL WHERE condition - Can only reference current model columns - Use <code>{dimension_proxy_name}</code> syntax for dimension proxies</p> <p>Basic examples: <pre><code>segments:\n  active:\n    expression: \"status = 'active'\"\n\n  high_value:\n    expression: \"total_spent &gt; 10000\"\n\n  recent_signups:\n    expression: \"signup_date &gt;= CURRENT_DATE - INTERVAL '30 days'\"\n</code></pre></p> <p>Complex examples: <pre><code>segments:\n  active_enterprise:\n    expression: |\n      status = 'active'\n      AND customer_tier = 'Enterprise'\n      AND signup_date &gt;= CURRENT_DATE - INTERVAL '90 days'\n\n  at_risk:\n    expression: |\n      status = 'active'\n      AND last_activity_date &lt; CURRENT_DATE - INTERVAL '14 days'\n      AND total_spent &lt; 1000\n</code></pre></p> <p>Using dimension proxies: <pre><code>dimensions:\n  proxies:\n    order_count_dim:\n      measure: orders.total_orders\n\nsegments:\n  has_orders:\n    expression: \"{order_count_dim} &gt; 0\"  # Use proxy in segment\n</code></pre></p> <p>What can be referenced: - \u2705 Current model columns: <code>status</code>, <code>amount</code>, <code>customer_id</code> - \u2705 Current model dimensions: <code>customer_tier</code>, <code>signup_date</code> - \u2705 Current model dimension proxies: <code>{order_count_dim}</code> - \u274c Other models: <code>users.country</code> (not allowed) - \u274c Measures: <code>total_revenue</code> (not allowed)</p> <p>Validation: - Must be valid SQL WHERE condition - Can only reference current model's raw columns - Dimension proxies must use <code>{proxy_name}</code> syntax - Cannot reference other models</p> <p>Error examples: <pre><code># \u274c Reference other model\nsegments:\n  us_customers:\n    expression: \"users.country = 'US'\"  # Not allowed\n\n# \u274c Reference measure\nsegments:\n  high_revenue:\n    expression: \"total_revenue &gt; 1000\"  # Not allowed\n</code></pre></p>"},{"location":"semantic-layer/yaml-reference/#64-description-optional","title":"6.4 <code>description</code> (Optional)","text":"<p>Purpose: Human-readable description of the segment</p> <p>Format: - String (single or multi-line) - No length limit</p> <p>Examples: <pre><code>segments:\n  active_users:\n    expression: \"status = 'active'\"\n    description: \"Users with active status\"\n\n  high_value:\n    expression: \"total_spent &gt; 10000\"\n    description: |\n      Customers with lifetime spend exceeding $10,000.\n      Used for VIP program eligibility and targeted marketing.\n</code></pre></p>"},{"location":"semantic-layer/yaml-reference/#65-tags-optional","title":"6.5 <code>tags</code> (Optional)","text":"<p>Purpose: Categorize segments for discovery</p> <p>Format: - Array of strings - No predefined values</p> <p>Examples: <pre><code>segments:\n  active_users:\n    expression: \"status = 'active'\"\n    tags:\n      - lifecycle\n      - active\n      - core_segment\n\n  high_value:\n    expression: \"total_spent &gt; 10000\"\n    tags:\n      - segmentation\n      - revenue\n      - vip\n</code></pre></p>"},{"location":"semantic-layer/yaml-reference/#66-meta-optional","title":"6.6 <code>meta</code> (Optional)","text":"<p>Purpose: Free-form metadata dictionary</p> <p>Format: - Dictionary (key-value pairs) - Any keys allowed</p> <p>Examples: <pre><code>segments:\n  active_users:\n    expression: \"status = 'active'\"\n    meta:\n      business_owner: \"Product Team\"\n      use_cases: [\"dashboard\", \"reporting\", \"alerts\"]\n      last_reviewed: \"2024-01-15\"\n</code></pre></p> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/yaml-reference/#7-joins","title":"7. Joins","text":""},{"location":"semantic-layer/yaml-reference/#71-join-structure","title":"7.1 Join Structure","text":"<p>Joins connect semantic models for cross-model analysis:</p> <pre><code>joins:\n  &lt;target_model_alias&gt;:            # REQUIRED (dictionary key)\n    type: &lt;type&gt;                   # REQUIRED (one_to_one, one_to_many, many_to_one)\n    expression: \"&lt;JOIN_CONDITION&gt;\"  # REQUIRED\n    description: \"...\"             # Optional\n    meta: {...}                   # Optional: Dictionary\n</code></pre>"},{"location":"semantic-layer/yaml-reference/#72-name-required","title":"7.2 <code>name</code> (Required)","text":"<p>Purpose: Semantic alias of the target model to join</p> <p>Format: - Must be a semantic model alias (not physical name) - Must exist in <code>models:</code> array - Case-sensitive</p> <p>Examples: <pre><code># In customers model\njoins:\n  orders:                     # Join to orders semantic model\n    type: one_to_many\n    expression: \"customers.customer_id = orders.customer_id\"\n\n# In orders model\njoins:\n  customers:                 # Join to customers semantic model\n    type: many_to_one\n    expression: \"orders.customer_id = customers.customer_id\"\n</code></pre></p> <p>Validation: - Target model alias must exist - Cannot reference non-existent models - Cannot create circular dependencies (see Join Graph)</p> <p>Error examples: <pre><code># \u274c Target model doesn't exist\njoins:\n  non_existent_model:\n    type: one_to_many\n    expression: \"...\"\n\n# \u274c Using physical name instead of alias\njoins:\n  analytics.customers:  # Should be 'customers' (alias)\n    type: one_to_many\n    expression: \"...\"\n</code></pre></p>"},{"location":"semantic-layer/yaml-reference/#73-relationship-required","title":"7.3 <code>relationship</code> (Required)","text":"<p>Purpose: Defines the cardinality of the join relationship</p> <p>Format: - String value from predefined list - Case-sensitive</p> <p>Valid values: - <code>one_to_one</code> - One row matches one row (1:1) - <code>one_to_many</code> - One row matches many rows (1:N) - <code>many_to_one</code> - Many rows match one row (N:1)</p> <p>Examples: <pre><code># Customer \u2192 Orders (one customer has many orders)\njoins:\n  orders:\n    type: one_to_many\n    expression: \"customers.customer_id = orders.customer_id\"\n\n# Orders \u2192 Customer (many orders belong to one customer)\njoins:\n  customers:\n    type: many_to_one\n    expression: \"orders.customer_id = customers.customer_id\"\n\n# User \u2192 Profile (one user has one profile)\njoins:\n  user_profile:\n    type: one_to_one\n    expression: \"users.user_id = user_profile.user_id\"\n</code></pre></p> <p>Choosing relationship type: - <code>one_to_many</code>: Current model is \"one\" side (e.g., customer \u2192 orders) - <code>many_to_one</code>: Current model is \"many\" side (e.g., orders \u2192 customer)</p> <p>Note: The field name is <code>type:</code> not <code>relationship:</code> in the YAML definition. - <code>one_to_one</code>: Both sides are unique (e.g., user \u2192 profile)</p> <p>Note: Relationship type is informational - actual join behavior depends on SQL engine</p>"},{"location":"semantic-layer/yaml-reference/#74-expression-required","title":"7.4 <code>expression</code> (Required)","text":"<p>Purpose: SQL join condition</p> <p>Format: - Valid SQL join condition - Must use <code>model.column</code> format for all references - Both models must be specified</p> <p>Examples: <pre><code># Simple join\njoins:\n  orders:\n    type: one_to_many\n    expression: \"customers.customer_id = orders.customer_id\"\n\n# Multi-column join\njoins:\n  product_locations:\n    type: many_to_one\n    expression: |\n      inventory.product_id = product_locations.product_id\n      AND inventory.warehouse_id = product_locations.warehouse_id\n\n# Join with additional conditions\njoins:\n  active_orders:\n    type: one_to_many\n    expression: |\n      customers.customer_id = orders.customer_id\n      AND orders.status = 'active'\n</code></pre></p> <p>What can be referenced: - \u2705 Current model columns: <code>customers.customer_id</code> - \u2705 Target model columns: <code>orders.customer_id</code> - \u274c Unqualified columns: <code>customer_id</code> (must use <code>model.column</code>) - \u274c Other models: <code>third_model.field</code> (not allowed)</p> <p>Validation: - All column references must use <code>model.column</code> format - Model name must be either current model or join target - Both columns must exist in their respective SQL models - Expression must be valid SQL join condition</p> <p>Error examples: <pre><code># \u274c Unqualified column\njoins:\n  orders:\n    type: one_to_many\n    expression: \"customer_id = orders.customer_id\"  # Missing model prefix\n\n# \u274c Column doesn't exist\njoins:\n  orders:\n    type: one_to_many\n    expression: \"customers.non_existent_col = orders.customer_id\"\n</code></pre></p>"},{"location":"semantic-layer/yaml-reference/#75-join-graph-consistency","title":"7.5 Join Graph Consistency","text":"<p>Purpose: Ensures joins form a valid, non-cyclic graph</p> <p>Rules: - Join graph must not contain circular dependencies - Joins must allow system to determine join paths between models - All models referenced in metrics must be reachable via joins</p> <p>Example of valid join graph: <pre><code>customers \u2190\u2192 orders \u2190\u2192 products\n     \u2193\nsubscriptions\n</code></pre></p> <p>Example of invalid join graph (circular): <pre><code>customers \u2192 orders \u2192 products \u2192 customers  # Circular!\n</code></pre></p> <p>Validation: - System checks for cycles during semantic layer load - Errors indicate which models form a cycle - Fix by removing or restructuring joins</p>"},{"location":"semantic-layer/yaml-reference/#76-description-optional","title":"7.6 <code>description</code> (Optional)","text":"<p>Purpose: Human-readable description of the join</p> <p>Format: - String (single or multi-line)</p> <p>Examples: <pre><code>joins:\n  orders:\n    type: one_to_many\n    expression: \"customers.customer_id = orders.customer_id\"\n    description: \"Customer's orders relationship\"\n</code></pre></p>"},{"location":"semantic-layer/yaml-reference/#77-meta-optional","title":"7.7 <code>meta</code> (Optional)","text":"<p>Purpose: Free-form metadata dictionary</p> <p>Format: - Dictionary (key-value pairs)</p> <p>Examples: <pre><code>joins:\n  orders:\n    type: one_to_many\n    expression: \"customers.customer_id = orders.customer_id\"\n    meta:\n      join_type: \"INNER\"\n      performance_note: \"Indexed on customer_id\"\n</code></pre></p> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/yaml-reference/#8-business-metrics","title":"8. Business Metrics","text":""},{"location":"semantic-layer/yaml-reference/#81-metric-structure","title":"8.1 Metric Structure","text":"<p>Metrics combine measures, time dimensions, and grouping dimensions:</p> <pre><code>metrics:\n  &lt;metric_name&gt;:                 # REQUIRED: Dictionary key\n    measure: &lt;model&gt;.&lt;measure&gt;   # REQUIRED\n    time: &lt;model&gt;.&lt;column&gt;       # REQUIRED\n    dimensions: [...]            # Optional: Array of dimension references\n    description: \"...\"           # Optional\n    tags: [...]                  # Optional: Array of strings\n    meta: {...}                  # Optional: Dictionary\n</code></pre>"},{"location":"semantic-layer/yaml-reference/#82-metric-name-required","title":"8.2 Metric Name (Required)","text":"<p>Purpose: Unique identifier for the metric</p> <p>Format: - Dictionary key (not a field) - Must follow identifier rules (see Naming Rules) - Letters, digits, underscores only - Starts with letter - Max 64 characters - Must be unique across all semantic files</p> <p>Examples: <pre><code>metrics:\n  monthly_revenue: ...\n  customer_growth: ...\n  daily_active_users: ...\n  conversion_rate_by_channel: ...\n</code></pre></p> <p>Validation: - Must be unique across all files - Cannot conflict with other metric names</p>"},{"location":"semantic-layer/yaml-reference/#83-measure-required","title":"8.3 <code>measure</code> (Required)","text":"<p>Purpose: Reference to a measure to aggregate</p> <p>Format: - Must be in <code>model.measure</code> format (exactly one dot) - Model must be semantic alias (not physical name) - Measure must exist on target model</p> <p>Examples: <pre><code>metrics:\n  monthly_revenue:\n    measure: orders.total_revenue\n    time: orders.order_date\n\n  customer_growth:\n    measure: customers.total_customers\n    time: customers.signup_date\n</code></pre></p> <p>Validation: - Must use <code>model.measure</code> format - Model alias must exist - Measure must exist on target model - Model must be reachable via joins (if multiple models in metric)</p> <p>Error examples: <pre><code># \u274c Missing model prefix\nmetrics:\n  monthly_revenue:\n    measure: total_revenue  # Should be 'orders.total_revenue'\n\n# \u274c Measure doesn't exist\nmetrics:\n  monthly_revenue:\n    measure: orders.non_existent_measure\n</code></pre></p>"},{"location":"semantic-layer/yaml-reference/#84-time-required","title":"8.4 <code>time</code> (Required)","text":"<p>Purpose: Reference to a time column for time-series aggregation</p> <p>Format: - Must be in <code>model.column</code> format (exactly one dot) - Model must be semantic alias (not physical name) - Column must exist and be timestamp/datetime type</p> <p>Examples: <pre><code>metrics:\n  monthly_revenue:\n    measure: orders.total_revenue\n    time: orders.order_date\n\n  daily_signups:\n    measure: customers.new_signups\n    time: customers.signup_date\n</code></pre></p> <p>Validation: - Must use <code>model.column</code> format - Model alias must exist - Column must exist on target model - Column must be timestamp/datetime type (not DATE, TIME, or INTERVAL) - Cannot be the same field as measure (if measure references same model)</p> <p>Error examples: <pre><code># \u274c Wrong column type\nmetrics:\n  daily_revenue:\n    measure: orders.total_revenue\n    time: orders.status  # Not a timestamp column\n\n# \u274c Column doesn't exist\nmetrics:\n  daily_revenue:\n    measure: orders.total_revenue\n    time: orders.non_existent_date\n</code></pre></p>"},{"location":"semantic-layer/yaml-reference/#85-dimensions-optional","title":"8.5 <code>dimensions</code> (Optional)","text":"<p>Purpose: List of dimensions to group by</p> <p>Format: - Array of dimension references - Each reference must be in <code>model.field</code> format - Can reference columns, dimensions, or dimension proxies</p> <p>Examples: <pre><code>metrics:\n  monthly_revenue_by_tier:\n    measure: orders.total_revenue\n    time: orders.order_date\n    dimensions:\n      - customers.customer_tier\n      - customers.region\n\n  daily_signups_by_channel:\n    measure: customers.new_signups\n    time: customers.signup_date\n    dimensions:\n      - customers.signup_channel\n      - customers.customer_tier\n</code></pre></p> <p>Cross-model dimensions: <pre><code>metrics:\n  revenue_by_product_category:\n    measure: orders.total_revenue\n    time: orders.order_date\n    dimensions:\n      - customers.customer_tier    # From joined model\n      - products.category           # From joined model\n      - orders.status               # From measure's model\n</code></pre></p> <p>Validation: - All references must use <code>model.field</code> format - Referenced models must exist - Referenced fields must exist (columns, dimensions, or proxies) - All models must be connected via joins (if multiple models) - No duplicate dimensions in list</p> <p>Error examples: <pre><code># \u274c Duplicate dimension\nmetrics:\n  monthly_revenue:\n    measure: orders.total_revenue\n    time: orders.order_date\n    dimensions:\n      - customers.customer_tier\n      - customers.customer_tier  # Duplicate!\n\n# \u274c Models not connected\nmetrics:\n  revenue_by_product:\n    measure: orders.total_revenue\n    time: orders.order_date\n    dimensions:\n      - products.category  # No join path from orders to products\n</code></pre></p>"},{"location":"semantic-layer/yaml-reference/#86-description-optional","title":"8.6 <code>description</code> (Optional)","text":"<p>Purpose: Human-readable description of the metric</p> <p>Format: - String (single or multi-line)</p> <p>Examples: <pre><code>metrics:\n  monthly_revenue:\n    measure: orders.total_revenue\n    time: orders.order_date\n    dimensions:\n      - customers.customer_tier\n    description: \"Monthly revenue trends by customer tier\"\n</code></pre></p>"},{"location":"semantic-layer/yaml-reference/#87-tags-optional","title":"8.7 <code>tags</code> (Optional)","text":"<p>Purpose: Categorize metrics for discovery</p> <p>Format: - Array of strings</p> <p>Examples: <pre><code>metrics:\n  monthly_revenue:\n    measure: orders.total_revenue\n    time: orders.order_date\n    tags:\n      - revenue\n      - financial\n      - kpi\n      - time_series\n</code></pre></p>"},{"location":"semantic-layer/yaml-reference/#88-meta-optional","title":"8.8 <code>meta</code> (Optional)","text":"<p>Purpose: Free-form metadata dictionary</p> <p>Format: - Dictionary (key-value pairs)</p> <p>Examples: <pre><code>metrics:\n  monthly_revenue:\n    measure: orders.total_revenue\n    time: orders.order_date\n    meta:\n      business_owner: \"Finance Team\"\n      certified: true\n      kpi_target: 1000000\n      update_frequency: \"daily\"\n</code></pre></p> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/yaml-reference/#9-naming-and-validation-rules","title":"9. Naming and Validation Rules","text":""},{"location":"semantic-layer/yaml-reference/#91-identifier-format-rules","title":"9.1 Identifier Format Rules","text":"<p>The following semantic identifiers must follow the same naming rules:</p> <ul> <li>Semantic model aliases (<code>alias</code>)</li> <li>Measure names</li> <li>Segment names</li> <li>Join names (target model aliases)</li> <li>Metric names</li> <li>Dimension proxy names</li> <li>Dimension override names</li> </ul> <p>Rules: - Must not be empty - Must start with a letter (<code>A\u2013Z</code> or <code>a\u2013z</code>) - After the first character, may contain only:   - Letters (<code>A\u2013Z</code>, <code>a\u2013z</code>)   - Digits (<code>0\u20139</code>)   - Underscores (<code>_</code>) - Maximum length: 64 characters - Case-sensitive</p> <p>Valid examples: <pre><code># \u2705 Valid names\n- name: total_revenue\n- name: customer_count_30d\n- name: avg_order_value\n- name: monthly_revenue_by_tier\n\n# \u274c Invalid names\n- name: \"total-revenue\"      # Hyphens not allowed\n- name: \"123revenue\"         # Cannot start with digit\n- name: \"total revenue\"      # Spaces not allowed\n- name: \"total.revenue\"      # Dots not allowed (except in references)\n</code></pre></p>"},{"location":"semantic-layer/yaml-reference/#92-uniqueness-rules","title":"9.2 Uniqueness Rules","text":"<p>Within a semantic model: - Measure names must be unique - Segment names must be unique - Dimension proxy names must be unique - Dimension override names must be unique - No semantic field name should be reused across measures, segments, and dimension proxies</p> <p>Across semantic files: - Metric names must be unique across all files - Model aliases must be unique across all files</p> <p>Error examples: <pre><code># \u274c Duplicate measure name\nmeasures:\n  total_revenue:\n    type: sum\n  total_revenue:  # Duplicate! (same key twice)\n    type: sum\n\n# \u274c Measure and segment with same name\nmeasures:\n  active_users:\n    type: count\nsegments:\n  active_users:  # Conflicts with measure name\n    expression: \"...\"\n\n# \u274c Duplicate metric name across files\n# In file1.yml:\nmetrics:\n  monthly_revenue: ...\n\n# In file2.yml:\nmetrics:\n  monthly_revenue: ...  # Duplicate!\n</code></pre></p>"},{"location":"semantic-layer/yaml-reference/#93-reference-format-rules","title":"9.3 Reference Format Rules","text":"<p>Model references: - Always use semantic alias (not physical name) - Format: <code>model_alias.field_name</code> - Exactly one dot required</p> <p>Examples: <pre><code># \u2705 Correct references\nmeasure: orders.total_revenue\ntime: orders.order_date\ndimensions:\n  - customers.customer_tier\n\n# \u274c Incorrect references\nmeasure: analytics.orders.total_revenue  # Too many dots\nmeasure: total_revenue                   # Missing model prefix\ntime: analytics.orders.order_date        # Using physical name\n</code></pre></p>"},{"location":"semantic-layer/yaml-reference/#94-column-existence-rules","title":"9.4 Column Existence Rules","text":"<p>Columns referenced in: - <code>dimensions.includes</code> - Must exist in physical model - <code>dimensions.excludes</code> - Must exist in physical model - <code>dimensions.overrides[].name</code> - Must exist (after includes/excludes) - <code>segments[].expression</code> - Must exist in current model - <code>joins[].expression</code> - Must exist in source/target models - <code>metrics[].time</code> - Must exist and be timestamp/datetime type</p> <p>Validation: - All column references are validated against physical models - Errors indicate which column is missing - Case-sensitive matching</p> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/yaml-reference/#10-yaml-formatting-best-practices","title":"10. YAML Formatting Best Practices","text":""},{"location":"semantic-layer/yaml-reference/#101-multi-line-expressions","title":"10.1 Multi-line Expressions","text":"<p>Use <code>|</code> for multi-line SQL:</p> <pre><code># \u2705 Good: Multi-line expression\nexpression: |\n  SUM(CASE \n    WHEN status = 'active' \n    THEN amount \n    ELSE 0 \n  END)\n\n# \u2705 Good: Single-line expression\nexpression: \"SUM(amount)\"\n\n# \u274c Bad: Inconsistent formatting\nexpression: \"SUM(CASE WHEN status = 'active' THEN amount ELSE 0 END)\"\n</code></pre>"},{"location":"semantic-layer/yaml-reference/#102-arrays","title":"10.2 Arrays","text":"<p>One per line (preferred for readability):</p> <pre><code># \u2705 Good: One per line\ntags:\n  - revenue\n  - financial\n  - kpi\n\n# \u2705 Also OK: Inline for short lists\ntags: [revenue, financial, kpi]\n\n# \u274c Bad: Inconsistent\ntags: [revenue,\n  financial, kpi]\n</code></pre>"},{"location":"semantic-layer/yaml-reference/#103-indentation","title":"10.3 Indentation","text":"<p>Use 2 spaces per level:</p> <pre><code>models:\n  analytics.customers:\n    alias: customers\n    measures:\n      total_customers:\n        type: count\n        expression: \"COUNT(*)\"\n        filters:\n          - \"status = 'active'\"\n</code></pre> <p>Common indentation errors: <pre><code># \u274c Bad: Tabs instead of spaces\nmodels:\n    customers:  # Tab character\n      alias: customers\n\n# \u274c Bad: Inconsistent spacing\nmodels:\n  analytics.customers:\n     alias: users  # 3 spaces instead of 2\n</code></pre></p>"},{"location":"semantic-layer/yaml-reference/#104-string-quoting","title":"10.4 String Quoting","text":"<p>When to quote: - Strings with special characters: <code>\"status = 'active'\"</code> - Strings starting with numbers: <code>\"30_day_count\"</code> - Strings with colons: <code>\"format: currency\"</code></p> <p>When not to quote: - Simple identifiers: <code>name: total_revenue</code> - Simple values: <code>format: currency</code></p> <p>Examples: <pre><code># \u2705 Good: Quote filter expressions\nfilters:\n  - \"status = 'active'\"\n  - \"signup_date &gt;= CURRENT_DATE - INTERVAL '30 days'\"\n\n# \u2705 Good: No quotes for simple names\nname: total_revenue\nformat: currency\n\n# \u274c Bad: Missing quotes for expressions with special chars\nfilters:\n  - status = 'active'  # Should be quoted\n</code></pre></p>"},{"location":"semantic-layer/yaml-reference/#105-comments","title":"10.5 Comments","text":"<p>Use <code>#</code> for comments:</p> <pre><code>models:\n  analytics.customers:\n    alias: customers\n\n    # Hide sensitive columns\n    dimensions:\n      excludes:\n        - password_hash\n        - ssn\n\n    # Core revenue metrics\n    measures:\n      total_revenue:\n        type: sum\n        expression: \"SUM(amount)\"\n</code></pre> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/yaml-reference/#11-quick-reference","title":"11. Quick Reference","text":""},{"location":"semantic-layer/yaml-reference/#111-component-quick-reference","title":"11.1 Component Quick Reference","text":"Component Required Fields Optional Fields Model <code>name</code> <code>alias</code> (req for FQN), <code>description</code>, <code>dimensions</code>, <code>measures</code>, <code>segments</code>, <code>joins</code> Dimension Selection One of: <code>includes</code> OR <code>excludes</code> <code>overrides</code>, <code>proxies</code> Dimension Override <code>name</code> <code>tags</code>, <code>meta</code> Dimension Proxy <code>name</code>, <code>measure</code> - Measure <code>name</code>, <code>expression</code> <code>description</code>, <code>filters</code>, <code>format</code>, <code>tags</code>, <code>meta</code> Segment <code>name</code>, <code>expression</code> <code>description</code>, <code>tags</code>, <code>meta</code> Join <code>name</code>, <code>relationship</code>, <code>expression</code> <code>description</code>, <code>meta</code> Metric <code>measure</code>, <code>time</code> <code>dimensions</code>, <code>description</code>, <code>tags</code>, <code>meta</code>"},{"location":"semantic-layer/yaml-reference/#112-reference-format-quick-reference","title":"11.2 Reference Format Quick Reference","text":"Context Format Example Measure reference <code>model.measure</code> <code>orders.total_revenue</code> Time reference <code>model.column</code> <code>orders.order_date</code> Dimension reference <code>model.field</code> <code>customers.customer_tier</code> Dimension proxy in segment <code>{proxy_name}</code> <code>{order_count_dim}</code> Join expression <code>model.column</code> <code>customers.customer_id = orders.customer_id</code>"},{"location":"semantic-layer/yaml-reference/#113-relationship-types-quick-reference","title":"11.3 Relationship Types Quick Reference","text":"Type Description Example <code>one_to_one</code> One row matches one row User \u2194 Profile <code>one_to_many</code> One row matches many rows Customer \u2192 Orders <code>many_to_one</code> Many rows match one row Orders \u2192 Customer"},{"location":"semantic-layer/yaml-reference/#114-format-types-quick-reference","title":"11.4 Format Types Quick Reference","text":"Format Description Example <code>currency</code> Monetary values $1,234.56 <code>percentage</code> Percentages 12.5% <code>number</code> Numeric values 1,234.56 <code>duration_ms</code> Time duration 1,500 ms <code>bytes</code> Byte sizes 1.5 MB <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/yaml-reference/#12-complete-examples","title":"12. Complete Examples","text":""},{"location":"semantic-layer/yaml-reference/#121-minimal-example","title":"12.1 Minimal Example","text":"<pre><code>models:\n  analytics.customers:\n    alias: customers\n</code></pre> <p>Result: - All columns from <code>analytics.customers</code> model are available as dimensions - No measures, segments, or joins defined</p>"},{"location":"semantic-layer/yaml-reference/#122-complete-example","title":"12.2 Complete Example","text":"<pre><code>models:\n  analytics.dim_customers:\n    alias: customers\n    description: \"Customer dimension table\"\n\n    dimensions:\n      excludes:\n        - password_hash\n        - internal_notes\n\n      overrides:\n        customer_tier:\n          tags: [segmentation, revenue]\n          meta:\n            business_owner: \"Product Team\"\n            sort_order: [\"Free\", \"Pro\", \"Enterprise\"]\n\n      proxies:\n        order_count_dim:\n          measure: orders.total_orders\n\n    measures:\n      total_customers:\n        type: count\n        expression: \"COUNT(*)\"\n        description: \"Total number of customers\"\n        tags: [count, core_metric]\n\n      active_customers:\n        type: count\n        expression: \"COUNT(*)\"\n        filters:\n          - \"status = 'active'\"\n        description: \"Customers with active status\"\n        tags: [count, active]\n\n    segments:\n      high_value:\n        expression: \"total_spent &gt; 10000\"\n        description: \"Customers with &gt;$10K lifetime spend\"\n        tags: [segmentation, revenue]\n\n      has_orders:\n        expression: \"{order_count_dim} &gt; 0\"\n        description: \"Customers with at least one order\"\n        tags: [behavior]\n\n    joins:\n      orders:\n        type: one_to_many\n        expression: \"customers.customer_id = orders.customer_id\"\n        description: \"Customer's orders\"\n\n  analytics.fact_orders:\n    alias: orders\n\n    measures:\n      total_revenue:\n        type: sum\n        expression: \"SUM(amount)\"\n        format: currency\n        description: \"Total order revenue\"\n        tags: [revenue, financial, kpi]\n\n      completed_revenue:\n        type: sum\n        expression: \"SUM(amount)\"\n        filters:\n          - \"status = 'completed'\"\n        format: currency\n        description: \"Revenue from completed orders\"\n        tags: [revenue, completed]\n\n    joins:\n      customers:\n        type: many_to_one\n        expression: \"orders.customer_id = customers.customer_id\"\n\nmetrics:\n  monthly_revenue:\n    measure: orders.total_revenue\n    time: orders.order_date\n    dimensions:\n      - customers.customer_tier\n      - customers.region\n    description: \"Monthly revenue by tier and region\"\n    tags: [revenue, financial, time_series]\n    meta:\n      business_owner: \"Finance Team\"\n      certified: true\n\n  customer_growth:\n    measure: customers.total_customers\n    time: customers.signup_date\n    dimensions:\n      - customers.signup_channel\n      - customers.customer_tier\n    description: \"Customer acquisition trends\"\n    tags: [growth, acquisition]\n</code></pre>"},{"location":"semantic-layer/yaml-reference/#123-cross-model-example","title":"12.3 Cross-Model Example","text":"<pre><code>models:\n  analytics.orders:\n    alias: orders\n\n    measures:\n      total_revenue:\n        type: sum\n        expression: \"SUM(amount)\"\n        filters:\n          - \"customers.country = 'US'\"  # Cross-model filter\n          - \"products.category = 'Electronics'\"  # Cross-model filter\n\n    joins:\n      customers:\n        type: many_to_one\n        expression: \"orders.customer_id = customers.customer_id\"\n\n      products:\n        type: many_to_many\n        expression: \"orders.order_id = order_items.order_id AND order_items.product_id = products.product_id\"\n\nmetrics:\n  us_electronics_revenue:\n    measure: orders.total_revenue\n    time: orders.order_date\n    dimensions:\n      - customers.customer_tier\n      - products.brand\n    description: \"US electronics revenue by tier and brand\"\n</code></pre> <p>\u2191 Back to Top</p>"},{"location":"semantic-layer/yaml-reference/#summary","title":"Summary","text":"<p>This reference covers every field, option, and pattern in semantic layer YAML files. Use it as your definitive guide when:</p> <ul> <li>Writing semantic layer definitions</li> <li>Debugging validation errors</li> <li>Understanding field requirements</li> <li>Finding syntax examples</li> </ul> <p>Key takeaways: - All model references use semantic aliases (not physical names) - Reference format is always <code>model.field</code> (exactly one dot) - Dimensions default to all columns (use excludes/includes to control) - Segments can only reference current model columns - Measures can reference joined models via <code>model.field</code> syntax - Metrics combine measures, time, and dimensions across models</p> <p>Next steps: - Chapter 3B: Advanced Measures - Complex measure patterns - Chapter 3C: Advanced Joins - Cross-model analysis patterns - Chapter 3D: Validation - Complete validation rules</p> <p>\u2191 Back to Top</p>"}]}